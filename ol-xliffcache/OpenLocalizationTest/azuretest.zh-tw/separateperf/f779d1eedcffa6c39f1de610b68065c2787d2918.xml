{
  "nodes": [
    {
      "content": "About the A8, A9, A10, and A11 instances | Microsoft Azure",
      "pos": [
        24,
        82
      ]
    },
    {
      "content": "Get background information and considerations for using the Azure A8, A9, A10, and A11 compute-intensive instances.",
      "pos": [
        98,
        213
      ]
    },
    {
      "content": "About the A8, A9, A10, and A11 compute-intensive instances",
      "pos": [
        520,
        578
      ]
    },
    {
      "content": "This article provides background information and considerations for using the Azure A8, A9, A10, and A11 instances, also known as <bpt id=\"p1\">*</bpt>compute-intensive<ept id=\"p1\">*</ept> instances.",
      "pos": [
        580,
        740
      ]
    },
    {
      "content": "Key features of these instances include:",
      "pos": [
        741,
        781
      ]
    },
    {
      "pos": [
        785,
        1048
      ],
      "content": "<bpt id=\"p1\">**</bpt>High-performance hardware<ept id=\"p1\">**</ept> – The Azure datacenter hardware that runs these instances is designed and optimized for compute-intensive and network-intensive applications, including high-performance computing (HPC) cluster applications, modeling, and simulations."
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>RDMA network connection for MPI applications<ept id=\"p1\">**</ept> – When configured with the necessary network drivers, the A8 and A9 instances can communicate with other A8 and A9 instances over a low-latency, high-throughput network in Azure that is based on remote direct memory access (RDMA) technology.",
      "pos": [
        1052,
        1342
      ]
    },
    {
      "content": "This feature can boost the performance of applications that use supported Linux or Windows Message Passing Interface (MPI) implementations.",
      "pos": [
        1343,
        1482
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Support for Linux and Windows HPC clusters<ept id=\"p1\">**</ept> – Deploy cluster management and job scheduling software on the A8, A9, A10, and A11 instances in Azure to create a stand-alone HPC cluster or to add capacity to an on-premises cluster.",
      "pos": [
        1486,
        1717
      ]
    },
    {
      "content": "Like other Azure VM sizes, the A8, A9, A10, and A11 instances support standard or custom Windows Server and Linux operating system images or Azure Resource Manager templates in Azure VMs (IaaS), or Azure Guest OS releases in cloud services (PaaS, for Windows Server only).",
      "pos": [
        1718,
        1990
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>A10 and A11 instances have the same performance optimizations and specifications as the A8 and A9 instances.",
      "pos": [
        1993,
        2113
      ]
    },
    {
      "content": "However, they do not include access to the RDMA network in Azure.",
      "pos": [
        2114,
        2179
      ]
    },
    {
      "content": "They are designed for HPC applications that do not require constant and low-latency communication between nodes, also known as parametric or embarrassingly parallel applications.",
      "pos": [
        2180,
        2358
      ]
    },
    {
      "content": "And for running workloads other than MPI applications, the A8 and A9 instances do not access the RDMA network and are functionally equivalent to the A10 and A11 instances.",
      "pos": [
        2359,
        2530
      ]
    },
    {
      "content": "Specs",
      "pos": [
        2536,
        2541
      ]
    },
    {
      "content": "CPU and memory",
      "pos": [
        2547,
        2561
      ]
    },
    {
      "content": "The Azure A8, A9, A10, and A11 compute-intensive instances feature high-speed, multicore CPUs and large amounts of memory, as shown in the following table.",
      "pos": [
        2563,
        2718
      ]
    },
    {
      "content": "Size",
      "pos": [
        2720,
        2724
      ]
    },
    {
      "content": "CPU",
      "pos": [
        2727,
        2730
      ]
    },
    {
      "content": "Memory",
      "pos": [
        2733,
        2739
      ]
    },
    {
      "content": "A8 and A10",
      "pos": [
        2787,
        2797
      ]
    },
    {
      "content": "Intel Xeon E5-2670",
      "pos": [
        2800,
        2818
      ]
    },
    {
      "content": "8 cores @ 2.6 GHz",
      "pos": [
        2823,
        2840
      ]
    },
    {
      "content": "DDR3-1600 MHz",
      "pos": [
        2843,
        2856
      ]
    },
    {
      "content": "56 GB",
      "pos": [
        2861,
        2866
      ]
    },
    {
      "content": "A9 and A11",
      "pos": [
        2867,
        2877
      ]
    },
    {
      "content": "Intel Xeon E5-2670",
      "pos": [
        2880,
        2898
      ]
    },
    {
      "content": "16 cores @ 2.6 GHz",
      "pos": [
        2903,
        2921
      ]
    },
    {
      "content": "DDR3-1600 MHz",
      "pos": [
        2924,
        2937
      ]
    },
    {
      "content": "112 GB",
      "pos": [
        2942,
        2948
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>Additional processor details, including supported instruction set extensions, are at the Intel.com website.",
      "pos": [
        2952,
        3071
      ]
    },
    {
      "content": "For VM storage capacities and disk details, see <bpt id=\"p1\">[</bpt>Sizes for virtual machines<ept id=\"p1\">](virtual-machines-size-specs.md)</ept>.",
      "pos": [
        3072,
        3181
      ]
    },
    {
      "content": "Network adapters",
      "pos": [
        3187,
        3203
      ]
    },
    {
      "content": "A8 and A9 instances have two network adapters, which connect to the following two back-end Azure networks.",
      "pos": [
        3205,
        3311
      ]
    },
    {
      "content": "Network",
      "pos": [
        3314,
        3321
      ]
    },
    {
      "content": "Description",
      "pos": [
        3324,
        3335
      ]
    },
    {
      "content": "10-Gbps Ethernet",
      "pos": [
        3359,
        3375
      ]
    },
    {
      "content": "Connects to Azure services (such as Azure Storage and Azure Virtual Network) and to the Internet.",
      "pos": [
        3378,
        3475
      ]
    },
    {
      "content": "32-Gbps back end, RDMA capable",
      "pos": [
        3476,
        3506
      ]
    },
    {
      "content": "Enables low-latency, high-throughput application communication between instances within a single cloud service or availability set.",
      "pos": [
        3509,
        3640
      ]
    },
    {
      "content": "Reserved for MPI traffic only.",
      "pos": [
        3641,
        3671
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph>On A8 and A9 VMs running Linux in IaaS, access to the RDMA network is currently enabled only through applications that use Azure Linux RDMA and Intel MPI Library 5.0 on SUSE Linux Enterprise Server 12 (SLES 12).",
      "pos": [
        3675,
        3903
      ]
    },
    {
      "content": "On A8 and A9 instances running Windows Server in IaaS or PaaS, access to the RDMA network is currently enabled only through applications that use the Microsoft Network Direct interface.",
      "pos": [
        3904,
        4089
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Access to the RDMA network<ept id=\"p1\">](#access-the-rdma-network)</ept> in this article for additional requirements.",
      "pos": [
        4090,
        4193
      ]
    },
    {
      "content": "A10 and A11 instances have a single, 10-Gbps Ethernet network adapter that connects to Azure services and the Internet.",
      "pos": [
        4195,
        4314
      ]
    },
    {
      "content": "Considerations for the Azure subscription",
      "pos": [
        4319,
        4360
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Azure account<ept id=\"p1\">**</ept> – If you want to deploy more than a small number of compute-intensive instances, consider a pay-as-you-go subscription or other purchase options.",
      "pos": [
        4364,
        4527
      ]
    },
    {
      "content": "You can also use your MSDN subscription.",
      "pos": [
        4528,
        4568
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Azure benefit for MSDN subscribers<ept id=\"p1\">](http://azure.microsoft.com/pricing/member-offers/msdn-benefits-details/)</ept>.",
      "pos": [
        4569,
        4683
      ]
    },
    {
      "content": "If you're using an <bpt id=\"p1\">[</bpt>Azure free trial<ept id=\"p1\">](http://azure.microsoft.com/pricing/free-trial/)</ept>, you can use only a limited number of Azure compute cores.",
      "pos": [
        4684,
        4828
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Cores quota<ept id=\"p1\">**</ept> – You might need to increase the cores quota in your Azure subscription from the default of 20 cores, which is not enough for many scenarios with 8-core or 16-core instances.",
      "pos": [
        4832,
        5022
      ]
    },
    {
      "content": "For initial tests, you might consider requesting a quota increase to 100 cores.",
      "pos": [
        5023,
        5102
      ]
    },
    {
      "content": "To do this, open a free support ticket as shown in <bpt id=\"p1\">[</bpt>Understanding Azure limits and increases<ept id=\"p1\">](http://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/)</ept>.",
      "pos": [
        5103,
        5280
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>Azure quotas are credit limits, not capacity guarantees.",
      "pos": [
        5283,
        5351
      ]
    },
    {
      "content": "You are charged only for cores that you use.",
      "pos": [
        5352,
        5396
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Affinity group<ept id=\"p1\">**</ept> – Currently, an affinity group is not recommended for most new deployments.",
      "pos": [
        5400,
        5494
      ]
    },
    {
      "content": "However, note that if you're using an affinity group that contains instances of sizes other than A8–A11, you won't be able to use it for the A8–A11 instances, and vice versa.",
      "pos": [
        5495,
        5669
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Virtual network<ept id=\"p1\">**</ept> – An Azure virtual network is not required to use the compute-intensive instances.",
      "pos": [
        5673,
        5775
      ]
    },
    {
      "content": "However, you may need at least a cloud-based Azure virtual network for many IaaS scenarios, or a site-to-site connection if you need to access on-premises resources such as an application license server.",
      "pos": [
        5776,
        5979
      ]
    },
    {
      "content": "You will need to create a new (regional) virtual network before deploying the instances.",
      "pos": [
        5980,
        6068
      ]
    },
    {
      "content": "Adding an A8, A9, A10, or A11 VM to a virtual network in an affinity group is not supported.",
      "pos": [
        6069,
        6161
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>How to create a virtual network (VNet)<ept id=\"p1\">](../virtual-network/virtual-networks-create-vnet.md)</ept> and <bpt id=\"p2\">[</bpt>Configure a virtual network with a site-to-site VPN connection<ept id=\"p2\">](../vpn-gateway/vpn-gateway-site-to-site-create.md)</ept>.",
      "pos": [
        6162,
        6401
      ]
    },
    {
      "pos": [
        6405,
        6777
      ],
      "content": "<bpt id=\"p1\">**</bpt>Cloud service or availability set<ept id=\"p1\">**</ept> – To connect through the RDMA network, the A8 and A9 instances must be deployed in the same cloud service (for IaaS scenarios with Linux-based VMs or Windows-based VMs in Azure Service Management, or PaaS scenarios with Windows Server) or the same availability set (for Linux-based VMs or Windows-based VMs in Azure Resource Manager)."
    },
    {
      "content": "Considerations for using HPC Pack",
      "pos": [
        6782,
        6815
      ]
    },
    {
      "content": "Considerations for HPC Pack and Linux",
      "pos": [
        6821,
        6858
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>HPC Pack<ept id=\"p1\">](https://technet.microsoft.com/library/jj899572.aspx)</ept> is Microsoft’s free HPC cluster and job management solution for Windows.",
      "pos": [
        6860,
        6996
      ]
    },
    {
      "content": "Starting with HPC Pack 2012 R2 Update 2, HPC Pack supports several Linux distributions to run on compute nodes deployed in Azure VMs, managed by a Windows Server head node.",
      "pos": [
        6997,
        7169
      ]
    },
    {
      "content": "With the latest release of HPC Pack, you can deploy a Linux-based cluster that can run MPI applications that access the RDMA network in Azure.",
      "pos": [
        7170,
        7312
      ]
    },
    {
      "content": "For more information, see the <bpt id=\"p1\">[</bpt>HPC Pack documentation<ept id=\"p1\">](http://go.microsoft.com/fwlink/?LinkId=617894)</ept>.",
      "pos": [
        7313,
        7415
      ]
    },
    {
      "content": "Considerations for HPC Pack and Windows",
      "pos": [
        7421,
        7460
      ]
    },
    {
      "content": "HPC Pack is not required for you to use the A8, A9, A10, and A11 instances with Windows Server, but it is a recommended tool to create Windows HPC Server–based clusters in Azure.",
      "pos": [
        7462,
        7640
      ]
    },
    {
      "content": "In the case of A8 and A9 instances, HPC Pack is the most efficient way to run Windows-based MPI applications that access the RDMA network in Azure.",
      "pos": [
        7641,
        7788
      ]
    },
    {
      "content": "HPC Pack includes a runtime environment for the Microsoft implementation of the Message Passing Interface for Windows.",
      "pos": [
        7789,
        7907
      ]
    },
    {
      "pos": [
        7909,
        8182
      ],
      "content": "For more information and checklists to deploy and use the compute-intensive instances in IaaS and PaaS scenarios with HPC Pack on Windows Server, see <bpt id=\"p1\">[</bpt>A8 and A9 compute intensive instances: Quick start with HPC Pack<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn594431.aspx)</ept>."
    },
    {
      "content": "Access to the RDMA network",
      "pos": [
        8187,
        8213
      ]
    },
    {
      "content": "Access from Linux A8 and A9 VMs",
      "pos": [
        8219,
        8250
      ]
    },
    {
      "content": "Within a single cloud service or an availability set, the A8 and A9 instances can access the RDMA network in Azure for running MPI applications that use the Linux RDMA drivers to communicate between instances.",
      "pos": [
        8252,
        8461
      ]
    },
    {
      "content": "At this time, Azure Linux RDMA is supported only with <bpt id=\"p1\">[</bpt>Intel MPI Library 5.0<ept id=\"p1\">](https://software.intel.com/en-us/intel-mpi-library/)</ept>.",
      "pos": [
        8462,
        8593
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Currently, Azure Linux RDMA drivers are not available for installation via driver extensions.",
      "pos": [
        8596,
        8702
      ]
    },
    {
      "content": "They are available only by using the RDMA-enabled SLES 12 image from the Azure Marketplace.",
      "pos": [
        8703,
        8794
      ]
    },
    {
      "content": "See the following table for prerequisites for Linux MPI applications to access the RDMA network in clusters of compute nodes (IaaS).",
      "pos": [
        8796,
        8928
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Set up a Linux RDMA cluster to run MPI applications<ept id=\"p1\">](virtual-machines-linux-cluster-rdma.md)</ept> for deployment options and configuration steps.",
      "pos": [
        8929,
        9074
      ]
    },
    {
      "content": "Prerequisite",
      "pos": [
        9076,
        9088
      ]
    },
    {
      "content": "Virtual machines (IaaS)",
      "pos": [
        9091,
        9114
      ]
    },
    {
      "content": "Operating system",
      "pos": [
        9144,
        9160
      ]
    },
    {
      "content": "SLES 12 HPC image from the Azure Marketplace",
      "pos": [
        9163,
        9207
      ]
    },
    {
      "content": "MPI",
      "pos": [
        9208,
        9211
      ]
    },
    {
      "content": "Intel MPI Library 5.0",
      "pos": [
        9214,
        9235
      ]
    },
    {
      "content": "Access from Windows A8 and A9 instances",
      "pos": [
        9241,
        9280
      ]
    },
    {
      "content": "Within a single cloud service or availability set, the A8 and A9 instances can access the RDMA network in Azure for running MPI applications that use the Microsoft Network Direct interface to communicate between instances.",
      "pos": [
        9282,
        9504
      ]
    },
    {
      "content": "The A10 and A11 instances do not include access to the RDMA network.",
      "pos": [
        9505,
        9573
      ]
    },
    {
      "content": "See the following table for prerequisites for MPI applications to access the RDMA network in virtual machine (IaaS) and cloud service (PaaS) deployments of the A8 or A9 instances.",
      "pos": [
        9575,
        9754
      ]
    },
    {
      "content": "For typical deployment scenarios, see <bpt id=\"p1\">[</bpt>A8 and A9 compute intensive instances: Quick start with HPC Pack<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn594431.aspx)</ept>.",
      "pos": [
        9755,
        9916
      ]
    },
    {
      "content": "Prerequisite",
      "pos": [
        9919,
        9931
      ]
    },
    {
      "content": "Virtual machines (IaaS)",
      "pos": [
        9934,
        9957
      ]
    },
    {
      "content": "Cloud services (PaaS)",
      "pos": [
        9960,
        9981
      ]
    },
    {
      "content": "Operating system",
      "pos": [
        10024,
        10040
      ]
    },
    {
      "content": "Windows Server 2012 R2 or Windows Server 2012",
      "pos": [
        10043,
        10088
      ]
    },
    {
      "content": "Windows Server 2012 R2, Windows Server 2012, or Windows Server 2008 R2 Guest OS family",
      "pos": [
        10091,
        10177
      ]
    },
    {
      "content": "MPI",
      "pos": [
        10178,
        10181
      ]
    },
    {
      "content": "MS-MPI 2012 R2 or later, either stand-alone or installed via HPC Pack 2012 R2 or later",
      "pos": [
        10184,
        10270
      ]
    },
    {
      "content": "Intel MPI Library 5.0",
      "pos": [
        10280,
        10301
      ]
    },
    {
      "content": "MS-MPI 2012 R2 or later, installed via HPC Pack 2012 R2 or later",
      "pos": [
        10304,
        10368
      ]
    },
    {
      "content": "Intel MPI Library 5.0",
      "pos": [
        10378,
        10399
      ]
    },
    {
      "pos": [
        10403,
        10610
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>For IaaS scenarios, the <bpt id=\"p1\">[</bpt>HpcVmDrivers extension<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn690126.aspx)</ept> must be added to the VMs to install Windows drivers that are needed for RDMA connectivity."
    },
    {
      "content": "Additional things to know",
      "pos": [
        10616,
        10641
      ]
    },
    {
      "content": "The A8–A11 VM sizes are available only in the Standard pricing tier.",
      "pos": [
        10645,
        10713
      ]
    },
    {
      "content": "You can't resize an existing Azure VM to the A8, A9, A10, or A11 size.",
      "pos": [
        10717,
        10787
      ]
    },
    {
      "content": "A8, A9, A10, and A11 instances can't currently be deployed by using a cloud service that is part of an existing affinity group.",
      "pos": [
        10791,
        10918
      ]
    },
    {
      "content": "Likewise, an affinity group with a cloud service that contains A8, A9, A10, and A11 instances can't be used for deployments of other instance sizes.",
      "pos": [
        10919,
        11067
      ]
    },
    {
      "content": "If you attempt these deployments, you will see an error message similar to <ph id=\"ph1\">`Azure deployment failure (Compute.OverconstrainedAllocationRequest): The VM size (or combination of VM sizes) required by this deployment cannot be provisioned due to deployment request constraints.`</ph>",
      "pos": [
        11068,
        11343
      ]
    },
    {
      "content": "The RDMA network in Azure reserves the address space 172.16.0.0/12.",
      "pos": [
        11347,
        11414
      ]
    },
    {
      "content": "If you plan to run MPI applications on A8 and A9 instances that are deployed in an Azure virtual network, make sure that the virtual network address space does not overlap the RDMA network.",
      "pos": [
        11415,
        11604
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        11609,
        11619
      ]
    },
    {
      "pos": [
        11623,
        11888
      ],
      "content": "For details about availability and pricing of the A8, A9, A10, and  A11 instances, see <bpt id=\"p1\">[</bpt>Virtual Machines pricing<ept id=\"p1\">](http://azure.microsoft.com/pricing/details/virtual-machines/)</ept> and <bpt id=\"p2\">[</bpt>Cloud Services pricing<ept id=\"p2\">](http://azure.microsoft.com/pricing/details/cloud-services/)</ept>."
    },
    {
      "pos": [
        11891,
        12094
      ],
      "content": "To deploy and configure a Linux-based cluster with A8 and A9 instances to access the Azure RDMA network, see <bpt id=\"p1\">[</bpt>Set up a Linux RDMA cluster to run MPI applications<ept id=\"p1\">](virtual-machines-linux-cluster-rdma.md)</ept>."
    },
    {
      "pos": [
        12097,
        12411
      ],
      "content": "To get started deploying and using A8 and A9 instances with HPC Pack on Windows, see <bpt id=\"p1\">[</bpt>A8 and A9 compute intensive instances: Quick start with HPC Pack<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn594431.aspx)</ept> and <bpt id=\"p2\">[</bpt>Run MPI applications on A8 and A9 instances<ept id=\"p2\">](https://msdn.microsoft.com/library/azure/dn592104.aspx)</ept>."
    }
  ],
  "content": "<properties\n pageTitle=\"About the A8, A9, A10, and A11 instances | Microsoft Azure\"\n description=\"Get background information and considerations for using the Azure A8, A9, A10, and A11 compute-intensive instances.\"\n services=\"virtual-machines, cloud-services\"\n documentationCenter=\"\"\n authors=\"dlepow\"\n manager=\"timlt\"\n editor=\"\"/>\n<tags\nms.service=\"virtual-machines\"\n ms.devlang=\"na\"\n ms.topic=\"article\"\n ms.tgt_pltfrm=\"vm-multiple\"\n ms.workload=\"infrastructure-services\"\n ms.date=\"07/22/2015\"\n ms.author=\"danlep\"/>\n\n# About the A8, A9, A10, and A11 compute-intensive instances\n\nThis article provides background information and considerations for using the Azure A8, A9, A10, and A11 instances, also known as *compute-intensive* instances. Key features of these instances include:\n\n* **High-performance hardware** – The Azure datacenter hardware that runs these instances is designed and optimized for compute-intensive and network-intensive applications, including high-performance computing (HPC) cluster applications, modeling, and simulations.\n\n* **RDMA network connection for MPI applications** – When configured with the necessary network drivers, the A8 and A9 instances can communicate with other A8 and A9 instances over a low-latency, high-throughput network in Azure that is based on remote direct memory access (RDMA) technology. This feature can boost the performance of applications that use supported Linux or Windows Message Passing Interface (MPI) implementations.\n\n* **Support for Linux and Windows HPC clusters** – Deploy cluster management and job scheduling software on the A8, A9, A10, and A11 instances in Azure to create a stand-alone HPC cluster or to add capacity to an on-premises cluster. Like other Azure VM sizes, the A8, A9, A10, and A11 instances support standard or custom Windows Server and Linux operating system images or Azure Resource Manager templates in Azure VMs (IaaS), or Azure Guest OS releases in cloud services (PaaS, for Windows Server only).\n\n>[AZURE.NOTE]A10 and A11 instances have the same performance optimizations and specifications as the A8 and A9 instances. However, they do not include access to the RDMA network in Azure. They are designed for HPC applications that do not require constant and low-latency communication between nodes, also known as parametric or embarrassingly parallel applications. And for running workloads other than MPI applications, the A8 and A9 instances do not access the RDMA network and are functionally equivalent to the A10 and A11 instances.\n\n\n## Specs\n\n### CPU and memory\n\nThe Azure A8, A9, A10, and A11 compute-intensive instances feature high-speed, multicore CPUs and large amounts of memory, as shown in the following table.\n\nSize | CPU | Memory\n------------- | ----------- | ----------------\nA8 and A10 | Intel Xeon E5-2670<br/>8 cores @ 2.6 GHz | DDR3-1600 MHz<br/>56 GB\nA9 and A11 | Intel Xeon E5-2670<br/>16 cores @ 2.6 GHz | DDR3-1600 MHz<br/>112 GB\n\n\n>[AZURE.NOTE]Additional processor details, including supported instruction set extensions, are at the Intel.com website. For VM storage capacities and disk details, see [Sizes for virtual machines](virtual-machines-size-specs.md).\n\n### Network adapters\n\nA8 and A9 instances have two network adapters, which connect to the following two back-end Azure networks.\n\n\nNetwork | Description\n-------- | -----------\n10-Gbps Ethernet | Connects to Azure services (such as Azure Storage and Azure Virtual Network) and to the Internet.\n32-Gbps back end, RDMA capable | Enables low-latency, high-throughput application communication between instances within a single cloud service or availability set. Reserved for MPI traffic only.\n\n\n>[AZURE.IMPORTANT]On A8 and A9 VMs running Linux in IaaS, access to the RDMA network is currently enabled only through applications that use Azure Linux RDMA and Intel MPI Library 5.0 on SUSE Linux Enterprise Server 12 (SLES 12). On A8 and A9 instances running Windows Server in IaaS or PaaS, access to the RDMA network is currently enabled only through applications that use the Microsoft Network Direct interface. See [Access to the RDMA network](#access-the-rdma-network) in this article for additional requirements.\n\nA10 and A11 instances have a single, 10-Gbps Ethernet network adapter that connects to Azure services and the Internet.\n\n## Considerations for the Azure subscription\n\n* **Azure account** – If you want to deploy more than a small number of compute-intensive instances, consider a pay-as-you-go subscription or other purchase options. You can also use your MSDN subscription. See [Azure benefit for MSDN subscribers](http://azure.microsoft.com/pricing/member-offers/msdn-benefits-details/). If you're using an [Azure free trial](http://azure.microsoft.com/pricing/free-trial/), you can use only a limited number of Azure compute cores.\n\n* **Cores quota** – You might need to increase the cores quota in your Azure subscription from the default of 20 cores, which is not enough for many scenarios with 8-core or 16-core instances. For initial tests, you might consider requesting a quota increase to 100 cores. To do this, open a free support ticket as shown in [Understanding Azure limits and increases](http://azure.microsoft.com/blog/2014/06/04/azure-limits-quotas-increase-requests/).\n\n>[AZURE.NOTE]Azure quotas are credit limits, not capacity guarantees. You are charged only for cores that you use.\n\n* **Affinity group** – Currently, an affinity group is not recommended for most new deployments. However, note that if you're using an affinity group that contains instances of sizes other than A8–A11, you won't be able to use it for the A8–A11 instances, and vice versa.\n\n* **Virtual network** – An Azure virtual network is not required to use the compute-intensive instances. However, you may need at least a cloud-based Azure virtual network for many IaaS scenarios, or a site-to-site connection if you need to access on-premises resources such as an application license server. You will need to create a new (regional) virtual network before deploying the instances. Adding an A8, A9, A10, or A11 VM to a virtual network in an affinity group is not supported. For more information, see [How to create a virtual network (VNet)](../virtual-network/virtual-networks-create-vnet.md) and [Configure a virtual network with a site-to-site VPN connection](../vpn-gateway/vpn-gateway-site-to-site-create.md).\n\n* **Cloud service or availability set** – To connect through the RDMA network, the A8 and A9 instances must be deployed in the same cloud service (for IaaS scenarios with Linux-based VMs or Windows-based VMs in Azure Service Management, or PaaS scenarios with Windows Server) or the same availability set (for Linux-based VMs or Windows-based VMs in Azure Resource Manager).\n\n## Considerations for using HPC Pack\n\n### Considerations for HPC Pack and Linux\n\n[HPC Pack](https://technet.microsoft.com/library/jj899572.aspx) is Microsoft’s free HPC cluster and job management solution for Windows. Starting with HPC Pack 2012 R2 Update 2, HPC Pack supports several Linux distributions to run on compute nodes deployed in Azure VMs, managed by a Windows Server head node. With the latest release of HPC Pack, you can deploy a Linux-based cluster that can run MPI applications that access the RDMA network in Azure. For more information, see the [HPC Pack documentation](http://go.microsoft.com/fwlink/?LinkId=617894).\n\n### Considerations for HPC Pack and Windows\n\nHPC Pack is not required for you to use the A8, A9, A10, and A11 instances with Windows Server, but it is a recommended tool to create Windows HPC Server–based clusters in Azure. In the case of A8 and A9 instances, HPC Pack is the most efficient way to run Windows-based MPI applications that access the RDMA network in Azure. HPC Pack includes a runtime environment for the Microsoft implementation of the Message Passing Interface for Windows.\n\nFor more information and checklists to deploy and use the compute-intensive instances in IaaS and PaaS scenarios with HPC Pack on Windows Server, see [A8 and A9 compute intensive instances: Quick start with HPC Pack](https://msdn.microsoft.com/library/azure/dn594431.aspx).\n\n## Access to the RDMA network\n\n### Access from Linux A8 and A9 VMs\n\nWithin a single cloud service or an availability set, the A8 and A9 instances can access the RDMA network in Azure for running MPI applications that use the Linux RDMA drivers to communicate between instances. At this time, Azure Linux RDMA is supported only with [Intel MPI Library 5.0](https://software.intel.com/en-us/intel-mpi-library/).\n\n>[AZURE.NOTE] Currently, Azure Linux RDMA drivers are not available for installation via driver extensions. They are available only by using the RDMA-enabled SLES 12 image from the Azure Marketplace.\n\nSee the following table for prerequisites for Linux MPI applications to access the RDMA network in clusters of compute nodes (IaaS). See [Set up a Linux RDMA cluster to run MPI applications](virtual-machines-linux-cluster-rdma.md) for deployment options and configuration steps.\n\nPrerequisite | Virtual machines (IaaS)\n------------ | -------------\nOperating system | SLES 12 HPC image from the Azure Marketplace\nMPI | Intel MPI Library 5.0\n\n### Access from Windows A8 and A9 instances\n\nWithin a single cloud service or availability set, the A8 and A9 instances can access the RDMA network in Azure for running MPI applications that use the Microsoft Network Direct interface to communicate between instances. The A10 and A11 instances do not include access to the RDMA network.\n\nSee the following table for prerequisites for MPI applications to access the RDMA network in virtual machine (IaaS) and cloud service (PaaS) deployments of the A8 or A9 instances. For typical deployment scenarios, see [A8 and A9 compute intensive instances: Quick start with HPC Pack](https://msdn.microsoft.com/library/azure/dn594431.aspx).\n\n\nPrerequisite | Virtual machines (IaaS) | Cloud services (PaaS)\n---------- | ------------ | -------------\nOperating system | Windows Server 2012 R2 or Windows Server 2012 | Windows Server 2012 R2, Windows Server 2012, or Windows Server 2008 R2 Guest OS family\nMPI | MS-MPI 2012 R2 or later, either stand-alone or installed via HPC Pack 2012 R2 or later<br/><br/>Intel MPI Library 5.0 | MS-MPI 2012 R2 or later, installed via HPC Pack 2012 R2 or later<br/><br/>Intel MPI Library 5.0\n\n\n>[AZURE.NOTE]For IaaS scenarios, the [HpcVmDrivers extension](https://msdn.microsoft.com/library/azure/dn690126.aspx) must be added to the VMs to install Windows drivers that are needed for RDMA connectivity.\n\n\n## Additional things to know\n\n* The A8–A11 VM sizes are available only in the Standard pricing tier.\n\n* You can't resize an existing Azure VM to the A8, A9, A10, or A11 size.\n\n* A8, A9, A10, and A11 instances can't currently be deployed by using a cloud service that is part of an existing affinity group. Likewise, an affinity group with a cloud service that contains A8, A9, A10, and A11 instances can't be used for deployments of other instance sizes. If you attempt these deployments, you will see an error message similar to `Azure deployment failure (Compute.OverconstrainedAllocationRequest): The VM size (or combination of VM sizes) required by this deployment cannot be provisioned due to deployment request constraints.`\n\n* The RDMA network in Azure reserves the address space 172.16.0.0/12. If you plan to run MPI applications on A8 and A9 instances that are deployed in an Azure virtual network, make sure that the virtual network address space does not overlap the RDMA network.\n\n## Next steps\n\n* For details about availability and pricing of the A8, A9, A10, and  A11 instances, see [Virtual Machines pricing](http://azure.microsoft.com/pricing/details/virtual-machines/) and [Cloud Services pricing](http://azure.microsoft.com/pricing/details/cloud-services/).\n* To deploy and configure a Linux-based cluster with A8 and A9 instances to access the Azure RDMA network, see [Set up a Linux RDMA cluster to run MPI applications](virtual-machines-linux-cluster-rdma.md).\n* To get started deploying and using A8 and A9 instances with HPC Pack on Windows, see [A8 and A9 compute intensive instances: Quick start with HPC Pack](https://msdn.microsoft.com/library/azure/dn594431.aspx) and [Run MPI applications on A8 and A9 instances](https://msdn.microsoft.com/library/azure/dn592104.aspx).\n"
}