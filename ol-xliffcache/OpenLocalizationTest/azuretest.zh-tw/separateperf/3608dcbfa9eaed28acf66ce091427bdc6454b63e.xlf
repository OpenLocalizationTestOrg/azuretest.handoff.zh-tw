<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Upload data for Hadoop jobs in HDInsight | Microsoft Azure</source>
          <target state="new">Upload data for Hadoop jobs in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to upload and access data for Hadoop jobs in HDInsight using the Azure CLI, Azure Storage Explorer, Azure PowerShell, the Hadoop command line, or Sqoop.</source>
          <target state="new">Learn how to upload and access data for Hadoop jobs in HDInsight using the Azure CLI, Azure Storage Explorer, Azure PowerShell, the Hadoop command line, or Sqoop.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Upload data for Hadoop jobs in HDInsight</source>
          <target state="new">Upload data for Hadoop jobs in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Azure HDInsight provides a full-featured Hadoop distributed file system (HDFS) over Azure Blob storage.</source>
          <target state="new">Azure HDInsight provides a full-featured Hadoop distributed file system (HDFS) over Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>It is designed as an HDFS extension to provide a seamless experience to customers.</source>
          <target state="new">It is designed as an HDFS extension to provide a seamless experience to customers.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>It enables the full set of components in the Hadoop ecosystem to operate directly on the data it manages.</source>
          <target state="new">It enables the full set of components in the Hadoop ecosystem to operate directly on the data it manages.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Azure Blob storage and HDFS are distinct file systems that are optimized for storage of data and computations on that data.</source>
          <target state="new">Azure Blob storage and HDFS are distinct file systems that are optimized for storage of data and computations on that data.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>For information about the benefits of using Azure Blob storage, see <bpt id="p1">[</bpt>Use Azure Blob storage with HDInsight<ept id="p1">][hdinsight-storage]</ept>.</source>
          <target state="new">For information about the benefits of using Azure Blob storage, see <bpt id="p1">[</bpt>Use Azure Blob storage with HDInsight<ept id="p1">][hdinsight-storage]</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Note the following requirement before you begin:</source>
          <target state="new">Note the following requirement before you begin:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>An Azure HDInsight cluster.</source>
          <target state="new">An Azure HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Get started with Azure HDInsight<ept id="p1">][hdinsight-get-started]</ept> or <bpt id="p2">[</bpt>Provision HDInsight clusters<ept id="p2">][hdinsight-provision]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Get started with Azure HDInsight<ept id="p1">][hdinsight-get-started]</ept> or <bpt id="p2">[</bpt>Provision HDInsight clusters<ept id="p2">][hdinsight-provision]</ept>.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Why blob storage?</source>
          <target state="new">Why blob storage?</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Azure HDInsight clusters are typically deployed to run MapReduce jobs, and the clusters are dropped after these jobs complete.</source>
          <target state="new">Azure HDInsight clusters are typically deployed to run MapReduce jobs, and the clusters are dropped after these jobs complete.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Keeping the data in the HDFS clusters after computations are complete would be an expensive way to store this data.</source>
          <target state="new">Keeping the data in the HDFS clusters after computations are complete would be an expensive way to store this data.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Azure Blob storage is a highly available, highly scalable, high capacity, low cost, and shareable storage option for data that is to be processed using HDInsight.</source>
          <target state="new">Azure Blob storage is a highly available, highly scalable, high capacity, low cost, and shareable storage option for data that is to be processed using HDInsight.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Storing data in a blob enables the HDInsight clusters that are used for computation to be safely released without losing data.</source>
          <target state="new">Storing data in a blob enables the HDInsight clusters that are used for computation to be safely released without losing data.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Directories</source>
          <target state="new">Directories</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Azure Blob storage containers store data as key/value pairs, and there is no directory hierarchy.</source>
          <target state="new">Azure Blob storage containers store data as key/value pairs, and there is no directory hierarchy.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>However the "/" character can be used within the key name to make it appear as if a file is stored within a directory structure.</source>
          <target state="new">However the "/" character can be used within the key name to make it appear as if a file is stored within a directory structure.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>HDInsight sees these as if they are actual directories.</source>
          <target state="new">HDInsight sees these as if they are actual directories.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>For example, a blob's key may be <bpt id="p1">*</bpt>input/log1.txt<ept id="p1">*</ept>.</source>
          <target state="new">For example, a blob's key may be <bpt id="p1">*</bpt>input/log1.txt<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>No actual "input" directory exists, but due to the presence of the "/" character in the key name, it has the appearance of a file path.</source>
          <target state="new">No actual "input" directory exists, but due to the presence of the "/" character in the key name, it has the appearance of a file path.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Because of this, if you use Azure Explorer tools you may notice some 0 byte files.</source>
          <target state="new">Because of this, if you use Azure Explorer tools you may notice some 0 byte files.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>These files serve two purposes:</source>
          <target state="new">These files serve two purposes:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>If there are empty folders, they mark of the existence of the folder.</source>
          <target state="new">If there are empty folders, they mark of the existence of the folder.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Azure Blob storage is clever enough to know that if a blob called foo/bar exists, there is a folder called <bpt id="p1">**</bpt>foo<ept id="p1">**</ept>.</source>
          <target state="new">Azure Blob storage is clever enough to know that if a blob called foo/bar exists, there is a folder called <bpt id="p1">**</bpt>foo<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>But the only way to signify an empty folder called <bpt id="p1">**</bpt>foo<ept id="p1">**</ept> is by having this special 0 byte file in place.</source>
          <target state="new">But the only way to signify an empty folder called <bpt id="p1">**</bpt>foo<ept id="p1">**</ept> is by having this special 0 byte file in place.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>They hold special metadata that is needed by the Hadoop file system, notably the permissions and owners for the folders.</source>
          <target state="new">They hold special metadata that is needed by the Hadoop file system, notably the permissions and owners for the folders.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Command-line utilities</source>
          <target state="new">Command-line utilities</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Microsoft provides the following utilities to work with Azure Blob storage:</source>
          <target state="new">Microsoft provides the following utilities to work with Azure Blob storage:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Tool</source>
          <target state="new">Tool</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Linux</source>
          <target state="new">Linux</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>OS X</source>
          <target state="new">OS X</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Azure Command-Line Interface</source>
          <target state="new">Azure Command-Line Interface</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Azure PowerShell</source>
          <target state="new">Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>AzCopy</source>
          <target state="new">AzCopy</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Hadoop command</source>
          <target state="new">Hadoop command</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> While the Azure CLI, Azure PowerShell, and AzCopy can all be used from outside Azure, the Hadoop command is only available on the HDInsight cluster and only allows loading data from the local file system into Azure Blob storage.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> While the Azure CLI, Azure PowerShell, and AzCopy can all be used from outside Azure, the Hadoop command is only available on the HDInsight cluster and only allows loading data from the local file system into Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="xplatcli"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure CLI</source>
          <target state="new"><ph id="ph1">&lt;a id="xplatcli"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure CLI</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The Azure CLI is a cross-platform tool that allows you to manage Azure services.</source>
          <target state="new">The Azure CLI is a cross-platform tool that allows you to manage Azure services.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Use the following steps to upload data to Azure Blob storage:</source>
          <target state="new">Use the following steps to upload data to Azure Blob storage:</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Install and configure the Azure CLI for Mac, Linux and Windows<ept id="p1">](../xplat-cli.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Install and configure the Azure CLI for Mac, Linux and Windows<ept id="p1">](../xplat-cli.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Open a command prompt, bash, or other shell, and use the following to authenticate to your Azure subscription.</source>
          <target state="new">Open a command prompt, bash, or other shell, and use the following to authenticate to your Azure subscription.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>When prompted, enter the user name and password for your subscription.</source>
          <target state="new">When prompted, enter the user name and password for your subscription.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Enter the following command to list the storage accounts for your subscription:</source>
          <target state="new">Enter the following command to list the storage accounts for your subscription:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Select the storage account that contains the blob you want to work with, then use the following command to retrieve the key for this account:</source>
          <target state="new">Select the storage account that contains the blob you want to work with, then use the following command to retrieve the key for this account:</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>This should return <bpt id="p1">**</bpt>Primary<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Secondary<ept id="p2">**</ept> keys.</source>
          <target state="new">This should return <bpt id="p1">**</bpt>Primary<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Secondary<ept id="p2">**</ept> keys.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Copy the <bpt id="p1">**</bpt>Primary<ept id="p1">**</ept> key value because it will be used in the next steps.</source>
          <target state="new">Copy the <bpt id="p1">**</bpt>Primary<ept id="p1">**</ept> key value because it will be used in the next steps.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Use the following command to retrieve a list of blob containers within the storage account:</source>
          <target state="new">Use the following command to retrieve a list of blob containers within the storage account:</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Use the following commands to upload and download files to the blob:</source>
          <target state="new">Use the following commands to upload and download files to the blob:</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>To upload a file:</source>
          <target state="new">To upload a file:</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>To download a file:</source>
          <target state="new">To download a file:</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you will always be working with the same storage account, you can set the following environment variables instead of specifying the account and key for every command:</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you will always be working with the same storage account, you can set the following environment variables instead of specifying the account and key for every command:</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept>: The storage account name</source>
          <target state="new"><bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept>: The storage account name</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p1">**</ept>: The storage account key</source>
          <target state="new"><bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p1">**</ept>: The storage account key</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="powershell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure PowerShell</source>
          <target state="new"><ph id="ph1">&lt;a id="powershell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Azure PowerShell is a scripting environment that you can use to control and automate the deployment and management of your workloads in Azure.</source>
          <target state="new">Azure PowerShell is a scripting environment that you can use to control and automate the deployment and management of your workloads in Azure.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>For information about configuring your workstation to run Azure PowerShell, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept>.</source>
          <target state="new">For information about configuring your workstation to run Azure PowerShell, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>To upload a local file to Azure Blob storage</source>
          <target state="new">To upload a local file to Azure Blob storage</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Open the Azure PowerShell console as instructed in <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept>.</source>
          <target state="new">Open the Azure PowerShell console as instructed in <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Set the values of the first five variables in the following script:</source>
          <target state="new">Set the values of the first five variables in the following script:</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Paste the script into the Azure PowerShell console to run it to copy the file.</source>
          <target state="new">Paste the script into the Azure PowerShell console to run it to copy the file.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>For example PowerShell scripts created to work with HDInsight, see <bpt id="p1">[</bpt>HDInsight tools<ept id="p1">](https://github.com/blackmist/hdinsight-tools)</ept>.</source>
          <target state="new">For example PowerShell scripts created to work with HDInsight, see <bpt id="p1">[</bpt>HDInsight tools<ept id="p1">](https://github.com/blackmist/hdinsight-tools)</ept>.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="azcopy"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>AzCopy</source>
          <target state="new"><ph id="ph1">&lt;a id="azcopy"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>AzCopy</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>AzCopy is a command-line tool that is designed to simplify the task of transferring data into and out of an Azure Storage account.</source>
          <target state="new">AzCopy is a command-line tool that is designed to simplify the task of transferring data into and out of an Azure Storage account.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>You can use it as a standalone tool or incorporate this tool in an existing application.</source>
          <target state="new">You can use it as a standalone tool or incorporate this tool in an existing application.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Download AzCopy<ept id="p1">][azure-azcopy-download]</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Download AzCopy<ept id="p1">][azure-azcopy-download]</ept>.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The AzCopy syntax is:</source>
          <target state="new">The AzCopy syntax is:</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>AzCopy - Uploading/Downloading files for Azure Blobs<ept id="p1">][azure-azcopy]</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>AzCopy - Uploading/Downloading files for Azure Blobs<ept id="p1">][azure-azcopy]</ept>.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="commandline"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Hadoop command line</source>
          <target state="new"><ph id="ph1">&lt;a id="commandline"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Hadoop command line</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>The Hadoop command line is only useful for storing data into blob storage when the data is already present on the cluster head node.</source>
          <target state="new">The Hadoop command line is only useful for storing data into blob storage when the data is already present on the cluster head node.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>In order to use the Hadoop command, you must first connect to the headnode using one of the following methods:</source>
          <target state="new">In order to use the Hadoop command, you must first connect to the headnode using one of the following methods:</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Windows-based HDInsight<ept id="p1">**</ept>: <bpt id="p2">[</bpt>Connect using Remote Desktop<ept id="p2">](hdinsight-administer-use-management-portal.md#connect-to-hdinsight-clusters-by-using-rdp)</ept></source>
          <target state="new"><bpt id="p1">**</bpt>Windows-based HDInsight<ept id="p1">**</ept>: <bpt id="p2">[</bpt>Connect using Remote Desktop<ept id="p2">](hdinsight-administer-use-management-portal.md#connect-to-hdinsight-clusters-by-using-rdp)</ept></target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Linux-based HDInsight<ept id="p1">**</ept>: Connect using SSH (<bpt id="p2">[</bpt>the SSH command<ept id="p2">](hdinsight-hadoop-linux-use-ssh-unix.md#connect-to-a-linux-based-hdinsight-cluster)</ept> or <bpt id="p3">[</bpt>PuTTY<ept id="p3">](hdinsight-hadoop-linux-use-ssh-windows.md#connect-to-a-linux-based-hdinsight-cluster)</ept>)</source>
          <target state="new"><bpt id="p1">**</bpt>Linux-based HDInsight<ept id="p1">**</ept>: Connect using SSH (<bpt id="p2">[</bpt>the SSH command<ept id="p2">](hdinsight-hadoop-linux-use-ssh-unix.md#connect-to-a-linux-based-hdinsight-cluster)</ept> or <bpt id="p3">[</bpt>PuTTY<ept id="p3">](hdinsight-hadoop-linux-use-ssh-windows.md#connect-to-a-linux-based-hdinsight-cluster)</ept>)</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Once connected, you can use the following syntax to upload a file to storage.</source>
          <target state="new">Once connected, you can use the following syntax to upload a file to storage.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph1">`hadoop fs -copyFromLocal data.txt /example/data/data.txt`</ph></source>
          <target state="new">For example, <ph id="ph1">`hadoop fs -copyFromLocal data.txt /example/data/data.txt`</ph></target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Because the default file system for HDInsight is in Azure Blob storage, /example/data.txt is actually in Azure Blob storage.</source>
          <target state="new">Because the default file system for HDInsight is in Azure Blob storage, /example/data.txt is actually in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>You can also refer to the file as:</source>
          <target state="new">You can also refer to the file as:</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>or</source>
          <target state="new">or</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>For a list of other Hadoop commands that work with files, see <bpt id="p1">[</bpt>http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/FileSystemShell.html<ept id="p1">](http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/FileSystemShell.html)</ept></source>
          <target state="new">For a list of other Hadoop commands that work with files, see <bpt id="p1">[</bpt>http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/FileSystemShell.html<ept id="p1">](http://hadoop.apache.org/docs/r2.7.0/hadoop-project-dist/hadoop-common/FileSystemShell.html)</ept></target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Graphical clients</source>
          <target state="new">Graphical clients</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>There are also several applications that provide a graphical interface for working with Azure Storage.</source>
          <target state="new">There are also several applications that provide a graphical interface for working with Azure Storage.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>The following is a list of a few of these applications:</source>
          <target state="new">The following is a list of a few of these applications:</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Client</source>
          <target state="new">Client</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Linux</source>
          <target state="new">Linux</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>OS X</source>
          <target state="new">OS X</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Azure Storage Explorer</source>
          <target state="new">Azure Storage Explorer</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Cloud Storage Studio 2</source>
          <target state="new">Cloud Storage Studio 2</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>CloudXplorer</source>
          <target state="new">CloudXplorer</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Azure Explorer</source>
          <target state="new">Azure Explorer</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Zudio</source>
          <target state="new">Zudio</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Cyberduck</source>
          <target state="new">Cyberduck</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>✔</source>
          <target state="new">✔</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="storageexplorer"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure Storage Explorer</source>
          <target state="new"><ph id="ph1">&lt;a id="storageexplorer"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Azure Storage Explorer</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>Azure Storage Explorer<ept id="p1">*</ept> is a useful tool for inspecting and altering the data in Azure Storage.</source>
          <target state="new"><bpt id="p1">*</bpt>Azure Storage Explorer<ept id="p1">*</ept> is a useful tool for inspecting and altering the data in Azure Storage.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>It is a free tool that can be downloaded from CodePlex: <bpt id="p1">[</bpt>Azure Storage Explorer<ept id="p1">]</ept><bpt id="p2">(http://azurestorageexplorer.codeplex.com/ "</bpt>Azure Storage Explorer<ept id="p2">")</ept>.</source>
          <target state="new">It is a free tool that can be downloaded from CodePlex: <bpt id="p1">[</bpt>Azure Storage Explorer<ept id="p1">]</ept><bpt id="p2">(http://azurestorageexplorer.codeplex.com/ "</bpt>Azure Storage Explorer<ept id="p2">")</ept>.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Before using the tool, you must know your Azure storage account name and account key.</source>
          <target state="new">Before using the tool, you must know your Azure storage account name and account key.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>For instructions about getting this information, see the "How to: View, copy and regenerate storage access keys" section of <bpt id="p1">[</bpt>Create, manage, or delete a storage account<ept id="p1">][azure-create-storage-account]</ept>.</source>
          <target state="new">For instructions about getting this information, see the "How to: View, copy and regenerate storage access keys" section of <bpt id="p1">[</bpt>Create, manage, or delete a storage account<ept id="p1">][azure-create-storage-account]</ept>.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Run Azure Storage Explorer.</source>
          <target state="new">Run Azure Storage Explorer.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>HDI.AzureStorageExplorer</source>
          <target state="new">HDI.AzureStorageExplorer</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Add Account<ept id="p1">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Add Account<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>After an account is added to Azure Storage Explorer, you don't need to go through this step again.</source>
          <target state="new">After an account is added to Azure Storage Explorer, you don't need to go through this step again.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>HDI.ASEAddAccount</source>
          <target state="new">HDI.ASEAddAccount</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>Enter your <bpt id="p1">**</bpt>Storage account name<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Storage account key<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Add Storage Account<ept id="p3">**</ept>.</source>
          <target state="new">Enter your <bpt id="p1">**</bpt>Storage account name<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Storage account key<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Add Storage Account<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>You can add multiple storage accounts, and each account will be displayed on a tab.</source>
          <target state="new">You can add multiple storage accounts, and each account will be displayed on a tab.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Under <bpt id="p1">**</bpt>Storage Type<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Blobs<ept id="p2">**</ept>.</source>
          <target state="new">Under <bpt id="p1">**</bpt>Storage Type<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Blobs<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>HDI.ASEBlob</source>
          <target state="new">HDI.ASEBlob</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Under <bpt id="p1">**</bpt>Container<ept id="p1">**</ept>, click the name of the container that is associated with your HDInsight cluster.</source>
          <target state="new">Under <bpt id="p1">**</bpt>Container<ept id="p1">**</ept>, click the name of the container that is associated with your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>When you create an HDInsight cluster, you must specify a container.</source>
          <target state="new">When you create an HDInsight cluster, you must specify a container.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Otherwise, the cluster creation process creates one for you.</source>
          <target state="new">Otherwise, the cluster creation process creates one for you.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Under <bpt id="p1">**</bpt>Blob<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Upload<ept id="p2">**</ept>.</source>
          <target state="new">Under <bpt id="p1">**</bpt>Blob<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Upload<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Specify a file to upload, and then click <bpt id="p1">**</bpt>Open<ept id="p1">**</ept>.</source>
          <target state="new">Specify a file to upload, and then click <bpt id="p1">**</bpt>Open<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>Mount Azure Blob Storage as Local Drive</source>
          <target state="new">Mount Azure Blob Storage as Local Drive</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Mount Azure Blob Storage as Local Drive<ept id="p1">](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/09/mount-azure-blob-storage-as-local-drive.aspx)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Mount Azure Blob Storage as Local Drive<ept id="p1">](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/09/mount-azure-blob-storage-as-local-drive.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Services</source>
          <target state="new">Services</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Azure Data Factory</source>
          <target state="new">Azure Data Factory</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>The Azure Data Factory service is a fully managed service for composing data storage, data processing, and data movement services into streamlined, scalable, and reliable data production pipelines.</source>
          <target state="new">The Azure Data Factory service is a fully managed service for composing data storage, data processing, and data movement services into streamlined, scalable, and reliable data production pipelines.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Azure Data Factory can be used to move data into Azure Blob storage, or to create data pipelines that directly use HDInsight features such as Hive and Pig.</source>
          <target state="new">Azure Data Factory can be used to move data into Azure Blob storage, or to create data pipelines that directly use HDInsight features such as Hive and Pig.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>For more information, see the <bpt id="p1">[</bpt>Azure Data Factory documentation<ept id="p1">](http://azure.microsoft.com/documentation/services/data-factory/)</ept>.</source>
          <target state="new">For more information, see the <bpt id="p1">[</bpt>Azure Data Factory documentation<ept id="p1">](http://azure.microsoft.com/documentation/services/data-factory/)</ept>.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="sqoop"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Apache Sqoop</source>
          <target state="new"><ph id="ph1">&lt;a id="sqoop"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Apache Sqoop</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>Sqoop is a tool designed to transfer data between Hadoop and relational databases.</source>
          <target state="new">Sqoop is a tool designed to transfer data between Hadoop and relational databases.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>You can use it to import data from a relational database management system (RDBMS), such as SQL Server, MySQL, or Oracle into the Hadoop distributed file system (HDFS), transform the data in Hadoop with MapReduce or Hive, and then export the data back into an RDBMS.</source>
          <target state="new">You can use it to import data from a relational database management system (RDBMS), such as SQL Server, MySQL, or Oracle into the Hadoop distributed file system (HDFS), transform the data in Hadoop with MapReduce or Hive, and then export the data back into an RDBMS.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Use Sqoop with HDInsight<ept id="p1">][hdinsight-use-sqoop]</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Use Sqoop with HDInsight<ept id="p1">][hdinsight-use-sqoop]</ept>.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Development SDKs</source>
          <target state="new">Development SDKs</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Azure Blob storage can also be accessed using an Azure SDK from the following programming languages:</source>
          <target state="new">Azure Blob storage can also be accessed using an Azure SDK from the following programming languages:</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>.NET</source>
          <target state="new">.NET</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>Java</source>
          <target state="new">Java</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Node.js</source>
          <target state="new">Node.js</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>PHP</source>
          <target state="new">PHP</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Python</source>
          <target state="new">Python</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Ruby</source>
          <target state="new">Ruby</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>For more information on installing the Azure SDKs, see <bpt id="p1">[</bpt>Azure downloads<ept id="p1">](http://azure.microsoft.com/downloads/)</ept></source>
          <target state="new">For more information on installing the Azure SDKs, see <bpt id="p1">[</bpt>Azure downloads<ept id="p1">](http://azure.microsoft.com/downloads/)</ept></target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Now that you understand how to get data into HDInsight, read the following articles to learn how to perform analysis:</source>
          <target state="new">Now that you understand how to get data into HDInsight, read the following articles to learn how to perform analysis:</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Get started with Azure HDInsight</source>
          <target state="new">Get started with Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>Submit Hadoop jobs programmatically</source>
          <target state="new">Submit Hadoop jobs programmatically</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3608dcbfa9eaed28acf66ce091427bdc6454b63e</xliffext:olfilehash>
  </header>
</xliff>