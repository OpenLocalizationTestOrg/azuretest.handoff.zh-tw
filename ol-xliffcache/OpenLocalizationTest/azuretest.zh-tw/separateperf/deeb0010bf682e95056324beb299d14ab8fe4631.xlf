<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Python with Hive and Pig in HDInsight | Microsoft Azure</source>
          <target state="new">Use Python with Hive and Pig in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use Python User Defined Functions (UDF) from Hive and Pig in HDInsight, the Hadoop technology stack on Azure.</source>
          <target state="new">Learn how to use Python User Defined Functions (UDF) from Hive and Pig in HDInsight, the Hadoop technology stack on Azure.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use Python with Hive and Pig in HDInsight</source>
          <target state="new">Use Python with Hive and Pig in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Hive and Pig are great for working with data in HDInsight, but sometimes you need a more general purpose language.</source>
          <target state="new">Hive and Pig are great for working with data in HDInsight, but sometimes you need a more general purpose language.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Both Hive and Pig allow you to create User Defined Functions (UDF) using a variety of programming languages.</source>
          <target state="new">Both Hive and Pig allow you to create User Defined Functions (UDF) using a variety of programming languages.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In this article, you will learn how to use a Python UDF from Hive and Pig.</source>
          <target state="new">In this article, you will learn how to use a Python UDF from Hive and Pig.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The steps in this article apply to HDInsight cluster versions 2.1, 3.0, 3.1, and 3.2.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The steps in this article apply to HDInsight cluster versions 2.1, 3.0, 3.1, and 3.2.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="python"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Python on HDInsight</source>
          <target state="new"><ph id="ph1">&lt;a name="python"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Python on HDInsight</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Python2.7 is installed by default on HDInsight 3.0 and later clusters.</source>
          <target state="new">Python2.7 is installed by default on HDInsight 3.0 and later clusters.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Hive can be used with this version of Python for stream processing (data is passed between Hive and Python using STDOUT/STDIN).</source>
          <target state="new">Hive can be used with this version of Python for stream processing (data is passed between Hive and Python using STDOUT/STDIN).</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>HDInsight also includes Jython, which is a Python implementation written in Java.</source>
          <target state="new">HDInsight also includes Jython, which is a Python implementation written in Java.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Pig understands how to talk to Jython without having to resort to streaming, so it's preferable when using Pig.</source>
          <target state="new">Pig understands how to talk to Jython without having to resort to streaming, so it's preferable when using Pig.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hivepython"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Hive and Python</source>
          <target state="new"><ph id="ph1">&lt;a name="hivepython"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Hive and Python</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Python can be used as a UDF from Hive through the HiveQL <bpt id="p1">**</bpt>TRANSFORM<ept id="p1">**</ept> statement.</source>
          <target state="new">Python can be used as a UDF from Hive through the HiveQL <bpt id="p1">**</bpt>TRANSFORM<ept id="p1">**</ept> statement.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>For example, the following HiveQL invokes a Python script stored in the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> file.</source>
          <target state="new">For example, the following HiveQL invokes a Python script stored in the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> file.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Linux-based HDInsight</source>
          <target state="new">Linux-based HDInsight</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Windows-based HDInsight</source>
          <target state="new">Windows-based HDInsight</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> On Windows-based HDInsight clusters, the <bpt id="p1">**</bpt>USING<ept id="p1">**</ept> clause must specify the full path to python.exe.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> On Windows-based HDInsight clusters, the <bpt id="p1">**</bpt>USING<ept id="p1">**</ept> clause must specify the full path to python.exe.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>This is always <ph id="ph1">`D:\Python27\python.exe`</ph>.</source>
          <target state="new">This is always <ph id="ph1">`D:\Python27\python.exe`</ph>.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Here's what this example does:</source>
          <target state="new">Here's what this example does:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>add file<ept id="p1">**</ept> statement at the beginning of the file adds the <bpt id="p2">**</bpt>streaming.py<ept id="p2">**</ept> file to the distributed cache, so it's accessible by all nodes in the cluster.</source>
          <target state="new">The <bpt id="p1">**</bpt>add file<ept id="p1">**</ept> statement at the beginning of the file adds the <bpt id="p2">**</bpt>streaming.py<ept id="p2">**</ept> file to the distributed cache, so it's accessible by all nodes in the cluster.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The  <bpt id="p1">**</bpt>SELECT TRANSFORM ... USING<ept id="p1">**</ept> statement selects data from the <bpt id="p2">**</bpt>hivesampletable<ept id="p2">**</ept>, and passes clientid, devicemake, and devicemodel to the <bpt id="p3">**</bpt>streaming.py<ept id="p3">**</ept> script.</source>
          <target state="new">The  <bpt id="p1">**</bpt>SELECT TRANSFORM ... USING<ept id="p1">**</ept> statement selects data from the <bpt id="p2">**</bpt>hivesampletable<ept id="p2">**</ept>, and passes clientid, devicemake, and devicemodel to the <bpt id="p3">**</bpt>streaming.py<ept id="p3">**</ept> script.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>AS<ept id="p1">**</ept> clause describes the fields returned from <bpt id="p2">**</bpt>streaming.py<ept id="p2">**</ept></source>
          <target state="new">The <bpt id="p1">**</bpt>AS<ept id="p1">**</ept> clause describes the fields returned from <bpt id="p2">**</bpt>streaming.py<ept id="p2">**</ept></target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Here's the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> file used by the HiveQL example.</source>
          <target state="new">Here's the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> file used by the HiveQL example.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Since we are using streaming, this script has to do the following:</source>
          <target state="new">Since we are using streaming, this script has to do the following:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Read data from STDIN.</source>
          <target state="new">Read data from STDIN.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>This is accomplished by using <ph id="ph1">`sys.stdin.readline()`</ph> in this example.</source>
          <target state="new">This is accomplished by using <ph id="ph1">`sys.stdin.readline()`</ph> in this example.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The trailing newline character is removed using <ph id="ph1">`string.strip(line, "\n ")`</ph>, since we just want the text data and not the end of line indicator.</source>
          <target state="new">The trailing newline character is removed using <ph id="ph1">`string.strip(line, "\n ")`</ph>, since we just want the text data and not the end of line indicator.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>When doing stream processing, a single line contains all the values with a tab character between each value.</source>
          <target state="new">When doing stream processing, a single line contains all the values with a tab character between each value.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>So <ph id="ph1">`string.split(line, "\t")`</ph> can be used to split the input at each tab, returning just the fields.</source>
          <target state="new">So <ph id="ph1">`string.split(line, "\t")`</ph> can be used to split the input at each tab, returning just the fields.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>When processing is complete, the output must be written to STDOUT as a single line, with a tab between each field.</source>
          <target state="new">When processing is complete, the output must be written to STDOUT as a single line, with a tab between each field.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>This is accomplished by using <ph id="ph1">`print "\t".join([clientid, phone_label, hashlib.md5(phone_label).hexdigest()])`</ph>.</source>
          <target state="new">This is accomplished by using <ph id="ph1">`print "\t".join([clientid, phone_label, hashlib.md5(phone_label).hexdigest()])`</ph>.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>This all occurs within a <ph id="ph1">`while`</ph> loop, that will repeat until no <ph id="ph2">`line`</ph> is read, at which point <ph id="ph3">`break`</ph> exits the loop and the script terminates.</source>
          <target state="new">This all occurs within a <ph id="ph1">`while`</ph> loop, that will repeat until no <ph id="ph2">`line`</ph> is read, at which point <ph id="ph3">`break`</ph> exits the loop and the script terminates.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Beyond that, the script just concatenates the input values for <ph id="ph1">`devicemake`</ph> and <ph id="ph2">`devicemodel`</ph>, and calculates a hash of the concatenated value.</source>
          <target state="new">Beyond that, the script just concatenates the input values for <ph id="ph1">`devicemake`</ph> and <ph id="ph2">`devicemodel`</ph>, and calculates a hash of the concatenated value.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Pretty simple, but it describes the basics of how any Python script invoked from Hive should function: Loop, read input until there is no more, break each line of input apart at the tabs, process, write a single line of tab delimited output.</source>
          <target state="new">Pretty simple, but it describes the basics of how any Python script invoked from Hive should function: Loop, read input until there is no more, break each line of input apart at the tabs, process, write a single line of tab delimited output.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Running the examples<ept id="p1">](#running)</ept> for how to run this example on your HDInsight cluster.</source>
          <target state="new">See <bpt id="p1">[</bpt>Running the examples<ept id="p1">](#running)</ept> for how to run this example on your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="pigpython"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Pig and Python</source>
          <target state="new"><ph id="ph1">&lt;a name="pigpython"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Pig and Python</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>A Python script can be used as a UDF from Pig through the <bpt id="p1">**</bpt>GENERATE<ept id="p1">**</ept> statement.</source>
          <target state="new">A Python script can be used as a UDF from Pig through the <bpt id="p1">**</bpt>GENERATE<ept id="p1">**</ept> statement.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>For example, the following example uses a Python script stored in the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> file.</source>
          <target state="new">For example, the following example uses a Python script stored in the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> file.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Here's how this example works:</source>
          <target state="new">Here's how this example works:</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>It registers the file containing the Python script (<bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept>,) using <bpt id="p2">**</bpt>Jython<ept id="p2">**</ept>, and exposes it to Pig as <bpt id="p3">**</bpt>myfuncs<ept id="p3">**</ept>.</source>
          <target state="new">It registers the file containing the Python script (<bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept>,) using <bpt id="p2">**</bpt>Jython<ept id="p2">**</ept>, and exposes it to Pig as <bpt id="p3">**</bpt>myfuncs<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Jython is a Python implementation in Java, and runs in the same Java Virtual machine as Pig.</source>
          <target state="new">Jython is a Python implementation in Java, and runs in the same Java Virtual machine as Pig.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>This allows us to treat the Python script like a traditional function call vs. the streaming approach used with Hive.</source>
          <target state="new">This allows us to treat the Python script like a traditional function call vs. the streaming approach used with Hive.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>The next line loads the sample data file, <bpt id="p1">**</bpt>sample.log<ept id="p1">**</ept> into <bpt id="p2">**</bpt>LOGS<ept id="p2">**</ept>.</source>
          <target state="new">The next line loads the sample data file, <bpt id="p1">**</bpt>sample.log<ept id="p1">**</ept> into <bpt id="p2">**</bpt>LOGS<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Since this log file doesn't have a consistent schema, it also defines each record (<bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> in this case,) as a <bpt id="p2">**</bpt>chararray<ept id="p2">**</ept>.</source>
          <target state="new">Since this log file doesn't have a consistent schema, it also defines each record (<bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> in this case,) as a <bpt id="p2">**</bpt>chararray<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Chararray is, essentially, a string.</source>
          <target state="new">Chararray is, essentially, a string.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The third line filters out any null values, storing the result of the operation into <bpt id="p1">**</bpt>LOG<ept id="p1">**</ept>.</source>
          <target state="new">The third line filters out any null values, storing the result of the operation into <bpt id="p1">**</bpt>LOG<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Next, it iterates over the records in <bpt id="p1">**</bpt>LOG<ept id="p1">**</ept> and uses <bpt id="p2">**</bpt>GENERATE<ept id="p2">**</ept> to invoke the <bpt id="p3">**</bpt>create_structure<ept id="p3">**</ept> method contained in the <bpt id="p4">**</bpt>jython.py<ept id="p4">**</ept> script loaded as <bpt id="p5">**</bpt>myfuncs<ept id="p5">**</ept>.</source>
          <target state="new">Next, it iterates over the records in <bpt id="p1">**</bpt>LOG<ept id="p1">**</ept> and uses <bpt id="p2">**</bpt>GENERATE<ept id="p2">**</ept> to invoke the <bpt id="p3">**</bpt>create_structure<ept id="p3">**</ept> method contained in the <bpt id="p4">**</bpt>jython.py<ept id="p4">**</ept> script loaded as <bpt id="p5">**</bpt>myfuncs<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> is used to pass the current record to the function.</source>
          <target state="new"><bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> is used to pass the current record to the function.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Finally, the outputs are dumped to STDOUT using the <bpt id="p1">**</bpt>DUMP<ept id="p1">**</ept> command.</source>
          <target state="new">Finally, the outputs are dumped to STDOUT using the <bpt id="p1">**</bpt>DUMP<ept id="p1">**</ept> command.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>This is just to immediately show the results after the operation completes; in a real script you would normally <bpt id="p1">**</bpt>STORE<ept id="p1">**</ept> the data into a new file.</source>
          <target state="new">This is just to immediately show the results after the operation completes; in a real script you would normally <bpt id="p1">**</bpt>STORE<ept id="p1">**</ept> the data into a new file.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Here's the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> file used by the Pig example:</source>
          <target state="new">Here's the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> file used by the Pig example:</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Remember that we previously just defined the <bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> input as a chararray because there was no consistent schema for the input?</source>
          <target state="new">Remember that we previously just defined the <bpt id="p1">**</bpt>LINE<ept id="p1">**</ept> input as a chararray because there was no consistent schema for the input?</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>What the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> does is to transform the data into a consistent schema for output.</source>
          <target state="new">What the <bpt id="p1">**</bpt>jython.py<ept id="p1">**</ept> does is to transform the data into a consistent schema for output.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>It works like this:</source>
          <target state="new">It works like this:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>@outputSchema<ept id="p1">**</ept> statement defines the format of the data that will be returned to Pig.</source>
          <target state="new">The <bpt id="p1">**</bpt>@outputSchema<ept id="p1">**</ept> statement defines the format of the data that will be returned to Pig.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>In this case, it's a <bpt id="p1">**</bpt>data bag<ept id="p1">**</ept>, which is a Pig data type.</source>
          <target state="new">In this case, it's a <bpt id="p1">**</bpt>data bag<ept id="p1">**</ept>, which is a Pig data type.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>The bag contains the following fields, all of which are chararray (strings):</source>
          <target state="new">The bag contains the following fields, all of which are chararray (strings):</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>date - the date the log entry was created</source>
          <target state="new">date - the date the log entry was created</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>time - the time the log entry was created</source>
          <target state="new">time - the time the log entry was created</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>classname - the class name the entry was created for</source>
          <target state="new">classname - the class name the entry was created for</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>level - the log level</source>
          <target state="new">level - the log level</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>detail - verbose details for the log entry</source>
          <target state="new">detail - verbose details for the log entry</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Next, the <bpt id="p1">**</bpt>def create_structure(input)<ept id="p1">**</ept> defines the function that Pig will pass line items to.</source>
          <target state="new">Next, the <bpt id="p1">**</bpt>def create_structure(input)<ept id="p1">**</ept> defines the function that Pig will pass line items to.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The example data, <bpt id="p1">**</bpt>sample.log<ept id="p1">**</ept>, mostly conforms to the date, time, classname, level, and detail schema we want to return.</source>
          <target state="new">The example data, <bpt id="p1">**</bpt>sample.log<ept id="p1">**</ept>, mostly conforms to the date, time, classname, level, and detail schema we want to return.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>But it also contains a few lines that begin with the string '<bpt id="p1">*</bpt>java.lang.Exception<ept id="p1">*</ept>' that need to be modified to match the schema.</source>
          <target state="new">But it also contains a few lines that begin with the string '<bpt id="p1">*</bpt>java.lang.Exception<ept id="p1">*</ept>' that need to be modified to match the schema.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>if<ept id="p1">**</ept> statement checks for those, then massages the input data to move the '<bpt id="p2">*</bpt>java.lang.Exception<ept id="p2">*</ept>' string to the end, bringing the data in-line with our expected output schema.</source>
          <target state="new">The <bpt id="p1">**</bpt>if<ept id="p1">**</ept> statement checks for those, then massages the input data to move the '<bpt id="p2">*</bpt>java.lang.Exception<ept id="p2">*</ept>' string to the end, bringing the data in-line with our expected output schema.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Next, the <bpt id="p1">**</bpt>split<ept id="p1">**</ept> command is used to split the data at the first four space characters.</source>
          <target state="new">Next, the <bpt id="p1">**</bpt>split<ept id="p1">**</ept> command is used to split the data at the first four space characters.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>This results in five values, which are assigned into <bpt id="p1">**</bpt>date<ept id="p1">**</ept>, <bpt id="p2">**</bpt>time<ept id="p2">**</ept>, <bpt id="p3">**</bpt>classname<ept id="p3">**</ept>, <bpt id="p4">**</bpt>level<ept id="p4">**</ept>, and <bpt id="p5">**</bpt>detail<ept id="p5">**</ept>.</source>
          <target state="new">This results in five values, which are assigned into <bpt id="p1">**</bpt>date<ept id="p1">**</ept>, <bpt id="p2">**</bpt>time<ept id="p2">**</ept>, <bpt id="p3">**</bpt>classname<ept id="p3">**</ept>, <bpt id="p4">**</bpt>level<ept id="p4">**</ept>, and <bpt id="p5">**</bpt>detail<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Finally, the values are returned to Pig.</source>
          <target state="new">Finally, the values are returned to Pig.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>When the data is returned to Pig, it will have a consistent schema as defined in the <bpt id="p1">**</bpt>@outputSchema<ept id="p1">**</ept> statement.</source>
          <target state="new">When the data is returned to Pig, it will have a consistent schema as defined in the <bpt id="p1">**</bpt>@outputSchema<ept id="p1">**</ept> statement.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="running"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Running the examples</source>
          <target state="new"><ph id="ph1">&lt;a name="running"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Running the examples</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>If you are using a Linux-based HDInsight cluster, use the <bpt id="p1">**</bpt>SSH<ept id="p1">**</ept> steps below.</source>
          <target state="new">If you are using a Linux-based HDInsight cluster, use the <bpt id="p1">**</bpt>SSH<ept id="p1">**</ept> steps below.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>If you are using a Windows-based HDInsight cluster and a Windows client, use the <bpt id="p1">**</bpt>PowerShell<ept id="p1">**</ept> steps.</source>
          <target state="new">If you are using a Windows-based HDInsight cluster and a Windows client, use the <bpt id="p1">**</bpt>PowerShell<ept id="p1">**</ept> steps.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>SSH</source>
          <target state="new">SSH</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>For more information on using SSH, see <ph id="ph1">&lt;a href="../hdinsight-hadoop-linux-use-ssh-unix/" target="_blank"&gt;</ph>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ph id="ph2">&lt;/a&gt;</ph> or <ph id="ph3">&lt;a href="../hdinsight-hadoop-linux-use-ssh-windows/" target="_blank"&gt;</ph>Use SSH with Linux-based Hadoop on HDInsight from Windows<ph id="ph4">&lt;/a&gt;</ph>.</source>
          <target state="new">For more information on using SSH, see <ph id="ph1">&lt;a href="../hdinsight-hadoop-linux-use-ssh-unix/" target="_blank"&gt;</ph>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X<ph id="ph2">&lt;/a&gt;</ph> or <ph id="ph3">&lt;a href="../hdinsight-hadoop-linux-use-ssh-windows/" target="_blank"&gt;</ph>Use SSH with Linux-based Hadoop on HDInsight from Windows<ph id="ph4">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Using the Python examples <bpt id="p1">[</bpt>streaming.py<ept id="p1">](#streamingpy)</ept> and <bpt id="p2">[</bpt>jython.py<ept id="p2">](#jythonpy)</ept>, create local copies of the files on your development machine.</source>
          <target state="new">Using the Python examples <bpt id="p1">[</bpt>streaming.py<ept id="p1">](#streamingpy)</ept> and <bpt id="p2">[</bpt>jython.py<ept id="p2">](#jythonpy)</ept>, create local copies of the files on your development machine.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Use <ph id="ph1">`scp`</ph> to copy the files to your HDInsight cluster.</source>
          <target state="new">Use <ph id="ph1">`scp`</ph> to copy the files to your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>For example, the following would copy the files to a cluster named <bpt id="p1">**</bpt>mycluster<ept id="p1">**</ept>.</source>
          <target state="new">For example, the following would copy the files to a cluster named <bpt id="p1">**</bpt>mycluster<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Use SSH to connect to the cluster.</source>
          <target state="new">Use SSH to connect to the cluster.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>For example, the following would connect to a cluster named <bpt id="p1">**</bpt>mycluster<ept id="p1">**</ept> as user <bpt id="p2">**</bpt>myuser<ept id="p2">**</ept>.</source>
          <target state="new">For example, the following would connect to a cluster named <bpt id="p1">**</bpt>mycluster<ept id="p1">**</ept> as user <bpt id="p2">**</bpt>myuser<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>From the SSH session, add the python files uploaded previously to the WASB storage for the cluster.</source>
          <target state="new">From the SSH session, add the python files uploaded previously to the WASB storage for the cluster.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>After uploading the files, use the following steps to run the Hive and Pig jobs.</source>
          <target state="new">After uploading the files, use the following steps to run the Hive and Pig jobs.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Hive</source>
          <target state="new">Hive</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Use the <ph id="ph1">`hive`</ph> command to start the hive shell.</source>
          <target state="new">Use the <ph id="ph1">`hive`</ph> command to start the hive shell.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>You should see a <ph id="ph1">`hive&gt;`</ph> prompt once the shell has loaded.</source>
          <target state="new">You should see a <ph id="ph1">`hive&gt;`</ph> prompt once the shell has loaded.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Enter the following at the <ph id="ph1">`hive&gt;`</ph> prompt.</source>
          <target state="new">Enter the following at the <ph id="ph1">`hive&gt;`</ph> prompt.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>After entering the last line, the job should start.</source>
          <target state="new">After entering the last line, the job should start.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Eventually it will return output similar to the following.</source>
          <target state="new">Eventually it will return output similar to the following.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Pig</source>
          <target state="new">Pig</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Use the <ph id="ph1">`pig`</ph> command to start the shell.</source>
          <target state="new">Use the <ph id="ph1">`pig`</ph> command to start the shell.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>You should see a <ph id="ph1">`grunt&gt;`</ph> prompt once the shell has loaded.</source>
          <target state="new">You should see a <ph id="ph1">`grunt&gt;`</ph> prompt once the shell has loaded.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Enter the following statements at the <ph id="ph1">`grunt&gt;`</ph> prompt.</source>
          <target state="new">Enter the following statements at the <ph id="ph1">`grunt&gt;`</ph> prompt.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>After entering the following line,the job should start.</source>
          <target state="new">After entering the following line,the job should start.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Eventually it will return output similar to the following.</source>
          <target state="new">Eventually it will return output similar to the following.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>PowerShell</source>
          <target state="new">PowerShell</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>These steps use Azure PowerShell.</source>
          <target state="new">These steps use Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>If this is not already installed and configured on your development machine, see <bpt id="p1">[</bpt>How to install and configure Azure PowerShell<ept id="p1">](../install-configure-powershell.md)</ept> before using the following steps.</source>
          <target state="new">If this is not already installed and configured on your development machine, see <bpt id="p1">[</bpt>How to install and configure Azure PowerShell<ept id="p1">](../install-configure-powershell.md)</ept> before using the following steps.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Using the Python examples <bpt id="p1">[</bpt>streaming.py<ept id="p1">](#streamingpy)</ept> and <bpt id="p2">[</bpt>jython.py<ept id="p2">](#jythonpy)</ept>, create local copies of the files on your development machine.</source>
          <target state="new">Using the Python examples <bpt id="p1">[</bpt>streaming.py<ept id="p1">](#streamingpy)</ept> and <bpt id="p2">[</bpt>jython.py<ept id="p2">](#jythonpy)</ept>, create local copies of the files on your development machine.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Use  the following PowerShell script to upload the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>jython.py<ept id="p2">**</ept> files to the server.</source>
          <target state="new">Use  the following PowerShell script to upload the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>jython.py<ept id="p2">**</ept> files to the server.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Substitute the name of your Azure HDInsight cluster, and the path to the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>jython.py<ept id="p2">**</ept> files on the first three lines of the script.</source>
          <target state="new">Substitute the name of your Azure HDInsight cluster, and the path to the <bpt id="p1">**</bpt>streaming.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>jython.py<ept id="p2">**</ept> files on the first three lines of the script.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>This script retrieves information for your HDInsight cluster, then extracts the account and key for the default storage account, and uploads the files to the root of the container.</source>
          <target state="new">This script retrieves information for your HDInsight cluster, then extracts the account and key for the default storage account, and uploads the files to the root of the container.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> Other methods of uploading the scripts can be found in the <bpt id="p1">[</bpt>Upload data for Hadoop jobs in HDInsight<ept id="p1">](hdinsight-upload-data.md)</ept> document.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> Other methods of uploading the scripts can be found in the <bpt id="p1">[</bpt>Upload data for Hadoop jobs in HDInsight<ept id="p1">](hdinsight-upload-data.md)</ept> document.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>After uploading the files, use the following PowerShell scripts to start the jobs.</source>
          <target state="new">After uploading the files, use the following PowerShell scripts to start the jobs.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>When the job completes, the output should be written to the PowerShell console.</source>
          <target state="new">When the job completes, the output should be written to the PowerShell console.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Hive</source>
          <target state="new">Hive</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The output for the <bpt id="p1">**</bpt>Hive<ept id="p1">**</ept> job should appear similar to the following:</source>
          <target state="new">The output for the <bpt id="p1">**</bpt>Hive<ept id="p1">**</ept> job should appear similar to the following:</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Pig</source>
          <target state="new">Pig</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>The output for the <bpt id="p1">**</bpt>Pig<ept id="p1">**</ept> job should appear similar to the following:</source>
          <target state="new">The output for the <bpt id="p1">**</bpt>Pig<ept id="p1">**</ept> job should appear similar to the following:</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="troubleshooting"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Troubleshooting</source>
          <target state="new"><ph id="ph1">&lt;a name="troubleshooting"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Troubleshooting</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Both of the example PowerShell scripts used to run the examples contain a commented line that will display error output for the job.</source>
          <target state="new">Both of the example PowerShell scripts used to run the examples contain a commented line that will display error output for the job.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>If you are not seeing the expected output for the job, uncomment the following line and see if the error information indicates a problem.</source>
          <target state="new">If you are not seeing the expected output for the job, uncomment the following line and see if the error information indicates a problem.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>The error information (STDERR,) and the result of the job (STDOUT,) are also logged to the default blob container for your clusters at the following locations.</source>
          <target state="new">The error information (STDERR,) and the result of the job (STDOUT,) are also logged to the default blob container for your clusters at the following locations.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>For this job..</source>
          <target state="new">For this job..</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>Look at these files in the blob container</source>
          <target state="new">Look at these files in the blob container</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Hive</source>
          <target state="new">Hive</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>/HivePython/stderr</source>
          <target state="new">/HivePython/stderr</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>/HivePython/stdout</source>
          <target state="new">/HivePython/stdout</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Pig</source>
          <target state="new">Pig</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>/PigPython/stderr</source>
          <target state="new">/PigPython/stderr</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>/PigPython/stdout</source>
          <target state="new">/PigPython/stdout</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="next"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a name="next"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>If you need to load Python modules that aren't provided by default, see <bpt id="p1">[</bpt>How to deploy a module to Azure HDInsight<ept id="p1">](http://blogs.msdn.com/b/benjguin/archive/2014/03/03/how-to-deploy-a-python-module-to-windows-azure-hdinsight.aspx)</ept> for an example of how to do this.</source>
          <target state="new">If you need to load Python modules that aren't provided by default, see <bpt id="p1">[</bpt>How to deploy a module to Azure HDInsight<ept id="p1">](http://blogs.msdn.com/b/benjguin/archive/2014/03/03/how-to-deploy-a-python-module-to-windows-azure-hdinsight.aspx)</ept> for an example of how to do this.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>For other ways to use Pig, Hive, and to learn about using MapReduce, see the following.</source>
          <target state="new">For other ways to use Pig, Hive, and to learn about using MapReduce, see the following.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Use MapReduce with HDInsight</source>
          <target state="new">Use MapReduce with HDInsight</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">deeb0010bf682e95056324beb299d14ab8fe4631</xliffext:olfilehash>
  </header>
</xliff>