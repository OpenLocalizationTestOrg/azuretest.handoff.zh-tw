<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Azure Data Factory - Frequently Asked Questions</source>
          <target state="new">Azure Data Factory - Frequently Asked Questions</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Frequently asked questions about Azure Data Factory.</source>
          <target state="new">Frequently asked questions about Azure Data Factory.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Azure Data Factory - Frequently Asked Questions</source>
          <target state="new">Azure Data Factory - Frequently Asked Questions</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>General questions</source>
          <target state="new">General questions</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>What is Azure Data Factory?</source>
          <target state="new">What is Azure Data Factory?</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Data Factory is a cloud-based data integration service that orchestrates and automates the movement and transformation of data.</source>
          <target state="new">Data Factory is a cloud-based data integration service that orchestrates and automates the movement and transformation of data.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Just like a manufacturing factory that runs equipment to take raw materials and transform them into finished goods, Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</source>
          <target state="new">Just like a manufacturing factory that runs equipment to take raw materials and transform them into finished goods, Data Factory orchestrates existing services that collect raw data and transform it into ready-to-use information.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Data Factory works across on-premises and cloud data sources and SaaS to ingest, prepare, transform, analyze, and publish your data.</source>
          <target state="new">Data Factory works across on-premises and cloud data sources and SaaS to ingest, prepare, transform, analyze, and publish your data.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Use Data Factory to compose services into managed data flow pipelines to transform your data using services like <bpt id="p1">[</bpt>Azure HDInsight (Hadoop)<ept id="p1">](http://azure.microsoft.com/documentation/services/hdinsight/)</ept> and <bpt id="p2">[</bpt>Azure Batch<ept id="p2">](http://azure.microsoft.com/documentation/services/batch/)</ept> for your big data computing needs, and with <bpt id="p3">[</bpt>Azure Machine Learning<ept id="p3">](http://azure.microsoft.com/documentation/services/machine-learning/)</ept> to operationalize your analytics solutions.</source>
          <target state="new">Use Data Factory to compose services into managed data flow pipelines to transform your data using services like <bpt id="p1">[</bpt>Azure HDInsight (Hadoop)<ept id="p1">](http://azure.microsoft.com/documentation/services/hdinsight/)</ept> and <bpt id="p2">[</bpt>Azure Batch<ept id="p2">](http://azure.microsoft.com/documentation/services/batch/)</ept> for your big data computing needs, and with <bpt id="p3">[</bpt>Azure Machine Learning<ept id="p3">](http://azure.microsoft.com/documentation/services/machine-learning/)</ept> to operationalize your analytics solutions.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Go beyond just a tabular monitoring view, and use the rich visualizations of Data Factory to quickly display the lineage and dependencies between your data pipelines.</source>
          <target state="new">Go beyond just a tabular monitoring view, and use the rich visualizations of Data Factory to quickly display the lineage and dependencies between your data pipelines.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Monitor all of your data flow pipelines from a single unified view to easily pinpoint issues and setup monitoring alerts.</source>
          <target state="new">Monitor all of your data flow pipelines from a single unified view to easily pinpoint issues and setup monitoring alerts.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Overview &amp; Key Concepts<ept id="p1">](data-factory-introduction.md)</ept> for more details.</source>
          <target state="new">See <bpt id="p1">[</bpt>Overview &amp; Key Concepts<ept id="p1">](data-factory-introduction.md)</ept> for more details.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>What customer challenge does Data Factory solve?</source>
          <target state="new">What customer challenge does Data Factory solve?</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Azure Data Factory balances the agility of leveraging diverse data storage, processing and movement services across traditional relational storage alongside unstructured data, with the control and monitoring capabilities of a fully managed service.</source>
          <target state="new">Azure Data Factory balances the agility of leveraging diverse data storage, processing and movement services across traditional relational storage alongside unstructured data, with the control and monitoring capabilities of a fully managed service.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Who are the target audiences for Data Factory?</source>
          <target state="new">Who are the target audiences for Data Factory?</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Data Developers: who are responsible for building integration services between Hadoop and other systems:</source>
          <target state="new">Data Developers: who are responsible for building integration services between Hadoop and other systems:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Must keep up and integrate with a continually changing and growing data landscape</source>
          <target state="new">Must keep up and integrate with a continually changing and growing data landscape</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Must write custom code for information production, and it  is expensive, hard to maintain, and not highly available or fault tolerant</source>
          <target state="new">Must write custom code for information production, and it  is expensive, hard to maintain, and not highly available or fault tolerant</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>IT Professionals: who are looking to incorporate more diverse data within their IT infrastructure:</source>
          <target state="new">IT Professionals: who are looking to incorporate more diverse data within their IT infrastructure:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Required to look across all of an organization’s data to derive rich business insights</source>
          <target state="new">Required to look across all of an organization’s data to derive rich business insights</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Must manage compute and storage resources to balance cost and scale across on-premises and cloud</source>
          <target state="new">Must manage compute and storage resources to balance cost and scale across on-premises and cloud</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Must quickly add diverse sources and processing to address new business needs, while maintaining visibility across all compute and storage assets</source>
          <target state="new">Must quickly add diverse sources and processing to address new business needs, while maintaining visibility across all compute and storage assets</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Where can I find pricing details for Azure Data Factory?</source>
          <target state="new">Where can I find pricing details for Azure Data Factory?</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory Pricing Details page<ept id="p1">][adf-pricing-details]</ept> for the pricing details for the Azure Data Factory.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory Pricing Details page<ept id="p1">][adf-pricing-details]</ept> for the pricing details for the Azure Data Factory.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>How do I get started with Azure Data Factory?</source>
          <target state="new">How do I get started with Azure Data Factory?</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>For an overview of Azure Data Factory, see <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">][adf-introduction]</ept>.</source>
          <target state="new">For an overview of Azure Data Factory, see <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">][adf-introduction]</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>For a quick tutorial, see <bpt id="p1">[</bpt>Get started with Azure Data Factory<ept id="p1">][adfgetstarted]</ept>.</source>
          <target state="new">For a quick tutorial, see <bpt id="p1">[</bpt>Get started with Azure Data Factory<ept id="p1">][adfgetstarted]</ept>.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>For comprehensive documentation, see <bpt id="p1">[</bpt>Azure Data Factory documentation<ept id="p1">][adf-documentation-landingpage]</ept>.</source>
          <target state="new">For comprehensive documentation, see <bpt id="p1">[</bpt>Azure Data Factory documentation<ept id="p1">][adf-documentation-landingpage]</ept>.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>How do customers access Data Factory?</source>
          <target state="new">How do customers access Data Factory?</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Customers can get access to Data Factory through the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">][azure-preview-portal]</ept>.</source>
          <target state="new">Customers can get access to Data Factory through the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">][azure-preview-portal]</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>What is the Data Factory’s region availability?</source>
          <target state="new">What is the Data Factory’s region availability?</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Data Factory is available in US West and North Europe.</source>
          <target state="new">Data Factory is available in US West and North Europe.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>The compute and storage services used by data factories can be in other regions.</source>
          <target state="new">The compute and storage services used by data factories can be in other regions.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>What are the limits on number of data factories/pipelines/activities/datasets?</source>
          <target state="new">What are the limits on number of data factories/pipelines/activities/datasets?</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">**</bpt>Azure Data Factory Limits<ept id="p1">**</ept> section of the <bpt id="p2">[</bpt>Azure Subscription and Service Limits, Quotas, and Constraints<ept id="p2">](../azure-subscription-service-limits.md#data-factory-limits)</ept> article.</source>
          <target state="new">See <bpt id="p1">**</bpt>Azure Data Factory Limits<ept id="p1">**</ept> section of the <bpt id="p2">[</bpt>Azure Subscription and Service Limits, Quotas, and Constraints<ept id="p2">](../azure-subscription-service-limits.md#data-factory-limits)</ept> article.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>What is the authoring/developer experience with Azure Data Factory service?</source>
          <target state="new">What is the authoring/developer experience with Azure Data Factory service?</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>You can author/create data factories using one of the following:</source>
          <target state="new">You can author/create data factories using one of the following:</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The Data Factory blades in the Azure Preview Portal provide rich user interface for you to create data factories ad linked services.</source>
          <target state="new">The Data Factory blades in the Azure Preview Portal provide rich user interface for you to create data factories ad linked services.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>Data Factory Editor<ept id="p1">**</ept>, which is also part of the portal, allows you to easily create linked services, tables, data sets, and pipelines by specifying JSON definitions for these artifacts.</source>
          <target state="new">The <bpt id="p1">**</bpt>Data Factory Editor<ept id="p1">**</ept>, which is also part of the portal, allows you to easily create linked services, tables, data sets, and pipelines by specifying JSON definitions for these artifacts.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory Editor<ept id="p1">][data-factory-editor]</ept> for an overview of the editor and <bpt id="p2">[</bpt>Get started with Data Factory<ept id="p2">][datafactory-getstarted]</ept> for an example of using the portal/editor to create and deploy a data factory.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory Editor<ept id="p1">][data-factory-editor]</ept> for an overview of the editor and <bpt id="p2">[</bpt>Get started with Data Factory<ept id="p2">][datafactory-getstarted]</ept> for an example of using the portal/editor to create and deploy a data factory.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>If you are a PowerShell user and prefer to use PowerShell instead of Portal UI, you can use Azure Data Factory cmdlets that are shipped as part of Azure PowerShell to create and deploy data factories.</source>
          <target state="new">If you are a PowerShell user and prefer to use PowerShell instead of Portal UI, you can use Azure Data Factory cmdlets that are shipped as part of Azure PowerShell to create and deploy data factories.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Create and monitor Azure Data Factory using Azure PowerShell<ept id="p1">][create-data-factory-using-powershell]</ept> for a simple example and <bpt id="p2">[</bpt>Tutorial: Move and process log files using Data Factory<ept id="p2">][adf-tutorial]</ept> for an advanced example of using PowerShell cmdles to create ad deploy a data factory.</source>
          <target state="new">See <bpt id="p1">[</bpt>Create and monitor Azure Data Factory using Azure PowerShell<ept id="p1">][create-data-factory-using-powershell]</ept> for a simple example and <bpt id="p2">[</bpt>Tutorial: Move and process log files using Data Factory<ept id="p2">][adf-tutorial]</ept> for an advanced example of using PowerShell cmdles to create ad deploy a data factory.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory Cmdlet Reference<ept id="p1">][adf-powershell-reference]</ept> content on MSDN Library for a comprehensive documentation of Data Factory cmdlets.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory Cmdlet Reference<ept id="p1">][adf-powershell-reference]</ept> content on MSDN Library for a comprehensive documentation of Data Factory cmdlets.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Visual Studio<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Visual Studio<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>You can also use Visual Studio to programmatically create, monitor, and manage data factories.</source>
          <target state="new">You can also use Visual Studio to programmatically create, monitor, and manage data factories.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Create, monitor, and manage Azure data factories using Data Factory .NET SDK<ept id="p1">](data-factory-create-data-factories-programmatically)</ept> article for details.</source>
          <target state="new">See <bpt id="p1">[</bpt>Create, monitor, and manage Azure data factories using Data Factory .NET SDK<ept id="p1">](data-factory-create-data-factories-programmatically)</ept> article for details.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>.NET Class Library<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>.NET Class Library<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>You can programmatically create data factories by using Data Factory .NET SDK.</source>
          <target state="new">You can programmatically create data factories by using Data Factory .NET SDK.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Create, monitor, and manage data factories using .NET SDK<ept id="p1">][create-factory-using-dotnet-sdk]</ept> for a walkthrough of creating a data factory using .NET SDK.</source>
          <target state="new">See <bpt id="p1">[</bpt>Create, monitor, and manage data factories using .NET SDK<ept id="p1">][create-factory-using-dotnet-sdk]</ept> for a walkthrough of creating a data factory using .NET SDK.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory Class Library Reference<ept id="p1">][msdn-class-library-reference]</ept> for a comprehensive documentation of Data Factory .NET SDK.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory Class Library Reference<ept id="p1">][msdn-class-library-reference]</ept> for a comprehensive documentation of Data Factory .NET SDK.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>REST API<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>REST API<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>You can also use the REST API exposed by the Azure Data Factory service to create and deploy data factories.</source>
          <target state="new">You can also use the REST API exposed by the Azure Data Factory service to create and deploy data factories.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory REST API Reference<ept id="p1">][msdn-rest-api-reference]</ept> for  a comprehensive documentation of Data Factory REST API.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory REST API Reference<ept id="p1">][msdn-rest-api-reference]</ept> for  a comprehensive documentation of Data Factory REST API.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Can I rename a data factory?</source>
          <target state="new">Can I rename a data factory?</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>No.</source>
          <target state="new">No.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Like other Azure resources, the name of an Azure data factory cannot be changed.</source>
          <target state="new">Like other Azure resources, the name of an Azure data factory cannot be changed.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Activities - FAQ</source>
          <target state="new">Activities - FAQ</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>What are the supported data sources and activities?</source>
          <target state="new">What are the supported data sources and activities?</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Movement Activities<ept id="p1">](data-factory-data-movement-activities.md)</ept> and <bpt id="p2">[</bpt>Data Transformation Activities<ept id="p2">](data-factory-data-transformation-activities.md)</ept> articles for the supported data sources and activities.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Movement Activities<ept id="p1">](data-factory-data-movement-activities.md)</ept> and <bpt id="p2">[</bpt>Data Transformation Activities<ept id="p2">](data-factory-data-transformation-activities.md)</ept> articles for the supported data sources and activities.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>When does an activity run?</source>
          <target state="new">When does an activity run?</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>availability<ept id="p1">**</ept> configuration setting in the output data table determines when the activity is run.</source>
          <target state="new">The <bpt id="p1">**</bpt>availability<ept id="p1">**</ept> configuration setting in the output data table determines when the activity is run.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The activity checks whether all the input data dependencies are satisfied (i.e., <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> state) before it starts running.</source>
          <target state="new">The activity checks whether all the input data dependencies are satisfied (i.e., <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> state) before it starts running.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Copy Activity - FAQ</source>
          <target state="new">Copy Activity - FAQ</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Is it better to have a pipeline with multiple activities or a separate pipeline for each activity?</source>
          <target state="new">Is it better to have a pipeline with multiple activities or a separate pipeline for each activity?</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Pipelines are supposed to bundle related activities.</source>
          <target state="new">Pipelines are supposed to bundle related activities.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Logically, you can keep the activities in one pipeline if the tables that connect them are not consumed by any other activity outside the pipeline.</source>
          <target state="new">Logically, you can keep the activities in one pipeline if the tables that connect them are not consumed by any other activity outside the pipeline.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>This way, you would not need to chain pipeline active periods so that they align with each other.</source>
          <target state="new">This way, you would not need to chain pipeline active periods so that they align with each other.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Also, the data integrity in the tables internal to the pipeline will be better preserved when updating the pipeline.</source>
          <target state="new">Also, the data integrity in the tables internal to the pipeline will be better preserved when updating the pipeline.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Pipeline update essentially stops all the activities within the pipeline, removes them, and creates them again.</source>
          <target state="new">Pipeline update essentially stops all the activities within the pipeline, removes them, and creates them again.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>From authoring perspective, it might also be easier to see the flow of data within the related activities in one JSON file for the pipeline.</source>
          <target state="new">From authoring perspective, it might also be easier to see the flow of data within the related activities in one JSON file for the pipeline.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>HDInsight Activity - FAQ</source>
          <target state="new">HDInsight Activity - FAQ</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>What regions are supported by HDInsight?</source>
          <target state="new">What regions are supported by HDInsight?</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>See the Geographic Availability section in the following article: or <bpt id="p1">[</bpt>HDInsight Pricing Details<ept id="p1">][hdinsight-supported-regions]</ept>.</source>
          <target state="new">See the Geographic Availability section in the following article: or <bpt id="p1">[</bpt>HDInsight Pricing Details<ept id="p1">][hdinsight-supported-regions]</ept>.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>What region is used by an on-demand HDInsight cluster?</source>
          <target state="new">What region is used by an on-demand HDInsight cluster?</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>The on-demand HDInsight cluster is created in the same region where the storage you specified to be used with the cluster exists.</source>
          <target state="new">The on-demand HDInsight cluster is created in the same region where the storage you specified to be used with the cluster exists.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>How to associate additional storage accounts to your HDInsight cluster?</source>
          <target state="new">How to associate additional storage accounts to your HDInsight cluster?</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>If you are using your own HDInsight Cluster (BYOC - Bring Your Own Cluster), see the following topics:</source>
          <target state="new">If you are using your own HDInsight Cluster (BYOC - Bring Your Own Cluster), see the following topics:</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Using an HDInsight Cluster with Alternate Storage Accounts and Metastores</source>
          <target state="new">Using an HDInsight Cluster with Alternate Storage Accounts and Metastores</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Use Additional Storage Accounts with HDInsight Hive</source>
          <target state="new">Use Additional Storage Accounts with HDInsight Hive</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>If you are using an on-demand cluster that is created by the Data Factory service, you need to specify additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf.</source>
          <target state="new">If you are using an on-demand cluster that is created by the Data Factory service, you need to specify additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>In the JSON definition for the on-demand linked service, use <bpt id="p1">**</bpt>additionalLinkedServiceNames<ept id="p1">**</ept> property to specify alternate storage accounts as shown in the following JSON snippet:</source>
          <target state="new">In the JSON definition for the on-demand linked service, use <bpt id="p1">**</bpt>additionalLinkedServiceNames<ept id="p1">**</ept> property to specify alternate storage accounts as shown in the following JSON snippet:</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>In the example above, otherLinkedServiceName1 and otherLinkedServiceName2 represent linked services whose definitions contain credentials that the HDInsight cluster needs to access alternate storage accounts.</source>
          <target state="new">In the example above, otherLinkedServiceName1 and otherLinkedServiceName2 represent linked services whose definitions contain credentials that the HDInsight cluster needs to access alternate storage accounts.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Stored Procedure Activity - FAQ</source>
          <target state="new">Stored Procedure Activity - FAQ</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>What data sources does the Stored Procedure Activity support?</source>
          <target state="new">What data sources does the Stored Procedure Activity support?</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The Stored Procedure Activity supports only Azure SQL Database at this time.</source>
          <target state="new">The Stored Procedure Activity supports only Azure SQL Database at this time.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Slices - FAQ</source>
          <target state="new">Slices - FAQ</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>How can I rerun a slice?</source>
          <target state="new">How can I rerun a slice?</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>You can rerun a slice in one of the following ways:</source>
          <target state="new">You can rerun a slice in one of the following ways:</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> in the command bar on the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade for the slice in the portal.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> in the command bar on the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade for the slice in the portal.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Set-AzureDataFactorySliceStatus<ept id="p1">**</ept> cmdlet with Status set to <bpt id="p2">**</bpt>PendingExecution<ept id="p2">**</ept> for the slice.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Set-AzureDataFactorySliceStatus<ept id="p1">**</ept> cmdlet with Status set to <bpt id="p2">**</bpt>PendingExecution<ept id="p2">**</ept> for the slice.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Set-AzureDataFactorySliceStatus<ept id="p1">][set-azure-datafactory-slice-status]</ept> for details about the cmdlet.</source>
          <target state="new">See <bpt id="p1">[</bpt>Set-AzureDataFactorySliceStatus<ept id="p1">][set-azure-datafactory-slice-status]</ept> for details about the cmdlet.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>How long did it take to process a slice?</source>
          <target state="new">How long did it take to process a slice?</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Datasets<ept id="p1">**</ept> tile on the <bpt id="p2">**</bpt>DATA FACTORY<ept id="p2">**</ept> blade for your data factory.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Datasets<ept id="p1">**</ept> tile on the <bpt id="p2">**</bpt>DATA FACTORY<ept id="p2">**</ept> blade for your data factory.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>Click the specific dataset on the <bpt id="p1">**</bpt>Datasets<ept id="p1">**</ept> blade.</source>
          <target state="new">Click the specific dataset on the <bpt id="p1">**</bpt>Datasets<ept id="p1">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Select the slice that you are interested in from the <bpt id="p1">**</bpt>Recent slices<ept id="p1">**</ept> list on the <bpt id="p2">**</bpt>TABLE<ept id="p2">**</ept> blade.</source>
          <target state="new">Select the slice that you are interested in from the <bpt id="p1">**</bpt>Recent slices<ept id="p1">**</ept> list on the <bpt id="p2">**</bpt>TABLE<ept id="p2">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Click the activity run from the <bpt id="p1">**</bpt>Activity Runs<ept id="p1">**</ept> list on the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade.</source>
          <target state="new">Click the activity run from the <bpt id="p1">**</bpt>Activity Runs<ept id="p1">**</ept> list on the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Properties<ept id="p1">**</ept> tile on the <bpt id="p2">**</bpt>ACTIVITY RUN DETAILS<ept id="p2">**</ept> blade.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Properties<ept id="p1">**</ept> tile on the <bpt id="p2">**</bpt>ACTIVITY RUN DETAILS<ept id="p2">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>You should see the <bpt id="p1">**</bpt>DURATION<ept id="p1">**</ept> field with a value.</source>
          <target state="new">You should see the <bpt id="p1">**</bpt>DURATION<ept id="p1">**</ept> field with a value.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>This is the time taken to process the slice.</source>
          <target state="new">This is the time taken to process the slice.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>How to stop a running slice?</source>
          <target state="new">How to stop a running slice?</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>If you need to stop the pipeline from executing, you can use <bpt id="p1">[</bpt>Suspend-AzureDataFactoryPipeline<ept id="p1">](https://msdn.microsoft.com/library/dn834939.aspx)</ept> cmdlet.</source>
          <target state="new">If you need to stop the pipeline from executing, you can use <bpt id="p1">[</bpt>Suspend-AzureDataFactoryPipeline<ept id="p1">](https://msdn.microsoft.com/library/dn834939.aspx)</ept> cmdlet.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Currently, suspending the pipeline does not stop the slice executions that are in progress.</source>
          <target state="new">Currently, suspending the pipeline does not stop the slice executions that are in progress.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Once the in-progress executions finish, no extra slice is picked up.</source>
          <target state="new">Once the in-progress executions finish, no extra slice is picked up.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>If you really want to stop all the executions immediately, the only way would be to delete the pipeline and create it again.</source>
          <target state="new">If you really want to stop all the executions immediately, the only way would be to delete the pipeline and create it again.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>If you choose to delete the pipeline, you do NOT need to delete tables and linked services used by the pipeline.</source>
          <target state="new">If you choose to delete the pipeline, you do NOT need to delete tables and linked services used by the pipeline.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">dd94a4f1152da504c5f1aa0e1bac28dfb04727f7</xliffext:olfilehash>
  </header>
</xliff>