{
  "nodes": [
    {
      "content": "Build a prototype application for Azure Search",
      "pos": [
        28,
        74
      ]
    },
    {
      "content": "Create your first application prototype to get started with Azure Search.",
      "pos": [
        94,
        167
      ]
    },
    {
      "content": "Build a prototype application for Azure Search",
      "pos": [
        475,
        521
      ]
    },
    {
      "content": "Developers who evaluate Azure Search almost always start with a preliminary test application that demonstrates the value of adding Azure Search to a custom application.",
      "pos": [
        523,
        691
      ]
    },
    {
      "content": "In this article, we give you a few building blocks to speed up the prototyping process.",
      "pos": [
        692,
        779
      ]
    },
    {
      "content": "A visual studio C# project that includes data.json and schema.json files.",
      "pos": [
        784,
        857
      ]
    },
    {
      "content": "Having sample data lets you immediately build and run the solution, confirming the solution works on your system before you write one line of code.",
      "pos": [
        858,
        1005
      ]
    },
    {
      "content": "If possible, try to substitute these standalone, disconnected schema and data files with data from your business.",
      "pos": [
        1012,
        1125
      ]
    },
    {
      "content": "Then, when you run the application, the index that gets created is based on your schema, and documents based on your data files, will be immediately available to work with in Azure Search.",
      "pos": [
        1126,
        1314
      ]
    },
    {
      "content": "Guidance on how to structure the data you'll upload to Azure Search.",
      "pos": [
        1318,
        1386
      ]
    },
    {
      "content": "You need one dataset for each  index.",
      "pos": [
        1387,
        1424
      ]
    },
    {
      "content": "Azure Search uses JSON for data serialization.",
      "pos": [
        1425,
        1471
      ]
    },
    {
      "content": "Lastly, we'll point you to a few additional features that will take your prototype to the next level, incorporating search-specific features like faceted navigation, scoring profiles for tuning results, type-ahead or auto-complete queries, and search page-related functionality that isn't available in strictly full-text search alternative.",
      "pos": [
        1475,
        1815
      ]
    },
    {
      "content": "In the end, you will have a prototype application, using your data, to demonstrate a robust search experience using Azure Search.",
      "pos": [
        1817,
        1946
      ]
    },
    {
      "content": "Prepare the data",
      "pos": [
        1952,
        1968
      ]
    },
    {
      "content": "Search operations are performed against a search index that you create on Azure Search.",
      "pos": [
        1970,
        2057
      ]
    },
    {
      "content": "An index has multiple parts, including scoring profiles and suggesters, but the bulk of an index consists of data fields used in search operations.",
      "pos": [
        2058,
        2205
      ]
    },
    {
      "content": "The dataset providing the fields should be a flat data file (in JSON), where each field in your dataset maps to an equivalent field in the index you are trying to populate.",
      "pos": [
        2208,
        2380
      ]
    },
    {
      "content": "Other parts of the index, such as a scoring profile or CORS options, are added independently, directly in the schema.",
      "pos": [
        2381,
        2498
      ]
    },
    {
      "content": "Data sources that use JSON natively, such as as Azure Table Storage, will provide data that is easier to consume than relational data, you will require a single view or table that provides all fields in one rowset.",
      "pos": [
        2500,
        2714
      ]
    },
    {
      "content": "To upload data and schema files using the code in the prototype sample application, you can overwrite the default schema and data files that are embedded in the solution.",
      "pos": [
        2716,
        2886
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You can load multiple data files, perhaps to upload data in batches, but the structure of the data has to be the same for every data file you upload to the same index.",
      "pos": [
        2890,
        3070
      ]
    },
    {
      "content": "You cannot join indexes; each index functions as a standalone search corpus.",
      "pos": [
        3071,
        3147
      ]
    },
    {
      "content": "Test the prototype solution on your system",
      "pos": [
        3152,
        3194
      ]
    },
    {
      "pos": [
        3199,
        3285
      ],
      "content": "<bpt id=\"p1\">[</bpt>Create an Azure Search service in the Azure portal<ept id=\"p1\">](search-create-service-portal.md)</ept>."
    },
    {
      "content": "You can add a shared (free) version of the service to any existing Azure subscription.",
      "pos": [
        3291,
        3377
      ]
    },
    {
      "content": "The shared service is often used for prototypes.",
      "pos": [
        3378,
        3426
      ]
    },
    {
      "content": "Keep in mind that the shared service provides 50 MB of data or 10,000 documents total, whichever comes first.",
      "pos": [
        3427,
        3536
      ]
    },
    {
      "content": "Additionally, data and documents can be spread across a maximum of 3 indexes.",
      "pos": [
        3537,
        3614
      ]
    },
    {
      "content": "Running the prototype sample application, with the built-in sample data files, will create in one index named \"musicstoreindex\", containing 246 documents, at 278 KB on your Azure Search service.",
      "pos": [
        3621,
        3815
      ]
    },
    {
      "content": "Later in this walkthrough, you'll replace this index with a new one using Adventure Works data that will consume up to ## documents and ## MB.",
      "pos": [
        3816,
        3958
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Download the prototype builder solution<ept id=\"p1\">](http://go.microsoft.com/fwlink/p/?LinkId=536479)</ept>.",
      "pos": [
        3963,
        4054
      ]
    },
    {
      "content": "This is a Visual Studio 2013 solution in C# that builds a console application used to create, load, and query an index.",
      "pos": [
        4055,
        4174
      ]
    },
    {
      "content": "If you don't have Visual Studio, you can get the free <bpt id=\"p1\">[</bpt>Visual Studio 2013 Express edition<ept id=\"p1\">](http://www.visualstudio.com/products/visual-studio-express-vs.aspx)</ept> version.",
      "pos": [
        4175,
        4342
      ]
    },
    {
      "content": "Edit app.config to add configuration settings that target your Search service and api-key.",
      "pos": [
        4347,
        4437
      ]
    },
    {
      "content": "You can get the URL and the admin api-key from <bpt id=\"p1\">[</bpt>service dashboard in the portal<ept id=\"p1\">](search-create-service-portal.md)</ept>.",
      "pos": [
        4444,
        4558
      ]
    },
    {
      "content": "For the URL, type the full path of the service name, including the https prefix and the <ph id=\"ph1\">`search.windows.net`</ph> domain.",
      "pos": [
        4559,
        4675
      ]
    },
    {
      "content": "Build the solution to ensure there are no build errors.",
      "pos": [
        4680,
        4735
      ]
    },
    {
      "content": "You might need to update packages to resolve build errors.",
      "pos": [
        4736,
        4794
      ]
    },
    {
      "content": "Right-click <bpt id=\"p1\">**</bpt>Manage NuGet packages<ept id=\"p1\">**</ept> on the solution to update the packages.",
      "pos": [
        4795,
        4872
      ]
    },
    {
      "content": "Run the solution using the built-in schema and data files.",
      "pos": [
        4877,
        4935
      ]
    },
    {
      "content": "This step is optional, but it confirms the solution works before you invest any time into adding your own data.",
      "pos": [
        4936,
        5047
      ]
    },
    {
      "content": "The console outputs the following messages:",
      "pos": [
        5048,
        5091
      ]
    },
    {
      "content": "Index deleted (occurs only if an index of the name \"musicstoreindex\" exists)",
      "pos": [
        5099,
        5175
      ]
    },
    {
      "content": "Index created (a new index named \"musicstoreindex\" is created in your service)",
      "pos": [
        5182,
        5260
      ]
    },
    {
      "content": "Documents posted (one message for each JSON file)",
      "pos": [
        5267,
        5316
      ]
    },
    {
      "content": "Waiting 5 seconds (allows indexing to complete before issuing the first query)",
      "pos": [
        5323,
        5401
      ]
    },
    {
      "content": "Search Results for search term 'best' with no boosting (runs a simple query proving the data is loaded in the index)",
      "pos": [
        5408,
        5524
      ]
    },
    {
      "content": "Stop the application and delete the index to make room for yours.",
      "pos": [
        5529,
        5594
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.TIP]</ph> You can use <bpt id=\"p1\">[</bpt>the portal<ept id=\"p1\">](https://portal.azure.com)</ept> to delete the index.",
      "pos": [
        5603,
        5686
      ]
    },
    {
      "content": "Click the index name to open the index blade and use the <bpt id=\"p1\">**</bpt>Delete<ept id=\"p1\">**</ept> command.",
      "pos": [
        5687,
        5763
      ]
    },
    {
      "content": "Replace the schema and data JSON files with your data",
      "pos": [
        5768,
        5821
      ]
    },
    {
      "content": "In the prototype solution, there is one schema file and three data files: data1.json, data2.json, and data3.json.",
      "pos": [
        5823,
        5936
      ]
    },
    {
      "content": "The schema file (schema.json) should be replaced with a schema that describes your data.",
      "pos": [
        5937,
        6025
      ]
    },
    {
      "content": "By default, these files are located in the solution folder:",
      "pos": [
        6028,
        6087
      ]
    },
    {
      "content": "![][1]",
      "pos": [
        6089,
        6095
      ]
    },
    {
      "content": "If you can get your data into JSON files, you can overwrite the existing files with your data, and then run the application to create and load an index.",
      "pos": [
        6097,
        6249
      ]
    },
    {
      "content": "Distributing data across multiple files helps demonstrate a batch upload operation.",
      "pos": [
        6250,
        6333
      ]
    },
    {
      "content": "Other approaches for loading data include using an indexer (requires either an Azure DocumentDB data source or an Azure SQL Database data source).",
      "pos": [
        6336,
        6482
      ]
    },
    {
      "content": "Sample code that demonstrates additional ways of loading data can be found at <bpt id=\"p1\">[</bpt>Azure Search Video and Tutorials List<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn818681.aspx)</ept> on MSDN.",
      "pos": [
        6483,
        6665
      ]
    },
    {
      "content": "Edit the query",
      "pos": [
        6671,
        6685
      ]
    },
    {
      "content": "The default query built into the solution references fields and structures from the built-in data files.",
      "pos": [
        6687,
        6791
      ]
    },
    {
      "content": "Once you have overwritten the data files to use your data, you can either comment out the query code or modify it to use fields from your schema.",
      "pos": [
        6792,
        6937
      ]
    },
    {
      "content": "For more information on search query syntax, see <bpt id=\"p1\">[</bpt>Search Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn798927.aspx)</ept>.",
      "pos": [
        6938,
        7062
      ]
    },
    {
      "content": "Build and run the application",
      "pos": [
        7068,
        7097
      ]
    },
    {
      "content": "Press <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> to run the app.",
      "pos": [
        7099,
        7127
      ]
    },
    {
      "content": "As before, you should see messages indicating the index is created, loaded, and queryable.",
      "pos": [
        7128,
        7218
      ]
    },
    {
      "content": "You now have an operational index which you can use as the basis for further investigation.",
      "pos": [
        7220,
        7311
      ]
    },
    {
      "pos": [
        7313,
        7575
      ],
      "content": "At this point, you might want to switch to <bpt id=\"p1\">[</bpt>Fiddler<ept id=\"p1\">](search-fiddler.md)</ept> or <bpt id=\"p2\">[</bpt>Chrome Postman<ept id=\"p2\">](search-chrome-postman.md)</ept> to run queries, modify any of the sample applications to use your Search service and index, or add custom code that provides data visualization."
    },
    {
      "content": "Add a scoring profile",
      "pos": [
        7580,
        7601
      ]
    },
    {
      "content": "We suggest that you experiment with <bpt id=\"p1\">[</bpt>scoring profiles<ept id=\"p1\">](search-get-started-scoring-profiles.md)</ept> either through the portal or through code.",
      "pos": [
        7603,
        7740
      ]
    },
    {
      "content": "Scoring profiles boost the importance of a search term being found in a specific field.",
      "pos": [
        7741,
        7828
      ]
    },
    {
      "content": "For example, if the search term is a city name, you would expect documents having <bpt id=\"p1\">*</bpt>Seattle<ept id=\"p1\">*</ept> in the City field to appear higher in the results than documents having the <bpt id=\"p2\">*</bpt>Seattle<ept id=\"p2\">*</ept> in a Description field.",
      "pos": [
        7829,
        8030
      ]
    },
    {
      "content": "Adding a scoring profile changes the index; you will need to rebuild and reload the index whenever you modify the schema.",
      "pos": [
        8032,
        8153
      ]
    },
    {
      "content": "For this reason, consider adding scoring profile code segments to your prototype (or modify scoring profile samples to use your indexing code).",
      "pos": [
        8154,
        8297
      ]
    },
    {
      "pos": [
        8299,
        8429
      ],
      "content": "See <bpt id=\"p1\">[</bpt>Add a scoring profile<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798928.aspx)</ept> for the reference documentation on scoring profiles."
    },
    {
      "content": "Add a suggesters",
      "pos": [
        8434,
        8450
      ]
    },
    {
      "content": "Suggesters refers to the popular search feature that projects a list of possible search terms based on text inputs from the user (typing \"wea\" prompts a list of autocomplete search terms for \"weather\", \"weather channel\", \"weather underground\", and so forth).",
      "pos": [
        8452,
        8710
      ]
    },
    {
      "content": "To add suggesters, add a section to the index schema that specifies which fields are used to build autocomplete or typeahead queries.",
      "pos": [
        8712,
        8845
      ]
    },
    {
      "content": "Fields containing names or shorter strings having non-repetitive values tend to work the best.",
      "pos": [
        8846,
        8940
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Create Index<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798928.aspx)</ept> for more information.",
      "pos": [
        8941,
        9031
      ]
    },
    {
      "content": "Try a language analyzer",
      "pos": [
        9036,
        9059
      ]
    },
    {
      "content": "Language analyzers provide the linguistic rules for distinguishing between essential and non-essential words, root forms, and even synonyms.",
      "pos": [
        9061,
        9201
      ]
    },
    {
      "content": "By default, Azure Search uses the Lucene language analyzer for English.",
      "pos": [
        9202,
        9273
      ]
    },
    {
      "content": "You can specify different analyzers as an index attribute on specific fields, which allows you to build schemas and documents that include fields using different analyzers (for example, a multilingual application might combine French and English fields side by side in the same document).",
      "pos": [
        9274,
        9562
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Language Support<ept id=\"p1\">](https://msdn.microsoft.com/library/dn879793.aspx)</ept> for more details.",
      "pos": [
        9563,
        9653
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        9658,
        9668
      ]
    },
    {
      "content": "In the previous sections, you modified the index to add more functionality to your prototype.",
      "pos": [
        9670,
        9763
      ]
    },
    {
      "content": "At this point, your index changes are mostly complete (we didn't cover enabling CORS, which is the only remaining schema change you could make).",
      "pos": [
        9764,
        9908
      ]
    },
    {
      "content": "Further prototyping will now potentially lead you in two different directions: an outward focus on the UI, perhaps adding faceted navigation or other filters that help narrow the search, or further exploration on the data synchronization aspects of your solution.",
      "pos": [
        9910,
        10173
      ]
    },
    {
      "content": "Many solutions have volatile data.",
      "pos": [
        10174,
        10208
      ]
    },
    {
      "content": "For many developers, synchronizing data updates between transactional database systems and an Azure Search index is the next priority once basic search behaviors are verified.",
      "pos": [
        10209,
        10384
      ]
    },
    {
      "content": "Visit these links to learn more:",
      "pos": [
        10386,
        10418
      ]
    },
    {
      "content": "Typical workflows for development projects using Azure Search",
      "pos": [
        10423,
        10484
      ]
    },
    {
      "content": "Azure Search Indexer Customization",
      "pos": [
        10510,
        10544
      ]
    },
    {
      "content": "Faceted navigation in Azure Search",
      "pos": [
        10584,
        10618
      ]
    },
    {
      "content": "Paging search results in Azure Search",
      "pos": [
        10655,
        10692
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Build a prototype application for Azure Search\" \n    description=\"Create your first application prototype to get started with Azure Search.\" \n    services=\"search\" \n    documentationCenter=\"\" \n    authors=\"HeidiSteen\" \n    manager=\"mblythe\" \n    editor=\"\"/>\n\n<tags \n    ms.service=\"search\" \n    ms.devlang=\"rest-api\" \n    ms.workload=\"search\" \n    ms.topic=\"article\" \n    ms.tgt_pltfrm=\"na\" \n    ms.date=\"07/08/2015\" \n    ms.author=\"heidist\"/>\n\n# Build a prototype application for Azure Search\n\nDevelopers who evaluate Azure Search almost always start with a preliminary test application that demonstrates the value of adding Azure Search to a custom application.\nIn this article, we give you a few building blocks to speed up the prototyping process.\n \n- A visual studio C# project that includes data.json and schema.json files. Having sample data lets you immediately build and run the solution, confirming the solution works on your system before you write one line of code. \n\n    If possible, try to substitute these standalone, disconnected schema and data files with data from your business. Then, when you run the application, the index that gets created is based on your schema, and documents based on your data files, will be immediately available to work with in Azure Search.\n\n- Guidance on how to structure the data you'll upload to Azure Search. You need one dataset for each  index. Azure Search uses JSON for data serialization.\n\n- Lastly, we'll point you to a few additional features that will take your prototype to the next level, incorporating search-specific features like faceted navigation, scoring profiles for tuning results, type-ahead or auto-complete queries, and search page-related functionality that isn't available in strictly full-text search alternative.\n\nIn the end, you will have a prototype application, using your data, to demonstrate a robust search experience using Azure Search. \n\n## Prepare the data\n\nSearch operations are performed against a search index that you create on Azure Search. An index has multiple parts, including scoring profiles and suggesters, but the bulk of an index consists of data fields used in search operations. \n\nThe dataset providing the fields should be a flat data file (in JSON), where each field in your dataset maps to an equivalent field in the index you are trying to populate. Other parts of the index, such as a scoring profile or CORS options, are added independently, directly in the schema.\n\nData sources that use JSON natively, such as as Azure Table Storage, will provide data that is easier to consume than relational data, you will require a single view or table that provides all fields in one rowset.\n\nTo upload data and schema files using the code in the prototype sample application, you can overwrite the default schema and data files that are embedded in the solution.\n\n> [AZURE.NOTE] You can load multiple data files, perhaps to upload data in batches, but the structure of the data has to be the same for every data file you upload to the same index. You cannot join indexes; each index functions as a standalone search corpus.\n\n## Test the prototype solution on your system\n\n1. [Create an Azure Search service in the Azure portal](search-create-service-portal.md).\n\n    You can add a shared (free) version of the service to any existing Azure subscription. The shared service is often used for prototypes. Keep in mind that the shared service provides 50 MB of data or 10,000 documents total, whichever comes first. Additionally, data and documents can be spread across a maximum of 3 indexes. \n\n    Running the prototype sample application, with the built-in sample data files, will create in one index named \"musicstoreindex\", containing 246 documents, at 278 KB on your Azure Search service. Later in this walkthrough, you'll replace this index with a new one using Adventure Works data that will consume up to ## documents and ## MB.\n\n2. [Download the prototype builder solution](http://go.microsoft.com/fwlink/p/?LinkId=536479). This is a Visual Studio 2013 solution in C# that builds a console application used to create, load, and query an index. If you don't have Visual Studio, you can get the free [Visual Studio 2013 Express edition](http://www.visualstudio.com/products/visual-studio-express-vs.aspx) version.\n\n3. Edit app.config to add configuration settings that target your Search service and api-key. \n\n    You can get the URL and the admin api-key from [service dashboard in the portal](search-create-service-portal.md). For the URL, type the full path of the service name, including the https prefix and the `search.windows.net` domain.\n\n4. Build the solution to ensure there are no build errors. You might need to update packages to resolve build errors. Right-click **Manage NuGet packages** on the solution to update the packages.\n\n5. Run the solution using the built-in schema and data files. This step is optional, but it confirms the solution works before you invest any time into adding your own data. The console outputs the following messages:\n\n    - Index deleted (occurs only if an index of the name \"musicstoreindex\" exists)\n    - Index created (a new index named \"musicstoreindex\" is created in your service)\n    - Documents posted (one message for each JSON file)\n    - Waiting 5 seconds (allows indexing to complete before issuing the first query)\n    - Search Results for search term 'best' with no boosting (runs a simple query proving the data is loaded in the index)\n\n6. Stop the application and delete the index to make room for yours. \n\n    > [AZURE.TIP] You can use [the portal](https://portal.azure.com) to delete the index. Click the index name to open the index blade and use the **Delete** command.\n\n## Replace the schema and data JSON files with your data\n\nIn the prototype solution, there is one schema file and three data files: data1.json, data2.json, and data3.json. The schema file (schema.json) should be replaced with a schema that describes your data. \n\nBy default, these files are located in the solution folder:\n\n![][1]\n\nIf you can get your data into JSON files, you can overwrite the existing files with your data, and then run the application to create and load an index. Distributing data across multiple files helps demonstrate a batch upload operation. \n\nOther approaches for loading data include using an indexer (requires either an Azure DocumentDB data source or an Azure SQL Database data source). Sample code that demonstrates additional ways of loading data can be found at [Azure Search Video and Tutorials List](https://msdn.microsoft.com/library/azure/dn818681.aspx) on MSDN.\n\n### Edit the query\n\nThe default query built into the solution references fields and structures from the built-in data files. Once you have overwritten the data files to use your data, you can either comment out the query code or modify it to use fields from your schema. For more information on search query syntax, see [Search Documents](https://msdn.microsoft.com/library/azure/dn798927.aspx).\n\n### Build and run the application\n\nPress **F5** to run the app. As before, you should see messages indicating the index is created, loaded, and queryable.\n\nYou now have an operational index which you can use as the basis for further investigation.\n\nAt this point, you might want to switch to [Fiddler](search-fiddler.md) or [Chrome Postman](search-chrome-postman.md) to run queries, modify any of the sample applications to use your Search service and index, or add custom code that provides data visualization.\n\n## Add a scoring profile\n\nWe suggest that you experiment with [scoring profiles](search-get-started-scoring-profiles.md) either through the portal or through code. Scoring profiles boost the importance of a search term being found in a specific field. For example, if the search term is a city name, you would expect documents having *Seattle* in the City field to appear higher in the results than documents having the *Seattle* in a Description field.\n\nAdding a scoring profile changes the index; you will need to rebuild and reload the index whenever you modify the schema. For this reason, consider adding scoring profile code segments to your prototype (or modify scoring profile samples to use your indexing code).\n\nSee [Add a scoring profile](https://msdn.microsoft.com/library/dn798928.aspx) for the reference documentation on scoring profiles.\n\n## Add a suggesters\n\nSuggesters refers to the popular search feature that projects a list of possible search terms based on text inputs from the user (typing \"wea\" prompts a list of autocomplete search terms for \"weather\", \"weather channel\", \"weather underground\", and so forth).\n\nTo add suggesters, add a section to the index schema that specifies which fields are used to build autocomplete or typeahead queries. Fields containing names or shorter strings having non-repetitive values tend to work the best. See [Create Index](https://msdn.microsoft.com/library/dn798928.aspx) for more information.\n\n## Try a language analyzer\n\nLanguage analyzers provide the linguistic rules for distinguishing between essential and non-essential words, root forms, and even synonyms. By default, Azure Search uses the Lucene language analyzer for English. You can specify different analyzers as an index attribute on specific fields, which allows you to build schemas and documents that include fields using different analyzers (for example, a multilingual application might combine French and English fields side by side in the same document). See [Language Support](https://msdn.microsoft.com/library/dn879793.aspx) for more details.\n\n## Next steps\n\nIn the previous sections, you modified the index to add more functionality to your prototype. At this point, your index changes are mostly complete (we didn't cover enabling CORS, which is the only remaining schema change you could make).\n\nFurther prototyping will now potentially lead you in two different directions: an outward focus on the UI, perhaps adding faceted navigation or other filters that help narrow the search, or further exploration on the data synchronization aspects of your solution. Many solutions have volatile data. For many developers, synchronizing data updates between transactional database systems and an Azure Search index is the next priority once basic search behaviors are verified.\n\nVisit these links to learn more:\n\n- [Typical workflows for development projects using Azure Search](search-workflow.md)\n\n- [Azure Search Indexer Customization](search-indexers-customization.md)\n\n- [Faceted navigation in Azure Search](search-faceted-navigation.md) \n\n- [Paging search results in Azure Search](search-pagination-page-layout.md)\n\n\n<!--Image references-->\n[1]: ./media/search-build-prototype/azsearch-datafiles.png\n "
}