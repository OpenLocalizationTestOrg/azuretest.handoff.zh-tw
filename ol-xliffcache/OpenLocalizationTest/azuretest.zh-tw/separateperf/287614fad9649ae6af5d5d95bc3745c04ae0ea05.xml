{
  "nodes": [
    {
      "content": "Use MapReduce and PowerShell with Hadoop | Microsoft Azure",
      "pos": [
        26,
        84
      ]
    },
    {
      "content": "Learn how to use PowerShell to remotely run MapReduce jobs with Hadoop on HDInsight.",
      "pos": [
        102,
        186
      ]
    },
    {
      "content": "Run Hive queries with Hadoop on HDInsight using PowerShell",
      "pos": [
        503,
        561
      ]
    },
    {
      "content": "This document provides an example of using Azure PowerShell to run a MapReduce job in a Hadoop on HDInsight cluster.",
      "pos": [
        653,
        769
      ]
    },
    {
      "pos": [
        773,
        805
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"prereq\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Prerequisites"
    },
    {
      "content": "To complete the steps in this article, you will need the following:",
      "pos": [
        807,
        874
      ]
    },
    {
      "content": "An Azure HDInsight (Hadoop on HDInsight) cluster (Windows-based or Linux-based)",
      "pos": [
        880,
        959
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>A workstation with Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        965,
        1005
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Install and Configure Azure PowerShell<ept id=\"p1\">](../powershell-install-configure.md)</ept>",
      "pos": [
        1006,
        1086
      ]
    },
    {
      "pos": [
        1090,
        1155
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"powershell\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Run a MapReduce job using Azure PowerShell"
    },
    {
      "content": "Azure PowerShell provides <bpt id=\"p1\">*</bpt>cmdlets<ept id=\"p1\">*</ept> that allow you to remotely run MapReduce jobs on HDInsight.",
      "pos": [
        1157,
        1252
      ]
    },
    {
      "content": "Internally, this is accomplished by using REST calls to <bpt id=\"p1\">[</bpt>WebHCat<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/WebHCat)</ept> (formerly called Templeton) running on the HDInsight cluster.",
      "pos": [
        1253,
        1438
      ]
    },
    {
      "content": "The following cmdlets are used when running MapReduce jobs in a remote HDInsight cluster.",
      "pos": [
        1440,
        1529
      ]
    },
    {
      "pos": [
        1533,
        1612
      ],
      "content": "<bpt id=\"p1\">**</bpt>Add-AzureAccount<ept id=\"p1\">**</ept>: Authenticates Azure PowerShell to your Azure subscription"
    },
    {
      "pos": [
        1616,
        1737
      ],
      "content": "<bpt id=\"p1\">**</bpt>New-AzureHDInsightMapReduceJobDefinition<ept id=\"p1\">**</ept>: Creates a new <bpt id=\"p2\">*</bpt>job definition<ept id=\"p2\">*</ept> by using the specified MapReduce information"
    },
    {
      "pos": [
        1741,
        1899
      ],
      "content": "<bpt id=\"p1\">**</bpt>Start-AzureHDInsightJob<ept id=\"p1\">**</ept>: Sends the job definition to HDInsight, starts the job, and returns a <bpt id=\"p2\">*</bpt>job<ept id=\"p2\">*</ept> object that can be used to check the status of the job"
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Wait-AzureHDInsightJob<ept id=\"p1\">**</ept>: Uses the job object to check the status of the job.",
      "pos": [
        1903,
        1982
      ]
    },
    {
      "content": "It waits until the job completes or the wait time is exceeded.",
      "pos": [
        1983,
        2045
      ]
    },
    {
      "pos": [
        2049,
        2120
      ],
      "content": "<bpt id=\"p1\">**</bpt>Get-AzureHDInsightJobOutput<ept id=\"p1\">**</ept>: Used to retrieve the output of the job"
    },
    {
      "content": "The following steps demonstrate how to use these cmdlets to run a job in your HDInsight cluster.",
      "pos": [
        2122,
        2218
      ]
    },
    {
      "content": "Using an editor, save the following code as <bpt id=\"p1\">**</bpt>mapreducejob.ps1<ept id=\"p1\">**</ept>.",
      "pos": [
        2223,
        2288
      ]
    },
    {
      "content": "You must replace <bpt id=\"p1\">**</bpt>CLUSTERNAME<ept id=\"p1\">**</ept> with the name of your HDInsight cluster.",
      "pos": [
        2289,
        2362
      ]
    },
    {
      "content": "Open a new <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept> command prompt.",
      "pos": [
        3914,
        3961
      ]
    },
    {
      "content": "Change directories to the location of the <bpt id=\"p1\">**</bpt>mapreducejob.ps1<ept id=\"p1\">**</ept> file, then use the following command to run the script:",
      "pos": [
        3962,
        4080
      ]
    },
    {
      "content": "When the job completes, you should receive output similar to the following:",
      "pos": [
        4113,
        4188
      ]
    },
    {
      "content": "This output indicates that the job completed successfully.",
      "pos": [
        4565,
        4623
      ]
    },
    {
      "pos": [
        4631,
        4729
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> If the <bpt id=\"p1\">**</bpt>ExitCode<ept id=\"p1\">**</ept> is a value other than 0, see <bpt id=\"p2\">[</bpt>Troubleshooting<ept id=\"p2\">](#troubleshooting)</ept>."
    },
    {
      "pos": [
        4733,
        4772
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"results\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>View the job output"
    },
    {
      "content": "The MapReduce job stored the results of the operation to Azure Blob storage, in the <bpt id=\"p1\">**</bpt>wasb:///example/data/WordCountOutput<ept id=\"p1\">**</ept> path that was specified as an argument for the job.",
      "pos": [
        4774,
        4950
      ]
    },
    {
      "content": "Azure Blob storage is accessible through Azure PowerShell, but you must know the storage account name, key, and the  container that is used by your HDInsight cluster to directly access the files.",
      "pos": [
        4951,
        5146
      ]
    },
    {
      "content": "Fortunately, you can obtain this information by using the following Azure PowerShell cmdlets:",
      "pos": [
        5148,
        5241
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Get-AzureHDInsightCluster<ept id=\"p1\">**</ept>: Returns information about an HDInsight cluster, including any storage accounts associated with it.",
      "pos": [
        5245,
        5374
      ]
    },
    {
      "content": "There will always be a default storage account associated with a cluster.",
      "pos": [
        5375,
        5448
      ]
    },
    {
      "pos": [
        5451,
        5638
      ],
      "content": "<bpt id=\"p1\">**</bpt>New-AzureStorageContext<ept id=\"p1\">**</ept>: Given the storage account name and key retrieved using <bpt id=\"p2\">**</bpt>Get-AzureHDInsightCluster<ept id=\"p2\">**</ept>, returns a context object that can be used to access the storage account."
    },
    {
      "pos": [
        5641,
        5755
      ],
      "content": "<bpt id=\"p1\">**</bpt>Get-AzureStorageBlob<ept id=\"p1\">**</ept>: Given a context object and container name, returns a list of blobs within the container."
    },
    {
      "pos": [
        5758,
        5946
      ],
      "content": "<bpt id=\"p1\">**</bpt>Get-AzureStorageBlobContent<ept id=\"p1\">**</ept>: Given a context object, a file path and name, and a container name (returned from <bpt id=\"p2\">**</bpt>Get-AzureHDinsightCluster<ept id=\"p2\">**</ept>), downloads a file from Azure Blob storage."
    },
    {
      "content": "The following example retrieves the storage information, then downloads the output from <bpt id=\"p1\">**</bpt>wasb:///example/data/WordCountOutput<ept id=\"p1\">**</ept>.",
      "pos": [
        5948,
        6077
      ]
    },
    {
      "content": "Replace <bpt id=\"p1\">**</bpt>CLUSTERNAME<ept id=\"p1\">**</ept> with the name of your HDInsight cluster.",
      "pos": [
        6078,
        6142
      ]
    },
    {
      "pos": [
        7345,
        7497
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> This example will store the downloaded files to the  <bpt id=\"p1\">**</bpt>example/data/WordCountOutput<ept id=\"p1\">**</ept> folder in the directory that you run the script from."
    },
    {
      "content": "The output of the MapReduce job is stored in files with the name <bpt id=\"p1\">*</bpt>part-r-#####<ept id=\"p1\">*</ept>.",
      "pos": [
        7499,
        7579
      ]
    },
    {
      "content": "Open the <bpt id=\"p1\">**</bpt>example/data/WordCountOutput/part-r-00000<ept id=\"p1\">**</ept> file in a text editor to see the words and counts produced by the job.",
      "pos": [
        7580,
        7705
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The output files of a MapReduce job are immutable.",
      "pos": [
        7709,
        7772
      ]
    },
    {
      "content": "So if you rerun this sample, you need to change the name of the output file.",
      "pos": [
        7773,
        7849
      ]
    },
    {
      "pos": [
        7853,
        7896
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"troubleshooting\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Troubleshooting"
    },
    {
      "content": "If no information is returned when the job completes, an error may have occurred during processing.",
      "pos": [
        7898,
        7997
      ]
    },
    {
      "content": "To view error information for this job, add the following command to the end of the <bpt id=\"p1\">**</bpt>mapreducejob.ps1<ept id=\"p1\">**</ept> file, save it, and then run it again.",
      "pos": [
        7998,
        8140
      ]
    },
    {
      "content": "This returns the information that was written to STDERR on the server when you ran the job, and it may help determine why the job is failing.",
      "pos": [
        8356,
        8497
      ]
    },
    {
      "pos": [
        8501,
        8528
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"summary\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Summary"
    },
    {
      "content": "As you can see, Azure PowerShell provides an easy way to run MapReduce jobs on an HDInsight cluster, monitor the job status, and retrieve the output.",
      "pos": [
        8530,
        8679
      ]
    },
    {
      "pos": [
        8683,
        8715
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Next steps"
    },
    {
      "content": "For general information about MapReduce jobs in HDInsight:",
      "pos": [
        8717,
        8775
      ]
    },
    {
      "content": "Use MapReduce on HDInsight Hadoop",
      "pos": [
        8780,
        8813
      ]
    },
    {
      "content": "For information about other ways you can work with Hadoop on HDInsight:",
      "pos": [
        8844,
        8915
      ]
    },
    {
      "content": "Use Hive with Hadoop on HDInsight",
      "pos": [
        8920,
        8953
      ]
    },
    {
      "content": "Use Pig with Hadoop on HDInsight",
      "pos": [
        8982,
        9014
      ]
    },
    {
      "content": "test",
      "pos": [
        9039,
        9043
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"Use MapReduce and PowerShell with Hadoop | Microsoft Azure\"\n   description=\"Learn how to use PowerShell to remotely run MapReduce jobs with Hadoop on HDInsight.\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"07/06/2015\"\n   ms.author=\"larryfr\"/>\n\n#Run Hive queries with Hadoop on HDInsight using PowerShell\n\n[AZURE.INCLUDE [mapreduce-selector](../../includes/hdinsight-selector-use-mapreduce.md)]\n\nThis document provides an example of using Azure PowerShell to run a MapReduce job in a Hadoop on HDInsight cluster.\n\n##<a id=\"prereq\"></a>Prerequisites\n\nTo complete the steps in this article, you will need the following:\n\n- **An Azure HDInsight (Hadoop on HDInsight) cluster (Windows-based or Linux-based)**\n\n- **A workstation with Azure PowerShell**. See [Install and Configure Azure PowerShell](../powershell-install-configure.md)\n\n##<a id=\"powershell\"></a>Run a MapReduce job using Azure PowerShell\n\nAzure PowerShell provides *cmdlets* that allow you to remotely run MapReduce jobs on HDInsight. Internally, this is accomplished by using REST calls to [WebHCat](https://cwiki.apache.org/confluence/display/Hive/WebHCat) (formerly called Templeton) running on the HDInsight cluster.\n\nThe following cmdlets are used when running MapReduce jobs in a remote HDInsight cluster.\n\n* **Add-AzureAccount**: Authenticates Azure PowerShell to your Azure subscription\n\n* **New-AzureHDInsightMapReduceJobDefinition**: Creates a new *job definition* by using the specified MapReduce information\n\n* **Start-AzureHDInsightJob**: Sends the job definition to HDInsight, starts the job, and returns a *job* object that can be used to check the status of the job\n\n* **Wait-AzureHDInsightJob**: Uses the job object to check the status of the job. It waits until the job completes or the wait time is exceeded.\n\n* **Get-AzureHDInsightJobOutput**: Used to retrieve the output of the job\n\nThe following steps demonstrate how to use these cmdlets to run a job in your HDInsight cluster.\n\n1. Using an editor, save the following code as **mapreducejob.ps1**. You must replace **CLUSTERNAME** with the name of your HDInsight cluster.\n\n        #Login to your Azure subscription\n        # Is there an active Azure subscription?\n        $sub = Get-AzureSubscription -ErrorAction SilentlyContinue\n        if(-not($sub))\n        {\n            Add-AzureAccount\n        }\n\n        #Specify the cluster name\n        $clusterName = \"CLUSTERNAME\"\n\n        #Define the MapReduce job\n        #NOTE: If using an HDInsight 2.0 cluster, use hadoop-examples.jar instead.\n        # -JarFile = the JAR containing the MapReduce application\n        # -ClassName = the class of the application\n        # -Arguments = The input file, and the output directory\n        $wordCountJobDefinition = New-AzureHDInsightMapReduceJobDefinition -JarFile \"wasb:///example/jars/hadoop-mapreduce-examples.jar\" `\n                                  -ClassName \"wordcount\" `\n                                  -Arguments \"wasb:///example/data/gutenberg/davinci.txt\", \"wasb:///example/data/WordCountOutput\"\n\n        #Submit the job to the cluster\n        Write-Host \"Start the MapReduce job...\" -ForegroundColor Green\n        $wordCountJob = Start-AzureHDInsightJob -Cluster $clusterName -JobDefinition $wordCountJobDefinition\n\n        #Wait for the job to complete\n        Write-Host \"Wait for the job to complete...\" -ForegroundColor Green\n        Wait-AzureHDInsightJob -Job $wordCountJob -WaitTimeoutInSeconds 3600\n\n        # Print the output\n        Write-Host \"Display the standard output...\" -ForegroundColor Green\n        Get-AzureHDInsightJobOutput -Cluster $clusterName -JobId $wordCountJob.JobId -StandardOutput\n\n2. Open a new **Azure PowerShell** command prompt. Change directories to the location of the **mapreducejob.ps1** file, then use the following command to run the script:\n\n        .\\mapreducejob.ps1\n\n3. When the job completes, you should receive output similar to the following:\n\n        Cluster         : CLUSTERNAME\n        ExitCode        : 0\n        Name            : wordcount\n        PercentComplete : map 100% reduce 100%\n        Query           :\n        State           : Completed\n        StatusDirectory : f1ed2028-afe8-402f-a24b-13cc17858097\n        SubmissionTime  : 12/5/2014 8:34:09 PM\n        JobId           : job_1415949758166_0071\n\n    This output indicates that the job completed successfully.\n\n    > [AZURE.NOTE] If the **ExitCode** is a value other than 0, see [Troubleshooting](#troubleshooting).\n\n##<a id=\"results\"></a>View the job output\n\nThe MapReduce job stored the results of the operation to Azure Blob storage, in the **wasb:///example/data/WordCountOutput** path that was specified as an argument for the job. Azure Blob storage is accessible through Azure PowerShell, but you must know the storage account name, key, and the  container that is used by your HDInsight cluster to directly access the files.\n\nFortunately, you can obtain this information by using the following Azure PowerShell cmdlets:\n\n* **Get-AzureHDInsightCluster**: Returns information about an HDInsight cluster, including any storage accounts associated with it. There will always be a default storage account associated with a cluster.\n* **New-AzureStorageContext**: Given the storage account name and key retrieved using **Get-AzureHDInsightCluster**, returns a context object that can be used to access the storage account.\n* **Get-AzureStorageBlob**: Given a context object and container name, returns a list of blobs within the container.\n* **Get-AzureStorageBlobContent**: Given a context object, a file path and name, and a container name (returned from **Get-AzureHDinsightCluster**), downloads a file from Azure Blob storage.\n\nThe following example retrieves the storage information, then downloads the output from **wasb:///example/data/WordCountOutput**. Replace **CLUSTERNAME** with the name of your HDInsight cluster.\n\n        #Login to your Azure subscription\n        # Is there an active Azure subscription?\n        $sub = Get-AzureSubscription -ErrorAction SilentlyContinue\n        if(-not($sub))\n        {\n            Add-AzureAccount\n        }\n\n        #Specify the cluster name\n        $clusterName = \"CLUSTERNAME\"\n\n        #Retrieve the cluster information\n        $clusterInfo = Get-AzureHDInsightCluster -ClusterName $clusterName\n\n        #Get the storage account information\n        $storageAccountName = $clusterInfo.DefaultStorageAccount.StorageAccountName\n        $storageAccountKey = $clusterInfo.DefaultStorageAccount.StorageAccountKey\n        $storageContainer = $clusterInfo.DefaultStorageAccount.StorageContainerName\n\n        #Create the context object\n        $context = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey\n\n        #Download the files from wasb:///example/data/WordCountOutput\n        #Use the -blob switch to filter only blobs contained in example/data/WordCountOutput\n        Get-AzureStorageBlob -Container $storageContainer -Blob example/data/WordCountOutput/* -Context $context | Get-AzureStorageBlobContent -Context $context\n\n> [AZURE.NOTE] This example will store the downloaded files to the  **example/data/WordCountOutput** folder in the directory that you run the script from.\n\nThe output of the MapReduce job is stored in files with the name *part-r-#####*. Open the **example/data/WordCountOutput/part-r-00000** file in a text editor to see the words and counts produced by the job.\n\n> [AZURE.NOTE] The output files of a MapReduce job are immutable. So if you rerun this sample, you need to change the name of the output file.\n\n##<a id=\"troubleshooting\"></a>Troubleshooting\n\nIf no information is returned when the job completes, an error may have occurred during processing. To view error information for this job, add the following command to the end of the **mapreducejob.ps1** file, save it, and then run it again.\n\n    # Print the output of the WordCount job.\n    Write-Host \"Display the standard output ...\" -ForegroundColor Green\n    Get-AzureHDInsightJobOutput -Cluster $clusterName -JobId $wordCountJob.JobId -StandardError\n\nThis returns the information that was written to STDERR on the server when you ran the job, and it may help determine why the job is failing.\n\n##<a id=\"summary\"></a>Summary\n\nAs you can see, Azure PowerShell provides an easy way to run MapReduce jobs on an HDInsight cluster, monitor the job status, and retrieve the output.\n\n##<a id=\"nextsteps\"></a>Next steps\n\nFor general information about MapReduce jobs in HDInsight:\n\n* [Use MapReduce on HDInsight Hadoop](hdinsight-use-mapreduce.md)\n\nFor information about other ways you can work with Hadoop on HDInsight:\n\n* [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md)\n\n* [Use Pig with Hadoop on HDInsight](hdinsight-use-pig.md)\n\ntest\n"
}