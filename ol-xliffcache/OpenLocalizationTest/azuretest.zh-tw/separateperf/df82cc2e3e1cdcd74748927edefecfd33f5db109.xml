{
  "nodes": [
    {
      "content": "Data Movement Activities",
      "pos": [
        28,
        52
      ]
    },
    {
      "content": "Learn about Data Factory entities that you can use in an Data Factory pipelines to move data.",
      "pos": [
        72,
        165
      ]
    },
    {
      "content": "Data Movement Activities",
      "pos": [
        493,
        517
      ]
    },
    {
      "content": "Data factory has a <bpt id=\"p1\">[</bpt>globally available service<ept id=\"p1\">](#global)</ept> to support data movement with <bpt id=\"p2\">[</bpt>Copy activity<ept id=\"p2\">](#copyactivity)</ept> across a variety of data stores listed below.",
      "pos": [
        518,
        681
      ]
    },
    {
      "content": "Data factory also has built-in support for <bpt id=\"p1\">[</bpt>securely moving data between on-premises locations and cloud<ept id=\"p1\">](#moveonpremtocloud)</ept> using the data management gateway.",
      "pos": [
        682,
        842
      ]
    },
    {
      "content": "Supported data stores for Copy Activity",
      "pos": [
        847,
        886
      ]
    },
    {
      "content": "Copy activity copies data from a <bpt id=\"p1\">**</bpt>source<ept id=\"p1\">**</ept> data store to a <bpt id=\"p2\">**</bpt>sink<ept id=\"p2\">**</ept> data store.",
      "pos": [
        887,
        967
      ]
    },
    {
      "content": "Data factory supports the following data stores and source, sink combinations.",
      "pos": [
        968,
        1046
      ]
    },
    {
      "content": "Click on a data store to learn how to copy data from/to that store.",
      "pos": [
        1047,
        1114
      ]
    },
    {
      "content": "Source",
      "pos": [
        1120,
        1126
      ]
    },
    {
      "content": "Sink",
      "pos": [
        1133,
        1137
      ]
    },
    {
      "content": "Azure Blob",
      "pos": [
        1163,
        1173
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB, On-premises File System",
      "pos": [
        1215,
        1345
      ]
    },
    {
      "content": "Azure Table",
      "pos": [
        1351,
        1362
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB",
      "pos": [
        1405,
        1510
      ]
    },
    {
      "content": "Azure SQL Database",
      "pos": [
        1516,
        1534
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB",
      "pos": [
        1575,
        1680
      ]
    },
    {
      "content": "Azure DocumentDB",
      "pos": [
        1686,
        1702
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database",
      "pos": [
        1750,
        1793
      ]
    },
    {
      "content": "SQL Server on IaaS",
      "pos": [
        1799,
        1817
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        1858,
        1945
      ]
    },
    {
      "content": "On-premises File System",
      "pos": [
        1951,
        1974
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, On-premises File System",
      "pos": [
        2024,
        2136
      ]
    },
    {
      "content": "On-premises SQL Server",
      "pos": [
        2142,
        2164
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        2205,
        2292
      ]
    },
    {
      "content": "On-premises Oracle Database",
      "pos": [
        2298,
        2325
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        2370,
        2457
      ]
    },
    {
      "content": "On-premises MySQL Database",
      "pos": [
        2463,
        2489
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        2533,
        2620
      ]
    },
    {
      "content": "On-premises DB2 Database",
      "pos": [
        2626,
        2650
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        2692,
        2779
      ]
    },
    {
      "content": "On-premises Teradata Database",
      "pos": [
        2785,
        2814
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        2861,
        2948
      ]
    },
    {
      "content": "On-premises Sybase Database",
      "pos": [
        2954,
        2981
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        3026,
        3113
      ]
    },
    {
      "content": "On-premises PostgreSQL Database",
      "pos": [
        3119,
        3150
      ]
    },
    {
      "content": "Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS",
      "pos": [
        3199,
        3286
      ]
    },
    {
      "pos": [
        3293,
        3333
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"copyactivity\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Copy Activity"
    },
    {
      "content": "Copy activity takes one input dataset (<bpt id=\"p1\">**</bpt>source<ept id=\"p1\">**</ept>) and copies data per activity configuration to one output dataset (<bpt id=\"p2\">**</bpt>sink<ept id=\"p2\">**</ept>).",
      "pos": [
        3334,
        3461
      ]
    },
    {
      "content": "Data copy is done in a batch fashion according to the schedule specified on the activity.",
      "pos": [
        3462,
        3551
      ]
    },
    {
      "pos": [
        3555,
        3790
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> To learn about defining activities in general at a high level such as various JSON sections and properties available for all activities, see <bpt id=\"p1\">[</bpt>Understanding Pipelines &amp; Activities<ept id=\"p1\">](data-factory-create-pipelines.md)</ept> article."
    },
    {
      "content": "Copy activity provides the following capabilities:",
      "pos": [
        3792,
        3842
      ]
    },
    {
      "pos": [
        3848,
        3901
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"global\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Globally available data movement"
    },
    {
      "content": "The data movement service powering copy activity is available globally in the following regions and geographies.",
      "pos": [
        3902,
        4014
      ]
    },
    {
      "content": "The globally available topology ensures efficient data movement avoiding cross-region hops in most cases.",
      "pos": [
        4015,
        4120
      ]
    },
    {
      "content": "Region",
      "pos": [
        4124,
        4130
      ]
    },
    {
      "content": "Geography",
      "pos": [
        4133,
        4142
      ]
    },
    {
      "content": "Central US",
      "pos": [
        4171,
        4181
      ]
    },
    {
      "content": "US",
      "pos": [
        4184,
        4186
      ]
    },
    {
      "content": "East US",
      "pos": [
        4191,
        4198
      ]
    },
    {
      "content": "US",
      "pos": [
        4201,
        4203
      ]
    },
    {
      "content": "East US2",
      "pos": [
        4208,
        4216
      ]
    },
    {
      "content": "US",
      "pos": [
        4219,
        4221
      ]
    },
    {
      "content": "North Central US",
      "pos": [
        4226,
        4242
      ]
    },
    {
      "content": "US",
      "pos": [
        4245,
        4247
      ]
    },
    {
      "content": "South Central US",
      "pos": [
        4252,
        4268
      ]
    },
    {
      "content": "US",
      "pos": [
        4271,
        4273
      ]
    },
    {
      "content": "West US",
      "pos": [
        4278,
        4285
      ]
    },
    {
      "content": "US",
      "pos": [
        4288,
        4290
      ]
    },
    {
      "content": "Brazil South",
      "pos": [
        4295,
        4307
      ]
    },
    {
      "content": "LATAM",
      "pos": [
        4310,
        4315
      ]
    },
    {
      "content": "North Europe",
      "pos": [
        4320,
        4332
      ]
    },
    {
      "content": "EMEA",
      "pos": [
        4335,
        4339
      ]
    },
    {
      "content": "West Europe",
      "pos": [
        4344,
        4355
      ]
    },
    {
      "content": "EMEA",
      "pos": [
        4358,
        4362
      ]
    },
    {
      "content": "Southeast Asia",
      "pos": [
        4367,
        4381
      ]
    },
    {
      "content": "APAC",
      "pos": [
        4384,
        4388
      ]
    },
    {
      "content": "Japan East",
      "pos": [
        4393,
        4403
      ]
    },
    {
      "content": "APAC",
      "pos": [
        4406,
        4410
      ]
    },
    {
      "pos": [
        4418,
        4507
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"moveonpremtocloud\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Securely move data between on-premises location and cloud"
    },
    {
      "content": "One of the challenges for modern data integration is to seamlessly move data to and from on-premises to cloud.",
      "pos": [
        4508,
        4618
      ]
    },
    {
      "content": "Data management gateway is an agent you can install on-premises to enable hybrid data pipelines.",
      "pos": [
        4619,
        4715
      ]
    },
    {
      "content": "The data gateway provides the following capabilities:",
      "pos": [
        4718,
        4771
      ]
    },
    {
      "content": "Manage access to on-premises data stores securely.",
      "pos": [
        4778,
        4828
      ]
    },
    {
      "content": "Model on-premises data stores and cloud data stores within the same data factory and move data.",
      "pos": [
        4833,
        4928
      ]
    },
    {
      "content": "Have a single pane of glass for monitoring and management with visibility into gateway status with data factory cloud based dashboard.",
      "pos": [
        4933,
        5067
      ]
    },
    {
      "pos": [
        5070,
        5185
      ],
      "content": "See <bpt id=\"p1\">[</bpt>Move data between on-premises and cloud<ept id=\"p1\">](data-factory-move-data-between-onprem-and-cloud.md)</ept> for more details."
    },
    {
      "content": "Reliable and cost effective data movement",
      "pos": [
        5191,
        5232
      ]
    },
    {
      "content": "Copy activity is designed to move large volumes of data in a reliable way, resistant to transient errors across a large variety of data sources.",
      "pos": [
        5233,
        5377
      ]
    },
    {
      "content": "Data can be copied in a cost effective way with the option to enable compression over the wire.",
      "pos": [
        5378,
        5473
      ]
    },
    {
      "content": "Type conversions across different type systems",
      "pos": [
        5479,
        5525
      ]
    },
    {
      "content": "Different data stores have different native type systems.",
      "pos": [
        5526,
        5583
      ]
    },
    {
      "content": "Copy activity performs automatic type conversions from source types to sink types with the following 2 step approach:",
      "pos": [
        5584,
        5701
      ]
    },
    {
      "content": "Convert from native source types to .NET type",
      "pos": [
        5706,
        5751
      ]
    },
    {
      "content": "Convert from .NET type to native sink type",
      "pos": [
        5755,
        5797
      ]
    },
    {
      "content": "You can find the mapping for a given native type system to .NET for the data store in the respective data store connector articles.",
      "pos": [
        5799,
        5930
      ]
    },
    {
      "content": "You can use these mappings to determine appropriate types while creating your tables so that right conversions are performed during Copy activity.",
      "pos": [
        5931,
        6077
      ]
    },
    {
      "content": "Working with different file formats",
      "pos": [
        6083,
        6118
      ]
    },
    {
      "content": "For file based sources Copy activity supports variety of file format including binary, text and Avro formats.",
      "pos": [
        6119,
        6228
      ]
    },
    {
      "content": "Copy Activity Properties",
      "pos": [
        6234,
        6258
      ]
    },
    {
      "content": "Properties like name, description, input and output tables, various policies etc are available for all types of activities.",
      "pos": [
        6259,
        6382
      ]
    },
    {
      "content": "Properties available in the <bpt id=\"p1\">**</bpt>typeProperties<ept id=\"p1\">**</ept> section of the activity on the other hand vary with each activity type.",
      "pos": [
        6383,
        6501
      ]
    },
    {
      "content": "In case of Copy activity the <bpt id=\"p1\">**</bpt>typeProperties<ept id=\"p1\">**</ept> section varies depending on the types of sources and sinks.",
      "pos": [
        6504,
        6611
      ]
    },
    {
      "content": "Each of the data store specific page listed above documents these properties specific to the data store type.",
      "pos": [
        6612,
        6721
      ]
    },
    {
      "content": "Send Feedback",
      "pos": [
        6727,
        6740
      ]
    },
    {
      "content": "We would really appreciate your feedback on this article.",
      "pos": [
        6741,
        6798
      ]
    },
    {
      "content": "Please take a few minutes to submit your feedback via <bpt id=\"p1\">[</bpt>email<ept id=\"p1\">](mailto:adfdocfeedback@microsoft.com?subject=data-factory-data-movement-activities.md)</ept>.",
      "pos": [
        6799,
        6947
      ]
    },
    {
      "content": "test",
      "pos": [
        6949,
        6953
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Data Movement Activities\" \n    description=\"Learn about Data Factory entities that you can use in an Data Factory pipelines to move data.\" \n    services=\"data-factory\" \n    documentationCenter=\"\" \n    authors=\"spelluru\" \n    manager=\"jhubbard\" \n    editor=\"monicar\"/>\n\n<tags \n    ms.service=\"data-factory\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"07/29/2015\" \n    ms.author=\"spelluru\"/>\n\n# Data Movement Activities\nData factory has a [globally available service](#global) to support data movement with [Copy activity](#copyactivity) across a variety of data stores listed below. Data factory also has built-in support for [securely moving data between on-premises locations and cloud](#moveonpremtocloud) using the data management gateway.\n\n## Supported data stores for Copy Activity\nCopy activity copies data from a **source** data store to a **sink** data store. Data factory supports the following data stores and source, sink combinations. Click on a data store to learn how to copy data from/to that store.\n\n| **Source** | **Sink** |\n| ------ | ---- |\n| [Azure Blob](data-factory-azure-blob-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB, On-premises File System |\n| [Azure Table](data-factory-azure-table-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB |\n| [Azure SQL Database](data-factory-azure-sql-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, Azure DocumentDB |\n| [Azure DocumentDB](data-factory-azure-documentdb-connector.md) | Azure Blob, Azure Table, Azure SQL Database |\n| [SQL Server on IaaS](data-factory-sqlserver-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises File System](data-factory-onprem-file-system-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS, On-premises File System |\n| [On-premises SQL Server](data-factory-sqlserver-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises Oracle Database](data-factory-onprem-oracle-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises MySQL Database](data-factory-onprem-mysql-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises DB2 Database](data-factory-onprem-db2-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises Teradata Database](data-factory-onprem-teradata-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises Sybase Database](data-factory-onprem-sybase-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n| [On-premises PostgreSQL Database](data-factory-onprem-postgresql-connector.md) | Azure Blob, Azure Table, Azure SQL Database, On-premises SQL Server, SQL Server on IaaS |\n\n## <a name=\"copyactivity\"></a>Copy Activity\nCopy activity takes one input dataset (**source**) and copies data per activity configuration to one output dataset (**sink**). Data copy is done in a batch fashion according to the schedule specified on the activity.\n\n> [AZURE.NOTE] To learn about defining activities in general at a high level such as various JSON sections and properties available for all activities, see [Understanding Pipelines & Activities](data-factory-create-pipelines.md) article.\n\nCopy activity provides the following capabilities:\n\n### <a name=\"global\"></a>Globally available data movement\nThe data movement service powering copy activity is available globally in the following regions and geographies. The globally available topology ensures efficient data movement avoiding cross-region hops in most cases.\n\n| Region | Geography |\n| ------ | --------- | \n| Central US | US |\n| East US | US |\n| East US2 | US |\n| North Central US | US |\n| South Central US | US |\n| West US | US |\n| Brazil South | LATAM |\n| North Europe | EMEA |\n| West Europe | EMEA |\n| Southeast Asia | APAC |\n| Japan East | APAC |\n\n### <a name=\"moveonpremtocloud\"></a>Securely move data between on-premises location and cloud\nOne of the challenges for modern data integration is to seamlessly move data to and from on-premises to cloud. Data management gateway is an agent you can install on-premises to enable hybrid data pipelines. \n\nThe data gateway provides the following capabilities: \n\n1.  Manage access to on-premises data stores securely.\n2.  Model on-premises data stores and cloud data stores within the same data factory and move data.\n3.  Have a single pane of glass for monitoring and management with visibility into gateway status with data factory cloud based dashboard.\n\n\nSee [Move data between on-premises and cloud](data-factory-move-data-between-onprem-and-cloud.md) for more details.\n\n### Reliable and cost effective data movement\nCopy activity is designed to move large volumes of data in a reliable way, resistant to transient errors across a large variety of data sources. Data can be copied in a cost effective way with the option to enable compression over the wire.\n\n### Type conversions across different type systems\nDifferent data stores have different native type systems. Copy activity performs automatic type conversions from source types to sink types with the following 2 step approach:\n\n1. Convert from native source types to .NET type\n2. Convert from .NET type to native sink type\n\nYou can find the mapping for a given native type system to .NET for the data store in the respective data store connector articles. You can use these mappings to determine appropriate types while creating your tables so that right conversions are performed during Copy activity.\n\n### Working with different file formats\nFor file based sources Copy activity supports variety of file format including binary, text and Avro formats.\n\n### Copy Activity Properties\nProperties like name, description, input and output tables, various policies etc are available for all types of activities. Properties available in the **typeProperties** section of the activity on the other hand vary with each activity type. \n\nIn case of Copy activity the **typeProperties** section varies depending on the types of sources and sinks. Each of the data store specific page listed above documents these properties specific to the data store type.\n\n\n## Send Feedback\nWe would really appreciate your feedback on this article. Please take a few minutes to submit your feedback via [email](mailto:adfdocfeedback@microsoft.com?subject=data-factory-data-movement-activities.md). \ntest\n"
}