{
  "nodes": [
    {
      "content": "Detect, Triage, Diagnose",
      "pos": [
        27,
        51
      ]
    },
    {
      "content": "Analyse crashes and detect  and diagnose performance issues in your applications",
      "pos": [
        70,
        150
      ]
    },
    {
      "content": "Detect, Triage and Diagnose with Application Insights",
      "pos": [
        458,
        511
      ]
    },
    {
      "content": "Application Insights is in preview.",
      "pos": [
        514,
        549
      ]
    },
    {
      "content": "After you've published your application, Application Insights helps you make sure it's running OK and performing well.",
      "pos": [
        553,
        671
      ]
    },
    {
      "content": "If there's a problem, you want to know about it soon, and then you want to know what to do about it.",
      "pos": [
        672,
        772
      ]
    },
    {
      "content": "\"A couple of days ago, we deployed a 'minor' hotfix.",
      "pos": [
        777,
        829
      ]
    },
    {
      "content": "We didn't run a broad test pass, but unfortunately some unexpected change got merged into the payload, causing incompatibility between the front and back ends.",
      "pos": [
        830,
        989
      ]
    },
    {
      "content": "Immediately, server exceptions surged, our alert fired, and we were made aware of the situation.",
      "pos": [
        990,
        1086
      ]
    },
    {
      "content": "A few clicks away on the Application Insights portal, we got enough information from exception callstacks to narrow down the problem.",
      "pos": [
        1087,
        1220
      ]
    },
    {
      "content": "We rolled back immediately and limited the damage.",
      "pos": [
        1221,
        1271
      ]
    },
    {
      "content": "Application Insights has made this part of the devops cycle very easy and actionable.\"",
      "pos": [
        1272,
        1358
      ]
    },
    {
      "content": "We can think of this part of the devops cycle as a pipeline:",
      "pos": [
        1361,
        1421
      ]
    },
    {
      "content": "Detect-Triage-Diagnose",
      "pos": [
        1425,
        1447
      ]
    },
    {
      "content": "Once you've diagnosed the problem, you know where to focus your efforts - whether it's debugging your code, allocating more memory, or following up with a dependency.",
      "pos": [
        1509,
        1675
      ]
    },
    {
      "content": "Finally, you can check that your fix has worked:",
      "pos": [
        1676,
        1724
      ]
    },
    {
      "content": "Repair-Validate",
      "pos": [
        1730,
        1745
      ]
    },
    {
      "content": "Let's see how Application Insights works at each stage of the pipeline.",
      "pos": [
        1807,
        1878
      ]
    },
    {
      "content": "Application Insights works for devices apps and web applications.",
      "pos": [
        1880,
        1945
      ]
    },
    {
      "content": "In this walkthrough, we'll focus on a web application.",
      "pos": [
        1946,
        2000
      ]
    },
    {
      "content": "We'll follow the OBS team in Fabrikam Bank, who are responsible for the online banking system.",
      "pos": [
        2001,
        2095
      ]
    },
    {
      "content": "They have added Application Insights to their web projects.",
      "pos": [
        2096,
        2155
      ]
    },
    {
      "content": "Example bank web site",
      "pos": [
        2162,
        2183
      ]
    },
    {
      "content": "Detect poor availability",
      "pos": [
        2248,
        2272
      ]
    },
    {
      "content": "Marcela Markova is a test specialist on the OBS team, and takes the lead on monitoring online performance.",
      "pos": [
        2275,
        2381
      ]
    },
    {
      "content": "She sets up several [web tests][availability]:",
      "pos": [
        2382,
        2428
      ]
    },
    {
      "content": "A single-URL test for the main landing page for the app, http://fabrikambank.com/onlinebanking/.",
      "pos": [
        2432,
        2528
      ]
    },
    {
      "content": "She sets criteria of HTTP code 200 and text 'Welcome!'.",
      "pos": [
        2529,
        2584
      ]
    },
    {
      "content": "If this test fails, there's something seriously wrong with the network or the servers, or maybe a deployment issue.",
      "pos": [
        2585,
        2700
      ]
    },
    {
      "content": "(Or someone has changed the Welcome!",
      "pos": [
        2701,
        2737
      ]
    },
    {
      "content": "message on the page without letting her know.)",
      "pos": [
        2738,
        2784
      ]
    },
    {
      "content": "A deeper multi-step test, which logs in and gets a current account listing, checking a few key details on each page.",
      "pos": [
        2789,
        2905
      ]
    },
    {
      "content": "This test verifies that the link to the accounts database is working.",
      "pos": [
        2906,
        2975
      ]
    },
    {
      "content": "She uses a fictitious customer id: a few of them are maintained for test purposes.",
      "pos": [
        2976,
        3058
      ]
    },
    {
      "content": "With these tests set up, Marcela is confident that the team will quickly know about any outage.",
      "pos": [
        3061,
        3156
      ]
    },
    {
      "content": "Failures show up as red dots on the web test chart:",
      "pos": [
        3161,
        3212
      ]
    },
    {
      "content": "Display of web tests that have run over the preceding period",
      "pos": [
        3216,
        3276
      ]
    },
    {
      "content": "But more importantly, an alert about any failure will be emailed to the development team.",
      "pos": [
        3341,
        3430
      ]
    },
    {
      "content": "In that way, they know about it before nearly all of the customers.",
      "pos": [
        3431,
        3498
      ]
    },
    {
      "content": "Monitor performance metrics",
      "pos": [
        3504,
        3531
      ]
    },
    {
      "content": "On the overview page in Application Insights, there's a chart that shows a variety of [key metrics][perf].",
      "pos": [
        3534,
        3640
      ]
    },
    {
      "content": "Various metrics",
      "pos": [
        3644,
        3659
      ]
    },
    {
      "content": "Browser page load time is derived from telemetry sent directly from web pages.",
      "pos": [
        3726,
        3804
      ]
    },
    {
      "content": "Server response time, server request count and failed request count are all measured in the web server and sent to Application Insights from there.",
      "pos": [
        3805,
        3952
      ]
    },
    {
      "content": "The Failed Request count indicates cases where users have seen an error - typically following an exception thrown in the code.",
      "pos": [
        3955,
        4081
      ]
    },
    {
      "content": "Maybe they see a message saying \"Sorry we couldn't update your details right now\" or, at absolute embarrassing worst, a stack dump on the user's screen, courtesy of the web server.",
      "pos": [
        4082,
        4262
      ]
    },
    {
      "content": "Marcela likes to look at these charts from time to time.",
      "pos": [
        4265,
        4321
      ]
    },
    {
      "content": "The absence of failed requests is encouraging, although when she changes the range of the chart to cover the past week, occasional failures appear.",
      "pos": [
        4322,
        4469
      ]
    },
    {
      "content": "This is an acceptable level in a busy server.",
      "pos": [
        4470,
        4515
      ]
    },
    {
      "content": "But if there is a sudden jump in failures, or in some of the other metrics such as server response time, Marcela wants to know about it immediately.",
      "pos": [
        4517,
        4665
      ]
    },
    {
      "content": "It might indicate an unforeseen problem caused by a code release, or a failure in a dependency such as a database, or maybe an ungraceful reaction to a high load of requests.",
      "pos": [
        4666,
        4840
      ]
    },
    {
      "content": "Alerts",
      "pos": [
        4847,
        4853
      ]
    },
    {
      "content": "So she sets two [alerts][metrics]: one for response times greater than a typical threshold, and another for a rate of failed requests greater than the current background.",
      "pos": [
        4855,
        5025
      ]
    },
    {
      "content": "Together with the availability alert, these give her confidence that she'll know about it as soon as anything unusual happens.",
      "pos": [
        5028,
        5154
      ]
    },
    {
      "content": "It's also possible to set alerts on a wide variety of other metrics.",
      "pos": [
        5159,
        5227
      ]
    },
    {
      "content": "For example, you can receive emails if the exception count becomes high, or the available memory goes low, or if there is a peak in client requests.",
      "pos": [
        5228,
        5376
      ]
    },
    {
      "content": "Add alert blade",
      "pos": [
        5382,
        5397
      ]
    },
    {
      "content": "Detecting exceptions",
      "pos": [
        5465,
        5485
      ]
    },
    {
      "content": "With a little bit of setup, <bpt id=\"p1\">[</bpt>exceptions<ept id=\"p1\">](app-insights-asp-net-exceptions.md)</ept> are reported to Application Insights automatically.",
      "pos": [
        5488,
        5616
      ]
    },
    {
      "content": "They can also be captured explicitly by inserting calls to <bpt id=\"p1\">[</bpt>TrackException()<ept id=\"p1\">](app-insights-api-custom-events-metrics.md#track-exception)</ept> into the code:",
      "pos": [
        5617,
        5768
      ]
    },
    {
      "content": "The Fabrikam Bank team has evolved the practice of always sending telemetry on an exception, unless there's an obvious recovery.",
      "pos": [
        6225,
        6353
      ]
    },
    {
      "content": "In fact, their strategy is even broader than that: They send telemetry in every case where the customer is frustrated in what they wanted to do, whether it corresponds to an exception in the code or not.",
      "pos": [
        6357,
        6560
      ]
    },
    {
      "content": "For example, if the external inter-bank transfer system returns a \"can't complete this transaction\" message for some operational reason (no fault of the customer) then they track that event.",
      "pos": [
        6561,
        6751
      ]
    },
    {
      "content": "TrackException is used to report exceptions because it sends a copy of the stack; TrackEvent is used to report other events.",
      "pos": [
        7120,
        7244
      ]
    },
    {
      "content": "You can attach any properties that might be useful in diagnosis.",
      "pos": [
        7245,
        7309
      ]
    },
    {
      "content": "Exceptions and events show up in the [Diagnostic Search][diagnostic] blade.",
      "pos": [
        7311,
        7386
      ]
    },
    {
      "content": "You can drill into them to see the additional properties and stack trace.",
      "pos": [
        7387,
        7460
      ]
    },
    {
      "content": "In Diagnostic Search, use filters to show particular types of data",
      "pos": [
        7464,
        7530
      ]
    },
    {
      "content": "Monitoring user activity",
      "pos": [
        7607,
        7631
      ]
    },
    {
      "content": "When response time is consistently good and there are few exceptions, the dev team can think about how to improve the users' experience, and how to encourage more users to achieve the desired goals.",
      "pos": [
        7633,
        7831
      ]
    },
    {
      "content": "For example, a typical user journey through the web site has a clear 'funnel': Many customers look at the rates of different types of loan; some of them fill in the quotation form; and of those who get a quotation, a few go ahead and take out the loan.",
      "pos": [
        7834,
        8086
      ]
    },
    {
      "content": "By considering where the greatest numbers of customers drop out, the business can work out how to get more users through to the bottom of the funnel.",
      "pos": [
        8152,
        8301
      ]
    },
    {
      "content": "In some cases there might be a user experience (UX) failure - for example, the 'next' button is hard to find, or the instructions aren't obvious.",
      "pos": [
        8302,
        8447
      ]
    },
    {
      "content": "More likely, there are more significant business reasons for drop-outs: maybe the loan rates are too high.",
      "pos": [
        8448,
        8554
      ]
    },
    {
      "content": "Whatever the reasons, the data helps the team work out what users are doing.",
      "pos": [
        8556,
        8632
      ]
    },
    {
      "content": "More tracking calls can be inserted to work out more detail.",
      "pos": [
        8633,
        8693
      ]
    },
    {
      "content": "TrackEvent() can be used to count any user actions, from the fine detail of individual button clicks to significant achievements such as paying off a loan.",
      "pos": [
        8694,
        8849
      ]
    },
    {
      "content": "The team is getting used to having information about user activity.",
      "pos": [
        8851,
        8918
      ]
    },
    {
      "content": "Nowadays, whenever they design a new feature, they work out how they will get feedback about its usage.",
      "pos": [
        8919,
        9022
      ]
    },
    {
      "content": "They design tracking calls into the feature from the start.",
      "pos": [
        9023,
        9082
      ]
    },
    {
      "content": "They use the feedback to improve the feature in each development cycle.",
      "pos": [
        9083,
        9154
      ]
    },
    {
      "content": "Proactive monitoring",
      "pos": [
        9160,
        9180
      ]
    },
    {
      "content": "Marcela doesn't just sit around waiting for alerts.",
      "pos": [
        9185,
        9236
      ]
    },
    {
      "content": "Soon after every redeployment, she takes a look at [response times][perf] - both the overall figure and the table of slowest requests, as well as exception counts.",
      "pos": [
        9237,
        9400
      ]
    },
    {
      "content": "Response time graph and grid of server response times.",
      "pos": [
        9408,
        9462
      ]
    },
    {
      "content": "She can assess the performance effect of every deployment, typically comparing each week with the last.",
      "pos": [
        9530,
        9633
      ]
    },
    {
      "content": "If there's a sudden worsening, she raises that with the relevant developers.",
      "pos": [
        9634,
        9710
      ]
    },
    {
      "content": "Triage",
      "pos": [
        9716,
        9722
      ]
    },
    {
      "content": "Triage - assessing the severity and extent of a problem - is the first step after detection.",
      "pos": [
        9725,
        9817
      ]
    },
    {
      "content": "Should we call out the team at midnight?",
      "pos": [
        9818,
        9858
      ]
    },
    {
      "content": "Or can it be left until the next convenient gap in the backlog?",
      "pos": [
        9859,
        9922
      ]
    },
    {
      "content": "There are some key questions in triage.",
      "pos": [
        9923,
        9962
      ]
    },
    {
      "content": "How much is it happening?",
      "pos": [
        9965,
        9990
      ]
    },
    {
      "content": "The charts on the Overview blade give some perspective to a problem.",
      "pos": [
        9991,
        10059
      ]
    },
    {
      "content": "For example, the Fabrikam application generated four web test alerts one night.",
      "pos": [
        10060,
        10139
      ]
    },
    {
      "content": "Looking at the chart in the morning, the team could see that there were indeed some red dots, though still most of the tests were green.",
      "pos": [
        10140,
        10276
      ]
    },
    {
      "content": "Drilling into the availability chart, it was clear that all of these intermittent problems were from one test location.",
      "pos": [
        10277,
        10396
      ]
    },
    {
      "content": "This was obviously a network issue affecting only one route, and would most likely clear itself.",
      "pos": [
        10397,
        10493
      ]
    },
    {
      "content": "By contrast, a dramatic and stable rise in the graph of exception counts or response times is obviously something to panic about.",
      "pos": [
        10498,
        10627
      ]
    },
    {
      "content": "A useful triage tactic is Try It Yourself.",
      "pos": [
        10630,
        10672
      ]
    },
    {
      "content": "If you run into the same problem, you know it's real.",
      "pos": [
        10673,
        10726
      ]
    },
    {
      "content": "What fraction of users are affected?",
      "pos": [
        10729,
        10765
      ]
    },
    {
      "content": "To obtain a rough answer, divide the failure rate by the session count.",
      "pos": [
        10766,
        10837
      ]
    },
    {
      "content": "Charts of failed requests and sessions",
      "pos": [
        10842,
        10880
      ]
    },
    {
      "content": "In the case of slow response, compare the table of slowest-responding requests with the usage frequency of each page.",
      "pos": [
        10947,
        11064
      ]
    },
    {
      "content": "How important is the blocked scenario?",
      "pos": [
        11067,
        11105
      ]
    },
    {
      "content": "If this is a functional problem blocking a particular user story, does it matter much?",
      "pos": [
        11106,
        11192
      ]
    },
    {
      "content": "If customers can't pay their bills, this is serious; if they can't change their screen color preferences, maybe it can wait.",
      "pos": [
        11193,
        11317
      ]
    },
    {
      "content": "The detail of the event or exception, or the identity of the slow page, tells you where customers are having trouble.",
      "pos": [
        11318,
        11435
      ]
    },
    {
      "content": "Diagnosis",
      "pos": [
        11441,
        11450
      ]
    },
    {
      "content": "Diagnosis isn't quite the same as debugging.",
      "pos": [
        11453,
        11497
      ]
    },
    {
      "content": "Before you start tracing through the code, you should have a rough idea of why, where and when the issue is occurring.",
      "pos": [
        11498,
        11616
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>When does it happen?<ept id=\"p1\">**</ept> The historical view provided by the event and metric charts makes it easy to correlate effects with possible causes.",
      "pos": [
        11619,
        11760
      ]
    },
    {
      "content": "If there are intermittent peaks in response time or exception rates, look at the request count: if it peaks at the same time, then it looks like a resource problem.",
      "pos": [
        11761,
        11925
      ]
    },
    {
      "content": "Do you need to assign more CPU or memory?",
      "pos": [
        11926,
        11967
      ]
    },
    {
      "content": "Or is it a dependency that can't manage the load?",
      "pos": [
        11968,
        12017
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Is it us?<ept id=\"p1\">**</ept>  If you have a sudden drop in performance of a particular type of request - for example when the customer wants an account statement - then there's a possibility it might be an external subsystem rather than your web application.",
      "pos": [
        12020,
        12263
      ]
    },
    {
      "content": "In Metrics Explorer, select the Dependency Failure rate and Dependency Duration rates and compare their histories over the past few hours or days with the problem you detected.",
      "pos": [
        12264,
        12440
      ]
    },
    {
      "content": "If there are correlating changes, then an external subsystem might be to blame.",
      "pos": [
        12441,
        12520
      ]
    },
    {
      "content": "Charts of dependency failure and duration of calls to dependencies",
      "pos": [
        12527,
        12593
      ]
    },
    {
      "content": "Some slow dependency issues are geolocation problems.",
      "pos": [
        12661,
        12714
      ]
    },
    {
      "content": "Fabrikam Bank uses Azure virtual machines, and discovered that they had inadvertently located their web server and account server in different countries.",
      "pos": [
        12715,
        12868
      ]
    },
    {
      "content": "A dramatic improvement was brought about by migrating one of them.",
      "pos": [
        12869,
        12935
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>What did we do?<ept id=\"p1\">**</ept> If the issue doesn't appear to be in a dependency, and if it wasn't always there, it's probably caused by a recent change.",
      "pos": [
        12938,
        13080
      ]
    },
    {
      "content": "The historical perspective provided by the metric and event charts makes it easy to correlate any sudden changes with deployments.",
      "pos": [
        13081,
        13211
      ]
    },
    {
      "content": "That narrows down the search for the problem.",
      "pos": [
        13212,
        13257
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>What's going on?<ept id=\"p1\">**</ept> Some problems occur only rarely and can be difficult to track down by testing offline.",
      "pos": [
        13260,
        13367
      ]
    },
    {
      "content": "All we can do is to try to capture the bug when it occurs live.",
      "pos": [
        13368,
        13431
      ]
    },
    {
      "content": "You can inspect the stack dumps in exception reports.",
      "pos": [
        13432,
        13485
      ]
    },
    {
      "content": "In addition, you can write tracing calls, either with your favourite logging framework or with TrackTrace() or TrackEvent().",
      "pos": [
        13486,
        13610
      ]
    },
    {
      "content": "Fabrikam had an intermittent problem with inter-account transfers, but only with certain account types.",
      "pos": [
        13615,
        13718
      ]
    },
    {
      "content": "To understand better what was happening, they inserted TrackTrace() calls at key points in the code, attaching the account type as a property to each call.",
      "pos": [
        13719,
        13874
      ]
    },
    {
      "content": "That made it easy to filter out just those traces in Diagnostic Search.",
      "pos": [
        13875,
        13946
      ]
    },
    {
      "content": "They also attached parameter values as properties and measures to the trace calls.",
      "pos": [
        13947,
        14029
      ]
    },
    {
      "content": "Dealing with it",
      "pos": [
        14035,
        14050
      ]
    },
    {
      "content": "Once you've diagnosed the issue, you can make a plan to fix it.",
      "pos": [
        14053,
        14116
      ]
    },
    {
      "content": "Maybe you need to roll back a recent change, or maybe you can just go ahead and fix it.",
      "pos": [
        14117,
        14204
      ]
    },
    {
      "content": "Once the fix is done, Application Insights will tell you whether you succeeded.",
      "pos": [
        14205,
        14284
      ]
    },
    {
      "content": "Fabrikam Bank's development team take a more structured approach to performance measurement than they used to before they used Application Insights.",
      "pos": [
        14289,
        14437
      ]
    },
    {
      "content": "They set performance targets in terms of specific measures in the Application Insights overview page.",
      "pos": [
        14441,
        14542
      ]
    },
    {
      "content": "They design performance measures into the application from the start, such as the metrics that measure user progress through 'funnels.'",
      "pos": [
        14546,
        14681
      ]
    },
    {
      "content": "Usage",
      "pos": [
        14691,
        14696
      ]
    },
    {
      "content": "Application Insights can also be used to learn what users do with an app.",
      "pos": [
        14698,
        14771
      ]
    },
    {
      "content": "Once it's running smoothly, the team would like to know which features are the most popular, what users like or have difficulty with, and how often they come back.",
      "pos": [
        14772,
        14935
      ]
    },
    {
      "content": "That will help them prioritize their upcoming work.",
      "pos": [
        14936,
        14987
      ]
    },
    {
      "content": "And they can plan to measure the success of each feature as part of the development cycle.",
      "pos": [
        14988,
        15078
      ]
    },
    {
      "content": "[Read more][usage].",
      "pos": [
        15079,
        15098
      ]
    },
    {
      "content": "Your applications",
      "pos": [
        15103,
        15120
      ]
    },
    {
      "content": "So that's how one team use Application Insights not just to fix individual issues, but to improve their development lifecycle.",
      "pos": [
        15122,
        15248
      ]
    },
    {
      "content": "I hope it has given you some ideas about how Application Insights can help you improve the performance of your own applications.",
      "pos": [
        15249,
        15377
      ]
    },
    {
      "content": "Video",
      "pos": [
        15382,
        15387
      ]
    },
    {
      "content": "test",
      "pos": [
        15766,
        15770
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Detect, Triage, Diagnose\"\n    description=\"Analyse crashes and detect  and diagnose performance issues in your applications\"\n    authors=\"alancameronwills\"\n    services=\"application-insights\"\n    documentationCenter=\"\"\n    manager=\"douge\"/>\n\n<tags\n    ms.service=\"application-insights\"\n    ms.workload=\"tbd\"\n    ms.tgt_pltfrm=\"ibiza\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\" \n    ms.date=\"08/04/2015\"\n    ms.author=\"awills\"/>\n\n# Detect, Triage and Diagnose with Application Insights\n\n*Application Insights is in preview.*\n\n\nAfter you've published your application, Application Insights helps you make sure it's running OK and performing well. If there's a problem, you want to know about it soon, and then you want to know what to do about it.\n\n* *\"A couple of days ago, we deployed a 'minor' hotfix. We didn't run a broad test pass, but unfortunately some unexpected change got merged into the payload, causing incompatibility between the front and back ends. Immediately, server exceptions surged, our alert fired, and we were made aware of the situation. A few clicks away on the Application Insights portal, we got enough information from exception callstacks to narrow down the problem. We rolled back immediately and limited the damage. Application Insights has made this part of the devops cycle very easy and actionable.\"*\n\nWe can think of this part of the devops cycle as a pipeline:\n\n![Detect-Triage-Diagnose](./media/app-insights-detect-triage-diagnose/01-pipe1.png)\n\n\nOnce you've diagnosed the problem, you know where to focus your efforts - whether it's debugging your code, allocating more memory, or following up with a dependency. Finally, you can check that your fix has worked:\n\n\n\n![Repair-Validate](./media/app-insights-detect-triage-diagnose/02-pipe2.png)\n\n\nLet's see how Application Insights works at each stage of the pipeline.\n\nApplication Insights works for devices apps and web applications. In this walkthrough, we'll focus on a web application. We'll follow the OBS team in Fabrikam Bank, who are responsible for the online banking system. They have added Application Insights to their web projects.  \n\n\n![Example bank web site](./media/app-insights-detect-triage-diagnose/03-bank.png)\n\n\n\n## Detect poor availability\n\n\nMarcela Markova is a test specialist on the OBS team, and takes the lead on monitoring online performance. She sets up several [web tests][availability]:\n\n* A single-URL test for the main landing page for the app, http://fabrikambank.com/onlinebanking/. She sets criteria of HTTP code 200 and text 'Welcome!'. If this test fails, there's something seriously wrong with the network or the servers, or maybe a deployment issue. (Or someone has changed the Welcome! message on the page without letting her know.)\n\n\n* A deeper multi-step test, which logs in and gets a current account listing, checking a few key details on each page. This test verifies that the link to the accounts database is working. She uses a fictitious customer id: a few of them are maintained for test purposes.\n\n\nWith these tests set up, Marcela is confident that the team will quickly know about any outage.  \n\n\nFailures show up as red dots on the web test chart:\n\n![Display of web tests that have run over the preceding period](./media/app-insights-detect-triage-diagnose/04-webtests.png)\n\n\nBut more importantly, an alert about any failure will be emailed to the development team. In that way, they know about it before nearly all of the customers.\n\n\n## Monitor performance metrics\n\n\nOn the overview page in Application Insights, there's a chart that shows a variety of [key metrics][perf].\n\n![Various metrics](./media/app-insights-detect-triage-diagnose/05-perfMetrics.png)\n\nBrowser page load time is derived from telemetry sent directly from web pages. Server response time, server request count and failed request count are all measured in the web server and sent to Application Insights from there.\n\n\nThe Failed Request count indicates cases where users have seen an error - typically following an exception thrown in the code. Maybe they see a message saying \"Sorry we couldn't update your details right now\" or, at absolute embarrassing worst, a stack dump on the user's screen, courtesy of the web server.\n\n\nMarcela likes to look at these charts from time to time. The absence of failed requests is encouraging, although when she changes the range of the chart to cover the past week, occasional failures appear. This is an acceptable level in a busy server.  But if there is a sudden jump in failures, or in some of the other metrics such as server response time, Marcela wants to know about it immediately. It might indicate an unforeseen problem caused by a code release, or a failure in a dependency such as a database, or maybe an ungraceful reaction to a high load of requests.\n\n#### Alerts\n\nSo she sets two [alerts][metrics]: one for response times greater than a typical threshold, and another for a rate of failed requests greater than the current background.\n\n\nTogether with the availability alert, these give her confidence that she'll know about it as soon as anything unusual happens.  \n\n\nIt's also possible to set alerts on a wide variety of other metrics. For example, you can receive emails if the exception count becomes high, or the available memory goes low, or if there is a peak in client requests.\n\n\n\n![Add alert blade](./media/app-insights-detect-triage-diagnose/07-alerts.png)\n\n\n\n\n## Detecting exceptions\n\n\nWith a little bit of setup, [exceptions](app-insights-asp-net-exceptions.md) are reported to Application Insights automatically. They can also be captured explicitly by inserting calls to [TrackException()](app-insights-api-custom-events-metrics.md#track-exception) into the code:  \n\n    var telemetry = new TelemetryClient();\n    ...\n    try\n    { ...\n    }\n    catch (Exception ex)\n    {\n       // Set up some properties:\n       var properties = new Dictionary <string, string>\n         {{\"Game\", currentGame.Name}};\n\n       var measurements = new Dictionary <string, double>\n         {{\"Users\", currentGame.Users.Count}};\n\n       // Send the exception telemetry:\n       telemetry.TrackException(ex, properties, measurements);\n    }\n\n\nThe Fabrikam Bank team has evolved the practice of always sending telemetry on an exception, unless there's an obvious recovery.  \n\nIn fact, their strategy is even broader than that: They send telemetry in every case where the customer is frustrated in what they wanted to do, whether it corresponds to an exception in the code or not. For example, if the external inter-bank transfer system returns a \"can't complete this transaction\" message for some operational reason (no fault of the customer) then they track that event.\n\n    var successCode = AttemptTransfer(transferAmount, ...);\n    if (successCode < 0)\n    {\n       var properties = new Dictionary <string, string>\n            {{ \"Code\", returnCode, ... }};\n       var measurements = new Dictionary <string, double>\n         {{\"Value\", transferAmount}};\n       telemetry.TrackEvent(\"transfer failed\", properties, measurements);\n    }\n\nTrackException is used to report exceptions because it sends a copy of the stack; TrackEvent is used to report other events. You can attach any properties that might be useful in diagnosis.\n\nExceptions and events show up in the [Diagnostic Search][diagnostic] blade. You can drill into them to see the additional properties and stack trace.\n\n![In Diagnostic Search, use filters to show particular types of data](./media/app-insights-detect-triage-diagnose/appinsights-333facets.png)\n\n## Monitoring user activity\n\nWhen response time is consistently good and there are few exceptions, the dev team can think about how to improve the users' experience, and how to encourage more users to achieve the desired goals.\n\n\nFor example, a typical user journey through the web site has a clear 'funnel': Many customers look at the rates of different types of loan; some of them fill in the quotation form; and of those who get a quotation, a few go ahead and take out the loan.\n\n![](./media/app-insights-detect-triage-diagnose/12-funnel.png)\n\nBy considering where the greatest numbers of customers drop out, the business can work out how to get more users through to the bottom of the funnel. In some cases there might be a user experience (UX) failure - for example, the 'next' button is hard to find, or the instructions aren't obvious. More likely, there are more significant business reasons for drop-outs: maybe the loan rates are too high.\n\nWhatever the reasons, the data helps the team work out what users are doing. More tracking calls can be inserted to work out more detail. TrackEvent() can be used to count any user actions, from the fine detail of individual button clicks to significant achievements such as paying off a loan.\n\nThe team is getting used to having information about user activity. Nowadays, whenever they design a new feature, they work out how they will get feedback about its usage. They design tracking calls into the feature from the start. They use the feedback to improve the feature in each development cycle.\n\n\n## Proactive monitoring  \n\n\nMarcela doesn't just sit around waiting for alerts. Soon after every redeployment, she takes a look at [response times][perf] - both the overall figure and the table of slowest requests, as well as exception counts.  \n\n\n\n![Response time graph and grid of server response times.](./media/app-insights-detect-triage-diagnose/09-dependencies.png)\n\nShe can assess the performance effect of every deployment, typically comparing each week with the last. If there's a sudden worsening, she raises that with the relevant developers.\n\n\n## Triage\n\n\nTriage - assessing the severity and extent of a problem - is the first step after detection. Should we call out the team at midnight? Or can it be left until the next convenient gap in the backlog? There are some key questions in triage.\n\n\nHow much is it happening? The charts on the Overview blade give some perspective to a problem. For example, the Fabrikam application generated four web test alerts one night. Looking at the chart in the morning, the team could see that there were indeed some red dots, though still most of the tests were green. Drilling into the availability chart, it was clear that all of these intermittent problems were from one test location. This was obviously a network issue affecting only one route, and would most likely clear itself.  \n\n\nBy contrast, a dramatic and stable rise in the graph of exception counts or response times is obviously something to panic about.\n\n\nA useful triage tactic is Try It Yourself. If you run into the same problem, you know it's real.\n\n\nWhat fraction of users are affected? To obtain a rough answer, divide the failure rate by the session count.\n\n\n![Charts of failed requests and sessions](./media/app-insights-detect-triage-diagnose/10-failureRate.png)\n\nIn the case of slow response, compare the table of slowest-responding requests with the usage frequency of each page.\n\n\nHow important is the blocked scenario? If this is a functional problem blocking a particular user story, does it matter much? If customers can't pay their bills, this is serious; if they can't change their screen color preferences, maybe it can wait. The detail of the event or exception, or the identity of the slow page, tells you where customers are having trouble.\n\n\n## Diagnosis\n\n\nDiagnosis isn't quite the same as debugging. Before you start tracing through the code, you should have a rough idea of why, where and when the issue is occurring.\n\n\n**When does it happen?** The historical view provided by the event and metric charts makes it easy to correlate effects with possible causes. If there are intermittent peaks in response time or exception rates, look at the request count: if it peaks at the same time, then it looks like a resource problem. Do you need to assign more CPU or memory? Or is it a dependency that can't manage the load?\n\n\n**Is it us?**  If you have a sudden drop in performance of a particular type of request - for example when the customer wants an account statement - then there's a possibility it might be an external subsystem rather than your web application. In Metrics Explorer, select the Dependency Failure rate and Dependency Duration rates and compare their histories over the past few hours or days with the problem you detected. If there are correlating changes, then an external subsystem might be to blame.  \n\n\n![Charts of dependency failure and duration of calls to dependencies](./media/app-insights-detect-triage-diagnose/11-dependencies.png)\n\nSome slow dependency issues are geolocation problems. Fabrikam Bank uses Azure virtual machines, and discovered that they had inadvertently located their web server and account server in different countries. A dramatic improvement was brought about by migrating one of them.\n\n\n**What did we do?** If the issue doesn't appear to be in a dependency, and if it wasn't always there, it's probably caused by a recent change. The historical perspective provided by the metric and event charts makes it easy to correlate any sudden changes with deployments. That narrows down the search for the problem.\n\n\n**What's going on?** Some problems occur only rarely and can be difficult to track down by testing offline. All we can do is to try to capture the bug when it occurs live. You can inspect the stack dumps in exception reports. In addition, you can write tracing calls, either with your favourite logging framework or with TrackTrace() or TrackEvent().  \n\n\nFabrikam had an intermittent problem with inter-account transfers, but only with certain account types. To understand better what was happening, they inserted TrackTrace() calls at key points in the code, attaching the account type as a property to each call. That made it easy to filter out just those traces in Diagnostic Search. They also attached parameter values as properties and measures to the trace calls.\n\n\n## Dealing with it\n\n\nOnce you've diagnosed the issue, you can make a plan to fix it. Maybe you need to roll back a recent change, or maybe you can just go ahead and fix it. Once the fix is done, Application Insights will tell you whether you succeeded.  \n\n\nFabrikam Bank's development team take a more structured approach to performance measurement than they used to before they used Application Insights.\n\n* They set performance targets in terms of specific measures in the Application Insights overview page.\n\n* They design performance measures into the application from the start, such as the metrics that measure user progress through 'funnels.'  \n\n\n\n\n## Usage\n\nApplication Insights can also be used to learn what users do with an app. Once it's running smoothly, the team would like to know which features are the most popular, what users like or have difficulty with, and how often they come back. That will help them prioritize their upcoming work. And they can plan to measure the success of each feature as part of the development cycle. [Read more][usage].\n\n## Your applications\n\nSo that's how one team use Application Insights not just to fix individual issues, but to improve their development lifecycle. I hope it has given you some ideas about how Application Insights can help you improve the performance of your own applications.\n\n## Video\n\n[AZURE.VIDEO performance-monitoring-application-insights]\n\n<!--Link references-->\n\n[api]: app-insights-api-custom-events-metrics.md\n[availability]: app-insights-monitor-web-app-availability.md\n[diagnostic]: app-insights-diagnostic-search.md\n[metrics]: app-insights-metrics-explorer.md\n[perf]: app-insights-web-monitor-performance.md\n[usage]: app-insights-web-track-usage.md\n \n\ntest\n"
}