{
  "nodes": [
    {
      "content": "Real-time Twitter sentiment analysis with Stream Analytics | Microsoft Azure",
      "pos": [
        27,
        103
      ]
    },
    {
      "content": "Learn how to use Stream Analytics for real-time Twitter sentiment analysis.",
      "pos": [
        122,
        197
      ]
    },
    {
      "content": "Step-by-step guidance from event generation to data on a live dashboard.",
      "pos": [
        198,
        270
      ]
    },
    {
      "content": "Social media analysis: Real-time Twitter sentiment analysis in Azure Stream Analytics",
      "pos": [
        698,
        783
      ]
    },
    {
      "content": "In this tutorial, you'll learn how to build a sentiment analysis solution by bringing real-time Twitter events into Event Hubs, writing Stream Analytics queries to analyze the data, and then storing the results or using a dashboard to provide insights in real time.",
      "pos": [
        785,
        1050
      ]
    },
    {
      "content": "Social media analytics tools help organizations understand trending topics, meaning subjects and attitudes with a high volume of posts in social media.",
      "pos": [
        1053,
        1204
      ]
    },
    {
      "content": "Sentiment analysis - also called \"opinion mining\" - uses social media analytics tools to determine attitudes toward a product, idea, and so on.",
      "pos": [
        1205,
        1348
      ]
    },
    {
      "content": "Scenario",
      "pos": [
        1353,
        1361
      ]
    },
    {
      "content": "A news media website is interested in getting an edge over its competitors by featuring site content that is immediately relevant to its readers.",
      "pos": [
        1363,
        1508
      ]
    },
    {
      "content": "They use social media analysis on topics relevant to their readers by doing real time sentiment analysis on Twitter data.",
      "pos": [
        1509,
        1630
      ]
    },
    {
      "content": "Specifically, to identify what topics are trending in real time on Twitter, they need real-time analytics about the tweet volume and sentiment for key topics.",
      "pos": [
        1631,
        1789
      ]
    },
    {
      "content": "Prerequisites",
      "pos": [
        1794,
        1807
      ]
    },
    {
      "content": "A Twitter account is required for this tutorial.",
      "pos": [
        1812,
        1860
      ]
    },
    {
      "content": "This walkthough uses a Twitter client application which is located on GitHub.",
      "pos": [
        1867,
        1944
      ]
    },
    {
      "content": "Download it <bpt id=\"p1\">[</bpt>here<ept id=\"p1\">](https://github.com/Azure/azure-stream-analytics/tree/master/DataGenerators/TwitterClient)</ept> and follow the steps below to set up your solution.",
      "pos": [
        1946,
        2106
      ]
    },
    {
      "content": "Create an Event Hub input and a Consumer Group",
      "pos": [
        2111,
        2157
      ]
    },
    {
      "content": "The sample application will generate events and push them to an Event Hubs instance (an Event Hub, for short).",
      "pos": [
        2159,
        2269
      ]
    },
    {
      "content": "Service Bus Event Hubs are the preferred method of event ingestion for Stream Analytics.",
      "pos": [
        2270,
        2358
      ]
    },
    {
      "content": "See Event Hubs documentation in <bpt id=\"p1\">[</bpt>Service Bus documentation<ept id=\"p1\">](/documentation/services/service-bus/)</ept>",
      "pos": [
        2359,
        2456
      ]
    },
    {
      "content": "Follow the steps below to create an Event Hub.",
      "pos": [
        2458,
        2504
      ]
    },
    {
      "pos": [
        2510,
        2700
      ],
      "content": "In the Azure Portal click <bpt id=\"p1\">**</bpt>NEW<ept id=\"p1\">**</ept> &gt; <bpt id=\"p2\">**</bpt>APP SERVICES<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>SERVICE BUS<ept id=\"p3\">**</ept> &gt; <bpt id=\"p4\">**</bpt>EVENT HUB<ept id=\"p4\">**</ept> &gt; <bpt id=\"p5\">**</bpt>QUICK CREATE<ept id=\"p5\">**</ept> and provide a name, region, and new or existing namespace to create a new Event Hub."
    },
    {
      "content": "As a best practice, each Stream Analytics job should read from a single Event Hubs Consumer Group.",
      "pos": [
        2707,
        2805
      ]
    },
    {
      "content": "We will walk you through the process of creating a Consumer Group below and you can learn more about them here.",
      "pos": [
        2806,
        2917
      ]
    },
    {
      "content": "To create a Consumer Group, navigate to the newly created Event Hub and click the <bpt id=\"p1\">**</bpt>CONSUMER GROUPS<ept id=\"p1\">**</ept> tab, then click <bpt id=\"p2\">**</bpt>CREATE<ept id=\"p2\">**</ept> on the bottom of the page and provide a name for your Consumer Group.",
      "pos": [
        2919,
        3117
      ]
    },
    {
      "content": "To grant access to the Event Hub, we will need to create a shared access policy.",
      "pos": [
        3122,
        3202
      ]
    },
    {
      "content": "Click the <bpt id=\"p1\">**</bpt>CONFIGURE<ept id=\"p1\">**</ept> tab of your Event Hub.",
      "pos": [
        3204,
        3250
      ]
    },
    {
      "pos": [
        3255,
        3337
      ],
      "content": "Under <bpt id=\"p1\">**</bpt>SHARED ACCESS POLICIES<ept id=\"p1\">**</ept>, create a new policy with <bpt id=\"p2\">**</bpt>MANAGE<ept id=\"p2\">**</ept> permissions."
    },
    {
      "pos": [
        3535,
        3576
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>SAVE<ept id=\"p1\">**</ept> at the bottom of the page."
    },
    {
      "content": "Navigate to the <bpt id=\"p1\">**</bpt>DASHBOARD<ept id=\"p1\">**</ept> and click <bpt id=\"p2\">**</bpt>CONNECTION INFORMATION<ept id=\"p2\">**</ept> at the bottom of the page and copy and save the connection information.",
      "pos": [
        3581,
        3719
      ]
    },
    {
      "content": "(Use the copy icon that appears under the search icon.)",
      "pos": [
        3720,
        3775
      ]
    },
    {
      "content": "Configure and start the Twitter client application",
      "pos": [
        3780,
        3830
      ]
    },
    {
      "content": "We have provided a client application that will tap into Twitter data via <bpt id=\"p1\">[</bpt>Twitter's Streaming APIs<ept id=\"p1\">](https://dev.twitter.com/streaming/overview)</ept> to collect Tweet events about a parameterized set of topics.",
      "pos": [
        3832,
        4037
      ]
    },
    {
      "content": "The 3rd party open source tool <bpt id=\"p1\">[</bpt>Sentiment140<ept id=\"p1\">](http://help.sentiment140.com/)</ept> is used to assign a sentiment value to each tweet (0: negative, 2: neutral, 4: positive) and then Tweet events are pushed to Event Hub.",
      "pos": [
        4038,
        4250
      ]
    },
    {
      "content": "Follow these steps to set up the application:",
      "pos": [
        4254,
        4299
      ]
    },
    {
      "content": "Download the TwitterClient solution",
      "pos": [
        4306,
        4341
      ]
    },
    {
      "content": "Open App.config and replace oauth_consumer_key, oauth_consumer_secret, oauth_token, oauth_token_secret with Twitter tokens with your values.",
      "pos": [
        4417,
        4557
      ]
    },
    {
      "content": "Steps to generate an OAuth access token",
      "pos": [
        4566,
        4605
      ]
    },
    {
      "content": "Note that you will need to make an empty application to generate a token.",
      "pos": [
        4686,
        4759
      ]
    },
    {
      "content": "Replace the EventHubConnectionString and EventHubName values in App.config with your Event Hub connection string and name.",
      "pos": [
        4766,
        4888
      ]
    },
    {
      "content": "<bpt id=\"p1\">*</bpt>Optional:<ept id=\"p1\">*</ept> Adjust the keywords to search for.",
      "pos": [
        4893,
        4939
      ]
    },
    {
      "content": "As a default, this application looks for \"Azure,Skype,XBox,Microsoft,Seattle\".",
      "pos": [
        4941,
        5019
      ]
    },
    {
      "content": "You can adjust the values for twitter_keywords in App.config, if desired.",
      "pos": [
        5021,
        5094
      ]
    },
    {
      "content": "Build the solution",
      "pos": [
        5099,
        5117
      ]
    },
    {
      "content": "Start the application.",
      "pos": [
        5122,
        5144
      ]
    },
    {
      "content": "You will see Tweet events with the CreatedAt, Topic, and SentimentScore values being sent to your Event Hub:",
      "pos": [
        5146,
        5254
      ]
    },
    {
      "content": "Sentiment analysis: SentimentScore values sent to an event hub.",
      "pos": [
        5262,
        5325
      ]
    },
    {
      "content": "Create Stream Analytics job",
      "pos": [
        5450,
        5477
      ]
    },
    {
      "content": "Now that we have Tweet events streaming in real-time from Twitter, we can set up a Stream Analytics job to analyze these events in real time.",
      "pos": [
        5479,
        5620
      ]
    },
    {
      "content": "Provision a Stream Analytics job",
      "pos": [
        5626,
        5658
      ]
    },
    {
      "pos": [
        5664,
        5797
      ],
      "content": "In the <bpt id=\"p1\">[</bpt>Azure Portal<ept id=\"p1\">](https://manage.windowsazure.com/)</ept>, click <bpt id=\"p2\">**</bpt>NEW<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>DATA SERVICES<ept id=\"p3\">**</ept> &gt; <bpt id=\"p4\">**</bpt>STREAM ANALYTICS<ept id=\"p4\">**</ept> &gt; <bpt id=\"p5\">**</bpt>QUICK CREATE<ept id=\"p5\">**</ept>."
    },
    {
      "pos": [
        5802,
        5879
      ],
      "content": "Specify the following values, and then click <bpt id=\"p1\">**</bpt>CREATE STREAM ANALYTICS JOB<ept id=\"p1\">**</ept>:"
    },
    {
      "pos": [
        5887,
        5918
      ],
      "content": "<bpt id=\"p1\">**</bpt>JOB NAME<ept id=\"p1\">**</ept>: Enter a job name."
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>REGION<ept id=\"p1\">**</ept>: Select the region where you want to run the job.",
      "pos": [
        5925,
        5985
      ]
    },
    {
      "content": "Consider placing the job and the event hub in the same region to ensure better performance and to ensure that you will not be paying to transfer data between regions.",
      "pos": [
        5986,
        6152
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>STORAGE ACCOUNT<ept id=\"p1\">**</ept>: Choose the Storage account that you would like to use to store monitoring data for all Stream Analytics jobs running within this region.",
      "pos": [
        6159,
        6316
      ]
    },
    {
      "content": "You have the option to choose an existing Storage account or to create a new one.",
      "pos": [
        6317,
        6398
      ]
    },
    {
      "pos": [
        6404,
        6613
      ],
      "content": "Click **STREAM ANALYTICS** in the left pane to list the Stream Analytics jobs.\n![Stream Analytics service icon](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-service-icon.png)",
      "leadings": [
        "",
        "    "
      ],
      "nodes": [
        {
          "content": "Click <bpt id=\"p1\">**</bpt>STREAM ANALYTICS<ept id=\"p1\">**</ept> in the left pane to list the Stream Analytics jobs.",
          "pos": [
            0,
            78
          ]
        },
        {
          "content": "<ph id=\"ph1\">![</ph>Stream Analytics service icon<ph id=\"ph2\">](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-service-icon.png)</ph>",
          "pos": [
            79,
            205
          ]
        }
      ]
    },
    {
      "content": "The new job will be shown with a status of <bpt id=\"p1\">**</bpt>CREATED<ept id=\"p1\">**</ept>.",
      "pos": [
        6619,
        6674
      ]
    },
    {
      "content": "Notice that the <bpt id=\"p1\">**</bpt>START<ept id=\"p1\">**</ept> button on the bottom of the page is disabled.",
      "pos": [
        6675,
        6746
      ]
    },
    {
      "content": "You must configure the job input, output, and query before you can start the job.",
      "pos": [
        6747,
        6828
      ]
    },
    {
      "content": "Specify job input",
      "pos": [
        6835,
        6852
      ]
    },
    {
      "content": "In your Stream Analytics job click <bpt id=\"p1\">**</bpt>INPUTS<ept id=\"p1\">**</ept> from the top of the page, and then click <bpt id=\"p2\">**</bpt>ADD INPUT<ept id=\"p2\">**</ept>.",
      "pos": [
        6857,
        6958
      ]
    },
    {
      "content": "The dialog that opens will walk you through a number of steps to set up your input.",
      "pos": [
        6959,
        7042
      ]
    },
    {
      "pos": [
        7047,
        7103
      ],
      "content": "Select <bpt id=\"p1\">**</bpt>DATA STREAM<ept id=\"p1\">**</ept>, and then click the right button."
    },
    {
      "pos": [
        7108,
        7162
      ],
      "content": "Select <bpt id=\"p1\">**</bpt>EVENT HUB<ept id=\"p1\">**</ept>, and then click the right button."
    },
    {
      "content": "Type or select the following values on the third page:",
      "pos": [
        7167,
        7221
      ]
    },
    {
      "pos": [
        7229,
        7523
      ],
      "content": "**INPUT ALIAS**: Enter a friendly name for this job input, such as TwitterStream. Note that you will be using this name in the query later on.\n**EVENT HUB**: If the Event Hub you created is in the same subscription as the Stream Analytics job, select the namespace that the event hub is in.",
      "leadings": [
        "",
        "    "
      ],
      "nodes": [
        {
          "content": "**INPUT ALIAS**: Enter a friendly name for this job input, such as TwitterStream. Note that you will be using this name in the query later on.",
          "pos": [
            0,
            142
          ],
          "nodes": [
            {
              "content": "<bpt id=\"p1\">**</bpt>INPUT ALIAS<ept id=\"p1\">**</ept>: Enter a friendly name for this job input, such as TwitterStream.",
              "pos": [
                0,
                81
              ]
            },
            {
              "content": "Note that you will be using this name in the query later on.",
              "pos": [
                82,
                142
              ]
            }
          ]
        },
        {
          "content": "<bpt id=\"p1\">**</bpt>EVENT HUB<ept id=\"p1\">**</ept>: If the Event Hub you created is in the same subscription as the Stream Analytics job, select the namespace that the event hub is in.",
          "pos": [
            143,
            290
          ]
        }
      ]
    },
    {
      "pos": [
        7533,
        7809
      ],
      "content": "If your event hub is in a different subscription, select <bpt id=\"p1\">**</bpt>Use Event Hub from Another Subscription<ept id=\"p1\">**</ept>, and then manually enter information for <bpt id=\"p2\">**</bpt>SERVICE BUS NAMESPACE<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>EVENT HUB NAME<ept id=\"p3\">**</ept>, <bpt id=\"p4\">**</bpt>EVENT HUB POLICY NAME<ept id=\"p4\">**</ept>, <bpt id=\"p5\">**</bpt>EVENT HUB POLICY KEY<ept id=\"p5\">**</ept>, and <bpt id=\"p6\">**</bpt>EVENT HUB PARTITION COUNT<ept id=\"p6\">**</ept>."
    },
    {
      "pos": [
        7817,
        7869
      ],
      "content": "<bpt id=\"p1\">**</bpt>EVENT HUB NAME<ept id=\"p1\">**</ept>: Select the name of the Event Hub"
    },
    {
      "pos": [
        7876,
        7964
      ],
      "content": "<bpt id=\"p1\">**</bpt>EVENT HUB POLICY NAME<ept id=\"p1\">**</ept>: Select the event-hub policy created earlier in this tutorial."
    },
    {
      "pos": [
        7971,
        8061
      ],
      "content": "<bpt id=\"p1\">**</bpt>EVENT HUB CONSUMER GROUP<ept id=\"p1\">**</ept>: Type in the Consumer Group created earlier in this tutorial."
    },
    {
      "content": "Click the right button.",
      "pos": [
        8066,
        8089
      ]
    },
    {
      "content": "Specify the following values:",
      "pos": [
        8094,
        8123
      ]
    },
    {
      "pos": [
        8131,
        8164
      ],
      "content": "<bpt id=\"p1\">**</bpt>EVENT SERIALIZER FORMAT<ept id=\"p1\">**</ept>: JSON"
    },
    {
      "pos": [
        8171,
        8189
      ],
      "content": "<bpt id=\"p1\">**</bpt>ENCODING<ept id=\"p1\">**</ept>: UTF8"
    },
    {
      "content": "Click the check button to add this source and to verify that Stream Analytics can successfully connect to the event hub.",
      "pos": [
        8195,
        8315
      ]
    },
    {
      "content": "Specify job query",
      "pos": [
        8321,
        8338
      ]
    },
    {
      "content": "Stream Analytics supports a simple, declarative query model for describing transformations.",
      "pos": [
        8340,
        8431
      ]
    },
    {
      "content": "To learn more about the language, see the <bpt id=\"p1\">[</bpt>Azure Stream Analytics Query Language Reference<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn834998.aspx)</ept>.",
      "pos": [
        8432,
        8580
      ]
    },
    {
      "content": "This tutorial will help you author and test several queries over Twitter data.",
      "pos": [
        8582,
        8660
      ]
    },
    {
      "content": "Sample data input",
      "pos": [
        8667,
        8684
      ]
    },
    {
      "content": "To validate your query against actual job data, you can use the SAMPLE DATA feature to extract events from your stream and create a .JSON file of the events for testing.",
      "pos": [
        8686,
        8855
      ]
    },
    {
      "pos": [
        8861,
        8944
      ],
      "content": "Select on your Event Hub input and click <bpt id=\"p1\">**</bpt>SAMPLE DATA<ept id=\"p1\">**</ept> at the bottom of the page."
    },
    {
      "pos": [
        8949,
        9091
      ],
      "content": "In the dialog that appears, specify a <bpt id=\"p1\">**</bpt>START TIME<ept id=\"p1\">**</ept> to start collecting data from and a <bpt id=\"p2\">**</bpt>DURATION<ept id=\"p2\">**</ept> for how much additional data to consume."
    },
    {
      "pos": [
        9096,
        9213
      ],
      "content": "Click the <bpt id=\"p1\">**</bpt>DETAILS<ept id=\"p1\">**</ept> button, and then the <bpt id=\"p2\">**</bpt>Click here<ept id=\"p2\">**</ept> link to download and save the .JSON file that is generated."
    },
    {
      "content": "Pass-through query",
      "pos": [
        9220,
        9238
      ]
    },
    {
      "content": "To start with, we will do a simple pass-through query that projects all the fields in an event.",
      "pos": [
        9239,
        9334
      ]
    },
    {
      "pos": [
        9340,
        9402
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>QUERY<ept id=\"p1\">**</ept> from the top of the Stream Analytics job page."
    },
    {
      "content": "In the code editor, replace the initial query template with the following:",
      "pos": [
        9407,
        9481
      ]
    },
    {
      "content": "Make sure that the name of the input source matches the name of the input you specified earlier.",
      "pos": [
        9524,
        9620
      ]
    },
    {
      "pos": [
        9626,
        9663
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>TEST<ept id=\"p1\">**</ept> under the query editor"
    },
    {
      "content": "Browse to your sample .JSON file",
      "pos": [
        9668,
        9700
      ]
    },
    {
      "content": "Click the check button and see the results displayed below the query definition.",
      "pos": [
        9705,
        9785
      ]
    },
    {
      "content": "Results displayed below query definition",
      "pos": [
        9793,
        9833
      ]
    },
    {
      "content": "Count of tweets by topic: Tumbling window with aggregation",
      "pos": [
        9941,
        9999
      ]
    },
    {
      "pos": [
        10001,
        10195
      ],
      "content": "To compare the number of mentions between topics, we'll leverage a <bpt id=\"p1\">[</bpt>TumblingWindow<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn835055.aspx)</ept> to get the count of mentions by topic every 5 seconds."
    },
    {
      "content": "Change the query in the code editor to:",
      "pos": [
        10201,
        10240
      ]
    },
    {
      "content": "Note that this query uses the <bpt id=\"p1\">**</bpt>TIMESTAMP BY<ept id=\"p1\">**</ept> keyword to specify a timestamp field in the payload to be used in the temporal computation.",
      "pos": [
        10399,
        10537
      ]
    },
    {
      "content": "If this field wasn't specified, the windowing operation would be performed using the time each event arrived at Event Hub.",
      "pos": [
        10539,
        10661
      ]
    },
    {
      "content": "Learn more under \"Arrival Time Vs Application Time\" in the <bpt id=\"p1\">[</bpt>Stream Analytics Query Reference<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn834998.aspx)</ept>.",
      "pos": [
        10663,
        10813
      ]
    },
    {
      "pos": [
        10819,
        10909
      ],
      "content": "This query also accesses a timestamp for the end of each window with <bpt id=\"p1\">**</bpt>System.Timestamp<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        10915,
        10986
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>RERUN<ept id=\"p1\">**</ept> under the query editor to see the results of the query."
    },
    {
      "content": "Identifying trending topics: Sliding window",
      "pos": [
        10993,
        11036
      ]
    },
    {
      "content": "To identify trending topics we'll look for topics that cross a threshold value for mentions in a given amount of time.",
      "pos": [
        11038,
        11156
      ]
    },
    {
      "content": "For the purposes of this tutorial, we'll check for topics that are mentioned more than 20 times in the last 5 seconds using a <bpt id=\"p1\">[</bpt>SlidingWindow<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn835051.aspx)</ept>.",
      "pos": [
        11158,
        11356
      ]
    },
    {
      "content": "Change the query in the code editor to:",
      "pos": [
        11362,
        11401
      ]
    },
    {
      "pos": [
        11600,
        11671
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>RERUN<ept id=\"p1\">**</ept> under the query editor to see the results of the query."
    },
    {
      "content": "Sliding Window query output",
      "pos": [
        11679,
        11706
      ]
    },
    {
      "content": "Count of mentions and sentiment: Tumbling window with aggregation",
      "pos": [
        11808,
        11873
      ]
    },
    {
      "content": "The final query we will test uses a TumblingWindow to obtain the number of mentions and average, minimum, maximum, and standard deviation of sentiment score for each topic every 5 seconds.",
      "pos": [
        11875,
        12063
      ]
    },
    {
      "content": "Change the query in the code editor to:",
      "pos": [
        12069,
        12108
      ]
    },
    {
      "pos": [
        12361,
        12432
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>RERUN<ept id=\"p1\">**</ept> under the query editor to see the results of the query."
    },
    {
      "content": "This is the query we will use for our dashboard.",
      "pos": [
        12437,
        12485
      ]
    },
    {
      "content": "Click <bpt id=\"p1\">**</bpt>SAVE<ept id=\"p1\">**</ept> at the bottom of the page.",
      "pos": [
        12487,
        12528
      ]
    },
    {
      "content": "Create output sink",
      "pos": [
        12534,
        12552
      ]
    },
    {
      "content": "Now that we have defined an event stream, an Event Hub input to ingest events, and a query to perform a transformation over the stream, the last step is to define an output sink for the job.",
      "pos": [
        12554,
        12744
      ]
    },
    {
      "content": "We'll write the aggregated tweet events from our job query to an Azure Blob.",
      "pos": [
        12746,
        12822
      ]
    },
    {
      "content": "You could also push your results to SQL Database, Table Store or Event Hub, depending on your specific application needs.",
      "pos": [
        12824,
        12945
      ]
    },
    {
      "content": "Follow the steps below to create a container for Blob storage, if you don't already have one:",
      "pos": [
        12947,
        13040
      ]
    },
    {
      "pos": [
        13046,
        13231
      ],
      "content": "Use an existing Storage account or create a new Storage account by clicking <bpt id=\"p1\">**</bpt>NEW<ept id=\"p1\">**</ept> &gt; <bpt id=\"p2\">**</bpt>DATA SERVICES<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>STORAGE<ept id=\"p3\">**</ept> &gt; <bpt id=\"p4\">**</bpt>QUICK CREATE<ept id=\"p4\">**</ept> &gt; and following the instructions on  the screen."
    },
    {
      "pos": [
        13236,
        13340
      ],
      "content": "Select the Storage account and then click <bpt id=\"p1\">**</bpt>CONTAINERS<ept id=\"p1\">**</ept> at the top of the page, and then click <bpt id=\"p2\">**</bpt>ADD<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        13345,
        13421
      ],
      "content": "Specify a <bpt id=\"p1\">**</bpt>NAME<ept id=\"p1\">**</ept> for your container and set its <bpt id=\"p2\">**</bpt>ACCESS<ept id=\"p2\">**</ept> to Public Blob."
    },
    {
      "content": "Specify job output",
      "pos": [
        13426,
        13444
      ]
    },
    {
      "content": "In your Stream Analytics job, click <bpt id=\"p1\">**</bpt>OUTPUT<ept id=\"p1\">**</ept> at the top of the page, and then click <bpt id=\"p2\">**</bpt>ADD OUTPUT<ept id=\"p2\">**</ept>.",
      "pos": [
        13450,
        13551
      ]
    },
    {
      "content": "The dialog that opens will walk you through a number of steps to set up your output.",
      "pos": [
        13552,
        13636
      ]
    },
    {
      "pos": [
        13641,
        13698
      ],
      "content": "Select <bpt id=\"p1\">**</bpt>BLOB STORAGE<ept id=\"p1\">**</ept>, and then click the right button."
    },
    {
      "content": "Type or select the following values on the third page:",
      "pos": [
        13703,
        13757
      ]
    },
    {
      "pos": [
        13765,
        13824
      ],
      "content": "<bpt id=\"p1\">**</bpt>OUTPUT ALIAS<ept id=\"p1\">**</ept>: Enter a friendly name for this job output"
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>SUBSCRIPTION<ept id=\"p1\">**</ept>: If the Blob Storage you created is in the same subscription as the Stream Analytics job, select <bpt id=\"p2\">**</bpt>Use Storage Account from Current Subscription<ept id=\"p2\">**</ept>.",
      "pos": [
        13831,
        13995
      ]
    },
    {
      "content": "If your storage is in a different subscription, select <bpt id=\"p1\">**</bpt>Use Storage Account from Another Subscription<ept id=\"p1\">**</ept> and manually enter information for <bpt id=\"p2\">**</bpt>STORAGE ACCOUNT<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>STORAGE ACCOUNT KEY<ept id=\"p3\">**</ept>, <bpt id=\"p4\">**</bpt>CONTAINER<ept id=\"p4\">**</ept>.",
      "pos": [
        13997,
        14197
      ]
    },
    {
      "pos": [
        14204,
        14263
      ],
      "content": "<bpt id=\"p1\">**</bpt>STORAGE ACCOUNT<ept id=\"p1\">**</ept>: Select the name of the Storage Account"
    },
    {
      "pos": [
        14270,
        14317
      ],
      "content": "<bpt id=\"p1\">**</bpt>CONTAINER<ept id=\"p1\">**</ept>: Select the name of the Container"
    },
    {
      "pos": [
        14324,
        14398
      ],
      "content": "<bpt id=\"p1\">**</bpt>FILENAME PREFIX<ept id=\"p1\">**</ept>: Type in a file prefix to use when writing blob output"
    },
    {
      "content": "Click the right button.",
      "pos": [
        14404,
        14427
      ]
    },
    {
      "content": "Specify the following values:",
      "pos": [
        14432,
        14461
      ]
    },
    {
      "pos": [
        14468,
        14501
      ],
      "content": "<bpt id=\"p1\">**</bpt>EVENT SERIALIZER FORMAT<ept id=\"p1\">**</ept>: JSON"
    },
    {
      "pos": [
        14508,
        14526
      ],
      "content": "<bpt id=\"p1\">**</bpt>ENCODING<ept id=\"p1\">**</ept>: UTF8"
    },
    {
      "content": "Click the check button to add this source and to verify that Stream Analytics can successfully connect to the storage account.",
      "pos": [
        14531,
        14657
      ]
    },
    {
      "content": "Start job",
      "pos": [
        14662,
        14671
      ]
    },
    {
      "content": "Since a job input, query and output have all been specified, we are ready to start the Stream Analytics job.",
      "pos": [
        14673,
        14781
      ]
    },
    {
      "pos": [
        14787,
        14857
      ],
      "content": "From the job <bpt id=\"p1\">**</bpt>DASHBOARD<ept id=\"p1\">**</ept>, click <bpt id=\"p2\">**</bpt>START<ept id=\"p2\">**</ept> at the bottom of the page."
    },
    {
      "content": "In the dialog that appears, select <bpt id=\"p1\">**</bpt>JOB START TIME<ept id=\"p1\">**</ept>, and then click the checkmark button on the bottom of the dialog.",
      "pos": [
        14862,
        14981
      ]
    },
    {
      "content": "The job status will change to <bpt id=\"p1\">**</bpt>Starting<ept id=\"p1\">**</ept> and will shortly move to <bpt id=\"p2\">**</bpt>Running<ept id=\"p2\">**</ept>.",
      "pos": [
        14982,
        15062
      ]
    },
    {
      "content": "View output for sentiment analysis",
      "pos": [
        15068,
        15102
      ]
    },
    {
      "content": "Once your job is running and processing the real-time Twitter stream, choose how you want to view the output for sentiment analysis.",
      "pos": [
        15104,
        15236
      ]
    },
    {
      "content": "Use a tool like <bpt id=\"p1\">[</bpt>Azure Storage Explorer<ept id=\"p1\">](https://azurestorageexplorer.codeplex.com/)</ept> or <bpt id=\"p2\">[</bpt>Azure Explorer<ept id=\"p2\">](http://www.cerebrata.com/products/azure-explorer/introduction)</ept> to view your job output in real time.",
      "pos": [
        15237,
        15442
      ]
    },
    {
      "content": "From here, you could extend your application to include a customized dashboard over your output, like the one pictured below using <bpt id=\"p1\">[</bpt>Power BI<ept id=\"p1\">](https://powerbi.com/)</ept>.",
      "pos": [
        15443,
        15607
      ]
    },
    {
      "content": "Social media analysis: Stream Analytics sentiment analysis (opinion mining) output in a Power BI dashboard.",
      "pos": [
        15611,
        15718
      ]
    },
    {
      "content": "Get support",
      "pos": [
        15821,
        15832
      ]
    },
    {
      "pos": [
        15833,
        15976
      ],
      "content": "For further assistance, try our <bpt id=\"p1\">[</bpt>Azure Stream Analytics forum<ept id=\"p1\">](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics)</ept>."
    },
    {
      "content": "Next steps",
      "pos": [
        15983,
        15993
      ]
    },
    {
      "content": "Introduction to Azure Stream Analytics",
      "pos": [
        15998,
        16036
      ]
    },
    {
      "content": "Get started using Azure Stream Analytics",
      "pos": [
        16075,
        16115
      ]
    },
    {
      "content": "Scale Azure Stream Analytics jobs",
      "pos": [
        16153,
        16186
      ]
    },
    {
      "content": "Azure Stream Analytics Query Language Reference",
      "pos": [
        16223,
        16270
      ]
    },
    {
      "content": "Azure Stream Analytics Management REST API Reference",
      "pos": [
        16331,
        16383
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Real-time Twitter sentiment analysis with Stream Analytics | Microsoft Azure\"\n    description=\"Learn how to use Stream Analytics for real-time Twitter sentiment analysis. Step-by-step guidance from event generation to data on a live dashboard.\"\n    keywords=\"real-time twitter,sentiment analysis,social media analysis,social media analytics tools\"\n    services=\"stream-analytics\"\n    documentationCenter=\"\"\n    authors=\"jeffstokes72\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"stream-analytics\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.workload=\"big-data\"\n    ms.date=\"08/19/2015\"\n    ms.author=\"jeffstok\"/>\n\n\n# Social media analysis: Real-time Twitter sentiment analysis in Azure Stream Analytics\n\nIn this tutorial, you'll learn how to build a sentiment analysis solution by bringing real-time Twitter events into Event Hubs, writing Stream Analytics queries to analyze the data, and then storing the results or using a dashboard to provide insights in real time. \n\nSocial media analytics tools help organizations understand trending topics, meaning subjects and attitudes with a high volume of posts in social media. Sentiment analysis - also called \"opinion mining\" - uses social media analytics tools to determine attitudes toward a product, idea, and so on.\n\n## Scenario\n\nA news media website is interested in getting an edge over its competitors by featuring site content that is immediately relevant to its readers. They use social media analysis on topics relevant to their readers by doing real time sentiment analysis on Twitter data. Specifically, to identify what topics are trending in real time on Twitter, they need real-time analytics about the tweet volume and sentiment for key topics.\n\n## Prerequisites\n1.  A Twitter account is required for this tutorial.  \n2.  This walkthough uses a Twitter client application which is located on GitHub.  Download it [here](https://github.com/Azure/azure-stream-analytics/tree/master/DataGenerators/TwitterClient) and follow the steps below to set up your solution.\n\n## Create an Event Hub input and a Consumer Group\n\nThe sample application will generate events and push them to an Event Hubs instance (an Event Hub, for short). Service Bus Event Hubs are the preferred method of event ingestion for Stream Analytics. See Event Hubs documentation in [Service Bus documentation](/documentation/services/service-bus/)\n\nFollow the steps below to create an Event Hub.\n\n1.  In the Azure Portal click **NEW** > **APP SERVICES** > **SERVICE BUS** > **EVENT HUB** > **QUICK CREATE** and provide a name, region, and new or existing namespace to create a new Event Hub.  \n2.  As a best practice, each Stream Analytics job should read from a single Event Hubs Consumer Group. We will walk you through the process of creating a Consumer Group below and you can learn more about them here.  To create a Consumer Group, navigate to the newly created Event Hub and click the **CONSUMER GROUPS** tab, then click **CREATE** on the bottom of the page and provide a name for your Consumer Group.\n3.  To grant access to the Event Hub, we will need to create a shared access policy.  Click the **CONFIGURE** tab of your Event Hub.\n4.  Under **SHARED ACCESS POLICIES**, create a new policy with **MANAGE** permissions.\n\n\n    ![Shared Access Policies where you can create a policy with Manage permissions.](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-ananlytics-shared-access-policies.png)\n\n5.  Click **SAVE** at the bottom of the page.\n6.  Navigate to the **DASHBOARD** and click **CONNECTION INFORMATION** at the bottom of the page and copy and save the connection information. (Use the copy icon that appears under the search icon.)\n\n## Configure and start the Twitter client application\n\nWe have provided a client application that will tap into Twitter data via [Twitter's Streaming APIs](https://dev.twitter.com/streaming/overview) to collect Tweet events about a parameterized set of topics. The 3rd party open source tool [Sentiment140](http://help.sentiment140.com/) is used to assign a sentiment value to each tweet (0: negative, 2: neutral, 4: positive) and then Tweet events are pushed to Event Hub.  \n\nFollow these steps to set up the application:\n\n1.  [Download the TwitterClient solution](https://github.com/streamanalytics/samples/tree/master/TwitterClient)\n2.  Open App.config and replace oauth_consumer_key, oauth_consumer_secret, oauth_token, oauth_token_secret with Twitter tokens with your values.  \n\n    [Steps to generate an OAuth access token](https://dev.twitter.com/oauth/overview/application-owner-access-tokens)  \n\n    Note that you will need to make an empty application to generate a token.  \n3.  Replace the EventHubConnectionString and EventHubName values in App.config with your Event Hub connection string and name.\n4.  *Optional:* Adjust the keywords to search for.  As a default, this application looks for \"Azure,Skype,XBox,Microsoft,Seattle\".  You can adjust the values for twitter_keywords in App.config, if desired.\n5.  Build the solution\n6.  Start the application.  You will see Tweet events with the CreatedAt, Topic, and SentimentScore values being sent to your Event Hub:\n\n    ![Sentiment analysis: SentimentScore values sent to an event hub.](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-twitter-sentiment-output-to-event-hub.png)\n\n## Create Stream Analytics job\n\nNow that we have Tweet events streaming in real-time from Twitter, we can set up a Stream Analytics job to analyze these events in real time.\n\n### Provision a Stream Analytics job\n\n1.  In the [Azure Portal](https://manage.windowsazure.com/), click **NEW** > **DATA SERVICES** > **STREAM ANALYTICS** > **QUICK CREATE**.\n2.  Specify the following values, and then click **CREATE STREAM ANALYTICS JOB**:\n\n    * **JOB NAME**: Enter a job name.\n    * **REGION**: Select the region where you want to run the job. Consider placing the job and the event hub in the same region to ensure better performance and to ensure that you will not be paying to transfer data between regions.\n    * **STORAGE ACCOUNT**: Choose the Storage account that you would like to use to store monitoring data for all Stream Analytics jobs running within this region. You have the option to choose an existing Storage account or to create a new one.\n\n3.  Click **STREAM ANALYTICS** in the left pane to list the Stream Analytics jobs.\n    ![Stream Analytics service icon](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-service-icon.png)\n\n4.  The new job will be shown with a status of **CREATED**. Notice that the **START** button on the bottom of the page is disabled. You must configure the job input, output, and query before you can start the job.\n\n\n### Specify job input\n1.  In your Stream Analytics job click **INPUTS** from the top of the page, and then click **ADD INPUT**. The dialog that opens will walk you through a number of steps to set up your input.\n2.  Select **DATA STREAM**, and then click the right button.\n3.  Select **EVENT HUB**, and then click the right button.\n4.  Type or select the following values on the third page:\n\n    * **INPUT ALIAS**: Enter a friendly name for this job input, such as TwitterStream. Note that you will be using this name in the query later on.\n    **EVENT HUB**: If the Event Hub you created is in the same subscription as the Stream Analytics job, select the namespace that the event hub is in.\n\n        If your event hub is in a different subscription, select **Use Event Hub from Another Subscription**, and then manually enter information for **SERVICE BUS NAMESPACE**, **EVENT HUB NAME**, **EVENT HUB POLICY NAME**, **EVENT HUB POLICY KEY**, and **EVENT HUB PARTITION COUNT**.\n\n    * **EVENT HUB NAME**: Select the name of the Event Hub\n    * **EVENT HUB POLICY NAME**: Select the event-hub policy created earlier in this tutorial.\n    * **EVENT HUB CONSUMER GROUP**: Type in the Consumer Group created earlier in this tutorial.\n5.  Click the right button.\n6.  Specify the following values:\n\n    * **EVENT SERIALIZER FORMAT**: JSON\n    * **ENCODING**: UTF8\n\n7.  Click the check button to add this source and to verify that Stream Analytics can successfully connect to the event hub.\n\n### Specify job query\n\nStream Analytics supports a simple, declarative query model for describing transformations. To learn more about the language, see the [Azure Stream Analytics Query Language Reference](https://msdn.microsoft.com/library/azure/dn834998.aspx).  This tutorial will help you author and test several queries over Twitter data.\n\n#### Sample data input\n\nTo validate your query against actual job data, you can use the SAMPLE DATA feature to extract events from your stream and create a .JSON file of the events for testing.\n\n1.  Select on your Event Hub input and click **SAMPLE DATA** at the bottom of the page.\n2.  In the dialog that appears, specify a **START TIME** to start collecting data from and a **DURATION** for how much additional data to consume.\n3.  Click the **DETAILS** button, and then the **Click here** link to download and save the .JSON file that is generated.\n\n#### Pass-through query\nTo start with, we will do a simple pass-through query that projects all the fields in an event.\n\n1.  Click **QUERY** from the top of the Stream Analytics job page.\n2.  In the code editor, replace the initial query template with the following:\n\n        SELECT * FROM TwitterStream\n\n    Make sure that the name of the input source matches the name of the input you specified earlier.\n\n3.  Click **TEST** under the query editor\n4.  Browse to your sample .JSON file\n5.  Click the check button and see the results displayed below the query definition.\n\n    ![Results displayed below query definition](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-sentiment-by-topic.png)\n\n#### Count of tweets by topic: Tumbling window with aggregation\n\nTo compare the number of mentions between topics, we'll leverage a [TumblingWindow](https://msdn.microsoft.com/library/azure/dn835055.aspx) to get the count of mentions by topic every 5 seconds.\n\n1.  Change the query in the code editor to:\n\n        SELECT System.Timestamp as Time, Topic, COUNT(*)\n        FROM TwitterStream TIMESTAMP BY CreatedAt\n        GROUP BY TUMBLINGWINDOW(s, 5), Topic\n\n    Note that this query uses the **TIMESTAMP BY** keyword to specify a timestamp field in the payload to be used in the temporal computation.  If this field wasn't specified, the windowing operation would be performed using the time each event arrived at Event Hub.  Learn more under \"Arrival Time Vs Application Time\" in the [Stream Analytics Query Reference](https://msdn.microsoft.com/library/azure/dn834998.aspx).\n\n    This query also accesses a timestamp for the end of each window with **System.Timestamp**.\n\n2.  Click **RERUN** under the query editor to see the results of the query.\n\n#### Identifying trending topics: Sliding window\n\nTo identify trending topics we'll look for topics that cross a threshold value for mentions in a given amount of time.  For the purposes of this tutorial, we'll check for topics that are mentioned more than 20 times in the last 5 seconds using a [SlidingWindow](https://msdn.microsoft.com/library/azure/dn835051.aspx).\n\n1.  Change the query in the code editor to:\n\n        SELECT System.Timestamp as Time, Topic, COUNT(*) as Mentions\n        FROM TwitterStream TIMESTAMP BY CreatedAt\n        GROUP BY SLIDINGWINDOW(s, 5), topic\n        HAVING COUNT(*) > 20\n\n2.  Click **RERUN** under the query editor to see the results of the query.\n\n    ![Sliding Window query output](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-query-output.png)\n\n#### Count of mentions and sentiment: Tumbling window with aggregation\n\nThe final query we will test uses a TumblingWindow to obtain the number of mentions and average, minimum, maximum, and standard deviation of sentiment score for each topic every 5 seconds.\n\n1.  Change the query in the code editor to:\n\n        SELECT System.Timestamp as Time, Topic, COUNT(*), AVG(SentimentScore), MIN(SentimentScore),\n        Max(SentimentScore), STDEV(SentimentScore)\n        FROM TwitterStream TIMESTAMP BY CreatedAt\n        GROUP BY TUMBLINGWINDOW(s, 5), Topic\n\n2.  Click **RERUN** under the query editor to see the results of the query.\n3.  This is the query we will use for our dashboard.  Click **SAVE** at the bottom of the page.\n\n\n## Create output sink\n\nNow that we have defined an event stream, an Event Hub input to ingest events, and a query to perform a transformation over the stream, the last step is to define an output sink for the job.  We'll write the aggregated tweet events from our job query to an Azure Blob.  You could also push your results to SQL Database, Table Store or Event Hub, depending on your specific application needs.\n\nFollow the steps below to create a container for Blob storage, if you don't already have one:\n\n1.  Use an existing Storage account or create a new Storage account by clicking **NEW** > **DATA SERVICES** > **STORAGE** > **QUICK CREATE** > and following the instructions on  the screen.\n2.  Select the Storage account and then click **CONTAINERS** at the top of the page, and then click **ADD**.\n3.  Specify a **NAME** for your container and set its **ACCESS** to Public Blob.\n\n## Specify job output\n\n1.  In your Stream Analytics job, click **OUTPUT** at the top of the page, and then click **ADD OUTPUT**. The dialog that opens will walk you through a number of steps to set up your output.\n2.  Select **BLOB STORAGE**, and then click the right button.\n3.  Type or select the following values on the third page:\n\n    * **OUTPUT ALIAS**: Enter a friendly name for this job output\n    * **SUBSCRIPTION**: If the Blob Storage you created is in the same subscription as the Stream Analytics job, select **Use Storage Account from Current Subscription**.  If your storage is in a different subscription, select **Use Storage Account from Another Subscription** and manually enter information for **STORAGE ACCOUNT**, **STORAGE ACCOUNT KEY**, **CONTAINER**.\n    * **STORAGE ACCOUNT**: Select the name of the Storage Account\n    * **CONTAINER**: Select the name of the Container\n    * **FILENAME PREFIX**: Type in a file prefix to use when writing blob output\n\n4.  Click the right button.\n5.  Specify the following values:\n    * **EVENT SERIALIZER FORMAT**: JSON\n    * **ENCODING**: UTF8\n6.  Click the check button to add this source and to verify that Stream Analytics can successfully connect to the storage account.\n\n## Start job\n\nSince a job input, query and output have all been specified, we are ready to start the Stream Analytics job.\n\n1.  From the job **DASHBOARD**, click **START** at the bottom of the page.\n2.  In the dialog that appears, select **JOB START TIME**, and then click the checkmark button on the bottom of the dialog. The job status will change to **Starting** and will shortly move to **Running**.\n\n\n## View output for sentiment analysis\n\nOnce your job is running and processing the real-time Twitter stream, choose how you want to view the output for sentiment analysis. Use a tool like [Azure Storage Explorer](https://azurestorageexplorer.codeplex.com/) or [Azure Explorer](http://www.cerebrata.com/products/azure-explorer/introduction) to view your job output in real time. From here, you could extend your application to include a customized dashboard over your output, like the one pictured below using [Power BI](https://powerbi.com/).\n\n![Social media analysis: Stream Analytics sentiment analysis (opinion mining) output in a Power BI dashboard.](./media/stream-analytics-twitter-sentiment-analysis-trends/stream-analytics-output-power-bi.png)\n\n## Get support\nFor further assistance, try our [Azure Stream Analytics forum](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics). \n\n\n## Next steps\n\n- [Introduction to Azure Stream Analytics](stream-analytics-introduction.md)\n- [Get started using Azure Stream Analytics](stream-analytics-get-started.md)\n- [Scale Azure Stream Analytics jobs](stream-analytics-scale-jobs.md)\n- [Azure Stream Analytics Query Language Reference](https://msdn.microsoft.com/library/azure/dn834998.aspx)\n- [Azure Stream Analytics Management REST API Reference](https://msdn.microsoft.com/library/azure/dn835031.aspx)\n \n"
}