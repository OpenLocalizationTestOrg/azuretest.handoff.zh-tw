{
  "nodes": [
    {
      "content": "Use R in HDInsight to customize clusters | Microsoft Azure",
      "pos": [
        28,
        86
      ]
    },
    {
      "content": "Learn how to install and use R to customize Hadoop clusters.",
      "pos": [
        106,
        166
      ]
    },
    {
      "content": "Install and use R on HDInsight Hadoop clusters",
      "pos": [
        484,
        530
      ]
    },
    {
      "content": "You can install R on any type of cluster in Hadoop on HDInsight by using <bpt id=\"p1\">**</bpt>Script Action<ept id=\"p1\">**</ept> cluster customization.",
      "pos": [
        532,
        645
      ]
    },
    {
      "content": "This enables data scientists and analysts to use R to deploy the powerful MapReduce/YARN programming framework to process large amounts of data on Hadoop clusters that are deployed in HDInsight.",
      "pos": [
        646,
        840
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The steps in this document require a Linux-based HDInsight cluster.",
      "pos": [
        844,
        924
      ]
    },
    {
      "content": "For information on using R with a Windows-based cluster, see <bpt id=\"p1\">[</bpt>Install and use R on HDinsight Hadoop clusters (Windows)<ept id=\"p1\">](hdinsight-hadoop-r-scripts.md)</ept>",
      "pos": [
        925,
        1075
      ]
    },
    {
      "content": "What is R?",
      "pos": [
        1080,
        1090
      ]
    },
    {
      "content": "The <ph id=\"ph1\">&lt;a href=\"http://www.r-project.org/\" target=\"_blank\"&gt;</ph>R Project for Statistical Computing<ph id=\"ph2\">&lt;/a&gt;</ph> is an open source language and environment for statistical computing.",
      "pos": [
        1092,
        1257
      ]
    },
    {
      "content": "R provides hundreds of build-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.",
      "pos": [
        1258,
        1413
      ]
    },
    {
      "content": "It also provides extensive graphical capabilities.",
      "pos": [
        1414,
        1464
      ]
    },
    {
      "content": "R is the preferred programming environment for most professional statisticians and scientists in a wide variety of fields.",
      "pos": [
        1465,
        1587
      ]
    },
    {
      "content": "R scripts can be run on Hadoop clusters in HDInsight that were customized using Script Action when created to install the R environment.",
      "pos": [
        1590,
        1726
      ]
    },
    {
      "content": "R is compatible with Azure Blob Storage (WASB) so that data that is stored there can be processed using R on HDInsight.",
      "pos": [
        1727,
        1846
      ]
    },
    {
      "content": "What the script does",
      "pos": [
        1851,
        1871
      ]
    },
    {
      "content": "The script action used to install R on your HDInsight cluster installs the following Ubuntu packages, which provide a basic R installation:",
      "pos": [
        1873,
        2012
      ]
    },
    {
      "pos": [
        2016,
        2087
      ],
      "content": "<bpt id=\"p1\">[</bpt>r-base<ept id=\"p1\">](http://packages.ubuntu.com/precise/r-base)</ept>: Base GNU R package"
    },
    {
      "pos": [
        2090,
        2176
      ],
      "content": "<bpt id=\"p1\">[</bpt>r-base-dev<ept id=\"p1\">](http://packages.ubuntu.com/precise/r-base-dev)</ept>: Auxilliary GNU R packages"
    },
    {
      "content": "The following RHadoop packages are also installed, which provide integration with MapReduce and HDFS:",
      "pos": [
        2178,
        2279
      ]
    },
    {
      "pos": [
        2283,
        2379
      ],
      "content": "<bpt id=\"p1\">[</bpt>rmr2<ept id=\"p1\">](https://github.com/RevolutionAnalytics/rmr2)</ept>: Allows R developers to use Hadoop MapReduce"
    },
    {
      "pos": [
        2382,
        2496
      ],
      "content": "<bpt id=\"p1\">[</bpt>rhdfs<ept id=\"p1\">](https://github.com/RevolutionAnalytics/rhdfs)</ept>: Allows R developers to use Hadoop HDFS (WASB for HDInsight)"
    },
    {
      "content": "Additionally, the following R packages are installed:",
      "pos": [
        2498,
        2551
      ]
    },
    {
      "content": "R package",
      "pos": [
        2555,
        2564
      ]
    },
    {
      "content": "What it provides",
      "pos": [
        2567,
        2583
      ]
    },
    {
      "content": "rJava",
      "pos": [
        2622,
        2627
      ]
    },
    {
      "content": "A low level R to Java interface.",
      "pos": [
        2689,
        2721
      ]
    },
    {
      "content": "Rcpp",
      "pos": [
        2727,
        2731
      ]
    },
    {
      "content": "R and C++ integration.",
      "pos": [
        2792,
        2814
      ]
    },
    {
      "content": "RJSONIO",
      "pos": [
        2820,
        2827
      ]
    },
    {
      "content": "Serialize/deserialize R objects to JSON",
      "pos": [
        2891,
        2930
      ]
    },
    {
      "content": "bitops",
      "pos": [
        2936,
        2942
      ]
    },
    {
      "content": "Functions for bitwise operations on integer vectors.",
      "pos": [
        3005,
        3057
      ]
    },
    {
      "content": "[digest](Create Cryptographic Hash Digests of R Objects)",
      "pos": [
        3062,
        3118
      ]
    },
    {
      "content": "Create Cryptographic Hash Digests of R Objects.",
      "pos": [
        3121,
        3168
      ]
    },
    {
      "content": "functional",
      "pos": [
        3174,
        3184
      ]
    },
    {
      "content": "Curry, Compose, and other higher-order functions",
      "pos": [
        3251,
        3299
      ]
    },
    {
      "content": "reshape2",
      "pos": [
        3305,
        3313
      ]
    },
    {
      "content": "Flexibly restructure and aggregate data.",
      "pos": [
        3378,
        3418
      ]
    },
    {
      "content": "stringr",
      "pos": [
        3424,
        3431
      ]
    },
    {
      "content": "Simple, Consistent Wrappers for Common String Operations.",
      "pos": [
        3495,
        3552
      ]
    },
    {
      "content": "plyr",
      "pos": [
        3558,
        3562
      ]
    },
    {
      "content": "Tools for Splitting, Applying and Combining Data.",
      "pos": [
        3623,
        3672
      ]
    },
    {
      "content": "caTools",
      "pos": [
        3678,
        3685
      ]
    },
    {
      "content": "Tools for moving window statistics, GIF, Base64, ROC AUC, etc.",
      "pos": [
        3749,
        3811
      ]
    },
    {
      "content": "stringdist",
      "pos": [
        3817,
        3827
      ]
    },
    {
      "content": "Approximate String Matching and String Distance Functions.",
      "pos": [
        3894,
        3952
      ]
    },
    {
      "content": "Install R using Script Actions",
      "pos": [
        3959,
        3989
      ]
    },
    {
      "content": "The <bpt id=\"p1\">[</bpt>https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh<ept id=\"p1\">](https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh)</ept> script action is used to install R on an HDInsight cluster.",
      "pos": [
        3991,
        4233
      ]
    },
    {
      "content": "This section provides instructions about how to use the script when provisioning the cluster using the Azure portal.",
      "pos": [
        4234,
        4350
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.",
      "pos": [
        4354,
        4465
      ]
    },
    {
      "content": "For more information on using these methods, see <bpt id=\"p1\">[</bpt>Customize HDInsight clusters with Script Actions<ept id=\"p1\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
      "pos": [
        4466,
        4611
      ]
    },
    {
      "pos": [
        4616,
        4790
      ],
      "content": "Start provisioning a cluster by using the steps in <bpt id=\"p1\">[</bpt>Provision Linux-based HDInsight clusters<ept id=\"p1\">](hdinsight-provision-linux-clusters.md#portal)</ept>, but do not complete provisioning."
    },
    {
      "pos": [
        4795,
        4897
      ],
      "content": "On the <bpt id=\"p1\">**</bpt>Optional Configuration<ept id=\"p1\">**</ept> blade, select <bpt id=\"p2\">**</bpt>Script Actions<ept id=\"p2\">**</ept>, and provide the information below:"
    },
    {
      "pos": [
        4905,
        4959
      ],
      "content": "<bpt id=\"p1\">__</bpt>NAME<ept id=\"p1\">__</ept>: Enter a friendly name for the script action."
    },
    {
      "pos": [
        4966,
        5069
      ],
      "content": "<bpt id=\"p1\">__</bpt>SCRIPT URI<ept id=\"p1\">__</ept>: https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh"
    },
    {
      "pos": [
        5076,
        5103
      ],
      "content": "<bpt id=\"p1\">__</bpt>HEAD<ept id=\"p1\">__</ept>: Check this option"
    },
    {
      "pos": [
        5110,
        5139
      ],
      "content": "<bpt id=\"p1\">__</bpt>WORKER<ept id=\"p1\">__</ept>: Check this option"
    },
    {
      "pos": [
        5146,
        5212
      ],
      "content": "<bpt id=\"p1\">__</bpt>ZOOKEEPER<ept id=\"p1\">__</ept>: Check this option to install on the Zookeeper node."
    },
    {
      "pos": [
        5219,
        5257
      ],
      "content": "<bpt id=\"p1\">__</bpt>PARAMETERS<ept id=\"p1\">__</ept>: Leave this field blank"
    },
    {
      "content": "At the bottom of the <bpt id=\"p1\">**</bpt>Script Actions<ept id=\"p1\">**</ept>, use the <bpt id=\"p2\">**</bpt>Select<ept id=\"p2\">**</ept> button to save the configuration.",
      "pos": [
        5262,
        5355
      ]
    },
    {
      "content": "Finally, use the <bpt id=\"p1\">**</bpt>Select<ept id=\"p1\">**</ept> button at the bottom of the <bpt id=\"p2\">**</bpt>Optional Configuration<ept id=\"p2\">**</ept> blade to save the optional configuration information.",
      "pos": [
        5356,
        5492
      ]
    },
    {
      "pos": [
        5497,
        5635
      ],
      "content": "Continue provisining the cluster as described in <bpt id=\"p1\">[</bpt>Provision Linux-based HDInsight clusters<ept id=\"p1\">](hdinsight-provision-linux-clusters.md#portal)</ept>."
    },
    {
      "content": "Run R scripts",
      "pos": [
        5640,
        5653
      ]
    },
    {
      "content": "After the cluster has finished provisioning, use the following steps to use R to perform a MapReduce operation on the cluster.",
      "pos": [
        5655,
        5781
      ]
    },
    {
      "content": "Connect to the HDInsight cluster using SSH:",
      "pos": [
        5786,
        5829
      ]
    },
    {
      "content": "For more information on using SSH with HDInsight, see the following:",
      "pos": [
        5900,
        5968
      ]
    },
    {
      "content": "Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X",
      "pos": [
        5981,
        6051
      ]
    },
    {
      "content": "Use SSH with Linux-based Hadoop on HDInsight from Windows",
      "pos": [
        6105,
        6162
      ]
    },
    {
      "pos": [
        6211,
        6314
      ],
      "content": "From the <ph id=\"ph1\">`username@headnode1:~$`</ph> prompt, enter the following command to start an interactive R session:"
    },
    {
      "content": "Enter the following R program.",
      "pos": [
        6330,
        6360
      ]
    },
    {
      "content": "This generates the numbers 1 to 100 and then multiplies them by 2.",
      "pos": [
        6361,
        6427
      ]
    },
    {
      "content": "The first line calls the RHadoop library rmr2, which is used for MapReduce operations.",
      "pos": [
        6569,
        6655
      ]
    },
    {
      "pos": [
        6665,
        6765
      ],
      "content": "The second line generates values 1 - 100, then stores them to the Hadoop file system using <ph id=\"ph1\">`to.dfs`</ph>."
    },
    {
      "content": "The third line creates a MapReduce process using functionality provided by rmr2, and begins processing.",
      "pos": [
        6775,
        6878
      ]
    },
    {
      "content": "You should see several lines scroll past as the processing begins.",
      "pos": [
        6879,
        6945
      ]
    },
    {
      "content": "Next, use the following to see the temporary path that the MapReduce output was stored to:",
      "pos": [
        6954,
        7044
      ]
    },
    {
      "content": "This should be something similar to <ph id=\"ph1\">`/tmp/file5f615d870ad2`</ph>.",
      "pos": [
        7081,
        7141
      ]
    },
    {
      "content": "To view the actual output, use the following:",
      "pos": [
        7142,
        7187
      ]
    },
    {
      "content": "The output should look like this:",
      "pos": [
        7232,
        7265
      ]
    },
    {
      "content": "To exit R, enter the following:",
      "pos": [
        7416,
        7447
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        7466,
        7476
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install and use Hue on HDInsight clusters<ept id=\"p1\">](hdinsight-hadoop-hue-linux.md)</ept>.",
      "pos": [
        7480,
        7555
      ]
    },
    {
      "content": "Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.",
      "pos": [
        7556,
        7699
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install and use Spark on HDInsight clusters<ept id=\"p1\">][hdinsight-install-spark]</ept> for  instructions about how to use cluster customization to install and use Spark on HDInsight Hadoop clusters.",
      "pos": [
        7703,
        7885
      ]
    },
    {
      "content": "Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big data analytic applications.",
      "pos": [
        7886,
        8034
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install Giraph on HDInsight clusters<ept id=\"p1\">](../hdinsight-hadoop-giraph-install)</ept>.",
      "pos": [
        8038,
        8113
      ]
    },
    {
      "content": "Use cluster customization to install Giraph on HDInsight Hadoop clusters.",
      "pos": [
        8114,
        8187
      ]
    },
    {
      "content": "Giraph allows you to perform graph processing using Hadoop, and it can be used with Azure HDInsight.",
      "pos": [
        8188,
        8288
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install Solr on HDInsight clusters<ept id=\"p1\">](../hdinsight-hadoop-solr-install)</ept>.",
      "pos": [
        8292,
        8363
      ]
    },
    {
      "content": "Use cluster customization to install Solr on HDInsight Hadoop clusters.",
      "pos": [
        8364,
        8435
      ]
    },
    {
      "content": "Solr allows you to perform powerful search operations on stored data.",
      "pos": [
        8436,
        8505
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install Hue on HDInsight clusters<ept id=\"p1\">](hdinsight-hadoop-hue-linux.md)</ept>.",
      "pos": [
        8509,
        8576
      ]
    },
    {
      "content": "Use cluster customization to install Hue on HDInsight Hadoop clusters.",
      "pos": [
        8577,
        8647
      ]
    },
    {
      "content": "Hue is a set of Web applications used to interact with a Hadoop cluster.",
      "pos": [
        8648,
        8720
      ]
    },
    {
      "content": "test",
      "pos": [
        8997,
        9001
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Use R in HDInsight to customize clusters | Microsoft Azure\" \n    description=\"Learn how to install and use R to customize Hadoop clusters.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"Blackmist\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"08/20/2015\" \n    ms.author=\"larryfr\"/>\n\n# Install and use R on HDInsight Hadoop clusters\n\nYou can install R on any type of cluster in Hadoop on HDInsight by using **Script Action** cluster customization. This enables data scientists and analysts to use R to deploy the powerful MapReduce/YARN programming framework to process large amounts of data on Hadoop clusters that are deployed in HDInsight.\n\n> [AZURE.NOTE] The steps in this document require a Linux-based HDInsight cluster. For information on using R with a Windows-based cluster, see [Install and use R on HDinsight Hadoop clusters (Windows)](hdinsight-hadoop-r-scripts.md)\n\n## What is R?\n\nThe <a href=\"http://www.r-project.org/\" target=\"_blank\">R Project for Statistical Computing</a> is an open source language and environment for statistical computing. R provides hundreds of build-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming. It also provides extensive graphical capabilities. R is the preferred programming environment for most professional statisticians and scientists in a wide variety of fields. \n\nR scripts can be run on Hadoop clusters in HDInsight that were customized using Script Action when created to install the R environment. R is compatible with Azure Blob Storage (WASB) so that data that is stored there can be processed using R on HDInsight.\n\n## What the script does\n\nThe script action used to install R on your HDInsight cluster installs the following Ubuntu packages, which provide a basic R installation:\n\n* [r-base](http://packages.ubuntu.com/precise/r-base): Base GNU R package\n* [r-base-dev](http://packages.ubuntu.com/precise/r-base-dev): Auxilliary GNU R packages\n\nThe following RHadoop packages are also installed, which provide integration with MapReduce and HDFS:\n\n* [rmr2](https://github.com/RevolutionAnalytics/rmr2): Allows R developers to use Hadoop MapReduce\n* [rhdfs](https://github.com/RevolutionAnalytics/rhdfs): Allows R developers to use Hadoop HDFS (WASB for HDInsight)\n\nAdditionally, the following R packages are installed:\n\n| R package | What it provides |\n| --------- | ---------------- |\n| [rJava](https://cran.r-project.org/web/packages/rJava/index.html) | A low level R to Java interface. |\n| [Rcpp](https://cran.r-project.org/web/packages/Rcpp/index.html) | R and C++ integration. |\n| [RJSONIO](https://cran.r-project.org/web/packages/RJSONIO/index.html) | Serialize/deserialize R objects to JSON |\n| [bitops](https://cran.r-project.org/web/packages/bitops/index.html) | Functions for bitwise operations on integer vectors. |\n| [digest](Create Cryptographic Hash Digests of R Objects) | Create Cryptographic Hash Digests of R Objects. |\n| [functional](https://cran.r-project.org/web/packages/functional/index.html) | Curry, Compose, and other higher-order functions |\n| [reshape2](https://cran.r-project.org/web/packages/reshape2/index.html) | Flexibly restructure and aggregate data. |\n| [stringr](https://cran.r-project.org/web/packages/stringr/index.html) | Simple, Consistent Wrappers for Common String Operations. |\n| [plyr](https://cran.r-project.org/web/packages/plyr/index.html) | Tools for Splitting, Applying and Combining Data. |\n| [caTools](https://cran.r-project.org/web/packages/caTools/index.html) | Tools for moving window statistics, GIF, Base64, ROC AUC, etc. |\n| [stringdist](https://cran.r-project.org/web/packages/stringdist/index.html) | Approximate String Matching and String Distance Functions. |\n\n## Install R using Script Actions\n\nThe [https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh) script action is used to install R on an HDInsight cluster. This section provides instructions about how to use the script when provisioning the cluster using the Azure portal.\n\n> [AZURE.NOTE] You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script. For more information on using these methods, see [Customize HDInsight clusters with Script Actions](hdinsight-hadoop-customize-cluster-linux.md).\n\n1. Start provisioning a cluster by using the steps in [Provision Linux-based HDInsight clusters](hdinsight-provision-linux-clusters.md#portal), but do not complete provisioning.\n\n2. On the **Optional Configuration** blade, select **Script Actions**, and provide the information below:\n\n    * __NAME__: Enter a friendly name for the script action.\n    * __SCRIPT URI__: https://hdiconfigactions.blob.core.windows.net/linuxrconfigactionv01/r-installer-v01.sh\n    * __HEAD__: Check this option\n    * __WORKER__: Check this option\n    * __ZOOKEEPER__: Check this option to install on the Zookeeper node.\n    * __PARAMETERS__: Leave this field blank\n\n3. At the bottom of the **Script Actions**, use the **Select** button to save the configuration. Finally, use the **Select** button at the bottom of the **Optional Configuration** blade to save the optional configuration information.\n\n4. Continue provisining the cluster as described in [Provision Linux-based HDInsight clusters](hdinsight-provision-linux-clusters.md#portal).\n\n## Run R scripts\n\nAfter the cluster has finished provisioning, use the following steps to use R to perform a MapReduce operation on the cluster.\n\n1. Connect to the HDInsight cluster using SSH:\n\n        ssh USERNAME@CLUSTERNAME-ssh.azurehdinsight.net\n        \n    For more information on using SSH with HDInsight, see the following:\n    \n    * [Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md)\n    \n    * [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md)\n\n2. From the `username@headnode1:~$` prompt, enter the following command to start an interactive R session:\n\n        R\n\n3. Enter the following R program. This generates the numbers 1 to 100 and then multiplies them by 2.\n\n        library(rmr2)\n        ints = to.dfs(1:100)\n        calc = mapreduce(input = ints, map = function(k, v) cbind(v, 2*v))\n        \n\n    The first line calls the RHadoop library rmr2, which is used for MapReduce operations.\n    \n    The second line generates values 1 - 100, then stores them to the Hadoop file system using `to.dfs`.\n    \n    The third line creates a MapReduce process using functionality provided by rmr2, and begins processing. You should see several lines scroll past as the processing begins.\n    \n4. Next, use the following to see the temporary path that the MapReduce output was stored to:\n\n        print(calc())\n        \n    This should be something similar to `/tmp/file5f615d870ad2`. To view the actual output, use the following:\n    \n        print(from.dfs(calc))\n    \n    The output should look like this:\n    \n        [1,]  1 2\n        [2,]  2 4\n        .\n        .\n        .\n        [98,]  98 196\n        [99,]  99 198\n        [100,] 100 200\n        \n5. To exit R, enter the following:\n\n        q()\n\n\n## Next steps\n\n- [Install and use Hue on HDInsight clusters](hdinsight-hadoop-hue-linux.md). Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.\n\n- [Install and use Spark on HDInsight clusters][hdinsight-install-spark] for  instructions about how to use cluster customization to install and use Spark on HDInsight Hadoop clusters. Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big data analytic applications.\n\n- [Install Giraph on HDInsight clusters](../hdinsight-hadoop-giraph-install). Use cluster customization to install Giraph on HDInsight Hadoop clusters. Giraph allows you to perform graph processing using Hadoop, and it can be used with Azure HDInsight.\n\n- [Install Solr on HDInsight clusters](../hdinsight-hadoop-solr-install). Use cluster customization to install Solr on HDInsight Hadoop clusters. Solr allows you to perform powerful search operations on stored data.\n\n- [Install Hue on HDInsight clusters](hdinsight-hadoop-hue-linux.md). Use cluster customization to install Hue on HDInsight Hadoop clusters. Hue is a set of Web applications used to interact with a Hadoop cluster.\n\n[powershell-install-configure]: install-configure-powershell-linux.md\n[hdinsight-provision]: hdinsight-provision-clusters-linux.md\n[hdinsight-cluster-customize]: hdinsight-hadoop-customize-cluster-linux.md\n[hdinsight-install-spark]: hdinsight-hadoop-spark-install-linux.md\n \ntest\n"
}