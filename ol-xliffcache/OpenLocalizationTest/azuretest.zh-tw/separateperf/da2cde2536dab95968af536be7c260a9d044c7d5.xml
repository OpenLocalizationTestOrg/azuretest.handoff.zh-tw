{
  "nodes": [
    {
      "content": "Submit Hadoop jobs in HDInsight | Microsoft Azure",
      "pos": [
        27,
        76
      ]
    },
    {
      "content": "Learn how to submit Hadoop jobs to Azure HDInsight Hadoop.",
      "pos": [
        95,
        153
      ]
    },
    {
      "content": "Submit Hadoop jobs in HDInsight",
      "pos": [
        477,
        508
      ]
    },
    {
      "content": "Learn how to use Azure PowerShell to submit MapReduce and Hive jobs, and how to use the HDInsight .NET SDK to submit MapReduce, Hadoop streaming, and Hive jobs.",
      "pos": [
        510,
        670
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The steps in this article must be performed from a Windows client.",
      "pos": [
        674,
        753
      ]
    },
    {
      "content": "For information on using a Linux, OS X, or Unix client to work with MapReduce, Hive, or Pig on HDInsight, see the following articles and select either the <bpt id=\"p1\">**</bpt>SSH<ept id=\"p1\">**</ept> or <bpt id=\"p2\">**</bpt>Curl<ept id=\"p2\">**</ept> links within each:",
      "pos": [
        754,
        947
      ]
    },
    {
      "content": "Use Hive with HDInsight",
      "pos": [
        955,
        978
      ]
    },
    {
      "content": "Use Pig with HDInsight",
      "pos": [
        1008,
        1030
      ]
    },
    {
      "content": "Use MapReduce with HDInsight",
      "pos": [
        1059,
        1087
      ]
    },
    {
      "content": "Prerequisites",
      "pos": [
        1120,
        1133
      ]
    },
    {
      "content": "Before you begin this article, you must have the following:",
      "pos": [
        1135,
        1194
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>An Azure HDInsight cluster<ept id=\"p1\">**</ept>.",
      "pos": [
        1198,
        1229
      ]
    },
    {
      "content": "For instructions, see <bpt id=\"p1\">[</bpt>Get started with HDInsight<ept id=\"p1\">][hdinsight-get-started]</ept> or <bpt id=\"p2\">[</bpt>Provision HDInsight clusters<ept id=\"p2\">][hdinsight-provision]</ept>.",
      "pos": [
        1230,
        1359
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>A workstation with Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        1362,
        1402
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Install and use Azure PowerShell<ept id=\"p1\">](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.",
      "pos": [
        1403,
        1525
      ]
    },
    {
      "content": "Submit MapReduce jobs by using Azure PowerShell",
      "pos": [
        1531,
        1578
      ]
    },
    {
      "content": "Azure PowerShell is a powerful scripting environment that you can use to control and automate the deployment and management of your workloads in Azure.",
      "pos": [
        1579,
        1730
      ]
    },
    {
      "content": "For more information about using Azure PowerShell with HDInsight, see <bpt id=\"p1\">[</bpt>Manage HDInsight by using PowerShell<ept id=\"p1\">][hdinsight-admin-powershell]</ept>.",
      "pos": [
        1731,
        1868
      ]
    },
    {
      "content": "Hadoop MapReduce is a software framework for writing applications that process vast amounts of data.",
      "pos": [
        1870,
        1970
      ]
    },
    {
      "content": "HDInsight clusters come with a JAR file (located at <bpt id=\"p1\">*</bpt>\\example\\jars\\hadoop-mapreduce-examples.jar<ept id=\"p1\">*</ept>), which contains several MapReduce examples.",
      "pos": [
        1971,
        2113
      ]
    },
    {
      "content": "One of the examples is for counting word frequencies in source files.",
      "pos": [
        2115,
        2184
      ]
    },
    {
      "content": "In this session, you will learn how to use Azure PowerShell from a workstation to run the word count sample.",
      "pos": [
        2185,
        2293
      ]
    },
    {
      "content": "For more information about developing and running MapReduce jobs, see <bpt id=\"p1\">[</bpt>Use MapReduce with HDInsight<ept id=\"p1\">][hdinsight-use-mapreduce]</ept>.",
      "pos": [
        2294,
        2420
      ]
    },
    {
      "content": "To run the word count MapReduce program by using Azure PowerShell",
      "pos": [
        2424,
        2489
      ]
    },
    {
      "content": "Open <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        2497,
        2523
      ]
    },
    {
      "content": "For instructions about how to open the Azure PowerShell console window, see <bpt id=\"p1\">[</bpt>Install and configure Azure PowerShell<ept id=\"p1\">][powershell-install-configure]</ept>.",
      "pos": [
        2524,
        2671
      ]
    },
    {
      "content": "Set the following variables by running these Azure PowerShell commands:",
      "pos": [
        2676,
        2747
      ]
    },
    {
      "content": "The subscription name is the one you used to create the HDInsight cluster.",
      "pos": [
        2851,
        2925
      ]
    },
    {
      "content": "The HDInsight cluster is the one you want to use to run the MapReduce job.",
      "pos": [
        2926,
        3000
      ]
    },
    {
      "content": "Run the following commands to create a MapReduce job definition:",
      "pos": [
        3005,
        3069
      ]
    },
    {
      "content": "There are two arguments.",
      "pos": [
        3378,
        3402
      ]
    },
    {
      "content": "The first one is the source file name, and the second is the output file path.",
      "pos": [
        3403,
        3481
      ]
    },
    {
      "content": "For more information about the wasb:// prefix, see <bpt id=\"p1\">[</bpt>Use Azure Blob storage with HDInsight<ept id=\"p1\">][hdinsight-storage]</ept>.",
      "pos": [
        3482,
        3592
      ]
    },
    {
      "content": "Run the following command to run the MapReduce job:",
      "pos": [
        3597,
        3648
      ]
    },
    {
      "content": "In addition to the MapReduce job definition, you also provide the HDInsight cluster name for where you want to run the MapReduce job.",
      "pos": [
        3850,
        3983
      ]
    },
    {
      "content": "Run the following command to check the completion of the MapReduce job:",
      "pos": [
        3988,
        4059
      ]
    },
    {
      "content": "Run the following command to check any errors with running the MapReduce job:",
      "pos": [
        4182,
        4259
      ]
    },
    {
      "content": "The following screenshot shows the output of a successful run.",
      "pos": [
        4410,
        4472
      ]
    },
    {
      "content": "Otherwise, you will see some error messages.",
      "pos": [
        4473,
        4517
      ]
    },
    {
      "content": "HDI.GettingStarted.RunMRJob",
      "pos": [
        4525,
        4552
      ]
    },
    {
      "content": "To retrieve the results of the MapReduce job",
      "pos": [
        4593,
        4637
      ]
    },
    {
      "pos": [
        4644,
        4670
      ],
      "content": "Open <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Set the following variables by running these Azure PowerShell commands:",
      "pos": [
        4674,
        4745
      ]
    },
    {
      "content": "The Storage account name is the Azure storage account that you specified during the HDInsight cluster provision.",
      "pos": [
        4897,
        5009
      ]
    },
    {
      "content": "The storage account is used to host the blob container that is used as the default HDInsight cluster file system.",
      "pos": [
        5010,
        5123
      ]
    },
    {
      "content": "The container name usually share the same name as the HDInsight cluster unless you specify a different name when you provision the cluster.",
      "pos": [
        5124,
        5263
      ]
    },
    {
      "content": "Run the following commands to create an Azure Blob storage context object:",
      "pos": [
        5268,
        5342
      ]
    },
    {
      "pos": [
        5669,
        5825
      ],
      "content": "<bpt id=\"p1\">**</bpt>Select-AzureSubscription<ept id=\"p1\">**</ept> is used to set the current subscription if you have multiple subscriptions, and the default subscription is not the one to use."
    },
    {
      "content": "Run the following command to download the MapReduce job output from the blob container to the workstation:",
      "pos": [
        5830,
        5936
      ]
    },
    {
      "content": "The <bpt id=\"p1\">*</bpt>example/data/WordCountOutput<ept id=\"p1\">*</ept> folder is the output folder specified when you run the MapReduce job.",
      "pos": [
        6116,
        6220
      ]
    },
    {
      "content": "<bpt id=\"p1\">*</bpt>part-r-00000<ept id=\"p1\">*</ept> is the default file name for MapReduce job output.",
      "pos": [
        6221,
        6286
      ]
    },
    {
      "content": "The file will be download to the same folder structure in the local folder.",
      "pos": [
        6287,
        6362
      ]
    },
    {
      "content": "For example, in the following screenshot, the current folder is the C: root folder.",
      "pos": [
        6363,
        6446
      ]
    },
    {
      "content": "The file will be downloaded to:",
      "pos": [
        6447,
        6478
      ]
    },
    {
      "content": "*C:\\example\\data\\WordCountOutput\\*",
      "pos": [
        6480,
        6514
      ]
    },
    {
      "content": "Run the following command to print the MapReduce job output file:",
      "pos": [
        6519,
        6584
      ]
    },
    {
      "content": "HDI.GettingStarted.MRJobOutput",
      "pos": [
        6667,
        6697
      ]
    },
    {
      "content": "The MapReduce job produces a file named <bpt id=\"p1\">*</bpt>part-r-00000<ept id=\"p1\">*</ept>, and it contains the words and the counts.",
      "pos": [
        6742,
        6839
      ]
    },
    {
      "content": "The script uses the <bpt id=\"p1\">**</bpt>findstr<ept id=\"p1\">**</ept> command to list all of the words that contains \"there.\"",
      "pos": [
        6840,
        6927
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> If you open ./example/data/WordCountOutput/part-r-00000 (a multiline output from a MapReduce job) in Notepad, you will notice the line breaks do not render correctly.",
      "pos": [
        6932,
        7111
      ]
    },
    {
      "content": "This is expected.",
      "pos": [
        7112,
        7129
      ]
    },
    {
      "content": "Submit Hive jobs by using Azure PowerShell",
      "pos": [
        7269,
        7311
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Apache Hive<ept id=\"p1\">][apache-hive]</ept> provides a means of running MapReduce job through an SQL-like scripting language, called <bpt id=\"p2\">*</bpt>HiveQL<ept id=\"p2\">*</ept>, which can be applied to summarize, query, and analyze large volumes of data.",
      "pos": [
        7312,
        7514
      ]
    },
    {
      "content": "HDInsight clusters come with a sample Hive table called <bpt id=\"p1\">*</bpt>hivesampletable<ept id=\"p1\">*</ept>.",
      "pos": [
        7516,
        7590
      ]
    },
    {
      "content": "In this session, you will use Azure PowerShell to run a Hive job to list some data from the Hive table.",
      "pos": [
        7591,
        7694
      ]
    },
    {
      "content": "To run a Hive job by using Azure PowerShell",
      "pos": [
        7698,
        7741
      ]
    },
    {
      "content": "Open <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        7749,
        7775
      ]
    },
    {
      "content": "For instructions about how to open the Azure PowerShell console window, see <bpt id=\"p1\">[</bpt>Install and configure Azure PowerShell<ept id=\"p1\">][powershell-install-configure]</ept>.",
      "pos": [
        7776,
        7923
      ]
    },
    {
      "content": "Set the first two variables in the following commands, and then run the commands:",
      "pos": [
        7928,
        8009
      ]
    },
    {
      "content": "The $querystring is the HiveQL query.",
      "pos": [
        8200,
        8237
      ]
    },
    {
      "content": "Run the following command to select the Azure subscription and the cluster to run the Hive job:",
      "pos": [
        8242,
        8337
      ]
    },
    {
      "content": "Run the following commands to submit the hive job:",
      "pos": [
        8412,
        8462
      ]
    },
    {
      "pos": [
        8556,
        8666
      ],
      "content": "You can use the <bpt id=\"p1\">**</bpt>-File<ept id=\"p1\">**</ept> switch to specify a HiveQL script file in the Hadoop distributed file system (HDFS)."
    },
    {
      "pos": [
        8668,
        8751
      ],
      "content": "For more information about Hive, see <bpt id=\"p1\">[</bpt>Use Hive with HDInsight<ept id=\"p1\">][hdinsight-use-hive]</ept>."
    },
    {
      "content": "Submit Hive jobs by using Visual Studio",
      "pos": [
        8757,
        8796
      ]
    },
    {
      "pos": [
        8798,
        8894
      ],
      "content": "See <bpt id=\"p1\">[</bpt>Get started using HDInsight Hadoop Tools for Visual Studio<ept id=\"p1\">][hdinsight-visual-studio-tools]</ept>."
    },
    {
      "content": "Submit Sqoop jobs by using Azure PowerShell",
      "pos": [
        8898,
        8941
      ]
    },
    {
      "pos": [
        8943,
        8995
      ],
      "content": "See <bpt id=\"p1\">[</bpt>Use Sqoop with HDInsight<ept id=\"p1\">][hdinsight-use-sqoop]</ept>."
    },
    {
      "content": "Submit MapReduce jobs using HDInsight .NET SDK",
      "pos": [
        8999,
        9045
      ]
    },
    {
      "content": "The HDInsight .NET SDK provides .NET client libraries, which makes it easier to work with HDInsight clusters from .NET.",
      "pos": [
        9046,
        9165
      ]
    },
    {
      "content": "HDInsight clusters come with a JAR file (located at <bpt id=\"p1\">*</bpt>\\example\\jars\\hadoop-mapreduce-examples.jar<ept id=\"p1\">*</ept>), which contains several MapReduce examples.",
      "pos": [
        9166,
        9308
      ]
    },
    {
      "content": "One of the examples is for counting word frequencies in source files.",
      "pos": [
        9309,
        9378
      ]
    },
    {
      "content": "In this session, you will learn how to create a .NET application to run the word count sample.",
      "pos": [
        9379,
        9473
      ]
    },
    {
      "content": "For more information about developing and running MapReduce jobs, see <bpt id=\"p1\">[</bpt>Use MapReduce with HDInsight<ept id=\"p1\">][hdinsight-use-mapreduce]</ept>.",
      "pos": [
        9474,
        9600
      ]
    },
    {
      "content": "The following procedures are needed to provision an HDInsight cluster by using the SDK:",
      "pos": [
        9603,
        9690
      ]
    },
    {
      "content": "Install the HDInsight .NET SDK",
      "pos": [
        9694,
        9724
      ]
    },
    {
      "content": "Create a console application",
      "pos": [
        9727,
        9755
      ]
    },
    {
      "content": "Run the application",
      "pos": [
        9758,
        9777
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>To install the HDInsight .NET SDK<ept id=\"p1\">**</ept>",
      "pos": [
        9780,
        9817
      ]
    },
    {
      "content": "You can install latest published build of the SDK from <bpt id=\"p1\">[</bpt>NuGet<ept id=\"p1\">](http://nuget.codeplex.com/wikipage?title=Getting%20Started)</ept>.",
      "pos": [
        9818,
        9941
      ]
    },
    {
      "content": "The instructions will be shown in the next procedure.",
      "pos": [
        9942,
        9995
      ]
    },
    {
      "content": "To create a Visual Studio console application",
      "pos": [
        9999,
        10044
      ]
    },
    {
      "content": "Open Visual Studio.",
      "pos": [
        10051,
        10070
      ]
    },
    {
      "pos": [
        10075,
        10141
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> menu, click <bpt id=\"p2\">**</bpt>New<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Project<ept id=\"p3\">**</ept>."
    },
    {
      "pos": [
        10146,
        10204
      ],
      "content": "From <bpt id=\"p1\">**</bpt>New Project<ept id=\"p1\">**</ept>, type or select the following values:"
    },
    {
      "pos": [
        10210,
        11602
      ],
      "content": "<table style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse;\">\n <tr>\n <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Property</th>\n <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Value</th></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Category</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px; padding-right:5px;\">Templates/Visual C#/Windows</td></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Template</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Console Application</td></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Name</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">SubmitMapReduceJob</td></tr>\n </table>",
      "leadings": [
        "",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   "
      ],
      "nodes": [
        {
          "content": "Property",
          "pos": [
            264,
            272
          ]
        },
        {
          "content": "Value",
          "pos": [
            430,
            435
          ]
        },
        {
          "content": "Category",
          "pos": [
            573,
            581
          ]
        },
        {
          "content": "Templates/Visual C#/Windows",
          "pos": [
            727,
            754
          ]
        },
        {
          "content": "Template",
          "pos": [
            892,
            900
          ]
        },
        {
          "content": "Console Application",
          "pos": [
            1027,
            1046
          ]
        },
        {
          "content": "Name",
          "pos": [
            1184,
            1188
          ]
        },
        {
          "content": "SubmitMapReduceJob",
          "pos": [
            1315,
            1333
          ]
        }
      ]
    },
    {
      "pos": [
        11607,
        11642
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept> to create the project."
    },
    {
      "pos": [
        11648,
        11751
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>Tools<ept id=\"p1\">**</ept> menu, click <bpt id=\"p2\">**</bpt>Library Package Manager<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Package Manager Console<ept id=\"p3\">**</ept>."
    },
    {
      "content": "Run the following commands in the console to install the packages.",
      "pos": [
        11756,
        11822
      ]
    },
    {
      "content": "This command adds .NET libraries and references to them to the current Visual Studio project.",
      "pos": [
        11898,
        11991
      ]
    },
    {
      "content": "The version should be 0.11.0.1 or later.",
      "pos": [
        11992,
        12032
      ]
    },
    {
      "pos": [
        12037,
        12104
      ],
      "content": "From <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, double-click <bpt id=\"p2\">**</bpt>Program.cs<ept id=\"p2\">**</ept> to open it."
    },
    {
      "content": "Add the following using statements to the top of the file:",
      "pos": [
        12109,
        12167
      ]
    },
    {
      "content": "Add the following function definition to the class.",
      "pos": [
        12488,
        12539
      ]
    },
    {
      "content": "This function is used to wait for a Hadoop job to complete.",
      "pos": [
        12540,
        12599
      ]
    },
    {
      "pos": [
        13083,
        13136
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, paste the following code:"
    },
    {
      "content": "These are all of the variables you need to set for the program.",
      "pos": [
        13546,
        13609
      ]
    },
    {
      "content": "You can get the Azure subscription name from the <bpt id=\"p1\">[</bpt>Azure preview portal<ept id=\"p1\">][azure-management-portal]</ept>.",
      "pos": [
        13610,
        13707
      ]
    },
    {
      "content": "For information about the certificate, see <bpt id=\"p1\">[</bpt>Create and Upload a Management Certificate for Azure<ept id=\"p1\">][azure-certificate]</ept>.",
      "pos": [
        13713,
        13830
      ]
    },
    {
      "content": "An easy way to configure the certificate is to run the <bpt id=\"p1\">**</bpt>Get-AzurePublishSettingsFile<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Import-AzurePublishSettingsFile<ept id=\"p2\">**</ept> Azure PowerShell cmdlets.",
      "pos": [
        13831,
        13984
      ]
    },
    {
      "content": "They will create and upload the management certificate automatically.",
      "pos": [
        13985,
        14054
      ]
    },
    {
      "content": "After you run these cmdlets, you can open <bpt id=\"p1\">**</bpt>certmgr.msc<ept id=\"p1\">**</ept> from the workstation, and find the certificate by expanding <bpt id=\"p2\">**</bpt>Personal<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Certificates<ept id=\"p3\">**</ept>.",
      "pos": [
        14055,
        14205
      ]
    },
    {
      "content": "The certificate that is created by the Azure PowerShell cmdlets has Azure Tools for the <bpt id=\"p1\">**</bpt>Issued To<ept id=\"p1\">**</ept> and the <bpt id=\"p2\">**</bpt>Issued By<ept id=\"p2\">**</ept> fields.",
      "pos": [
        14206,
        14337
      ]
    },
    {
      "content": "The Azure storage account name is the account you specify when you provision the HDInsight cluster.",
      "pos": [
        14343,
        14442
      ]
    },
    {
      "content": "The default container name is the same as the HDInsight cluster name.",
      "pos": [
        14443,
        14512
      ]
    },
    {
      "pos": [
        14518,
        14600
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to define the MapReduce job:"
    },
    {
      "pos": [
        15252,
        15360
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to create a JobSubmissionCertificateCredential object:"
    },
    {
      "pos": [
        15816,
        15918
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to run the job and wait for the job to complete:"
    },
    {
      "pos": [
        16269,
        16357
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to print the MapReduce job output:"
    },
    {
      "content": "The output folder is specified when you define the MapReduce job.",
      "pos": [
        17176,
        17241
      ]
    },
    {
      "content": "The default file name is <bpt id=\"p1\">**</bpt>part-r-00000<ept id=\"p1\">**</ept>.",
      "pos": [
        17242,
        17284
      ]
    },
    {
      "content": "To run the application",
      "pos": [
        17288,
        17310
      ]
    },
    {
      "content": "While the application is open in Visual Studio, press <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> to run the application.",
      "pos": [
        17314,
        17398
      ]
    },
    {
      "content": "A console window should open and display the status of the application and the application output.",
      "pos": [
        17399,
        17497
      ]
    },
    {
      "content": "Submit Hadoop streaming jobs using HDInsight .NET SDK",
      "pos": [
        17501,
        17554
      ]
    },
    {
      "content": "HDInsight clusters come with a word-counting Hadoop stream program, which is developed in C#.",
      "pos": [
        17555,
        17648
      ]
    },
    {
      "content": "The mapper program is <bpt id=\"p1\">*</bpt>/example/apps/cat.exe<ept id=\"p1\">*</ept>, and the reduce program is <bpt id=\"p2\">*</bpt>/example/apps/wc.exe<ept id=\"p2\">*</ept>.",
      "pos": [
        17649,
        17745
      ]
    },
    {
      "content": "In this session, you will learn how to create a .NET application to run the word-counting sample.",
      "pos": [
        17746,
        17843
      ]
    },
    {
      "pos": [
        17845,
        17995
      ],
      "content": "For the details about creating a .NET application for submitting MapReduce jobs, see <bpt id=\"p1\">[</bpt>Submit MapReduce jobs using HDInsight .NET SDK<ept id=\"p1\">](#mapreduce-sdk)</ept>."
    },
    {
      "pos": [
        17997,
        18163
      ],
      "content": "For more information about developing and deploying Hadoop streaming jobs, see <bpt id=\"p1\">[</bpt>Develop C# Hadoop streaming programs for HDInsight<ept id=\"p1\">][hdinsight-develop-streaming-jobs]</ept>."
    },
    {
      "content": "Submit Hive jobs by using HDInsight .NET SDK",
      "pos": [
        22068,
        22112
      ]
    },
    {
      "content": "HDInsight clusters come with a sample Hive table called <bpt id=\"p1\">*</bpt>hivesampletable<ept id=\"p1\">*</ept>.",
      "pos": [
        22113,
        22187
      ]
    },
    {
      "content": "In this session, you will create a .NET application to run a Hive job to list the Hive tables that are created in an HDInsight cluster.",
      "pos": [
        22188,
        22323
      ]
    },
    {
      "content": "For more information about using Hive, see <bpt id=\"p1\">[</bpt>Use Hive with HDInsight<ept id=\"p1\">][hdinsight-use-hive]</ept>.",
      "pos": [
        22324,
        22413
      ]
    },
    {
      "content": "The following procedures are needed to provision an HDInsight cluster by using the SDK:",
      "pos": [
        22415,
        22502
      ]
    },
    {
      "content": "Install the HDInsight .NET SDK",
      "pos": [
        22506,
        22536
      ]
    },
    {
      "content": "Create a console application",
      "pos": [
        22539,
        22567
      ]
    },
    {
      "content": "Run the application",
      "pos": [
        22570,
        22589
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>To install the HDInsight .NET SDK<ept id=\"p1\">**</ept>",
      "pos": [
        22592,
        22629
      ]
    },
    {
      "content": "You can install the latest published build of the SDK from <bpt id=\"p1\">[</bpt>NuGet<ept id=\"p1\">](http://nuget.codeplex.com/wikipage?title=Getting%20Started)</ept>.",
      "pos": [
        22630,
        22757
      ]
    },
    {
      "content": "The instructions will be shown in the next procedure.",
      "pos": [
        22758,
        22811
      ]
    },
    {
      "content": "To create a Visual Studio console application",
      "pos": [
        22815,
        22860
      ]
    },
    {
      "content": "Open Visual Studio.",
      "pos": [
        22867,
        22886
      ]
    },
    {
      "pos": [
        22891,
        22957
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> menu, click <bpt id=\"p2\">**</bpt>New<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Project<ept id=\"p3\">**</ept>."
    },
    {
      "pos": [
        22962,
        23020
      ],
      "content": "From <bpt id=\"p1\">**</bpt>New Project<ept id=\"p1\">**</ept>, type or select the following values:"
    },
    {
      "pos": [
        23026,
        24413
      ],
      "content": "<table style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse;\">\n <tr>\n <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Property</th>\n <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Value</th></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Category</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px; padding-right:5px;\">Templates/Visual C#/Windows</td></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Template</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Console Application</td></tr>\n <tr>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Name</td>\n <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">SubmitHiveJob</td></tr>\n </table>",
      "leadings": [
        "",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   "
      ],
      "nodes": [
        {
          "content": "Property",
          "pos": [
            264,
            272
          ]
        },
        {
          "content": "Value",
          "pos": [
            430,
            435
          ]
        },
        {
          "content": "Category",
          "pos": [
            573,
            581
          ]
        },
        {
          "content": "Templates/Visual C#/Windows",
          "pos": [
            727,
            754
          ]
        },
        {
          "content": "Template",
          "pos": [
            892,
            900
          ]
        },
        {
          "content": "Console Application",
          "pos": [
            1027,
            1046
          ]
        },
        {
          "content": "Name",
          "pos": [
            1184,
            1188
          ]
        },
        {
          "content": "SubmitHiveJob",
          "pos": [
            1315,
            1328
          ]
        }
      ]
    },
    {
      "pos": [
        24418,
        24453
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept> to create the project."
    },
    {
      "pos": [
        24459,
        24562
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>Tools<ept id=\"p1\">**</ept> menu, click <bpt id=\"p2\">**</bpt>Library Package Manager<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Package Manager Console<ept id=\"p3\">**</ept>."
    },
    {
      "content": "Run the following command in the console to install the package:",
      "pos": [
        24567,
        24631
      ]
    },
    {
      "content": "This command adds .NET libraries and references to them to the current Visual Studio project.",
      "pos": [
        24707,
        24800
      ]
    },
    {
      "pos": [
        24805,
        24872
      ],
      "content": "From <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, double-click <bpt id=\"p2\">**</bpt>Program.cs<ept id=\"p2\">**</ept> to open it."
    },
    {
      "pos": [
        24877,
        24939
      ],
      "content": "Add the following <bpt id=\"p1\">**</bpt>using<ept id=\"p1\">**</ept> statements to the top of the file:"
    },
    {
      "content": "Add the following function definition to the class.",
      "pos": [
        25162,
        25213
      ]
    },
    {
      "content": "This function is used to wait for a Hadoop job to complete.",
      "pos": [
        25214,
        25273
      ]
    },
    {
      "pos": [
        25757,
        25810
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, paste the following code:"
    },
    {
      "content": "These are all of the variables you need to set for the program.",
      "pos": [
        26028,
        26091
      ]
    },
    {
      "content": "You can get the Azure Subscription ID from your system administrator.",
      "pos": [
        26092,
        26161
      ]
    },
    {
      "content": "For information about the certificate, see <bpt id=\"p1\">[</bpt>Create and Upload a Management Certificate for Azure<ept id=\"p1\">][azure-certificate]</ept>.",
      "pos": [
        26167,
        26284
      ]
    },
    {
      "content": "An easy way to configure the certificate is to run the <bpt id=\"p1\">**</bpt>Get-AzurePublishSettingsFile<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Import-AzurePublishSettingsFile<ept id=\"p2\">**</ept> Azure PowerShell cmdlets.",
      "pos": [
        26285,
        26438
      ]
    },
    {
      "content": "They will create and upload the management certificate automatically.",
      "pos": [
        26439,
        26508
      ]
    },
    {
      "content": "After you run these cmdlets, you can open <bpt id=\"p1\">**</bpt>certmgr.msc<ept id=\"p1\">**</ept> from the workstation, and find the certificate by expanding <bpt id=\"p2\">**</bpt>Personal<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Certificates<ept id=\"p3\">**</ept>.",
      "pos": [
        26509,
        26659
      ]
    },
    {
      "content": "The certificate created by the Azure PowerShell cmdlets has Azure Tools for the <bpt id=\"p1\">**</bpt>Issued To<ept id=\"p1\">**</ept> and the <bpt id=\"p2\">**</bpt>Issued By<ept id=\"p2\">**</ept> fields.",
      "pos": [
        26660,
        26783
      ]
    },
    {
      "pos": [
        26789,
        26866
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to define the Hive job:"
    },
    {
      "pos": [
        27136,
        27229
      ],
      "content": "You can also use the <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> parameter to specify a HiveQL script file in HDFS, for example:"
    },
    {
      "pos": [
        27513,
        27625
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to create a <bpt id=\"p2\">**</bpt>JobSubmissionCertificateCredential<ept id=\"p2\">**</ept> object:"
    },
    {
      "pos": [
        28081,
        28183
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to run the job and wait for the job to complete:"
    },
    {
      "pos": [
        28466,
        28549
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Main()<ept id=\"p1\">**</ept> function, append the following code to print the Hive job output:"
    },
    {
      "content": "To run the application",
      "pos": [
        28855,
        28877
      ]
    },
    {
      "content": "While the application is open in Visual Studio, press <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> to run the application.",
      "pos": [
        28881,
        28965
      ]
    },
    {
      "content": "A console window should open and display the status of the application.",
      "pos": [
        28966,
        29037
      ]
    },
    {
      "content": "The output should be:",
      "pos": [
        29038,
        29059
      ]
    },
    {
      "content": "Submit jobs using the HDInsight Tools for Visual Studio",
      "pos": [
        29084,
        29139
      ]
    },
    {
      "content": "Using the HDInsight Tools for Visual Studio, you can run Hive queries and Pig scripts.",
      "pos": [
        29141,
        29227
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Get started using Visual Studio Hadoop tools for HDInsight<ept id=\"p1\">](hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>.",
      "pos": [
        29228,
        29346
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        29351,
        29361
      ]
    },
    {
      "content": "In this article, you have learned several ways to provision an HDInsight cluster.",
      "pos": [
        29362,
        29443
      ]
    },
    {
      "content": "To learn more, see the following articles:",
      "pos": [
        29444,
        29486
      ]
    },
    {
      "content": "Get started with Azure HDInsight",
      "pos": [
        29491,
        29523
      ]
    },
    {
      "content": "Provision HDInsight clusters",
      "pos": [
        29551,
        29579
      ]
    },
    {
      "content": "Manage HDInsight by using PowerShell",
      "pos": [
        29605,
        29641
      ]
    },
    {
      "content": "HDInsight Cmdlet Reference Documentation",
      "pos": [
        29674,
        29714
      ]
    },
    {
      "content": "Use Hive with HDInsight",
      "pos": [
        29751,
        29774
      ]
    },
    {
      "content": "Use Pig with HDInsight",
      "pos": [
        29799,
        29821
      ]
    },
    {
      "content": "test",
      "pos": [
        31027,
        31031
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Submit Hadoop jobs in HDInsight | Microsoft Azure\"\n    description=\"Learn how to submit Hadoop jobs to Azure HDInsight Hadoop.\"\n    editor=\"cgronlun\"\n    manager=\"paulettm\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    tags=\"azure-portal\"\n    authors=\"mumian\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"07/28/2015\"\n    ms.author=\"jgao\"/>\n\n# Submit Hadoop jobs in HDInsight\n\nLearn how to use Azure PowerShell to submit MapReduce and Hive jobs, and how to use the HDInsight .NET SDK to submit MapReduce, Hadoop streaming, and Hive jobs.\n\n> [AZURE.NOTE] The steps in this article must be performed from a Windows client. For information on using a Linux, OS X, or Unix client to work with MapReduce, Hive, or Pig on HDInsight, see the following articles and select either the **SSH** or **Curl** links within each:\n>\n> - [Use Hive with HDInsight](hdinsight-use-hive.md)\n> - [Use Pig with HDInsight](hdinsight-use-pig.md)\n> - [Use MapReduce with HDInsight](hdinsight-use-mapreduce.md)\n\n##Prerequisites\n\nBefore you begin this article, you must have the following:\n\n* **An Azure HDInsight cluster**. For instructions, see [Get started with HDInsight][hdinsight-get-started] or [Provision HDInsight clusters][hdinsight-provision].\n- **A workstation with Azure PowerShell**. See [Install and use Azure PowerShell](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/).\n\n\n\n##Submit MapReduce jobs by using Azure PowerShell\nAzure PowerShell is a powerful scripting environment that you can use to control and automate the deployment and management of your workloads in Azure. For more information about using Azure PowerShell with HDInsight, see [Manage HDInsight by using PowerShell][hdinsight-admin-powershell].\n\nHadoop MapReduce is a software framework for writing applications that process vast amounts of data. HDInsight clusters come with a JAR file (located at *\\example\\jars\\hadoop-mapreduce-examples.jar*), which contains several MapReduce examples.\n\nOne of the examples is for counting word frequencies in source files. In this session, you will learn how to use Azure PowerShell from a workstation to run the word count sample. For more information about developing and running MapReduce jobs, see [Use MapReduce with HDInsight][hdinsight-use-mapreduce].\n\n**To run the word count MapReduce program by using Azure PowerShell**\n\n1.  Open **Azure PowerShell**. For instructions about how to open the Azure PowerShell console window, see [Install and configure Azure PowerShell][powershell-install-configure].\n\n3. Set the following variables by running these Azure PowerShell commands:\n\n        $subscriptionName = \"<SubscriptionName>\"\n        $clusterName = \"<HDInsightClusterName>\"\n\n    The subscription name is the one you used to create the HDInsight cluster. The HDInsight cluster is the one you want to use to run the MapReduce job.\n\n5. Run the following commands to create a MapReduce job definition:\n\n        # Define the word count MapReduce job\n        $wordCountJobDefinition = New-AzureHDInsightMapReduceJobDefinition -JarFile \"wasb:///example/jars/hadoop-mapreduce-examples.jar\" -ClassName \"wordcount\" -Arguments \"wasb:///example/data/gutenberg/davinci.txt\", \"wasb:///example/data/WordCountOutput\"\n\n    There are two arguments. The first one is the source file name, and the second is the output file path. For more information about the wasb:// prefix, see [Use Azure Blob storage with HDInsight][hdinsight-storage].\n\n6. Run the following command to run the MapReduce job:\n\n        # Submit the MapReduce job\n        Select-AzureSubscription $subscriptionName\n        $wordCountJob = Start-AzureHDInsightJob -Cluster $clusterName -JobDefinition $wordCountJobDefinition\n\n    In addition to the MapReduce job definition, you also provide the HDInsight cluster name for where you want to run the MapReduce job.\n\n7. Run the following command to check the completion of the MapReduce job:\n\n        # Wait for the job to complete\n        Wait-AzureHDInsightJob -Job $wordCountJob -WaitTimeoutInSeconds 3600\n\n\n8. Run the following command to check any errors with running the MapReduce job:\n\n        # Get the job standard error output\n        Get-AzureHDInsightJobOutput -Cluster $clusterName -JobId $wordCountJob.JobId -StandardError\n\n    The following screenshot shows the output of a successful run. Otherwise, you will see some error messages.\n\n    ![HDI.GettingStarted.RunMRJob][image-hdi-gettingstarted-runmrjob]\n\n\n**To retrieve the results of the MapReduce job**\n\n1. Open **Azure PowerShell**.\n2. Set the following variables by running these Azure PowerShell commands:\n\n        $subscriptionName = \"<SubscriptionName>\"\n        $storageAccountName = \"<StorageAccountName>\"\n        $containerName = \"<ContainerName>\"\n\n    The Storage account name is the Azure storage account that you specified during the HDInsight cluster provision. The storage account is used to host the blob container that is used as the default HDInsight cluster file system. The container name usually share the same name as the HDInsight cluster unless you specify a different name when you provision the cluster.\n\n3. Run the following commands to create an Azure Blob storage context object:\n\n        # Create the storage account context object\n        Select-AzureSubscription $subscriptionName\n        $storageAccountKey = Get-AzureStorageKey $storageAccountName | %{ $_.Primary }\n        $storageContext = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey  \n\n    **Select-AzureSubscription** is used to set the current subscription if you have multiple subscriptions, and the default subscription is not the one to use.\n\n4. Run the following command to download the MapReduce job output from the blob container to the workstation:\n\n        # Get the blob content\n        Get-AzureStorageBlobContent -Container $ContainerName -Blob example/data/WordCountOutput/part-r-00000 -Context $storageContext -Force\n\n    The *example/data/WordCountOutput* folder is the output folder specified when you run the MapReduce job. *part-r-00000* is the default file name for MapReduce job output. The file will be download to the same folder structure in the local folder. For example, in the following screenshot, the current folder is the C: root folder. The file will be downloaded to:\n\n*C:\\example\\data\\WordCountOutput\\*\n\n5. Run the following command to print the MapReduce job output file:\n\n        cat ./example/data/WordCountOutput/part-r-00000 | findstr \"there\"\n\n    ![HDI.GettingStarted.MRJobOutput][image-hdi-gettingstarted-mrjoboutput]\n\n    The MapReduce job produces a file named *part-r-00000*, and it contains the words and the counts. The script uses the **findstr** command to list all of the words that contains \"there.\"\n\n\n> [AZURE.NOTE] If you open ./example/data/WordCountOutput/part-r-00000 (a multiline output from a MapReduce job) in Notepad, you will notice the line breaks do not render correctly. This is expected.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n##Submit Hive jobs by using Azure PowerShell\n[Apache Hive][apache-hive] provides a means of running MapReduce job through an SQL-like scripting language, called *HiveQL*, which can be applied to summarize, query, and analyze large volumes of data.\n\nHDInsight clusters come with a sample Hive table called *hivesampletable*. In this session, you will use Azure PowerShell to run a Hive job to list some data from the Hive table.\n\n**To run a Hive job by using Azure PowerShell**\n\n1.  Open **Azure PowerShell**. For instructions about how to open the Azure PowerShell console window, see [Install and configure Azure PowerShell][powershell-install-configure].\n\n2. Set the first two variables in the following commands, and then run the commands:\n\n        $subscriptionName = \"<SubscriptionName>\"\n        $clusterName = \"<HDInsightClusterName>\"\n        $querystring = \"SELECT * FROM hivesampletable WHERE Country='United Kingdom';\"\n\n    The $querystring is the HiveQL query.\n\n3. Run the following command to select the Azure subscription and the cluster to run the Hive job:\n\n        Select-AzureSubscription -SubscriptionName $subscriptionName\n\n4. Run the following commands to submit the hive job:\n\n        Use-AzureHDInsightCluster $clusterName\n        Invoke-Hive -Query $queryString\n\n    You can use the **-File** switch to specify a HiveQL script file in the Hadoop distributed file system (HDFS).\n\nFor more information about Hive, see [Use Hive with HDInsight][hdinsight-use-hive].\n\n\n## Submit Hive jobs by using Visual Studio\n\nSee [Get started using HDInsight Hadoop Tools for Visual Studio][hdinsight-visual-studio-tools].\n\n##Submit Sqoop jobs by using Azure PowerShell\n\nSee [Use Sqoop with HDInsight][hdinsight-use-sqoop].\n\n##Submit MapReduce jobs using HDInsight .NET SDK\nThe HDInsight .NET SDK provides .NET client libraries, which makes it easier to work with HDInsight clusters from .NET. HDInsight clusters come with a JAR file (located at *\\example\\jars\\hadoop-mapreduce-examples.jar*), which contains several MapReduce examples. One of the examples is for counting word frequencies in source files. In this session, you will learn how to create a .NET application to run the word count sample. For more information about developing and running MapReduce jobs, see [Use MapReduce with HDInsight][hdinsight-use-mapreduce].\n\n\nThe following procedures are needed to provision an HDInsight cluster by using the SDK:\n\n- Install the HDInsight .NET SDK\n- Create a console application\n- Run the application\n\n\n**To install the HDInsight .NET SDK**\nYou can install latest published build of the SDK from [NuGet](http://nuget.codeplex.com/wikipage?title=Getting%20Started). The instructions will be shown in the next procedure.\n\n**To create a Visual Studio console application**\n\n1. Open Visual Studio.\n\n2. From the **File** menu, click **New**, and then click **Project**.\n\n3. From **New Project**, type or select the following values:\n\n    <table style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse;\">\n    <tr>\n    <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Property</th>\n    <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Value</th></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Category</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px; padding-right:5px;\">Templates/Visual C#/Windows</td></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Template</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Console Application</td></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Name</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">SubmitMapReduceJob</td></tr>\n    </table>\n\n4. Click **OK** to create the project.\n\n\n5. From the **Tools** menu, click **Library Package Manager**, and then click **Package Manager Console**.\n\n6. Run the following commands in the console to install the packages.\n\n        Install-Package Microsoft.WindowsAzure.Management.HDInsight\n\n\n    This command adds .NET libraries and references to them to the current Visual Studio project. The version should be 0.11.0.1 or later.\n\n7. From **Solution Explorer**, double-click **Program.cs** to open it.\n\n8. Add the following using statements to the top of the file:\n\n        using System.IO;\n        using System.Threading;\n        using System.Security.Cryptography.X509Certificates;\n\n        using Microsoft.WindowsAzure.Storage;\n        using Microsoft.WindowsAzure.Storage.Blob;\n\n        using Microsoft.WindowsAzure.Management.HDInsight;\n        using Microsoft.Hadoop.Client;\n\n9. Add the following function definition to the class. This function is used to wait for a Hadoop job to complete.\n\n        private static void WaitForJobCompletion(JobCreationResults jobResults, IJobSubmissionClient client)\n        {\n            JobDetails jobInProgress = client.GetJob(jobResults.JobId);\n            while (jobInProgress.StatusCode != JobStatusCode.Completed && jobInProgress.StatusCode != JobStatusCode.Failed)\n            {\n                jobInProgress = client.GetJob(jobInProgress.JobId);\n                Thread.Sleep(TimeSpan.FromSeconds(10));\n            }\n        }\n\n10. In the **Main()** function, paste the following code:\n\n        // Set the variables\n        string subscriptionID = \"<Azure subscription ID>\";\n        string certFriendlyName = \"<certificate friendly name>\";\n\n        string clusterName = \"<HDInsight cluster name>\";\n\n        string storageAccountName = \"<Azure storage account name>\";\n        string storageAccountKey = \"<Azure storage account key>\";\n        string containerName = \"<Blob container name>\";\n\n\n    These are all of the variables you need to set for the program. You can get the Azure subscription name from the [Azure preview portal][azure-management-portal].\n\n    For information about the certificate, see [Create and Upload a Management Certificate for Azure][azure-certificate]. An easy way to configure the certificate is to run the **Get-AzurePublishSettingsFile** and **Import-AzurePublishSettingsFile** Azure PowerShell cmdlets. They will create and upload the management certificate automatically. After you run these cmdlets, you can open **certmgr.msc** from the workstation, and find the certificate by expanding **Personal** > **Certificates**. The certificate that is created by the Azure PowerShell cmdlets has Azure Tools for the **Issued To** and the **Issued By** fields.\n\n    The Azure storage account name is the account you specify when you provision the HDInsight cluster. The default container name is the same as the HDInsight cluster name.\n\n11. In the **Main()** function, append the following code to define the MapReduce job:\n\n\n        // Define the MapReduce job\n        MapReduceJobCreateParameters mrJobDefinition = new MapReduceJobCreateParameters()\n        {\n            JarFile = \"wasb:///example/jars/hadoop-mapreduce-examples.jar\",\n            ClassName = \"wordcount\"\n        };\n\n        mrJobDefinition.Arguments.Add(\"wasb:///example/data/gutenberg/davinci.txt\");\n        mrJobDefinition.Arguments.Add(\"wasb:///example/data/WordCountOutput\");\n\n    There are two arguments. The first one is the source file name, and the second is the output file path. For more information about the wasb:// prefix, see [Use Azure Blob storage with HDInsight][hdinsight-storage].\n\n12. In the **Main()** function, append the following code to create a JobSubmissionCertificateCredential object:\n\n        // Get the certificate object from certificate store using the friendly name to identify it\n        X509Store store = new X509Store();\n        store.Open(OpenFlags.ReadOnly);\n        X509Certificate2 cert = store.Certificates.Cast<X509Certificate2>().First(item => item.FriendlyName == certFriendlyName);\n        JobSubmissionCertificateCredential creds = new JobSubmissionCertificateCredential(new Guid(subscriptionID), cert, clusterName);\n\n13. In the **Main()** function, append the following code to run the job and wait for the job to complete:\n\n        // Create a hadoop client to connect to HDInsight\n        var jobClient = JobSubmissionClientFactory.Connect(creds);\n\n        // Run the MapReduce job\n        JobCreationResults mrJobResults = jobClient.CreateMapReduceJob(mrJobDefinition);\n\n        // Wait for the job to complete\n        WaitForJobCompletion(mrJobResults, jobClient);\n\n14. In the **Main()** function, append the following code to print the MapReduce job output:\n\n        // Print the MapReduce job output\n        Stream stream = new MemoryStream();\n\n        CloudStorageAccount storageAccount = CloudStorageAccount.Parse(\"DefaultEndpointsProtocol=https;AccountName=\" + storageAccountName + \";AccountKey=\" + storageAccountKey);\n        CloudBlobClient blobClient = storageAccount.CreateCloudBlobClient();\n        CloudBlobContainer blobContainer = blobClient.GetContainerReference(containerName);\n        CloudBlockBlob blockBlob = blobContainer.GetBlockBlobReference(\"example/data/WordCountOutput/part-r-00000\");\n\n        blockBlob.DownloadToStream(stream);\n        stream.Position = 0;\n\n        StreamReader reader = new StreamReader(stream);\n        Console.WriteLine(reader.ReadToEnd());\n\n        Console.WriteLine(\"Press ENTER to continue.\");\n        Console.ReadLine();\n\n    The output folder is specified when you define the MapReduce job. The default file name is **part-r-00000**.\n\n**To run the application**\n\nWhile the application is open in Visual Studio, press **F5** to run the application. A console window should open and display the status of the application and the application output.\n\n##Submit Hadoop streaming jobs using HDInsight .NET SDK\nHDInsight clusters come with a word-counting Hadoop stream program, which is developed in C#. The mapper program is */example/apps/cat.exe*, and the reduce program is */example/apps/wc.exe*. In this session, you will learn how to create a .NET application to run the word-counting sample.\n\nFor the details about creating a .NET application for submitting MapReduce jobs, see [Submit MapReduce jobs using HDInsight .NET SDK](#mapreduce-sdk).\n\nFor more information about developing and deploying Hadoop streaming jobs, see [Develop C# Hadoop streaming programs for HDInsight][hdinsight-develop-streaming-jobs].\n\n    using System;\n    using System.Collections.Generic;\n    using System.Linq;\n    using System.Text;\n    using System.Threading.Tasks;\n\n    using System.IO;\n    using System.Threading;\n    using System.Security.Cryptography.X509Certificates;\n\n    using Microsoft.WindowsAzure.Management.HDInsight;\n    using Microsoft.Hadoop.Client;\n\n    namespace SubmitStreamingJob\n    {\n        class Program\n        {\n            static void Main(string[] args)\n            {\n\n                // Set the variables\n                string subscriptionID = \"<Azure subscription ID>\";\n                string certFriendlyName = \"<certificate friendly name>\";\n\n                string clusterName = \"<HDInsight cluster name>\";\n                string statusFolderName = @\"/tutorials/wordcountstreaming/status\";\n\n                // Define the Hadoop streaming MapReduce job\n                StreamingMapReduceJobCreateParameters myJobDefinition = new StreamingMapReduceJobCreateParameters()\n                {\n                    JobName = \"my word counting job\",\n                    StatusFolder = statusFolderName,\n                    Input = \"/example/data/gutenberg/davinci.txt\",\n                    Output = \"/tutorials/wordcountstreaming/output\",\n                    Reducer = \"wc.exe\",\n                    Mapper = \"cat.exe\"\n                };\n\n                myJobDefinition.Files.Add(\"/example/apps/wc.exe\");\n                myJobDefinition.Files.Add(\"/example/apps/cat.exe\");\n\n                // Get the certificate object from certificate store using the friendly name to identify it\n                X509Store store = new X509Store();\n                store.Open(OpenFlags.ReadOnly);\n                X509Certificate2 cert = store.Certificates.Cast<X509Certificate2>().First(item => item.FriendlyName == certFriendlyName);\n\n                JobSubmissionCertificateCredential creds = new JobSubmissionCertificateCredential(new Guid(subscriptionID), cert, clusterName);\n\n                // Create a hadoop client to connect to HDInsight\n                var jobClient = JobSubmissionClientFactory.Connect(creds);\n\n                // Run the MapReduce job\n                Console.WriteLine(\"----- Submit the Hadoop streaming job ...\");\n                JobCreationResults mrJobResults = jobClient.CreateStreamingJob(myJobDefinition);\n\n                // Wait for the job to complete\n                Console.WriteLine(\"----- Wait for the Hadoop streaming job to complete ...\");\n                WaitForJobCompletion(mrJobResults, jobClient);\n\n                // Display the error log\n                Console.WriteLine(\"----- The hadoop streaming job error log.\");\n                using (Stream stream = jobClient.GetJobErrorLogs(mrJobResults.JobId))\n                {\n                    var reader = new StreamReader(stream);\n                    Console.WriteLine(reader.ReadToEnd());\n                }\n\n                // Display the output log\n                Console.WriteLine(\"----- The hadoop streaming job output log.\");\n                using (Stream stream = jobClient.GetJobOutput(mrJobResults.JobId))\n                {\n                    var reader = new StreamReader(stream);\n                    Console.WriteLine(reader.ReadToEnd());\n                }\n\n                Console.WriteLine(\"----- Press ENTER to continue.\");\n                Console.ReadLine();\n            }\n\n            private static void WaitForJobCompletion(JobCreationResults jobResults, IJobSubmissionClient client)\n            {\n                JobDetails jobInProgress = client.GetJob(jobResults.JobId);\n                while (jobInProgress.StatusCode != JobStatusCode.Completed && jobInProgress.StatusCode != JobStatusCode.Failed)\n                {\n                    jobInProgress = client.GetJob(jobInProgress.JobId);\n                    Thread.Sleep(TimeSpan.FromSeconds(10));\n                }\n            }\n        }\n    }\n\n\n\n\n\n\n##Submit Hive jobs by using HDInsight .NET SDK\nHDInsight clusters come with a sample Hive table called *hivesampletable*. In this session, you will create a .NET application to run a Hive job to list the Hive tables that are created in an HDInsight cluster. For more information about using Hive, see [Use Hive with HDInsight][hdinsight-use-hive].\n\nThe following procedures are needed to provision an HDInsight cluster by using the SDK:\n\n- Install the HDInsight .NET SDK\n- Create a console application\n- Run the application\n\n\n**To install the HDInsight .NET SDK**\nYou can install the latest published build of the SDK from [NuGet](http://nuget.codeplex.com/wikipage?title=Getting%20Started). The instructions will be shown in the next procedure.\n\n**To create a Visual Studio console application**\n\n1. Open Visual Studio.\n\n2. From the **File** menu, click **New**, and then click **Project**.\n\n3. From **New Project**, type or select the following values:\n\n    <table style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse;\">\n    <tr>\n    <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Property</th>\n    <th style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; width:90px; padding-left:5px; padding-right:5px;\">Value</th></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Category</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px; padding-right:5px;\">Templates/Visual C#/Windows</td></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Template</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Console Application</td></tr>\n    <tr>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">Name</td>\n    <td style=\"border-color: #c6c6c6; border-width: 2px; border-style: solid; border-collapse: collapse; padding-left:5px;\">SubmitHiveJob</td></tr>\n    </table>\n\n4. Click **OK** to create the project.\n\n\n5. From the **Tools** menu, click **Library Package Manager**, and then click **Package Manager Console**.\n\n6. Run the following command in the console to install the package:\n\n        Install-Package Microsoft.WindowsAzure.Management.HDInsight\n\n\n    This command adds .NET libraries and references to them to the current Visual Studio project.\n\n7. From **Solution Explorer**, double-click **Program.cs** to open it.\n\n8. Add the following **using** statements to the top of the file:\n\n        using System.IO;\n        using System.Threading;\n        using System.Security.Cryptography.X509Certificates;\n\n        using Microsoft.WindowsAzure.Management.HDInsight;\n        using Microsoft.Hadoop.Client;\n\n9. Add the following function definition to the class. This function is used to wait for a Hadoop job to complete.\n\n        private static void WaitForJobCompletion(JobCreationResults jobResults, IJobSubmissionClient client)\n        {\n            JobDetails jobInProgress = client.GetJob(jobResults.JobId);\n            while (jobInProgress.StatusCode != JobStatusCode.Completed && jobInProgress.StatusCode != JobStatusCode.Failed)\n            {\n                jobInProgress = client.GetJob(jobInProgress.JobId);\n                Thread.Sleep(TimeSpan.FromSeconds(10));\n            }\n        }\n\n10. In the **Main()** function, paste the following code:\n\n        // Set the variables\n        string subscriptionID = \"<Azure subscription ID>\";\n        string clusterName = \"<HDInsight cluster name>\";\n        string certFriendlyName = \"<certificate friendly name>\";\n\n\n    These are all of the variables you need to set for the program. You can get the Azure Subscription ID from your system administrator.\n\n    For information about the certificate, see [Create and Upload a Management Certificate for Azure][azure-certificate]. An easy way to configure the certificate is to run the **Get-AzurePublishSettingsFile** and **Import-AzurePublishSettingsFile** Azure PowerShell cmdlets. They will create and upload the management certificate automatically. After you run these cmdlets, you can open **certmgr.msc** from the workstation, and find the certificate by expanding **Personal** > **Certificates**. The certificate created by the Azure PowerShell cmdlets has Azure Tools for the **Issued To** and the **Issued By** fields.\n\n11. In the **Main()** function, append the following code to define the Hive job:\n\n        // define the Hive job\n        HiveJobCreateParameters hiveJobDefinition = new HiveJobCreateParameters()\n        {\n            JobName = \"show tables job\",\n            StatusFolder = \"/ShowTableStatusFolder\",\n            Query = \"show tables;\"\n        };\n\n    You can also use the **File** parameter to specify a HiveQL script file in HDFS, for example:\n\n        // define the Hive job\n        HiveJobCreateParameters hiveJobDefinition = new HiveJobCreateParameters()\n        {\n            JobName = \"show tables job\",\n            StatusFolder = \"/ShowTableStatusFolder\",\n            File = \"/user/admin/showtables.hql\"\n        };\n\n\n12. In the **Main()** function, append the following code to create a **JobSubmissionCertificateCredential** object:\n\n        // Get the certificate object from certificate store using the friendly name to identify it\n        X509Store store = new X509Store();\n        store.Open(OpenFlags.ReadOnly);\n        X509Certificate2 cert = store.Certificates.Cast<X509Certificate2>().First(item => item.FriendlyName == certFriendlyName);\n        JobSubmissionCertificateCredential creds = new JobSubmissionCertificateCredential(new Guid(subscriptionID), cert, clusterName);\n\n13. In the **Main()** function, append the following code to run the job and wait for the job to complete:\n\n        // Submit the Hive job\n        var jobClient = JobSubmissionClientFactory.Connect(creds);\n        JobCreationResults jobResults = jobClient.CreateHiveJob(hiveJobDefinition);\n\n        // Wait for the job to complete\n        WaitForJobCompletion(jobResults, jobClient);\n\n14. In the **Main()** function, append the following code to print the Hive job output:\n\n        // Print the Hive job output\n        System.IO.Stream stream = jobClient.GetJobOutput(jobResults.JobId);\n\n        StreamReader reader = new StreamReader(stream);\n        Console.WriteLine(reader.ReadToEnd());\n\n        Console.WriteLine(\"Press ENTER to continue.\");\n        Console.ReadLine();\n\n**To run the application**\n\nWhile the application is open in Visual Studio, press **F5** to run the application. A console window should open and display the status of the application. The output should be:\n\n    hivesampletable\n\n##Submit jobs using the HDInsight Tools for Visual Studio\n\nUsing the HDInsight Tools for Visual Studio, you can run Hive queries and Pig scripts. See [Get started using Visual Studio Hadoop tools for HDInsight](hdinsight-hadoop-visual-studio-tools-get-started.md).\n\n\n##Next steps\nIn this article, you have learned several ways to provision an HDInsight cluster. To learn more, see the following articles:\n\n* [Get started with Azure HDInsight][hdinsight-get-started]\n* [Provision HDInsight clusters][hdinsight-provision]\n* [Manage HDInsight by using PowerShell][hdinsight-admin-powershell]\n* [HDInsight Cmdlet Reference Documentation][hdinsight-powershell-reference]\n* [Use Hive with HDInsight][hdinsight-use-hive]\n* [Use Pig with HDInsight][hdinsight-use-pig]\n\n\n[azure-certificate]: http://msdn.microsoft.com/library/windowsazure/gg551722.aspx\n[azure-management-portal]: https://portal.azure.com/\n\n[hdinsight-visual-studio-tools]: ../HDInsight/hdinsight-hadoop-visual-studio-tools-get-started.md\n[hdinsight-use-sqoop]: hdinsight-use-sqoop.md\n[hdinsight-provision]: hdinsight-provision-clusters.md\n[hdinsight-use-mapreduce]: hdinsight-use-mapreduce.md\n[hdinsight-use-hive]: hdinsight-use-hive.md\n[hdinsight-use-pig]: hdinsight-use-pig.md\n[hdinsight-get-started]: ../hdinsight-get-started.md\n[hdinsight-storage]: ../hdinsight-use-blob-storage.md\n[hdinsight-admin-powershell]: hdinsight-administer-use-powershell.md\n[hdinsight-develop-streaming-jobs]: hdinsight-hadoop-develop-deploy-streaming-jobs.md\n\n[hdinsight-powershell-reference]: https://msdn.microsoft.com/library/dn858087.aspx\n\n[powershell-install-configure]: ../install-configure-powershell.md\n\n[image-hdi-gettingstarted-runmrjob]: ./media/hdinsight-submit-hadoop-jobs-programmatically/HDI.GettingStarted.RunMRJob.png\n[image-hdi-gettingstarted-mrjoboutput]: ./media/hdinsight-submit-hadoop-jobs-programmatically/HDI.GettingStarted.MRJobOutput.png\n\n[apache-hive]: http://hive.apache.org/\n\ntest\n"
}