{
  "nodes": [
    {
      "content": "Hadoop MapReduce word count example in HDInsight | Microsoft Azure",
      "pos": [
        27,
        93
      ]
    },
    {
      "content": "Run a MapReduce word count example on a Hadoop cluster in HDInsight.",
      "pos": [
        112,
        180
      ]
    },
    {
      "content": "The program, written in Java, counts word occurrences in a text file.",
      "pos": [
        181,
        250
      ]
    },
    {
      "content": "Run a MapReduce word count example written in Java on a Hadoop cluster in HDInsight",
      "pos": [
        573,
        656
      ]
    },
    {
      "content": "This tutorial shows you how to run a MapReduce word count example on a Hadoop cluster in HDInsight.",
      "pos": [
        658,
        757
      ]
    },
    {
      "content": "The program is written in Java.",
      "pos": [
        758,
        789
      ]
    },
    {
      "content": "It counts word occurrences in a text file, and then outputs a new text file that contains each word paired with its frequency of occurrence.",
      "pos": [
        790,
        930
      ]
    },
    {
      "content": "The text file analyzed in this sample is the Project Gutenberg eBook edition of The Notebooks of Leonardo Da Vinci.",
      "pos": [
        931,
        1046
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The steps in this document require a Windows client.",
      "pos": [
        1050,
        1115
      ]
    },
    {
      "content": "For steps on using the word count example from a Linux, OS X, or Unix client, with a Linux-based HDInsight cluster, see <bpt id=\"p1\">[</bpt>Use MapReduce with Hadoop on HDInsight with SSH<ept id=\"p1\">](hdinsight-hadoop-use-mapreduce-ssh.md)</ept> or <bpt id=\"p2\">[</bpt>Use MapReduce with Hadoop on HDInsight using Curl<ept id=\"p2\">](hdinsight-hadoop-use-mapreduce-curl.md)</ept>.",
      "pos": [
        1116,
        1420
      ]
    },
    {
      "content": "You will learn:",
      "pos": [
        1424,
        1439
      ]
    },
    {
      "content": "How to use Azure PowerShell to run a MapReduce program on an HDInsight cluster.",
      "pos": [
        1445,
        1524
      ]
    },
    {
      "content": "How to write MapReduce programs in Java.",
      "pos": [
        1527,
        1567
      ]
    },
    {
      "pos": [
        1570,
        1588
      ],
      "content": "<bpt id=\"p1\">**</bpt>Prerequisites<ept id=\"p1\">**</ept>:"
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>An Azure subscription<ept id=\"p1\">**</ept>.",
      "pos": [
        1592,
        1618
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Get Azure free trial<ept id=\"p1\">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.",
      "pos": [
        1619,
        1749
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>An HDInsight cluster<ept id=\"p1\">**</ept>.",
      "pos": [
        1753,
        1778
      ]
    },
    {
      "content": "For instructions about the various ways in which such clusters can be created, see <bpt id=\"p1\">[</bpt>Get Started with Azure HDInsight<ept id=\"p1\">][hdinsight-get-started]</ept> or <bpt id=\"p2\">[</bpt>Provision HDInsight Clusters<ept id=\"p2\">](hdinsight-provision-clusters.md)</ept>.",
      "pos": [
        1779,
        1987
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>A workstation with Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        1991,
        2031
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Install and use Azure PowerShell<ept id=\"p1\">](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.",
      "pos": [
        2032,
        2154
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"run-sample\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Run the sample by using Azure PowerShell",
      "pos": [
        2161,
        2224
      ]
    },
    {
      "content": "To submit the MapReduce job",
      "pos": [
        2233,
        2260
      ]
    },
    {
      "content": "Open the <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept> console.",
      "pos": [
        2268,
        2306
      ]
    },
    {
      "content": "For instructions, see <bpt id=\"p1\">[</bpt>Install and configure Azure PowerShell<ept id=\"p1\">][powershell-install-configure]</ept>.",
      "pos": [
        2307,
        2400
      ]
    },
    {
      "content": "Set the two variables in the following commands, and then run them:",
      "pos": [
        2405,
        2472
      ]
    },
    {
      "content": "Run the following command to create a MapReduce job definition:",
      "pos": [
        2631,
        2694
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> <bpt id=\"p1\">*</bpt>hadoop-examples.jar<ept id=\"p1\">*</ept> comes with HDInsight version 2.1 clusters.",
      "pos": [
        2994,
        3071
      ]
    },
    {
      "content": "The file was renamed <bpt id=\"p1\">*</bpt>hadoop-mapreduce.jar<ept id=\"p1\">*</ept> on HDInsight version 3.0 clusters.",
      "pos": [
        3072,
        3150
      ]
    },
    {
      "content": "The hadoop-mapreduce-examples.jar file comes with the HDInsight cluster.",
      "pos": [
        3156,
        3228
      ]
    },
    {
      "content": "There are two arguments for the MapReduce job.",
      "pos": [
        3229,
        3275
      ]
    },
    {
      "content": "The first one is the source file name, and the second is the output file path.",
      "pos": [
        3276,
        3354
      ]
    },
    {
      "content": "The source file comes with the HDInsight cluster, and the output file path will be created at run time.",
      "pos": [
        3355,
        3458
      ]
    },
    {
      "content": "Run the following command to submit the MapReduce job:",
      "pos": [
        3463,
        3517
      ]
    },
    {
      "content": "In addition to the MapReduce job definition, you also provide the HDInsight cluster name for where you want to run the MapReduce job.",
      "pos": [
        3763,
        3896
      ]
    },
    {
      "content": "Run the following command to check for errors with running the MapReduce job:",
      "pos": [
        3901,
        3978
      ]
    },
    {
      "content": "To retrieve the results of the MapReduce job",
      "pos": [
        4112,
        4156
      ]
    },
    {
      "pos": [
        4163,
        4200
      ],
      "content": "Open the <bpt id=\"p1\">**</bpt>Azure PowerShell<ept id=\"p1\">**</ept>console."
    },
    {
      "content": "Set the three variables in the following commands, and then run them:",
      "pos": [
        4204,
        4273
      ]
    },
    {
      "content": "The Azure Storage account is the one you created earlier in the tutorial.",
      "pos": [
        4530,
        4603
      ]
    },
    {
      "content": "The storage account is used to host the blob that is used as the default HDInsight cluster file system.",
      "pos": [
        4604,
        4707
      ]
    },
    {
      "content": "The Azure Blob storage container name usually shares the same name as the HDInsight cluster, unless you specify a different name when you provision the cluster.",
      "pos": [
        4708,
        4868
      ]
    },
    {
      "content": "Run the following commands to create an Azure storage context object:",
      "pos": [
        4873,
        4942
      ]
    },
    {
      "pos": [
        5312,
        5477
      ],
      "content": "<bpt id=\"p1\">**</bpt>Select-AzureSubscription<ept id=\"p1\">**</ept> is used to set the current subscription if you have multiple subscriptions, and the default subscription is not the one you want to use."
    },
    {
      "content": "Run the following command to download the MapReduce job output from the blob to the workstation:",
      "pos": [
        5482,
        5578
      ]
    },
    {
      "content": "The <bpt id=\"p1\">*</bpt>/example/data/WordCountOutput<ept id=\"p1\">*</ept> folder is the output folder specified when you run the MapReduce job.",
      "pos": [
        5780,
        5885
      ]
    },
    {
      "content": "<bpt id=\"p1\">*</bpt>part-r-00000<ept id=\"p1\">*</ept> is the default file name for MapReduce job output.",
      "pos": [
        5886,
        5951
      ]
    },
    {
      "content": "The file will be downloaded to the same folder structure in the local folder.",
      "pos": [
        5952,
        6029
      ]
    },
    {
      "content": "For example, in the following screenshot, the current folder is the C root folder.",
      "pos": [
        6030,
        6112
      ]
    },
    {
      "content": "The file will be downloaded to the <bpt id=\"p1\">*</bpt>C:\\example\\data\\WordCountOutput<ept id=\"p1\">*</ept> folder.",
      "pos": [
        6113,
        6189
      ]
    },
    {
      "content": "Run the following command to print the MapReduce job output file:",
      "pos": [
        6194,
        6259
      ]
    },
    {
      "content": "The MapReduce job produces a file named <bpt id=\"p1\">*</bpt>part-r-00000<ept id=\"p1\">*</ept>, which contains words and the counts.",
      "pos": [
        6341,
        6433
      ]
    },
    {
      "content": "The script uses the <bpt id=\"p1\">**</bpt>findstr<ept id=\"p1\">**</ept> command to list all of the words that contains <bpt id=\"p2\">*</bpt>\"there\"<ept id=\"p2\">*</ept>.",
      "pos": [
        6434,
        6523
      ]
    },
    {
      "content": "The output from the WordCount script should appear in the command window:",
      "pos": [
        6525,
        6598
      ]
    },
    {
      "content": "Word frequency results in PowerShell from the Hadoop MapReduce word count example in HDInsight.",
      "pos": [
        6602,
        6697
      ]
    },
    {
      "content": "Note that the output files of a MapReduce job are immutable.",
      "pos": [
        6735,
        6795
      ]
    },
    {
      "content": "So if you rerun this sample, you need to change the name of the output file.",
      "pos": [
        6796,
        6872
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"java-code\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Java code for the WordCount MapReduce program",
      "pos": [
        6877,
        6944
      ]
    },
    {
      "content": "In this tutorial, you have seen how to run a MapReduce program that counts word occurrences in a text file with HDInsight by using Azure PowerShell.",
      "pos": [
        9416,
        9564
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"next-steps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Next steps",
      "pos": [
        9569,
        9602
      ]
    },
    {
      "content": "For tutorials that run other samples and provide instructions about using Pig, Hive, and MapReduce jobs on Azure HDInsight with Azure PowerShell, see:",
      "pos": [
        9609,
        9759
      ]
    },
    {
      "content": "Get Started with Azure HDInsight",
      "pos": [
        9764,
        9796
      ]
    },
    {
      "content": "Sample: 10GB GraySort",
      "pos": [
        9824,
        9845
      ]
    },
    {
      "content": "Sample: Pi Estimator",
      "pos": [
        9882,
        9902
      ]
    },
    {
      "content": "Sample: C# Steaming",
      "pos": [
        9938,
        9957
      ]
    },
    {
      "content": "Use Pig with HDInsight",
      "pos": [
        9993,
        10015
      ]
    },
    {
      "content": "Use Hive with HDInsight",
      "pos": [
        10039,
        10062
      ]
    },
    {
      "content": "Azure HDInsight SDK documentation",
      "pos": [
        10088,
        10121
      ]
    },
    {
      "content": "test",
      "pos": [
        10771,
        10775
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Hadoop MapReduce word count example in HDInsight | Microsoft Azure\"\n    description=\"Run a MapReduce word count example on a Hadoop cluster in HDInsight. The program, written in Java, counts word occurrences in a text file.\"\n    editor=\"cgronlun\"\n    manager=\"paulettm\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    tags=\"azure-portal\"\n    authors=\"mumian\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"07/09/2015\"\n    ms.author=\"jgao\"/>\n\n#Run a MapReduce word count example written in Java on a Hadoop cluster in HDInsight\n\nThis tutorial shows you how to run a MapReduce word count example on a Hadoop cluster in HDInsight. The program is written in Java. It counts word occurrences in a text file, and then outputs a new text file that contains each word paired with its frequency of occurrence. The text file analyzed in this sample is the Project Gutenberg eBook edition of The Notebooks of Leonardo Da Vinci.\n\n> [AZURE.NOTE] The steps in this document require a Windows client. For steps on using the word count example from a Linux, OS X, or Unix client, with a Linux-based HDInsight cluster, see [Use MapReduce with Hadoop on HDInsight with SSH](hdinsight-hadoop-use-mapreduce-ssh.md) or [Use MapReduce with Hadoop on HDInsight using Curl](hdinsight-hadoop-use-mapreduce-curl.md).\n\n**You will learn:**\n\n* How to use Azure PowerShell to run a MapReduce program on an HDInsight cluster.\n* How to write MapReduce programs in Java.\n\n\n**Prerequisites**:\n\n- **An Azure subscription**. See [Get Azure free trial](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).\n\n- **An HDInsight cluster**. For instructions about the various ways in which such clusters can be created, see [Get Started with Azure HDInsight][hdinsight-get-started] or [Provision HDInsight Clusters](hdinsight-provision-clusters.md).\n\n- **A workstation with Azure PowerShell**. See [Install and use Azure PowerShell](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/).\n\n\n\n## <a id=\"run-sample\"></a>Run the sample by using Azure PowerShell</h2>\n\n**To submit the MapReduce job**\n\n1.  Open the **Azure PowerShell** console. For instructions, see [Install and configure Azure PowerShell][powershell-install-configure].\n\n3. Set the two variables in the following commands, and then run them:\n\n        $subscriptionName = \"<SubscriptionName>\"   # Azure subscription name\n        $clusterName = \"<ClusterName>\"             # HDInsight cluster name\n\n5. Run the following command to create a MapReduce job definition:\n\n        # Define the MapReduce job\n        $wordCountJobDefinition = New-AzureHDInsightMapReduceJobDefinition -JarFile \"wasb:///example/jars/hadoop-mapreduce-examples.jar\" -ClassName \"wordcount\" -Arguments \"wasb:///example/data/gutenberg/davinci.txt\", \"wasb:///example/data/WordCountOutput\"\n\n    > [AZURE.NOTE] *hadoop-examples.jar* comes with HDInsight version 2.1 clusters. The file was renamed *hadoop-mapreduce.jar* on HDInsight version 3.0 clusters.\n\n    The hadoop-mapreduce-examples.jar file comes with the HDInsight cluster. There are two arguments for the MapReduce job. The first one is the source file name, and the second is the output file path. The source file comes with the HDInsight cluster, and the output file path will be created at run time.\n\n6. Run the following command to submit the MapReduce job:\n\n        # Submit the job\n        Select-AzureSubscription $subscriptionName\n        $wordCountJob = Start-AzureHDInsightJob -Cluster $clusterName -JobDefinition $wordCountJobDefinition | Wait-AzureHDInsightJob -WaitTimeoutInSeconds 3600  \n\n    In addition to the MapReduce job definition, you also provide the HDInsight cluster name for where you want to run the MapReduce job.\n\n8. Run the following command to check for errors with running the MapReduce job:\n\n        # Get the job output\n        Get-AzureHDInsightJobOutput -Cluster $clusterName -JobId $wordCountJob.JobId -StandardError\n\n**To retrieve the results of the MapReduce job**\n\n1. Open the **Azure PowerShell**console.\n2. Set the three variables in the following commands, and then run them:\n\n        $subscriptionName = \"<SubscriptionName>\"       # Azure subscription name\n        $storageAccountName = \"<StorageAccountName>\"   # Azure storage account name\n        $containerName = \"<ContainerName>\"             # Blob storage container name\n\n    The Azure Storage account is the one you created earlier in the tutorial. The storage account is used to host the blob that is used as the default HDInsight cluster file system. The Azure Blob storage container name usually shares the same name as the HDInsight cluster, unless you specify a different name when you provision the cluster.\n\n3. Run the following commands to create an Azure storage context object:\n\n        # Select the current subscription\n        Select-AzureSubscription $subscriptionName\n\n        # Create the storage account context object\n        $storageAccountKey = Get-AzureStorageKey $storageAccountName | %{ $_.Primary }\n        $storageContext = New-AzureStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey  \n\n    **Select-AzureSubscription** is used to set the current subscription if you have multiple subscriptions, and the default subscription is not the one you want to use.\n\n4. Run the following command to download the MapReduce job output from the blob to the workstation:\n\n        # Download the job output to the workstation\n        Get-AzureStorageBlobContent -Container $ContainerName -Blob example/data/WordCountOutput/part-r-00000 -Context $storageContext -Force\n\n    The */example/data/WordCountOutput* folder is the output folder specified when you run the MapReduce job. *part-r-00000* is the default file name for MapReduce job output. The file will be downloaded to the same folder structure in the local folder. For example, in the following screenshot, the current folder is the C root folder. The file will be downloaded to the *C:\\example\\data\\WordCountOutput* folder.\n\n5. Run the following command to print the MapReduce job output file:\n\n        cat ./example/data/WordCountOutput/part-r-00000 | findstr \"there\"\n\n\n    The MapReduce job produces a file named *part-r-00000*, which contains words and the counts. The script uses the **findstr** command to list all of the words that contains *\"there\"*.\n\nThe output from the WordCount script should appear in the command window:\n\n![Word frequency results in PowerShell from the Hadoop MapReduce word count example in HDInsight.][image-hdi-sample-wordcount-output]\n\nNote that the output files of a MapReduce job are immutable. So if you rerun this sample, you need to change the name of the output file.\n\n## <a id=\"java-code\"></a>Java code for the WordCount MapReduce program</h2>\n\n\n\n    package org.apache.hadoop.examples;\n    import java.io.IOException;\n    import java.util.StringTokenizer;\n    import org.apache.hadoop.conf.Configuration;\n    import org.apache.hadoop.fs.Path;\n    import org.apache.hadoop.io.IntWritable;\n    import org.apache.hadoop.io.Text;\n    import org.apache.hadoop.mapreduce.Job;\n    import org.apache.hadoop.mapreduce.Mapper;\n    import org.apache.hadoop.mapreduce.Reducer;\n    import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n    import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n    import org.apache.hadoop.util.GenericOptionsParser;\n\n    public class WordCount {\n\n    public static class TokenizerMapper\n       extends Mapper<Object, Text, Text, IntWritable>{\n\n    private final static IntWritable one = new IntWritable(1);\n    private Text word = new Text();\n\n    public void map(Object key, Text value, Context context\n                    ) throws IOException, InterruptedException {\n      StringTokenizer itr = new StringTokenizer(value.toString());\n      while (itr.hasMoreTokens()) {\n        word.set(itr.nextToken());\n        context.write(word, one);\n        }\n      }\n    }\n\n    public static class IntSumReducer\n       extends Reducer<Text,IntWritable,Text,IntWritable> {\n    private IntWritable result = new IntWritable();\n\n    public void reduce(Text key, Iterable<IntWritable> values,\n                       Context context\n                       ) throws IOException, InterruptedException {\n      int sum = 0;\n      for (IntWritable val : values) {\n        sum += val.get();\n      }\n      result.set(sum);\n      context.write(key, result);\n      }\n    }\n\n    public static void main(String[] args) throws Exception {\n    Configuration conf = new Configuration();\n    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n    if (otherArgs.length != 2) {\n      System.err.println(\"Usage: wordcount <in> <out>\");\n      System.exit(2);\n        }\n    Job job = new Job(conf, \"word count\");\n    job.setJarByClass(WordCount.class);\n    job.setMapperClass(TokenizerMapper.class);\n    job.setCombinerClass(IntSumReducer.class);\n    job.setReducerClass(IntSumReducer.class);\n    job.setOutputKeyClass(Text.class);\n    job.setOutputValueClass(IntWritable.class);\n    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));\n    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n    }\n\n\n\nIn this tutorial, you have seen how to run a MapReduce program that counts word occurrences in a text file with HDInsight by using Azure PowerShell.\n\n## <a id=\"next-steps\"></a>Next steps</h2>\n\nFor tutorials that run other samples and provide instructions about using Pig, Hive, and MapReduce jobs on Azure HDInsight with Azure PowerShell, see:\n\n* [Get Started with Azure HDInsight][hdinsight-get-started]\n* [Sample: 10GB GraySort][hdinsight-sample-10gb-graysort]\n* [Sample: Pi Estimator][hdinsight-sample-pi-estimator]\n* [Sample: C# Steaming][hdinsight-sample-cs-streaming]\n* [Use Pig with HDInsight][hdinsight-use-pig]\n* [Use Hive with HDInsight] [hdinsight-use-hive]\n* [Azure HDInsight SDK documentation][hdinsight-sdk-documentation]\n\n[hdinsight-sdk-documentation]: http://msdnstage.redmond.corp.microsoft.com/library/dn479185.aspx\n\n[hdinsight-sample-10gb-graysort]: hdinsight-sample-10gb-graysort.md\n[hdinsight-sample-pi-estimator]: hdinsight-sample-pi-estimator.md\n[hdinsight-sample-cs-streaming]: hdinsight-sample-csharp-streaming.md\n\n\n[hdinsight-use-hive]: hdinsight-use-hive.md\n[hdinsight-use-pig]: hdinsight-use-pig.md\n\n[hdinsight-get-started]: ../hdinsight-get-started.md\n\n[powershell-install-configure]: ../install-configure-powershell.md\n\n[image-hdi-sample-wordcount-output]: ./media/hdinsight-sample-wordcount/HDI.Sample.WordCount.Output.png\n\ntest\n"
}