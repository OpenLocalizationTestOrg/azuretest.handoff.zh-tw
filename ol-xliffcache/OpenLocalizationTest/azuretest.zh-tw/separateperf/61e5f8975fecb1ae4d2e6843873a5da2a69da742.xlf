<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Import data into Machine Learning Studio | Microsoft Azure</source>
          <target state="new">Import data into Machine Learning Studio | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>How to import your training data Azure Machine Learning Studio from various data sources.</source>
          <target state="new">How to import your training data Azure Machine Learning Studio from various data sources.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Learn what data types and data formats are supported.</source>
          <target state="new">Learn what data types and data formats are supported.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Import your training data into Azure Machine Learning Studio from various data sources</source>
          <target state="new">Import your training data into Azure Machine Learning Studio from various data sources</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>When you develop a predictive analytics solution in Azure Machine Learning Studio, you train your model using data representative of your problem space.</source>
          <target state="new">When you develop a predictive analytics solution in Azure Machine Learning Studio, you train your model using data representative of your problem space.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This tutorial shows you how to import data from various data sources for training your model in Machine Learning Studio.</source>
          <target state="new">This tutorial shows you how to import data from various data sources for training your model in Machine Learning Studio.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>You'll also learn which data formats are supported.</source>
          <target state="new">You'll also learn which data formats are supported.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>There are a number of sample datasets available in Machine Learning Studio that you can use for this purpose</source>
          <target state="new">There are a number of sample datasets available in Machine Learning Studio that you can use for this purpose</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>(see <bpt id="p1">[</bpt>Use the sample datasets in Azure Machine Learning Studio<ept id="p1">](machine-learning-use-sample-datasets.md)</ept>).</source>
          <target state="new">(see <bpt id="p1">[</bpt>Use the sample datasets in Azure Machine Learning Studio<ept id="p1">](machine-learning-use-sample-datasets.md)</ept>).</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>But you can also import your own data into Machine Learning Studio for use in your experiments.</source>
          <target state="new">But you can also import your own data into Machine Learning Studio for use in your experiments.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>To use your own data in Machine Learning Studio, you can upload a data file ahead of time from your local hard drive to create a dataset module in your workspace.</source>
          <target state="new">To use your own data in Machine Learning Studio, you can upload a data file ahead of time from your local hard drive to create a dataset module in your workspace.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Or you can access data from one of several online data sources while your experiment is running using the [Reader][reader] module:</source>
          <target state="new">Or you can access data from one of several online data sources while your experiment is running using the [Reader][reader] module:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Azure Blob storage, table, or SQL database</source>
          <target state="new">Azure Blob storage, table, or SQL database</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Hadoop using HiveQL</source>
          <target state="new">Hadoop using HiveQL</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>A web URL using HTTP</source>
          <target state="new">A web URL using HTTP</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>A data feed provider</source>
          <target state="new">A data feed provider</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Machine Learning Studio is designed to work with rectangular or tabular data, such as text data that's delimited or structured data from a database, though in some circumstances non-rectangular data may be used.</source>
          <target state="new">Machine Learning Studio is designed to work with rectangular or tabular data, such as text data that's delimited or structured data from a database, though in some circumstances non-rectangular data may be used.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>It's best if your data is relatively clean.</source>
          <target state="new">It's best if your data is relatively clean.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>That is, you'll want to take care of issues such as unquoted strings before you upload the data into your experiment.</source>
          <target state="new">That is, you'll want to take care of issues such as unquoted strings before you upload the data into your experiment.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>However, there are modules available in Machine Learning Studio that will let you do some manipulation of data within your experiment.</source>
          <target state="new">However, there are modules available in Machine Learning Studio that will let you do some manipulation of data within your experiment.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Depending on the machine learning algorithms you'll be using, you may need to decide how you'll handle data structural issues such as missing values and sparse data, and there are modules that can help with that.</source>
          <target state="new">Depending on the machine learning algorithms you'll be using, you may need to decide how you'll handle data structural issues such as missing values and sparse data, and there are modules that can help with that.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Look in the <bpt id="p1">**</bpt>Data Transformation<ept id="p1">**</ept> section of the module palette for modules that perform these functions.</source>
          <target state="new">Look in the <bpt id="p1">**</bpt>Data Transformation<ept id="p1">**</ept> section of the module palette for modules that perform these functions.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>At any point in your experiment you can view or download the data that's produced by a module by right-clicking the output port.</source>
          <target state="new">At any point in your experiment you can view or download the data that's produced by a module by right-clicking the output port.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Depending on the module there may be different download options available, or you may be able to view the data within your web browser in Machine Learning Studio.</source>
          <target state="new">Depending on the module there may be different download options available, or you may be able to view the data within your web browser in Machine Learning Studio.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Data formats</source>
          <target state="new">Data formats</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>You can import a number of data types into your experiment, depending on what mechanism you use to import data and where it's coming from:</source>
          <target state="new">You can import a number of data types into your experiment, depending on what mechanism you use to import data and where it's coming from:</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Plain text (.txt)</source>
          <target state="new">Plain text (.txt)</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Comma-separated values (CSV) with a header (.csv) or without (.nh.csv)</source>
          <target state="new">Comma-separated values (CSV) with a header (.csv) or without (.nh.csv)</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Tab-separated values (TSV) with a header (.tsv) or without (.nh.tsv)</source>
          <target state="new">Tab-separated values (TSV) with a header (.tsv) or without (.nh.tsv)</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Hive table</source>
          <target state="new">Hive table</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>SQL database table</source>
          <target state="new">SQL database table</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>OData values</source>
          <target state="new">OData values</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>SVMLight data (.svmlight) (see the <bpt id="p1">[</bpt>SVMLight definition<ept id="p1">](http://svmlight.joachims.org/)</ept> for format information)</source>
          <target state="new">SVMLight data (.svmlight) (see the <bpt id="p1">[</bpt>SVMLight definition<ept id="p1">](http://svmlight.joachims.org/)</ept> for format information)</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Attribute Relation File Format (ARFF) data (.arff) (see the <bpt id="p1">[</bpt>ARFF definition<ept id="p1">](http://weka.wikispaces.com/ARFF)</ept> for format information)</source>
          <target state="new">Attribute Relation File Format (ARFF) data (.arff) (see the <bpt id="p1">[</bpt>ARFF definition<ept id="p1">](http://weka.wikispaces.com/ARFF)</ept> for format information)</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Zip file (.zip)</source>
          <target state="new">Zip file (.zip)</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>R object or workspace file (.RData)</source>
          <target state="new">R object or workspace file (.RData)</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>If you import data in a format such as ARFF that includes metadata, Machine Learning Studio uses this metadata to define the heading and data type of each column.</source>
          <target state="new">If you import data in a format such as ARFF that includes metadata, Machine Learning Studio uses this metadata to define the heading and data type of each column.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>If you import data such as TSV or CSV format that doesn't include this metadata, Machine Learning Studio infers the data type for each column by sampling the data.</source>
          <target state="new">If you import data such as TSV or CSV format that doesn't include this metadata, Machine Learning Studio infers the data type for each column by sampling the data.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>If the data also doesn't have column headings, Machine Learning Studio provides default names.</source>
          <target state="new">If the data also doesn't have column headings, Machine Learning Studio provides default names.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>You can explicitly specify or change the headings and data types for columns using the [Metadata Editor][metadata-editor].</source>
          <target state="new">You can explicitly specify or change the headings and data types for columns using the [Metadata Editor][metadata-editor].</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The following data types are recognized by Machine Learning Studio:</source>
          <target state="new">The following data types are recognized by Machine Learning Studio:</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>String</source>
          <target state="new">String</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Integer</source>
          <target state="new">Integer</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Double</source>
          <target state="new">Double</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Boolean</source>
          <target state="new">Boolean</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>DateTime</source>
          <target state="new">DateTime</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>TimeSpan</source>
          <target state="new">TimeSpan</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Machine Learning Studio uses an internal data type called <bpt id="p1">*</bpt>Data Table<ept id="p1">*</ept> to pass data between modules.</source>
          <target state="new">Machine Learning Studio uses an internal data type called <bpt id="p1">*</bpt>Data Table<ept id="p1">*</ept> to pass data between modules.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>You can explicitly convert your data into Data Table format using the [Convert to Dataset][convert-to-dataset] module.</source>
          <target state="new">You can explicitly convert your data into Data Table format using the [Convert to Dataset][convert-to-dataset] module.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Any module that accepts formats other than Data Table will convert the data to Data Table silently before passing it to the next module.</source>
          <target state="new">Any module that accepts formats other than Data Table will convert the data to Data Table silently before passing it to the next module.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>If necessary, you can convert Data Table format back into CSV, TSV, ARFF, or SVMLight format using other conversion modules.</source>
          <target state="new">If necessary, you can convert Data Table format back into CSV, TSV, ARFF, or SVMLight format using other conversion modules.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Look in the <bpt id="p1">**</bpt>Data Format Conversions<ept id="p1">**</ept> section of the module palette for modules that perform these functions.</source>
          <target state="new">Look in the <bpt id="p1">**</bpt>Data Format Conversions<ept id="p1">**</ept> section of the module palette for modules that perform these functions.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Import data from a local file</source>
          <target state="new">Import data from a local file</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>You can import data from a local hard drive by doing the following:</source>
          <target state="new">You can import data from a local hard drive by doing the following:</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>+NEW<ept id="p1">**</ept> at the bottom of the Machine Learning Studio window.</source>
          <target state="new">Click <bpt id="p1">**</bpt>+NEW<ept id="p1">**</ept> at the bottom of the Machine Learning Studio window.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>DATASET<ept id="p1">**</ept> and <bpt id="p2">**</bpt>FROM LOCAL FILE<ept id="p2">**</ept>.</source>
          <target state="new">Select <bpt id="p1">**</bpt>DATASET<ept id="p1">**</ept> and <bpt id="p2">**</bpt>FROM LOCAL FILE<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Upload a new dataset<ept id="p1">**</ept> dialog, browse to the file you want to upload</source>
          <target state="new">In the <bpt id="p1">**</bpt>Upload a new dataset<ept id="p1">**</ept> dialog, browse to the file you want to upload</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Enter a name, identify the data type, and optionally enter a description.</source>
          <target state="new">Enter a name, identify the data type, and optionally enter a description.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>A description is recommended - it allows you to record any characteristics about the data that you will want to remember when using the data in the future.</source>
          <target state="new">A description is recommended - it allows you to record any characteristics about the data that you will want to remember when using the data in the future.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>The checkbox <bpt id="p1">**</bpt>This is the new version of an existing dataset<ept id="p1">**</ept> allows you to update an existing dataset with new data.</source>
          <target state="new">The checkbox <bpt id="p1">**</bpt>This is the new version of an existing dataset<ept id="p1">**</ept> allows you to update an existing dataset with new data.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Just click this checkbox and then enter the name of an existing dataset.</source>
          <target state="new">Just click this checkbox and then enter the name of an existing dataset.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>During upload, you will see a message that your file is being uploaded.</source>
          <target state="new">During upload, you will see a message that your file is being uploaded.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Upload time will depend on the size of your data and the speed of your connection to the service.</source>
          <target state="new">Upload time will depend on the size of your data and the speed of your connection to the service.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>If you know the file will take a long time, you can do other things inside Machine Learning Studio while you wait.</source>
          <target state="new">If you know the file will take a long time, you can do other things inside Machine Learning Studio while you wait.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>However, closing the browser will cause the data upload to fail.</source>
          <target state="new">However, closing the browser will cause the data upload to fail.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Once your data is uploaded, it's stored in a dataset module and is available to any experiment in your workspace.</source>
          <target state="new">Once your data is uploaded, it's stored in a dataset module and is available to any experiment in your workspace.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>You can find the dataset, along with all the pre-loaded sample datasets, in the <bpt id="p1">**</bpt>Saved Datasets<ept id="p1">**</ept> list in the module palette when you're editing an experiment.</source>
          <target state="new">You can find the dataset, along with all the pre-loaded sample datasets, in the <bpt id="p1">**</bpt>Saved Datasets<ept id="p1">**</ept> list in the module palette when you're editing an experiment.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Access online data with the Reader module</source>
          <target state="new">Access online data with the Reader module</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Using the [Reader][reader] module in your experiment, you can access data from several online sources while your experiment is running.</source>
          <target state="new">Using the [Reader][reader] module in your experiment, you can access data from several online sources while your experiment is running.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Because this training data is accessed while your experiment is running, it's only available in one experiment (as opposed to dataset modules which are available to any experiment in your workspace).</source>
          <target state="new">Because this training data is accessed while your experiment is running, it's only available in one experiment (as opposed to dataset modules which are available to any experiment in your workspace).</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>After adding the [Reader][reader] module to your experiment, you select the <bpt id="p1">**</bpt>Data source<ept id="p1">**</ept> and then provide access information using module parameters.</source>
          <target state="new">After adding the [Reader][reader] module to your experiment, you select the <bpt id="p1">**</bpt>Data source<ept id="p1">**</ept> and then provide access information using module parameters.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>For example, if you select <bpt id="p1">**</bpt>Web URL via HTTP<ept id="p1">**</ept>, you provide the source URL and data format.</source>
          <target state="new">For example, if you select <bpt id="p1">**</bpt>Web URL via HTTP<ept id="p1">**</ept>, you provide the source URL and data format.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>If you're accessing your training data from Azure storage or HDInsight (using a Hive query), you provide the appropriate account information and the location of the data.</source>
          <target state="new">If you're accessing your training data from Azure storage or HDInsight (using a Hive query), you provide the appropriate account information and the location of the data.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This article provides general information about the [Reader][reader] module.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This article provides general information about the [Reader][reader] module.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>For more detailed information about the types of data you can access, formats, parameters, and answers to common questions, see the module reference topic for the [Reader][reader] module.</source>
          <target state="new">For more detailed information about the types of data you can access, formats, parameters, and answers to common questions, see the module reference topic for the [Reader][reader] module.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Get data from Azure</source>
          <target state="new">Get data from Azure</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>You can import from three Azure data sources:</source>
          <target state="new">You can import from three Azure data sources:</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure Blob Storage<ept id="p1">**</ept> - If you use the ARFF format for storage, columns are mapped by using the header metadata.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure Blob Storage<ept id="p1">**</ept> - If you use the ARFF format for storage, columns are mapped by using the header metadata.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>If you use TSV or CSV formats, mappings are inferred by sampling column data.</source>
          <target state="new">If you use TSV or CSV formats, mappings are inferred by sampling column data.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure Table Storage<ept id="p1">**</ept> - The [Reader][reader] module scans your data to identify column data types.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure Table Storage<ept id="p1">**</ept> - The [Reader][reader] module scans your data to identify column data types.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>If your data is fairly homogenous and predictable you can limit the number of rows that are scanned.</source>
          <target state="new">If your data is fairly homogenous and predictable you can limit the number of rows that are scanned.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure SQL Database<ept id="p1">**</ept> - The [Reader][reader] module leverages the SQL Azure Transact client API to import data using a database query that you provide.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure SQL Database<ept id="p1">**</ept> - The [Reader][reader] module leverages the SQL Azure Transact client API to import data using a database query that you provide.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>For Blob and table storage you supply a Shared Access Signature URI (SAS URI) or Azure storage account information to provide access to the data.</source>
          <target state="new">For Blob and table storage you supply a Shared Access Signature URI (SAS URI) or Azure storage account information to provide access to the data.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>For an Azure SQL database you supply your database and account information, plus a database query that identifies the data you want to import.</source>
          <target state="new">For an Azure SQL database you supply your database and account information, plus a database query that identifies the data you want to import.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Get data from the web</source>
          <target state="new">Get data from the web</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>You can use the [Reader][reader] module to read training data from a web or FTP site.</source>
          <target state="new">You can use the [Reader][reader] module to read training data from a web or FTP site.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>You need to provide:</source>
          <target state="new">You need to provide:</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>A complete HTTP URL address of a file</source>
          <target state="new">A complete HTTP URL address of a file</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The data format of the file (CSV, TSV, ARFF, or SvmLight)</source>
          <target state="new">The data format of the file (CSV, TSV, ARFF, or SvmLight)</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>For CSV or TSV files, indicate if the first line in the file is a header</source>
          <target state="new">For CSV or TSV files, indicate if the first line in the file is a header</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Get data from Hadoop</source>
          <target state="new">Get data from Hadoop</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>You can use the [Reader][reader] module to read training data from distributed storage using the HiveQL query language.</source>
          <target state="new">You can use the [Reader][reader] module to read training data from distributed storage using the HiveQL query language.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>You'll need to specify the Hive database query and provide user access information on the HCatalog server.</source>
          <target state="new">You'll need to specify the Hive database query and provide user access information on the HCatalog server.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>You also need to specify whether the data is stored in a Hadoop distributed file system (HDFS) or in Azure, and, if in Azure, the Azure account information</source>
          <target state="new">You also need to specify whether the data is stored in a Hadoop distributed file system (HDFS) or in Azure, and, if in Azure, the Azure account information</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Get data from a data feed provider</source>
          <target state="new">Get data from a data feed provider</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>By specifying an OData URL, you can read directly from a data feed provider.</source>
          <target state="new">By specifying an OData URL, you can read directly from a data feed provider.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>You'll need to provide the source URL and the data content type.</source>
          <target state="new">You'll need to provide the source URL and the data content type.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Save data from your experiment</source>
          <target state="new">Save data from your experiment</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>There will be times when you'll want to take an intermediate result from an experiment and use it as part of another experiment.</source>
          <target state="new">There will be times when you'll want to take an intermediate result from an experiment and use it as part of another experiment.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>To do this:</source>
          <target state="new">To do this:</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Right-click the output of the module that you want to save as a dataset.</source>
          <target state="new">Right-click the output of the module that you want to save as a dataset.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Save as Dataset<ept id="p1">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Save as Dataset<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>When prompted, enter a name and a description that would allow you to identify the dataset easily.</source>
          <target state="new">When prompted, enter a name and a description that would allow you to identify the dataset easily.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Click the <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> checkmark.</source>
          <target state="new">Click the <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> checkmark.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>When the save finishes, the dataset will be available for use within any experiment in your workspace.</source>
          <target state="new">When the save finishes, the dataset will be available for use within any experiment in your workspace.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>You can find it in the <bpt id="p1">**</bpt>Saved Datasets<ept id="p1">**</ept> list in the module palette.</source>
          <target state="new">You can find it in the <bpt id="p1">**</bpt>Saved Datasets<ept id="p1">**</ept> list in the module palette.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">61e5f8975fecb1ae4d2e6843873a5da2a69da742</xliffext:olfilehash>
  </header>
</xliff>