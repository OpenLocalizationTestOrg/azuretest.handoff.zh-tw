{
  "nodes": [
    {
      "content": "Modeling data in Azure DocumentDB | Microsoft Azure",
      "pos": [
        28,
        79
      ]
    },
    {
      "content": "Learn how to model data for a NoSQL document database like Azure DocumentDB.",
      "pos": [
        99,
        175
      ]
    },
    {
      "content": "Modeling data in DocumentDB",
      "pos": [
        501,
        528
      ]
    },
    {
      "content": "While schema-free databases, like DocumentDB, make it super easy to embrace changes to your data model you should still spend some time thinking about your data.",
      "pos": [
        530,
        691
      ]
    },
    {
      "content": "How is data going to be stored?",
      "pos": [
        694,
        725
      ]
    },
    {
      "content": "How is your application going to retrieve and query data?",
      "pos": [
        726,
        783
      ]
    },
    {
      "content": "Is your application read heavy, or write heavy?",
      "pos": [
        784,
        831
      ]
    },
    {
      "content": "After reading this article, you will be able to answer the following questions:",
      "pos": [
        833,
        912
      ]
    },
    {
      "content": "How should I think about a document in a document database?",
      "pos": [
        916,
        975
      ]
    },
    {
      "content": "What is data modeling and why should I care?",
      "pos": [
        978,
        1022
      ]
    },
    {
      "content": "How is modeling data in a document database different to a relational database?",
      "pos": [
        1026,
        1105
      ]
    },
    {
      "content": "How do I express data relationships in a non-relational database?",
      "pos": [
        1108,
        1173
      ]
    },
    {
      "content": "When do I embed data and when do I link to data?",
      "pos": [
        1176,
        1224
      ]
    },
    {
      "content": "Embedding data",
      "pos": [
        1228,
        1242
      ]
    },
    {
      "content": "When you start modeling data in a document store, such as DocumentDB, try to treat your entities as <bpt id=\"p1\">**</bpt>self-contained documents<ept id=\"p1\">**</ept> represented in JSON.",
      "pos": [
        1245,
        1394
      ]
    },
    {
      "content": "Before we dive in too much further, let us take a few steps back and have a look at how we might model something in a relational database, a subject many of us are already familiar with.",
      "pos": [
        1396,
        1582
      ]
    },
    {
      "content": "The following example shows how a person might be stored in a relational database.",
      "pos": [
        1583,
        1665
      ]
    },
    {
      "content": "Relational database model",
      "pos": [
        1670,
        1695
      ]
    },
    {
      "content": "When working with relational databases, we've been taught for years to normalize, normalize, normalize.",
      "pos": [
        1758,
        1861
      ]
    },
    {
      "content": "Normalizing your data typically involves taking an entity, such as a person, and breaking it down in to discreet pieces of data.",
      "pos": [
        1863,
        1991
      ]
    },
    {
      "content": "In the example above, a person can have multiple contact detail records as well as multiple address records.",
      "pos": [
        1992,
        2100
      ]
    },
    {
      "content": "We even go one step further and break down contact details by further extracting common fields like a type.",
      "pos": [
        2101,
        2208
      ]
    },
    {
      "content": "Same for address, each record here has a type like <bpt id=\"p1\">*</bpt>Home<ept id=\"p1\">*</ept> or <bpt id=\"p2\">*</bpt>Business<ept id=\"p2\">*</ept>",
      "pos": [
        2209,
        2280
      ]
    },
    {
      "content": "The guiding premise when normalizing data is to <bpt id=\"p1\">**</bpt>avoid storing redundant data<ept id=\"p1\">**</ept> on each record and rather refer to data.",
      "pos": [
        2283,
        2404
      ]
    },
    {
      "content": "In this example, to read a person, with all their contact details and addresses, you need to use JOINS to effectively aggregate your data at run time.",
      "pos": [
        2405,
        2555
      ]
    },
    {
      "content": "Updating a single person with their contact details and addresses requires write operations across many individual tables.",
      "pos": [
        2774,
        2896
      ]
    },
    {
      "content": "Now let's take a look at how we would model the same data as a self-contained entity in a document database.",
      "pos": [
        2899,
        3007
      ]
    },
    {
      "content": "Using the approach above we have now <bpt id=\"p1\">**</bpt>denormalized<ept id=\"p1\">**</ept> the person record where we <bpt id=\"p2\">**</bpt>embedded<ept id=\"p2\">**</ept> all the information relating to this person, such as their contact details and addresses, in to a single JSON document.",
      "pos": [
        3504,
        3717
      ]
    },
    {
      "content": "In addition, because we're not confined to a fixed schema we have the flexibility to do things like having contact details of different shapes entirely.",
      "pos": [
        3718,
        3870
      ]
    },
    {
      "content": "Retrieving a complete person record from the database is now a single read operation against a single collection and for a single document.",
      "pos": [
        3873,
        4012
      ]
    },
    {
      "content": "Updating a person record, with their contact details and addresses, is also a single write operation against a single document.",
      "pos": [
        4013,
        4140
      ]
    },
    {
      "content": "By denormalizing data, your application may need to issue fewer queries and updates to complete common operations.",
      "pos": [
        4142,
        4256
      ]
    },
    {
      "content": "When to embed",
      "pos": [
        4262,
        4275
      ]
    },
    {
      "content": "In general, use embedded data models when:",
      "pos": [
        4277,
        4319
      ]
    },
    {
      "pos": [
        4323,
        4377
      ],
      "content": "There are <bpt id=\"p1\">**</bpt>contains<ept id=\"p1\">**</ept> relationships between entities."
    },
    {
      "pos": [
        4380,
        4436
      ],
      "content": "There are <bpt id=\"p1\">**</bpt>one-to-few<ept id=\"p1\">**</ept> relationships between entities."
    },
    {
      "pos": [
        4439,
        4492
      ],
      "content": "There is embedded data that <bpt id=\"p1\">**</bpt>changes infrequently<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4495,
        4547
      ],
      "content": "There is embedded data won't grow <bpt id=\"p1\">**</bpt>without bound<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4550,
        4616
      ],
      "content": "There is embedded data that is <bpt id=\"p1\">**</bpt>integral<ept id=\"p1\">**</ept> to data in a document."
    },
    {
      "pos": [
        4620,
        4704
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Typically denormalized data models provide better <bpt id=\"p1\">**</bpt>read<ept id=\"p1\">**</ept> performance."
    },
    {
      "content": "When not to embed",
      "pos": [
        4709,
        4726
      ]
    },
    {
      "content": "While the rule of thumb in a document database is to denormalize everything and embed all data in to a single document, this can lead to some situations that should be avoided.",
      "pos": [
        4728,
        4904
      ]
    },
    {
      "content": "Take this JSON snippet.",
      "pos": [
        4906,
        4929
      ]
    },
    {
      "content": "This might be what a post entity with embedded comments would look like if we were modeling a typical blog, or CMS, system.",
      "pos": [
        5559,
        5682
      ]
    },
    {
      "content": "The problem with this example is that the comments array is <bpt id=\"p1\">**</bpt>unbounded<ept id=\"p1\">**</ept>, meaning that there is no (practical) limit to the number of comments any single post can have.",
      "pos": [
        5683,
        5852
      ]
    },
    {
      "content": "This will become a problem as the size of the document could grow significantly.",
      "pos": [
        5853,
        5933
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.TIP]</ph> Documents in DocumentDB have a maximum size.",
      "pos": [
        5937,
        5993
      ]
    },
    {
      "content": "For more on this refer to <bpt id=\"p1\">[</bpt>DocumentDB limits<ept id=\"p1\">](documentdb-limits.md)</ept>.",
      "pos": [
        5994,
        6062
      ]
    },
    {
      "content": "As the size of the document grows the ability to transmit the data over the wire as well as reading and updating the document, at scale, will be impacted.",
      "pos": [
        6064,
        6218
      ]
    },
    {
      "content": "In this case it would be better to consider the following model.",
      "pos": [
        6220,
        6284
      ]
    },
    {
      "content": "This model has the three most recent comments embedded on the post itself, which is an array with a fixed bound this time.",
      "pos": [
        7261,
        7383
      ]
    },
    {
      "content": "The other comments are grouped in to batches of 100 comments and stored in separate documents.",
      "pos": [
        7384,
        7478
      ]
    },
    {
      "content": "The size of the batch was chosen as 100 because our fictitious application allows the user to load 100 comments at a time.",
      "pos": [
        7479,
        7601
      ]
    },
    {
      "content": "Another case where embedding data is not a good idea is when the embedded data is used often across documents and will change frequently.",
      "pos": [
        7605,
        7742
      ]
    },
    {
      "content": "Take this JSON snippet.",
      "pos": [
        7745,
        7768
      ]
    },
    {
      "content": "This could represent a person's stock portfolio.",
      "pos": [
        8190,
        8238
      ]
    },
    {
      "content": "We have chosen to embed the stock information in to each portfolio document.",
      "pos": [
        8239,
        8315
      ]
    },
    {
      "content": "In an environment where related data is changing frequently, like a stock trading application, embedding data that changes frequently is going to mean that you are constantly updating each portfolio document every time a stock is traded.",
      "pos": [
        8316,
        8553
      ]
    },
    {
      "content": "Stock <bpt id=\"p1\">*</bpt>zaza<ept id=\"p1\">*</ept> may be traded many hundreds of times in a single day and thousands of users could have <bpt id=\"p2\">*</bpt>zaza<ept id=\"p2\">*</ept> on their portfolio.",
      "pos": [
        8555,
        8681
      ]
    },
    {
      "content": "With a data model like the above we would have to update many thousands of portfolio documents many times every day leading to a system that won't scale very well.",
      "pos": [
        8682,
        8845
      ]
    },
    {
      "pos": [
        8850,
        8884
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"Refer\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Referencing data"
    },
    {
      "content": "So, embedding data works nicely for many cases but it is clear that there are scenarios when denormalizing your data will cause more problems than it is worth.",
      "pos": [
        8888,
        9047
      ]
    },
    {
      "content": "So what do we do now?",
      "pos": [
        9048,
        9069
      ]
    },
    {
      "content": "Relational databases are not the only place where you can create relationships between entities.",
      "pos": [
        9072,
        9168
      ]
    },
    {
      "content": "In a document database you can have information in one document that actually relates to data in other documents.",
      "pos": [
        9169,
        9282
      ]
    },
    {
      "content": "Now, I am not advocating for even one minute that we build systems that would be better suited to a relational database in DocumentDB, or any other document database, but simple relationships are fine and can be very useful.",
      "pos": [
        9283,
        9507
      ]
    },
    {
      "content": "In the JSON below we chose to use the example of a stock portfolio from earlier but this time we refer to the stock item on the portfolio instead of embedding it.",
      "pos": [
        9510,
        9672
      ]
    },
    {
      "content": "This way, when the stock item changes frequently throughout the day the only document that needs to be updated is the single stock document.",
      "pos": [
        9673,
        9813
      ]
    },
    {
      "content": "An immediate downside to this approach though is if your application is required to show information about each stock that is held when displaying a person's portfolio; in this case you would need to make multiple trips to the database to load the information for each stock document.",
      "pos": [
        10470,
        10754
      ]
    },
    {
      "content": "Here we've made a decision to improve the efficiency of write operations, which happen frequently throughout the day, but in turn compromised on the read operations that potentially have less impact on the performance of this particular system.",
      "pos": [
        10755,
        10999
      ]
    },
    {
      "pos": [
        11003,
        11086
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Normalized data models <bpt id=\"p1\">**</bpt>can require more round trips<ept id=\"p1\">**</ept> to the server."
    },
    {
      "content": "What about foreign keys?",
      "pos": [
        11092,
        11116
      ]
    },
    {
      "content": "Because there is currently no concept of a constraint, foreign-key or otherwise, any inter-document relationships that you have in documents are effectively \"weak links\" and will not be verified by the database itself.",
      "pos": [
        11117,
        11335
      ]
    },
    {
      "content": "If you want to ensure that the data a document is referring to actually exists, then you need to do this in your application, or through the use of server-side triggers or stored procedures on DocumentDB.",
      "pos": [
        11336,
        11540
      ]
    },
    {
      "content": "When to reference",
      "pos": [
        11545,
        11562
      ]
    },
    {
      "content": "In general, use normalized data models when:",
      "pos": [
        11563,
        11607
      ]
    },
    {
      "pos": [
        11611,
        11654
      ],
      "content": "Representing <bpt id=\"p1\">**</bpt>one-to-many<ept id=\"p1\">**</ept> relationships."
    },
    {
      "pos": [
        11657,
        11701
      ],
      "content": "Representing <bpt id=\"p1\">**</bpt>many-to-many<ept id=\"p1\">**</ept> relationships."
    },
    {
      "pos": [
        11704,
        11740
      ],
      "content": "Related data <bpt id=\"p1\">**</bpt>changes frequently<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        11743,
        11782
      ],
      "content": "Referenced data could be <bpt id=\"p1\">**</bpt>unbounded<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        11786,
        11859
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Typically normalizing provides better <bpt id=\"p1\">**</bpt>write<ept id=\"p1\">**</ept> performance."
    },
    {
      "content": "Where do I put the relationship?",
      "pos": [
        11864,
        11896
      ]
    },
    {
      "content": "The growth of the relationship will help determine in which document to store the reference.",
      "pos": [
        11897,
        11989
      ]
    },
    {
      "content": "If we look at the JSON below that models publishers and books.",
      "pos": [
        11991,
        12053
      ]
    },
    {
      "content": "If the number of the books per publisher is small with limited growth, then storing the book reference inside the publisher document may be useful.",
      "pos": [
        12516,
        12663
      ]
    },
    {
      "content": "However, if the number of books per publisher is unbounded, then this data model would lead to mutable, growing arrays, as in the example publisher document above.",
      "pos": [
        12664,
        12827
      ]
    },
    {
      "content": "Switching things around a bit would result in a model that still represents the same data but now avoids these large mutable collections.",
      "pos": [
        12830,
        12967
      ]
    },
    {
      "content": "In the above example, we have dropped the unbounded collection on the publisher document.",
      "pos": [
        13460,
        13549
      ]
    },
    {
      "content": "Instead we just have a a reference to the publisher on each book document.",
      "pos": [
        13550,
        13624
      ]
    },
    {
      "content": "How do I model many:many relationships?",
      "pos": [
        13629,
        13668
      ]
    },
    {
      "content": "In a relational database <bpt id=\"p1\">*</bpt>many:many<ept id=\"p1\">*</ept> relationships are often modeled with join tables, which just join records from other tables together.",
      "pos": [
        13669,
        13807
      ]
    },
    {
      "content": "Join tables",
      "pos": [
        13812,
        13823
      ]
    },
    {
      "content": "You might be tempted to replicate the same thing using documents and produce a data model that looks similar to the following.",
      "pos": [
        13875,
        14001
      ]
    },
    {
      "content": "This would work.",
      "pos": [
        14576,
        14592
      ]
    },
    {
      "content": "However, loading either an author with their books, or loading a book with its author, would always require at least two additional queries against the database.",
      "pos": [
        14593,
        14754
      ]
    },
    {
      "content": "One query to the joining document and then another query to fetch the actual document being joined.",
      "pos": [
        14755,
        14854
      ]
    },
    {
      "content": "If all this join table is doing is gluing together two pieces of data, then why not drop it completely?",
      "pos": [
        14857,
        14960
      ]
    },
    {
      "content": "Consider the following.",
      "pos": [
        14961,
        14984
      ]
    },
    {
      "content": "Now, if I had an author, I immediately know which books they have written, and conversely if I had a book document loaded I would know the ids of the author(s).",
      "pos": [
        15421,
        15581
      ]
    },
    {
      "content": "This saves that intermediary query against the join table reducing the number of server round trips your application has to make.",
      "pos": [
        15582,
        15711
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"WrapUp\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Hybrid data models",
      "pos": [
        15716,
        15753
      ]
    },
    {
      "content": "We've now looked embedding (or denormalizing) and referencing (or normalizing) data, each have their upsides and each have compromises as we have seen.",
      "pos": [
        15756,
        15907
      ]
    },
    {
      "content": "It doesn't always have to be either or, don't be scared to mix things up a little.",
      "pos": [
        15910,
        15992
      ]
    },
    {
      "content": "Based on your application's specific usage patterns and workloads there may be cases where mixing embedded and referenced data makes sense and could lead to simpler application logic with fewer server round trips while still maintaining a good level of performance.",
      "pos": [
        15995,
        16260
      ]
    },
    {
      "content": "Consider the following JSON.",
      "pos": [
        16262,
        16290
      ]
    },
    {
      "content": "Here we've (mostly) followed the embedded model, where data from other entities are embedded in the top-level document, but other data is referenced.",
      "pos": [
        17328,
        17477
      ]
    },
    {
      "content": "If you look at the book document, we can see a few interesting fields when we look at the array of authors.",
      "pos": [
        17480,
        17587
      ]
    },
    {
      "content": "There is an <bpt id=\"p1\">*</bpt>id<ept id=\"p1\">*</ept> field which is the field we use to refer back to an author document, standard practice in a normalized model, but then we also have <bpt id=\"p2\">*</bpt>name<ept id=\"p2\">*</ept> and <bpt id=\"p3\">*</bpt>thumbnailUrl<ept id=\"p3\">*</ept>.",
      "pos": [
        17588,
        17763
      ]
    },
    {
      "content": "We could've just stuck with <bpt id=\"p1\">*</bpt>id<ept id=\"p1\">*</ept> and left the application to get any additional information it needed from the respective author document using the \"link\", but because our application displays the author's name and a thumbnail picture with every book displayed we can save a round trip to the server per book in a list by denormalizing <bpt id=\"p2\">**</bpt>some<ept id=\"p2\">**</ept> data from the author.",
      "pos": [
        17764,
        18130
      ]
    },
    {
      "content": "Sure, if the author's name changed or they wanted to update their photo we'd have to go an update every book they ever published but for our application, based on the assumption that authors don't change their names very often, this is an acceptable design decision.",
      "pos": [
        18132,
        18398
      ]
    },
    {
      "content": "In the example there are <bpt id=\"p1\">**</bpt>pre-calculated aggregates<ept id=\"p1\">**</ept> values to save expensive processing on a read operation.",
      "pos": [
        18402,
        18513
      ]
    },
    {
      "content": "In the example, some of the data embedded in the author document is data that is calculated at run-time.",
      "pos": [
        18514,
        18618
      ]
    },
    {
      "content": "Every time a new book is published, a book document is created <bpt id=\"p1\">**</bpt>and<ept id=\"p1\">**</ept> the countOfBooks field is set to a calculated value based on the number of book documents that exist for a particular author.",
      "pos": [
        18619,
        18815
      ]
    },
    {
      "content": "This optimization would be good in read heavy systems where we can afford to do computations on writes in order to optimize reads.",
      "pos": [
        18816,
        18946
      ]
    },
    {
      "content": "The ability to have a model with pre-calculated fields is made possible because DocumentDB supports <bpt id=\"p1\">**</bpt>multi-document transactions<ept id=\"p1\">**</ept>.",
      "pos": [
        18948,
        19080
      ]
    },
    {
      "content": "Many NoSQL stores cannot do transactions across documents and therefore advocate design decisions, such as \"always embed everything\", due to this limitation.",
      "pos": [
        19081,
        19238
      ]
    },
    {
      "content": "With DocumentDB, you can use server-side triggers, or stored procedures, that insert books and update authors all within an ACID transaction.",
      "pos": [
        19239,
        19380
      ]
    },
    {
      "content": "Now you don't <bpt id=\"p1\">**</bpt>have<ept id=\"p1\">**</ept> to embed everything in to one document just to be sure that your data remains consistent.",
      "pos": [
        19381,
        19493
      ]
    },
    {
      "pos": [
        19497,
        19531
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"NextSteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Next steps"
    },
    {
      "content": "The biggest takeaways from this article is to understand that data modeling in a schema-free world is just as important as ever.",
      "pos": [
        19533,
        19661
      ]
    },
    {
      "content": "Just as there is no single way to represent a piece of data on a screen, there is no single way to model your data.",
      "pos": [
        19664,
        19779
      ]
    },
    {
      "content": "You need to understand your application and how it will produce, consume, and process the data.",
      "pos": [
        19780,
        19875
      ]
    },
    {
      "content": "Then, by applying some of the guidelines presented here you can set about creating a model that addresses the immediate needs of your application.",
      "pos": [
        19876,
        20022
      ]
    },
    {
      "content": "When your applications need to change, you can leverage the flexibility of a schema-free database to embrace that change and evolve your data model easily.",
      "pos": [
        20023,
        20178
      ]
    },
    {
      "pos": [
        20181,
        20292
      ],
      "content": "To learn more about Azure DocumentDB, refer to the service’s <bpt id=\"p1\">[</bpt>documentation<ept id=\"p1\">]( ../../services/documentdb/)</ept> page."
    },
    {
      "pos": [
        20295,
        20423
      ],
      "content": "To learn about tuning indexes in Azure DocumentDB, refer to the article on <bpt id=\"p1\">[</bpt>indexing policies<ept id=\"p1\">](documentdb-indexing-policies.md)</ept>."
    },
    {
      "pos": [
        20425,
        20563
      ],
      "content": "To understand how to shard your data across multiple partitions, refer to <bpt id=\"p1\">[</bpt>Partitioning Data in DocumentDB<ept id=\"p1\">](documentdb-partition-data.md)</ept>."
    },
    {
      "pos": [
        20566,
        20837
      ],
      "content": "And finally, for guidance on data modeling and sharding for multi-tenant applications, consult <bpt id=\"p1\">[</bpt>Scaling a Multi-Tenant Application with Azure DocumentDB<ept id=\"p1\">](http://blogs.msdn.com/b/documentdb/archive/2014/12/03/scaling-a-multi-tenant-application-with-azure-documentdb.aspx)</ept>."
    },
    {
      "content": "test",
      "pos": [
        20841,
        20845
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Modeling data in Azure DocumentDB | Microsoft Azure\" \n    description=\"Learn how to model data for a NoSQL document database like Azure DocumentDB.\" \n    services=\"documentdb\" \n    authors=\"ryancrawcour\" \n    manager=\"jhubbard\" \n    editor=\"mimig1\" \n    documentationCenter=\"\"/>\n\n<tags \n    ms.service=\"documentdb\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"08/24/2015\" \n    ms.author=\"ryancraw\"/>\n\n#Modeling data in DocumentDB#\nWhile schema-free databases, like DocumentDB, make it super easy to embrace changes to your data model you should still spend some time thinking about your data. \n\nHow is data going to be stored? How is your application going to retrieve and query data? Is your application read heavy, or write heavy?\n\nAfter reading this article, you will be able to answer the following questions:\n\n- How should I think about a document in a document database?\n- What is data modeling and why should I care? \n- How is modeling data in a document database different to a relational database?\n- How do I express data relationships in a non-relational database?\n- When do I embed data and when do I link to data?\n\n##Embedding data##\nWhen you start modeling data in a document store, such as DocumentDB, try to treat your entities as **self-contained documents** represented in JSON.\n\nBefore we dive in too much further, let us take a few steps back and have a look at how we might model something in a relational database, a subject many of us are already familiar with. The following example shows how a person might be stored in a relational database. \n\n![Relational database model](./media/documentdb-modeling-data/relational-data-model.png)\n\nWhen working with relational databases, we've been taught for years to normalize, normalize, normalize.\n\nNormalizing your data typically involves taking an entity, such as a person, and breaking it down in to discreet pieces of data. In the example above, a person can have multiple contact detail records as well as multiple address records. We even go one step further and break down contact details by further extracting common fields like a type. Same for address, each record here has a type like *Home* or *Business* \n\nThe guiding premise when normalizing data is to **avoid storing redundant data** on each record and rather refer to data. In this example, to read a person, with all their contact details and addresses, you need to use JOINS to effectively aggregate your data at run time.\n\n    SELECT p.FirstName, p.LastName, a.City, cd.Detail\n    FROM Person p\n    JOIN ContactDetail cd ON cd.PersonId = p.Id\n    JOIN ContactDetailType on cdt ON cdt.Id = cd.TypeId\n    JOIN Address a ON a.PersonId = p.Id\n\nUpdating a single person with their contact details and addresses requires write operations across many individual tables. \n\nNow let's take a look at how we would model the same data as a self-contained entity in a document database.\n        \n    {\n        \"id\": \"1\",\n        \"firstName\": \"Thomas\",\n        \"lastName\": \"Andersen\",\n        \"addresses\": [\n            {            \n                \"line1\": \"100 Some Street\",\n                \"line2\": \"Unit 1\",\n                \"city\": \"Seattle\",\n                \"state\": \"WA\",\n                \"zip\": 98012\n            }\n        ],\n        \"contactDetails\": [\n            {\"email: \"thomas@andersen.com\"},\n            {\"phone\": \"+1 555 555-5555\", \"extension\": 5555}\n        ] \n    }\n\nUsing the approach above we have now **denormalized** the person record where we **embedded** all the information relating to this person, such as their contact details and addresses, in to a single JSON document.\nIn addition, because we're not confined to a fixed schema we have the flexibility to do things like having contact details of different shapes entirely. \n\nRetrieving a complete person record from the database is now a single read operation against a single collection and for a single document. Updating a person record, with their contact details and addresses, is also a single write operation against a single document.\n\nBy denormalizing data, your application may need to issue fewer queries and updates to complete common operations. \n\n###When to embed\n\nIn general, use embedded data models when:\n\n- There are **contains** relationships between entities.\n- There are **one-to-few** relationships between entities.\n- There is embedded data that **changes infrequently**.\n- There is embedded data won't grow **without bound**.\n- There is embedded data that is **integral** to data in a document.\n\n> [AZURE.NOTE] Typically denormalized data models provide better **read** performance.\n\n###When not to embed\n\nWhile the rule of thumb in a document database is to denormalize everything and embed all data in to a single document, this can lead to some situations that should be avoided.\n\nTake this JSON snippet.\n\n    {\n        \"id\": \"1\",\n        \"name\": \"What's new in the coolest Cloud\",\n        \"summary\": \"A blog post by someone real famous\",\n        \"comments\": [\n            {\"id\": 1, \"author\": \"anon\", \"comment\": \"something useful, I'm sure\"},\n            {\"id\": 2, \"author\": \"bob\", \"comment\": \"wisdom from the interwebs\"},\n            …\n            {\"id\": 100001, \"author\": \"jane\", \"comment\": \"and on we go ...\"},\n            …\n            {\"id\": 1000000001, \"author\": \"angry\", \"comment\": \"blah angry blah angry\"},\n            …\n            {\"id\": ∞ + 1, \"author\": \"bored\", \"comment\": \"oh man, will this ever end?\"},\n        ]\n    }\n\nThis might be what a post entity with embedded comments would look like if we were modeling a typical blog, or CMS, system. The problem with this example is that the comments array is **unbounded**, meaning that there is no (practical) limit to the number of comments any single post can have. This will become a problem as the size of the document could grow significantly.\n\n> [AZURE.TIP] Documents in DocumentDB have a maximum size. For more on this refer to [DocumentDB limits](documentdb-limits.md).\n\nAs the size of the document grows the ability to transmit the data over the wire as well as reading and updating the document, at scale, will be impacted.\n\nIn this case it would be better to consider the following model.\n        \n    Post document:\n    {\n        \"id\": 1,\n        \"name\": \"What's new in the coolest Cloud\",\n        \"summary\": \"A blog post by someone real famous\",\n        \"recentComments\": [\n            {\"id\": 1, \"author\": \"anon\", \"comment\": \"something useful, I'm sure\"},\n            {\"id\": 2, \"author\": \"bob\", \"comment\": \"wisdom from the interwebs\"},\n            {\"id\": 3, \"author\": \"jane\", \"comment\": \".....\"}\n        ]\n    }\n\n    Comment documents:\n    {\n        \"postId\": 1\n        \"comments\": [\n            {\"id\": 4, \"author\": \"anon\", \"comment\": \"more goodness\"},\n            {\"id\": 5, \"author\": \"bob\", \"comment\": \"tails from the field\"},\n            ...\n            {\"id\": 99, \"author\": \"angry\", \"comment\": \"blah angry blah angry\"}\n        ]\n    },\n    {\n        \"postId\": 1\n        \"comments\": [\n            {\"id\": 100, \"author\": \"anon\", \"comment\": \"yet more\"},\n            ...\n            {\"id\": 199, \"author\": \"bored\", \"comment\": \"will this ever end?\"}\n        ]\n    }\n\nThis model has the three most recent comments embedded on the post itself, which is an array with a fixed bound this time. The other comments are grouped in to batches of 100 comments and stored in separate documents. The size of the batch was chosen as 100 because our fictitious application allows the user to load 100 comments at a time.  \n\nAnother case where embedding data is not a good idea is when the embedded data is used often across documents and will change frequently. \n\nTake this JSON snippet.\n\n    {\n        \"id\": \"1\",\n        \"firstName\": \"Thomas\",\n        \"lastName\": \"Andersen\",\n        \"holdings\": [\n            {\n                \"numberHeld\": 100,\n                \"stock\": { \"symbol\": \"zaza\", \"open\": 1, \"high\": 2, \"low\": 0.5 }\n            },\n            {\n                \"numberHeld\": 50,\n                \"stock\": { \"symbol\": \"xcxc\", \"open\": 89, \"high\": 93.24, \"low\": 88.87 }\n            }\n        ]\n    }\n\nThis could represent a person's stock portfolio. We have chosen to embed the stock information in to each portfolio document. In an environment where related data is changing frequently, like a stock trading application, embedding data that changes frequently is going to mean that you are constantly updating each portfolio document every time a stock is traded.\n\nStock *zaza* may be traded many hundreds of times in a single day and thousands of users could have *zaza* on their portfolio. With a data model like the above we would have to update many thousands of portfolio documents many times every day leading to a system that won't scale very well. \n\n##<a id=\"Refer\"></a>Referencing data##\n\nSo, embedding data works nicely for many cases but it is clear that there are scenarios when denormalizing your data will cause more problems than it is worth. So what do we do now? \n\nRelational databases are not the only place where you can create relationships between entities. In a document database you can have information in one document that actually relates to data in other documents. Now, I am not advocating for even one minute that we build systems that would be better suited to a relational database in DocumentDB, or any other document database, but simple relationships are fine and can be very useful. \n\nIn the JSON below we chose to use the example of a stock portfolio from earlier but this time we refer to the stock item on the portfolio instead of embedding it. This way, when the stock item changes frequently throughout the day the only document that needs to be updated is the single stock document. \n\n    Person document:\n    {\n        \"id\": \"1\",\n        \"firstName\": \"Thomas\",\n        \"lastName\": \"Andersen\",\n        \"holdings\": [\n            { \"numberHeld\":  100, \"stockId\": 1},\n            { \"numberHeld\":  50, \"stockId\": 2}\n        ]\n    }\n    \n    Stock documents:\n    {\n        \"id\": 1,\n        \"symbol\": \"zaza\",\n        \"open\": 1,\n        \"high\": 2,\n        \"low\": 0.5,\n        \"vol\": 11970000,\n        \"mkt-cap\": 42000000,\n        \"pe\": 5.89\n    },\n    {\n        \"id\": 2,\n        \"symbol\": \"xcxc\",\n        \"open\": 89,\n        \"high\": 93.24,\n        \"low\": 88.87,\n        \"vol\": 2970200,\n        \"mkt-cap\": 1005000,\n        \"pe\": 75.82\n    }\n    \n\nAn immediate downside to this approach though is if your application is required to show information about each stock that is held when displaying a person's portfolio; in this case you would need to make multiple trips to the database to load the information for each stock document. Here we've made a decision to improve the efficiency of write operations, which happen frequently throughout the day, but in turn compromised on the read operations that potentially have less impact on the performance of this particular system.\n\n> [AZURE.NOTE] Normalized data models **can require more round trips** to the server.\n\n### What about foreign keys?\nBecause there is currently no concept of a constraint, foreign-key or otherwise, any inter-document relationships that you have in documents are effectively \"weak links\" and will not be verified by the database itself. If you want to ensure that the data a document is referring to actually exists, then you need to do this in your application, or through the use of server-side triggers or stored procedures on DocumentDB.\n\n###When to reference\nIn general, use normalized data models when:\n\n- Representing **one-to-many** relationships.\n- Representing **many-to-many** relationships.\n- Related data **changes frequently**.\n- Referenced data could be **unbounded**.\n\n> [AZURE.NOTE] Typically normalizing provides better **write** performance.\n\n###Where do I put the relationship?\nThe growth of the relationship will help determine in which document to store the reference.\n\nIf we look at the JSON below that models publishers and books.\n\n    Publisher document:\n    {\n        \"id\": \"mspress\",\n        \"name\": \"Microsoft Press\",\n        \"books\": [ 1, 2, 3, ..., 100, ..., 1000]\n    }\n\n    Book documents:\n    {\"id\": 1, \"name\": \"DocumentDB 101\" }\n    {\"id\": 2, \"name\": \"DocumentDB for RDBMS Users\" }\n    {\"id\": 3, \"name\": \"Taking over the world one JSON doc at a time\" }\n    ...\n    {\"id\": 100, \"name\": \"Learn about Azure DocumentDB\" }\n    ...\n    {\"id\": 1000, \"name\": \"Deep Dive in to DocumentDB\" }\n\nIf the number of the books per publisher is small with limited growth, then storing the book reference inside the publisher document may be useful. However, if the number of books per publisher is unbounded, then this data model would lead to mutable, growing arrays, as in the example publisher document above. \n\nSwitching things around a bit would result in a model that still represents the same data but now avoids these large mutable collections.\n\n    Publisher document: \n    {\n        \"id\": \"mspress\",\n        \"name\": \"Microsoft Press\"\n    }\n    \n    Book documents: \n    {\"id\": 1,\"name\": \"DocumentDB 101\", \"pub-id\": \"mspress\"}\n    {\"id\": 2,\"name\": \"DocumentDB for RDBMS Users\", \"pub-id\": \"mspress\"}\n    {\"id\": 3,\"name\": \"Taking over the world one JSON doc at a time\"}\n    ...\n    {\"id\": 100,\"name\": \"Learn about Azure DocumentDB\", \"pub-id\": \"mspress\"}\n    ...\n    {\"id\": 1000,\"name\": \"Deep Dive in to DocumentDB\", \"pub-id\": \"mspress\"}\n\nIn the above example, we have dropped the unbounded collection on the publisher document. Instead we just have a a reference to the publisher on each book document.\n\n###How do I model many:many relationships?\nIn a relational database *many:many* relationships are often modeled with join tables, which just join records from other tables together. \n\n![Join tables](./media/documentdb-modeling-data/join-table.png)\n\nYou might be tempted to replicate the same thing using documents and produce a data model that looks similar to the following.\n\n    Author documents: \n    {\"id\": 1, \"name\": \"Thomas Andersen\" }\n    {\"id\": 2, \"name\": \"William Wakefield\" }\n    \n    Book documents:\n    {\"id\": 1, \"name\": \"DocumentDB 101\" }\n    {\"id\": 2, \"name\": \"DocumentDB for RDBMS Users\" }\n    {\"id\": 3, \"name\": \"Taking over the world one JSON doc at a time\" }\n    {\"id\": 4, \"name\": \"Learn about Azure DocumentDB\" }\n    {\"id\": 5, \"name\": \"Deep Dive in to DocumentDB\" }\n    \n    Joining documents: \n    {\"authorId\": 1, \"bookId\": 1 }\n    {\"authorId\": 2, \"bookId\": 1 }\n    {\"authorId\": 1, \"bookId\": 2 }\n    {\"authorId\": 1, \"bookId\": 3 }\n\nThis would work. However, loading either an author with their books, or loading a book with its author, would always require at least two additional queries against the database. One query to the joining document and then another query to fetch the actual document being joined. \n\nIf all this join table is doing is gluing together two pieces of data, then why not drop it completely?\nConsider the following.\n\n    Author documents:\n    {\"id\": 1, \"name\": \"Thomas Andersen\", \"books\": [1, 2, 3]}\n    {\"id\": 2, \"name\": \"William Wakefield\", \"books\": [1, 4]}\n    \n    Book documents: \n    {\"id\": 1, \"name\": \"DocumentDB 101\", \"authors\": [1, 2]}\n    {\"id\": 2, \"name\": \"DocumentDB for RDBMS Users\", \"authors\": [1]}\n    {\"id\": 3, \"name\": \"Learn about Azure DocumentDB\", \"authors\": [1]}\n    {\"id\": 4, \"name\": \"Deep Dive in to DocumentDB\", \"authors\": [2]}\n\nNow, if I had an author, I immediately know which books they have written, and conversely if I had a book document loaded I would know the ids of the author(s). This saves that intermediary query against the join table reducing the number of server round trips your application has to make. \n\n##<a id=\"WrapUp\"></a>Hybrid data models##\nWe've now looked embedding (or denormalizing) and referencing (or normalizing) data, each have their upsides and each have compromises as we have seen. \n\nIt doesn't always have to be either or, don't be scared to mix things up a little. \n\nBased on your application's specific usage patterns and workloads there may be cases where mixing embedded and referenced data makes sense and could lead to simpler application logic with fewer server round trips while still maintaining a good level of performance.\n\nConsider the following JSON. \n\n    Author documents: \n    {\n        \"id\": 1,\n        \"firstName\": \"Thomas\",\n        \"lastName\": \"Andersen\",     \n        \"countOfBooks\": 3,\n        \"books\": [1, 2, 3],\n        \"images\": [\n            {\"thumbnail\": \"http://....png\"}\n            {\"profile\": \"http://....png\"}\n            {\"large\": \"http://....png\"}\n        ]\n    },\n    {\n        \"id\": 2,\n        \"firstName\": \"William\",\n        \"lastName\": \"Wakefield\",\n        \"countOfBooks\": 1,\n        \"books\": [1, 4, 5],\n        \"images\": [\n            {\"thumbnail\": \"http://....png\"}\n        ]\n    }\n    \n    Book documents:\n    {\n        \"id\": 1,\n        \"name\": \"DocumentDB 101\",\n        \"authors\": [\n            {\"id\": 1, \"name\": \"Thomas Andersen\", \"thumbnailUrl\": \"http://....png\"},\n            {\"id\": 2, \"name\": \"William Wakefield\", \"thumbnailUrl\": \"http://....png\"}\n        ]\n    },\n    {\n        \"id\": 2,\n        \"name\": \"DocumentDB for RDBMS Users\",\n        \"authors\": [\n            {\"id\": 1, \"name\": \"Thomas Andersen\", \"thumbnailUrl\": \"http://....png\"},\n        ]\n    }\n\nHere we've (mostly) followed the embedded model, where data from other entities are embedded in the top-level document, but other data is referenced. \n\nIf you look at the book document, we can see a few interesting fields when we look at the array of authors. There is an *id* field which is the field we use to refer back to an author document, standard practice in a normalized model, but then we also have *name* and *thumbnailUrl*. We could've just stuck with *id* and left the application to get any additional information it needed from the respective author document using the \"link\", but because our application displays the author's name and a thumbnail picture with every book displayed we can save a round trip to the server per book in a list by denormalizing **some** data from the author.\n\nSure, if the author's name changed or they wanted to update their photo we'd have to go an update every book they ever published but for our application, based on the assumption that authors don't change their names very often, this is an acceptable design decision.  \n\nIn the example there are **pre-calculated aggregates** values to save expensive processing on a read operation. In the example, some of the data embedded in the author document is data that is calculated at run-time. Every time a new book is published, a book document is created **and** the countOfBooks field is set to a calculated value based on the number of book documents that exist for a particular author. This optimization would be good in read heavy systems where we can afford to do computations on writes in order to optimize reads.\n\nThe ability to have a model with pre-calculated fields is made possible because DocumentDB supports **multi-document transactions**. Many NoSQL stores cannot do transactions across documents and therefore advocate design decisions, such as \"always embed everything\", due to this limitation. With DocumentDB, you can use server-side triggers, or stored procedures, that insert books and update authors all within an ACID transaction. Now you don't **have** to embed everything in to one document just to be sure that your data remains consistent.\n\n##<a name=\"NextSteps\"></a>Next steps\n\nThe biggest takeaways from this article is to understand that data modeling in a schema-free world is just as important as ever. \n\nJust as there is no single way to represent a piece of data on a screen, there is no single way to model your data. You need to understand your application and how it will produce, consume, and process the data. Then, by applying some of the guidelines presented here you can set about creating a model that addresses the immediate needs of your application. When your applications need to change, you can leverage the flexibility of a schema-free database to embrace that change and evolve your data model easily. \n\nTo learn more about Azure DocumentDB, refer to the service’s [documentation]( ../../services/documentdb/) page. \n\nTo learn about tuning indexes in Azure DocumentDB, refer to the article on [indexing policies](documentdb-indexing-policies.md).\n\nTo understand how to shard your data across multiple partitions, refer to [Partitioning Data in DocumentDB](documentdb-partition-data.md). \n\nAnd finally, for guidance on data modeling and sharding for multi-tenant applications, consult [Scaling a Multi-Tenant Application with Azure DocumentDB](http://blogs.msdn.com/b/documentdb/archive/2014/12/03/scaling-a-multi-tenant-application-with-azure-documentdb.aspx).\n \n\ntest\n"
}