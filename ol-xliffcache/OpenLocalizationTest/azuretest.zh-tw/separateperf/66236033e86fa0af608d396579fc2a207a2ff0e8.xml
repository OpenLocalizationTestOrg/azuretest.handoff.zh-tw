{
  "nodes": [
    {
      "content": "Generate recommendations using Mahout and Hadoop | Microsoft Azure",
      "pos": [
        27,
        93
      ]
    },
    {
      "content": "Learn how to use the Apache Mahout machine learning library to generate movie recommendations with HDInsight (Hadoop).",
      "pos": [
        112,
        230
      ]
    },
    {
      "content": "Generate movie recommendations by using Apache Mahout with Hadoop in HDInsight",
      "pos": [
        559,
        637
      ]
    },
    {
      "pos": [
        719,
        862
      ],
      "content": "Learn how to use the <bpt id=\"p1\">[</bpt>Apache Mahout<ept id=\"p1\">](http://mahout.apache.org)</ept> machine learning library with Azure HDInsight to generate movie recommendations."
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The steps in this document require a Windows client and a Windows-based HDInsight cluster.",
      "pos": [
        866,
        969
      ]
    },
    {
      "content": "For information on using Mahout from a Linux, OS X, or Unix client, with a Linux-based HDInsight cluster, see <bpt id=\"p1\">[</bpt>Generate movie recommendations by using Apache Mahout with Linux-based Hadoop in HDInsight<ept id=\"p1\">](hdinsight-hadoop-mahout-linux-mac.md)</ept>",
      "pos": [
        970,
        1210
      ]
    },
    {
      "pos": [
        1215,
        1254
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"learn\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>What you will learn"
    },
    {
      "content": "Mahout is a <bpt id=\"p1\">[</bpt>machine learning<ept id=\"p1\">][ml]</ept> library for Apache Hadoop.",
      "pos": [
        1256,
        1317
      ]
    },
    {
      "content": "Mahout contains algorithms for processing data, such as filtering, classification, and clustering.",
      "pos": [
        1318,
        1416
      ]
    },
    {
      "content": "In this article, you will use a recommendation engine to generate movie recommendations that are based on movies your friends have seen.",
      "pos": [
        1417,
        1553
      ]
    },
    {
      "content": "You will also learn how to perform classifications with a decision forest.",
      "pos": [
        1554,
        1628
      ]
    },
    {
      "content": "This will teach you the following:",
      "pos": [
        1629,
        1663
      ]
    },
    {
      "content": "How to run Mahout jobs by using Windows PowerShell",
      "pos": [
        1667,
        1717
      ]
    },
    {
      "content": "How to run Mahout jobs from the Hadoop command line",
      "pos": [
        1721,
        1772
      ]
    },
    {
      "content": "How to install Mahout on HDInsight 3.0 and HDInsight 2.0 clusters",
      "pos": [
        1776,
        1841
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Mahout is provided with the HDInsight 3.1 version of the clusters.",
      "pos": [
        1849,
        1928
      ]
    },
    {
      "content": "If you are using an earlier version of HDInsight, see <bpt id=\"p1\">[</bpt>Install Mahout<ept id=\"p1\">](#install)</ept> before you continue.",
      "pos": [
        1929,
        2030
      ]
    },
    {
      "content": "prerequisites",
      "pos": [
        2034,
        2047
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>An Windows-based Hadoop cluster in HDInsight<ept id=\"p1\">**</ept>.",
      "pos": [
        2051,
        2100
      ]
    },
    {
      "content": "For information about creating one, see <bpt id=\"p1\">[</bpt>Get started using Hadoop in HDInsight<ept id=\"p1\">][getstarted]</ept>",
      "pos": [
        2101,
        2192
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>A workstation with Azure PowerShell<ept id=\"p1\">**</ept>.",
      "pos": [
        2196,
        2236
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Install and use Azure PowerShell<ept id=\"p1\">](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.",
      "pos": [
        2237,
        2359
      ]
    },
    {
      "pos": [
        2364,
        2446
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"recommendations\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Generate recommendations by using Windows PowerShell"
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Although the job used in this section works by using Windows PowerShell, many of the classes provided with Mahout do not currently work with Windows PowerShell, and they must be run by using the Hadoop command line.",
      "pos": [
        2450,
        2678
      ]
    },
    {
      "content": "For a list of classes that do not work with Windows PowerShell, see the <bpt id=\"p1\">[</bpt>Troubleshooting<ept id=\"p1\">](#troubleshooting)</ept> section.",
      "pos": [
        2679,
        2795
      ]
    },
    {
      "pos": [
        2800,
        2932
      ],
      "content": "For an example of using the Hadoop command line to run Mahout jobs, see <bpt id=\"p1\">[</bpt>Classify data by using the Hadoop command line<ept id=\"p1\">](#classify)</ept>."
    },
    {
      "content": "One of the functions that is provided by Mahout is a recommendation engine.",
      "pos": [
        2934,
        3009
      ]
    },
    {
      "content": "This engine accepts data in the format of <ph id=\"ph1\">`userID`</ph>, <ph id=\"ph2\">`itemId`</ph>, and <ph id=\"ph3\">`prefValue`</ph> (the users preference for the item).",
      "pos": [
        3010,
        3124
      ]
    },
    {
      "content": "Mahout can then perform co-occurance analysis to determine: <bpt id=\"p1\">_</bpt>users who have a preference for an item also have a preference for these other items<ept id=\"p1\">_</ept>.",
      "pos": [
        3125,
        3272
      ]
    },
    {
      "content": "Mahout then determines users with like-item preferences, which can be used to make recommendations.",
      "pos": [
        3273,
        3372
      ]
    },
    {
      "content": "The following is an extremely simple example that uses movies:",
      "pos": [
        3374,
        3436
      ]
    },
    {
      "content": "<bpt id=\"p1\">__</bpt>Co-occurance<ept id=\"p1\">__</ept>: Joe, Alice, and Bob all liked <bpt id=\"p2\">_</bpt>Star Wars<ept id=\"p2\">_</ept>, <bpt id=\"p3\">_</bpt>The Empire Strikes Back<ept id=\"p3\">_</ept>, and <bpt id=\"p4\">_</bpt>Return of the Jedi<ept id=\"p4\">_</ept>.",
      "pos": [
        3440,
        3553
      ]
    },
    {
      "content": "Mahout determines that users who like any one of these movies also like the other two.",
      "pos": [
        3554,
        3640
      ]
    },
    {
      "content": "<bpt id=\"p1\">__</bpt>Co-occurance<ept id=\"p1\">__</ept>: Bob and Alice also liked <bpt id=\"p2\">_</bpt>The Phantom Menace<ept id=\"p2\">_</ept>, <bpt id=\"p3\">_</bpt>Attack of the Clones<ept id=\"p3\">_</ept>, and <bpt id=\"p4\">_</bpt>Revenge of the Sith<ept id=\"p4\">_</ept>.",
      "pos": [
        3644,
        3759
      ]
    },
    {
      "content": "Mahout determines that users who liked the previous three movies also like these three.",
      "pos": [
        3760,
        3847
      ]
    },
    {
      "content": "<bpt id=\"p1\">__</bpt>Similarity recommendation<ept id=\"p1\">__</ept>: Because Joe liked the first three movies, Mahout looks at movies that others with similar preferences liked, but Joe has not watched (liked/rated).",
      "pos": [
        3851,
        4029
      ]
    },
    {
      "content": "In this case, Mahout recommends <bpt id=\"p1\">_</bpt>The Phantom Menace<ept id=\"p1\">_</ept>, <bpt id=\"p2\">_</bpt>Attack of the Clones<ept id=\"p2\">_</ept>, and <bpt id=\"p3\">_</bpt>Revenge of the Sith<ept id=\"p3\">_</ept>.",
      "pos": [
        4030,
        4134
      ]
    },
    {
      "content": "Load the data",
      "pos": [
        4139,
        4152
      ]
    },
    {
      "pos": [
        4154,
        4275
      ],
      "content": "Conveniently, <bpt id=\"p1\">[</bpt>GroupLens Research<ept id=\"p1\">][movielens]</ept> provides rating data for movies in a format that is compatible with Mahout."
    },
    {
      "pos": [
        4280,
        4388
      ],
      "content": "Download the <bpt id=\"p1\">[</bpt>MovieLens 100k<ept id=\"p1\">][100k]</ept> archive, which contains 100,000 ratings from 1000 users for 1700 movies."
    },
    {
      "content": "Extract the archive.",
      "pos": [
        4393,
        4413
      ]
    },
    {
      "content": "It should contain an <bpt id=\"p1\">__</bpt>ml-100k<ept id=\"p1\">__</ept> directory, which contains many data files prefixed with <bpt id=\"p2\">__</bpt>u.<ept id=\"p2\">__</ept>.",
      "pos": [
        4414,
        4510
      ]
    },
    {
      "content": "The file that will be analyzed by Mahout is <bpt id=\"p1\">__</bpt>u.data<ept id=\"p1\">__</ept>.",
      "pos": [
        4511,
        4566
      ]
    },
    {
      "content": "The data structure of this file is <ph id=\"ph1\">`userID`</ph>, <ph id=\"ph2\">`movieID`</ph>, <ph id=\"ph3\">`userRating`</ph>, and <ph id=\"ph4\">`timestamp`</ph>.",
      "pos": [
        4567,
        4653
      ]
    },
    {
      "content": "Here is an example of the data:",
      "pos": [
        4654,
        4685
      ]
    },
    {
      "content": "Upload the <bpt id=\"p1\">__</bpt>u.data<ept id=\"p1\">__</ept> file to <bpt id=\"p2\">__</bpt>example/data/u.data<ept id=\"p2\">__</ept> in your HDInsight cluster.",
      "pos": [
        4843,
        4923
      ]
    },
    {
      "content": "If you have <bpt id=\"p1\">[</bpt>Azure PowerShell<ept id=\"p1\">][aps]</ept>, you can use the <bpt id=\"p2\">[</bpt>HDInsight-Tools<ept id=\"p2\">][tools]</ept> module to upload the file.",
      "pos": [
        4924,
        5028
      ]
    },
    {
      "content": "For other ways to upload files, see <bpt id=\"p1\">[</bpt>Upload data for Hadoop Jobs in HDInsight<ept id=\"p1\">][upload]</ept>.",
      "pos": [
        5029,
        5116
      ]
    },
    {
      "content": "The following command uses <ph id=\"ph1\">`Add-HDInsightFile`</ph> to upload the file:",
      "pos": [
        5117,
        5183
      ]
    },
    {
      "content": "This uploads the <bpt id=\"p1\">__</bpt>u.data<ept id=\"p1\">__</ept> file to <bpt id=\"p2\">__</bpt>example/data/u.data<ept id=\"p2\">__</ept> in the default storage in your cluster.",
      "pos": [
        5324,
        5423
      ]
    },
    {
      "content": "You can then access this data by using the <bpt id=\"p1\">__</bpt>wasb:///example/data/u.data<ept id=\"p1\">__</ept> URI from HDInsight jobs.",
      "pos": [
        5424,
        5523
      ]
    },
    {
      "content": "Run the job",
      "pos": [
        5528,
        5539
      ]
    },
    {
      "pos": [
        5541,
        5695
      ],
      "content": "Use the following Windows PowerShell script to run a job that uses the Mahout recommendation engine with the <bpt id=\"p1\">__</bpt>u.data<ept id=\"p1\">__</ept> file that you uploaded previously:"
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Mahout jobs do not remove temporary data that is created while processing the job.",
      "pos": [
        7447,
        7542
      ]
    },
    {
      "content": "The <ph id=\"ph1\">`--tempDir`</ph> parameter is specified in the example job to isolate the temporary files into a specific path for easy deletion.",
      "pos": [
        7543,
        7671
      ]
    },
    {
      "content": "To remove these files, you can use one of the tools mentioned in <bpt id=\"p1\">[</bpt>Upload data for Hadoop jobs in HDInsight<ept id=\"p1\">][upload]</ept>.",
      "pos": [
        7676,
        7792
      ]
    },
    {
      "content": "Or you can use the <ph id=\"ph1\">`Remove-HDInsightFile`</ph> function in the <bpt id=\"p1\">[</bpt>HDInsight-Tools<ept id=\"p1\">][tools]</ept> module.",
      "pos": [
        7793,
        7883
      ]
    },
    {
      "content": "If you do not remove the temporary files or the output file, you will receive an error message if you run the job again.",
      "pos": [
        7888,
        8008
      ]
    },
    {
      "content": "The Mahout job does not return the output to STDOUT.",
      "pos": [
        8010,
        8062
      ]
    },
    {
      "content": "Instead, it stores it in the specified output directory as <bpt id=\"p1\">__</bpt>part-r-00000<ept id=\"p1\">__</ept>.",
      "pos": [
        8063,
        8139
      ]
    },
    {
      "content": "To download and view the file, use the <ph id=\"ph1\">`Get-HDInsightFile`</ph> function in the <bpt id=\"p1\">[</bpt>HDInsight-Tools<ept id=\"p1\">][tools]</ept> module.",
      "pos": [
        8140,
        8247
      ]
    },
    {
      "content": "The following is an example of the content of the file:",
      "pos": [
        8249,
        8304
      ]
    },
    {
      "content": "The first column is the <ph id=\"ph1\">`userID`</ph>.",
      "pos": [
        8707,
        8740
      ]
    },
    {
      "content": "The values contained in '[' and ']' are <ph id=\"ph1\">`movieId`</ph>:<ph id=\"ph2\">`recommendationScore`</ph>.",
      "pos": [
        8741,
        8813
      ]
    },
    {
      "content": "View the output",
      "pos": [
        8818,
        8833
      ]
    },
    {
      "content": "Although the generated output might be OK for use in an application, it's not very readable.",
      "pos": [
        8835,
        8927
      ]
    },
    {
      "content": "Some of the other files extracted to the <bpt id=\"p1\">__</bpt>ml-100k<ept id=\"p1\">__</ept> folder earlier can be used to resolve <ph id=\"ph1\">`movieId`</ph> to a movie name, which is what the following PowerShell script does:",
      "pos": [
        8928,
        9097
      ]
    },
    {
      "content": "To use this script, you must have previously extracted the <bpt id=\"p1\">__</bpt>ml-100k<ept id=\"p1\">__</ept> folder, in addition to having a local copy of the <bpt id=\"p2\">__</bpt>part-r-00000<ept id=\"p2\">__</ept> output file that was generated by the Mahout job.",
      "pos": [
        11969,
        12156
      ]
    },
    {
      "content": "The following is an example of running the script:",
      "pos": [
        12157,
        12207
      ]
    },
    {
      "content": "The output should appear similar to the following:",
      "pos": [
        12348,
        12398
      ]
    },
    {
      "pos": [
        13538,
        13607
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"classify\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Classify data by using the Hadoop command line"
    },
    {
      "content": "One of the classification methods available with Mahout is to build a <bpt id=\"p1\">[</bpt>random forest<ept id=\"p1\">][forest]</ept>.",
      "pos": [
        13609,
        13703
      ]
    },
    {
      "content": "This is a multiple step process that involves using training data to generate decision trees, which are then used to classify data.",
      "pos": [
        13704,
        13835
      ]
    },
    {
      "content": "This uses the <bpt id=\"p1\">__</bpt>org.apache.mahout.classifier.df.tools.Describe<ept id=\"p1\">__</ept> class provided by Mahout.",
      "pos": [
        13836,
        13926
      ]
    },
    {
      "content": "It currently must be run by using the Hadoop command line.",
      "pos": [
        13927,
        13985
      ]
    },
    {
      "content": "Load the data",
      "pos": [
        13990,
        14003
      ]
    },
    {
      "pos": [
        14008,
        14096
      ],
      "content": "Download the following files from <bpt id=\"p1\">[</bpt>The NSL-KDD Data Set<ept id=\"p1\">](http://nsl.cs.unb.ca/NSL-KDD/)</ept>."
    },
    {
      "pos": [
        14102,
        14182
      ],
      "content": "<bpt id=\"p1\">[</bpt>KDDTrain+.ARFF<ept id=\"p1\">](http://nsl.cs.unb.ca/NSL-KDD/KDDTrain+.arff)</ept>: the training file"
    },
    {
      "pos": [
        14188,
        14262
      ],
      "content": "<bpt id=\"p1\">[</bpt>KDDTest+.ARFF<ept id=\"p1\">](http://nsl.cs.unb.ca/NSL-KDD/KDDTest+.arff)</ept>: the test data"
    },
    {
      "content": "Open each file and remove the lines at the top that begin with '@', and then save the files.",
      "pos": [
        14267,
        14359
      ]
    },
    {
      "content": "If these are not removed, you will receive error messages when using this data with Mahout.",
      "pos": [
        14360,
        14451
      ]
    },
    {
      "content": "Upload the files to <bpt id=\"p1\">__</bpt>example/data<ept id=\"p1\">__</ept>.",
      "pos": [
        14456,
        14493
      ]
    },
    {
      "content": "You can do this by using the <ph id=\"ph1\">`Add-HDInsightFile`</ph> function in the <bpt id=\"p1\">[</bpt>HDInsight-Tools<ept id=\"p1\">][tools]</ept> module.",
      "pos": [
        14494,
        14591
      ]
    },
    {
      "content": "Run the job",
      "pos": [
        14596,
        14607
      ]
    },
    {
      "content": "This job requires the Hadoop command line.",
      "pos": [
        14612,
        14654
      ]
    },
    {
      "content": "Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id=\"p1\">[</bpt>Connect to HDInsight clusters using RDP<ept id=\"p1\">](hdinsight-administer-use-management-portal.md#rdp)</ept>.",
      "pos": [
        14655,
        14849
      ]
    },
    {
      "pos": [
        14854,
        14941
      ],
      "content": "After connecting, use the <bpt id=\"p1\">__</bpt>Hadoop Command Line<ept id=\"p1\">__</ept> icon to open the Hadoop command line:"
    },
    {
      "content": "hadoop cli",
      "pos": [
        14949,
        14959
      ]
    },
    {
      "pos": [
        14976,
        15074
      ],
      "content": "Use the following command to generate the file descriptor (<bpt id=\"p1\">__</bpt>KDDTrain+.info<ept id=\"p1\">__</ept>), which uses Mahout."
    },
    {
      "content": "The <ph id=\"ph1\">`N 3 C 2 N C 4 N C 8 N 2 C 19 N L`</ph> describes the attributes of the data in the file.",
      "pos": [
        15365,
        15453
      ]
    },
    {
      "content": "For example, L indicates a label.",
      "pos": [
        15454,
        15487
      ]
    },
    {
      "content": "Build a forest of decision trees by using the following command:",
      "pos": [
        15492,
        15556
      ]
    },
    {
      "content": "The output of this operation is stored in the <bpt id=\"p1\">__</bpt>nsl-forest<ept id=\"p1\">__</ept> directory, which is located in the storage for your HDInsight cluster at __wasb://user/&amp;lt;username&gt;/nsl-forest/nsl-forest.seq.",
      "pos": [
        15875,
        16063
      ]
    },
    {
      "content": "The &amp;lt;username&gt; is the user name that you used for your Remote Desktop session.",
      "pos": [
        16064,
        16145
      ]
    },
    {
      "content": "This file is not readable by humans.",
      "pos": [
        16146,
        16182
      ]
    },
    {
      "content": "Test the forest by classifying the <bpt id=\"p1\">__</bpt>KDDTest+.arff<ept id=\"p1\">__</ept> dataset.",
      "pos": [
        16187,
        16248
      ]
    },
    {
      "content": "Use the following command:",
      "pos": [
        16249,
        16275
      ]
    },
    {
      "content": "This command returns summary information about the classification process similar to the following:",
      "pos": [
        16587,
        16686
      ]
    },
    {
      "content": "This job also produces a file located at <bpt id=\"p1\">__</bpt>wasb:///example/data/predictions/KDDTest+.arff.out<ept id=\"p1\">__</ept>.",
      "pos": [
        17794,
        17890
      ]
    },
    {
      "content": "However, this file is not readable by humans.",
      "pos": [
        17891,
        17936
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Mahout jobs do not overwrite files.",
      "pos": [
        17940,
        17988
      ]
    },
    {
      "content": "If you want to run these jobs again, you must delete the files that were created by previous jobs.",
      "pos": [
        17989,
        18087
      ]
    },
    {
      "pos": [
        18091,
        18136
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"troubleshooting\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Troubleshooting"
    },
    {
      "pos": [
        18141,
        18177
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"install\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Install Mahout"
    },
    {
      "content": "Mahout is installed on HDInsight 3.1 clusters, and it can be installed manually on HDInsight 3.0 or HDInsight 2.1 clusters by using the following steps:",
      "pos": [
        18179,
        18331
      ]
    },
    {
      "content": "The version of Mahout to use depends on the HDInsight version of your cluster.",
      "pos": [
        18336,
        18414
      ]
    },
    {
      "content": "You can find the cluster version by using the following <bpt id=\"p1\">[</bpt>Azure PowerShell<ept id=\"p1\">][aps]</ept> command:",
      "pos": [
        18415,
        18503
      ]
    },
    {
      "pos": [
        18592,
        18774
      ],
      "content": "<bpt id=\"p1\">__</bpt>For HDInsight 2.1<ept id=\"p1\">__</ept>, you can download a Java Archive (JAR) file that contains <bpt id=\"p2\">[</bpt>Mahout 0.9<ept id=\"p2\">](http://repo2.maven.org/maven2/org/apache/mahout/mahout-core/0.9/mahout-core-0.9-job.jar)</ept>."
    },
    {
      "content": "<bpt id=\"p1\">__</bpt>For HDInsight 3.0<ept id=\"p1\">__</ept>, you must <bpt id=\"p2\">[</bpt>build Mahout from the source<ept id=\"p2\">][build]</ept> and specify the Hadoop version provided by HDInsight.",
      "pos": [
        18780,
        18903
      ]
    },
    {
      "content": "Install the prerequisites listed on the build page, download the source, and then use the following command to create the Mahout jar files:",
      "pos": [
        18904,
        19043
      ]
    },
    {
      "content": "Upload the jar file to <bpt id=\"p1\">__</bpt>example/jars<ept id=\"p1\">__</ept> in the default storage for your cluster.",
      "pos": [
        19366,
        19446
      ]
    },
    {
      "content": "The following example uses add-hdinsightfile from the <bpt id=\"p1\">[</bpt>HDInsight-Tools<ept id=\"p1\">][tools]</ept> to upload the file:",
      "pos": [
        19447,
        19545
      ]
    },
    {
      "content": "Cannot overwrite files",
      "pos": [
        19721,
        19743
      ]
    },
    {
      "content": "Mahout jobs do not clean up temporary files that were created during processing.",
      "pos": [
        19745,
        19825
      ]
    },
    {
      "content": "In addition, the jobs will not overwrite an existing output file.",
      "pos": [
        19826,
        19891
      ]
    },
    {
      "content": "To avoid errors when running Mahout jobs, delete temporary and output files between runs, or use unique temporary and output directory names.",
      "pos": [
        19893,
        20034
      ]
    },
    {
      "content": "Cannot find the JAR file",
      "pos": [
        20039,
        20063
      ]
    },
    {
      "content": "HDInsight 3.1 clusters include Mahout.",
      "pos": [
        20065,
        20103
      ]
    },
    {
      "content": "The path and file name include the version number of Mahout that is installed on the cluster.",
      "pos": [
        20104,
        20197
      ]
    },
    {
      "content": "The Windows PowerShell example script in this tutorial uses a path that is valid as of July 2014, but the version number will change in future updates to HDInsight.",
      "pos": [
        20198,
        20362
      ]
    },
    {
      "content": "To determine the current path to the Mahout JAR file for your cluster, use the following Windows PowerShell command, and then modify the script to reference the file path that is returned:",
      "pos": [
        20363,
        20551
      ]
    },
    {
      "pos": [
        20716,
        20791
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"nopowershell\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Classes that do not work with Windows PowerShell"
    },
    {
      "content": "Mahout jobs that use the following classes return a variety of error messages if they are used from Windows PowerShell:",
      "pos": [
        20793,
        20912
      ]
    },
    {
      "content": "org.apache.mahout.utils.clustering.ClusterDumper",
      "pos": [
        20916,
        20964
      ]
    },
    {
      "content": "org.apache.mahout.utils.SequenceFileDumper",
      "pos": [
        20967,
        21009
      ]
    },
    {
      "content": "org.apache.mahout.utils.vectors.lucene.Driver",
      "pos": [
        21012,
        21057
      ]
    },
    {
      "content": "org.apache.mahout.utils.vectors.arff.Driver",
      "pos": [
        21060,
        21103
      ]
    },
    {
      "content": "org.apache.mahout.text.WikipediaToSequenceFile",
      "pos": [
        21106,
        21152
      ]
    },
    {
      "content": "org.apache.mahout.clustering.streaming.tools.ResplitSequenceFiles",
      "pos": [
        21155,
        21220
      ]
    },
    {
      "content": "org.apache.mahout.clustering.streaming.tools.ClusterQualitySummarizer",
      "pos": [
        21223,
        21292
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sgd.TrainLogistic",
      "pos": [
        21295,
        21341
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sgd.RunLogistic",
      "pos": [
        21344,
        21388
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sgd.TrainAdaptiveLogistic",
      "pos": [
        21391,
        21445
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sgd.ValidateAdaptiveLogistic",
      "pos": [
        21448,
        21505
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sgd.RunAdaptiveLogistic",
      "pos": [
        21508,
        21560
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sequencelearning.hmm.BaumWelchTrainer",
      "pos": [
        21563,
        21629
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sequencelearning.hmm.ViterbiEvaluator",
      "pos": [
        21632,
        21698
      ]
    },
    {
      "content": "org.apache.mahout.classifier.sequencelearning.hmm.RandomSequenceGenerator",
      "pos": [
        21701,
        21774
      ]
    },
    {
      "content": "org.apache.mahout.classifier.df.tools.Describe",
      "pos": [
        21777,
        21823
      ]
    },
    {
      "content": "To run jobs that use these classes, connect to the HDInsight cluster, and run the jobs by using the Hadoop command line.",
      "pos": [
        21825,
        21945
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Classify data using the Hadoop command line<ept id=\"p1\">](#classify)</ept> for an example.",
      "pos": [
        21946,
        22022
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        22026,
        22036
      ]
    },
    {
      "content": "Now that you have learned how to use Mahout, discover other ways of working with data on HDInsight:",
      "pos": [
        22038,
        22137
      ]
    },
    {
      "content": "Hive with HDInsight",
      "pos": [
        22142,
        22161
      ]
    },
    {
      "content": "Pig with HDInsight",
      "pos": [
        22189,
        22207
      ]
    },
    {
      "content": "MapReduce with HDInsight",
      "pos": [
        22234,
        22258
      ]
    },
    {
      "content": "test",
      "pos": [
        22959,
        22963
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Generate recommendations using Mahout and Hadoop | Microsoft Azure\"\n    description=\"Learn how to use the Apache Mahout machine learning library to generate movie recommendations with HDInsight (Hadoop).\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"Blackmist\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"na\"\n    ms.topic=\"article\"\n    ms.date=\"07/24/2015\"\n    ms.author=\"larryfr\"/>\n\n#Generate movie recommendations by using Apache Mahout with Hadoop in HDInsight\n\n[AZURE.INCLUDE [mahout-selector](../../includes/hdinsight-selector-mahout.md)]\n\nLearn how to use the [Apache Mahout](http://mahout.apache.org) machine learning library with Azure HDInsight to generate movie recommendations.\n\n> [AZURE.NOTE] The steps in this document require a Windows client and a Windows-based HDInsight cluster. For information on using Mahout from a Linux, OS X, or Unix client, with a Linux-based HDInsight cluster, see [Generate movie recommendations by using Apache Mahout with Linux-based Hadoop in HDInsight](hdinsight-hadoop-mahout-linux-mac.md)\n\n\n##<a name=\"learn\"></a>What you will learn\n\nMahout is a [machine learning][ml] library for Apache Hadoop. Mahout contains algorithms for processing data, such as filtering, classification, and clustering. In this article, you will use a recommendation engine to generate movie recommendations that are based on movies your friends have seen. You will also learn how to perform classifications with a decision forest. This will teach you the following:\n\n* How to run Mahout jobs by using Windows PowerShell\n\n* How to run Mahout jobs from the Hadoop command line\n\n* How to install Mahout on HDInsight 3.0 and HDInsight 2.0 clusters\n\n    > [AZURE.NOTE] Mahout is provided with the HDInsight 3.1 version of the clusters. If you are using an earlier version of HDInsight, see [Install Mahout](#install) before you continue.\n\n##prerequisites\n\n* **An Windows-based Hadoop cluster in HDInsight**. For information about creating one, see [Get started using Hadoop in HDInsight][getstarted]\n\n- **A workstation with Azure PowerShell**. See [Install and use Azure PowerShell](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/).\n\n\n##<a name=\"recommendations\"></a>Generate recommendations by using Windows PowerShell\n\n> [AZURE.NOTE] Although the job used in this section works by using Windows PowerShell, many of the classes provided with Mahout do not currently work with Windows PowerShell, and they must be run by using the Hadoop command line. For a list of classes that do not work with Windows PowerShell, see the [Troubleshooting](#troubleshooting) section.\n>\n> For an example of using the Hadoop command line to run Mahout jobs, see [Classify data by using the Hadoop command line](#classify).\n\nOne of the functions that is provided by Mahout is a recommendation engine. This engine accepts data in the format of `userID`, `itemId`, and `prefValue` (the users preference for the item). Mahout can then perform co-occurance analysis to determine: _users who have a preference for an item also have a preference for these other items_. Mahout then determines users with like-item preferences, which can be used to make recommendations.\n\nThe following is an extremely simple example that uses movies:\n\n* __Co-occurance__: Joe, Alice, and Bob all liked _Star Wars_, _The Empire Strikes Back_, and _Return of the Jedi_. Mahout determines that users who like any one of these movies also like the other two.\n\n* __Co-occurance__: Bob and Alice also liked _The Phantom Menace_, _Attack of the Clones_, and _Revenge of the Sith_. Mahout determines that users who liked the previous three movies also like these three.\n\n* __Similarity recommendation__: Because Joe liked the first three movies, Mahout looks at movies that others with similar preferences liked, but Joe has not watched (liked/rated). In this case, Mahout recommends _The Phantom Menace_, _Attack of the Clones_, and _Revenge of the Sith_.\n\n###Load the data\n\nConveniently, [GroupLens Research][movielens] provides rating data for movies in a format that is compatible with Mahout.\n\n1. Download the [MovieLens 100k][100k] archive, which contains 100,000 ratings from 1000 users for 1700 movies.\n\n2. Extract the archive. It should contain an __ml-100k__ directory, which contains many data files prefixed with __u.__. The file that will be analyzed by Mahout is __u.data__. The data structure of this file is `userID`, `movieID`, `userRating`, and `timestamp`. Here is an example of the data:\n\n\n        196 242 3   881250949\n        186 302 3   891717742\n        22  377 1   878887116\n        244 51  2   880606923\n        166 346 1   886397596\n\n\n3. Upload the __u.data__ file to __example/data/u.data__ in your HDInsight cluster. If you have [Azure PowerShell][aps], you can use the [HDInsight-Tools][tools] module to upload the file. For other ways to upload files, see [Upload data for Hadoop Jobs in HDInsight][upload]. The following command uses `Add-HDInsightFile` to upload the file:\n\n        PS C:\\> Add-HDInsightFile -LocalPath \"path\\to\\u.data\" -DestinationPath \"example/data/u.data\" -ClusterName \"your cluster name\"\n\n    This uploads the __u.data__ file to __example/data/u.data__ in the default storage in your cluster. You can then access this data by using the __wasb:///example/data/u.data__ URI from HDInsight jobs.\n\n###Run the job\n\nUse the following Windows PowerShell script to run a job that uses the Mahout recommendation engine with the __u.data__ file that you uploaded previously:\n\n    # The HDInsight cluster name.\n    $clusterName = \"the cluster name\"\n\n    # NOTE: The version number portion of the file path\n    # may change in future versions of HDInsight.\n    # So dynamically grab it using Hive.\n    $mahoutPath = Invoke-Hive -Query '!${env:COMSPEC} /c dir /b /s ${env:MAHOUT_HOME}\\examples\\target\\*-job.jar' | where {$_.startswith(\"C:\\apps\\dist\")}\n    $noCRLF = $mahoutPath -replace \"`r`n\", \"\"\n    $cleanedPath = $noCRLF -replace \"\\\\\", \"/\"\n    $jarFile = \"file:///$cleanedPath\"\n    #\n    # If you are using an earlier version of HDInsight,\n    # set $jarFile to the jar file you\n    # uploaded.\n    # For example,\n    # $jarFile = \"wasb:///example/jars/mahout-core-0.9-job.jar\"\n\n    # The arguments for this job\n    # * input - the path to the data uploaded to HDInsight\n    # * output - the path to store output data\n    # * tempDir - the directory for temp files\n    $jobArguments = \"-s\", \"SIMILARITY_COOCCURRENCE\",\n                    \"--input\", \"wasb:///example/data/u.data\",\n                    \"--output\", \"wasb:///example/out\",\n                    \"--tempDir\", \"wasb:///temp/mahout\"\n\n    # Create the job definition\n    $jobDefinition = New-AzureHDInsightMapReduceJobDefinition `\n      -JarFile $jarFile `\n      -ClassName \"org.apache.mahout.cf.taste.hadoop.item.RecommenderJob\" `\n      -Arguments $jobArguments\n\n    # Start the job\n    $job = Start-AzureHDInsightJob -Cluster $clusterName -JobDefinition $jobDefinition\n\n    # Wait on the job to complete\n    Write-Host \"Wait for the job to complete ...\" -ForegroundColor Green\n    Wait-AzureHDInsightJob -Job $job\n\n    # Write out any error information\n    Write-Host \"STDERR\"\n    Get-AzureHDInsightJobOutput -Cluster $clusterName -JobId $job.JobId -StandardError\n\n> [AZURE.NOTE] Mahout jobs do not remove temporary data that is created while processing the job. The `--tempDir` parameter is specified in the example job to isolate the temporary files into a specific path for easy deletion.\n>\n> To remove these files, you can use one of the tools mentioned in [Upload data for Hadoop jobs in HDInsight][upload]. Or you can use the `Remove-HDInsightFile` function in the [HDInsight-Tools][tools] module.\n>\n> If you do not remove the temporary files or the output file, you will receive an error message if you run the job again.\n\nThe Mahout job does not return the output to STDOUT. Instead, it stores it in the specified output directory as __part-r-00000__. To download and view the file, use the `Get-HDInsightFile` function in the [HDInsight-Tools][tools] module.\n\nThe following is an example of the content of the file:\n\n    1   [234:5.0,347:5.0,237:5.0,47:5.0,282:5.0,275:5.0,88:5.0,515:5.0,514:5.0,121:5.0]\n    2   [282:5.0,210:5.0,237:5.0,234:5.0,347:5.0,121:5.0,258:5.0,515:5.0,462:5.0,79:5.0]\n    3   [284:5.0,285:4.828125,508:4.7543354,845:4.75,319:4.705128,124:4.7045455,150:4.6938777,311:4.6769233,248:4.65625,272:4.649266]\n    4   [690:5.0,12:5.0,234:5.0,275:5.0,121:5.0,255:5.0,237:5.0,895:5.0,282:5.0,117:5.0]\n\nThe first column is the `userID`. The values contained in '[' and ']' are `movieId`:`recommendationScore`.\n\n###View the output\n\nAlthough the generated output might be OK for use in an application, it's not very readable. Some of the other files extracted to the __ml-100k__ folder earlier can be used to resolve `movieId` to a movie name, which is what the following PowerShell script does:\n\n    <#\n    .SYNOPSIS\n        Displays recommendations for movies.\n    .DESCRIPTION\n        Displays recommendations generated by Mahout\n        with HDInsight example in a human readable format.\n    .EXAMPLE\n        .\\Show-Recommendation -userId 4\n            -userDataFile \"u.data\"\n            -movieFile \"u.item\"\n            -recommendationFile \"output.txt\"\n    #>\n\n    [CmdletBinding(SupportsShouldProcess = $true)]\n    param(\n        #The user ID\n        [Parameter(Mandatory = $true)]\n        [String]$userId,\n\n        [Parameter(Mandatory = $true)]\n        [String]$userDataFile,\n\n        [Parameter(Mandatory = $true)]\n        [String]$movieFile,\n\n        [Parameter(Mandatory = $true)]\n        [String]$recommendationFile\n    )\n    # Read movie ID & description into hash table\n    Write-Host \"Reading movies descriptions\" -ForegroundColor Green\n    $movieById = @{}\n    foreach($line in Get-Content $movieFile)\n    {\n        $tokens = $line.Split(\"|\")\n        $movieById[$tokens[0]] = $tokens[1]\n    }\n    # Load movies user has already seen (rated)\n    # into a hash table\n    Write-Host \"Reading rated movies\" -ForegroundColor Green\n    $ratedMovieIds = @{}\n    foreach($line in Get-Content $userDataFile)\n    {\n        $tokens = $line.Split(\"`t\")\n        if($tokens[0] -eq $userId)\n        {\n            # Resolve the ID to the movie name\n            $ratedMovieIds[$movieById[$tokens[1]]] = $tokens[2]\n        }\n    }\n    # Read recommendations generated by Mahout\n    Write-Host \"Reading recommendations\" -ForegroundColor Green\n    $recommendations = @{}\n    foreach($line in get-content $recommendationFile)\n    {\n        $tokens = $line.Split(\"`t\")\n        if($tokens[0] -eq $userId)\n        {\n            #Trim leading/treailing [] and split at ,\n            $movieIdAndScores = $tokens[1].TrimStart(\"[\").TrimEnd(\"]\").Split(\",\")\n            foreach($movieIdAndScore in $movieIdAndScores)\n            {\n                #Split at : and store title and score in a hash table\n                $idAndScore = $movieIdAndScore.Split(\":\")\n                $recommendations[$movieById[$idAndScore[0]]] = $idAndScore[1]\n            }\n            break\n        }\n    }\n\n    Write-Host \"Rated movies\" -ForegroundColor Green\n    Write-Host \"---------------------------\" -ForegroundColor Green\n    $ratedFormat = @{Expression={$_.Name};Label=\"Movie\";Width=40}, `\n                   @{Expression={$_.Value};Label=\"Rating\"}\n    $ratedMovieIds | format-table $ratedFormat\n    Write-Host \"---------------------------\" -ForegroundColor Green\n\n    write-host \"Recommended movies\" -ForegroundColor Green\n    Write-Host \"---------------------------\" -ForegroundColor Green\n    $recommendationFormat = @{Expression={$_.Name};Label=\"Movie\";Width=40}, `\n                            @{Expression={$_.Value};Label=\"Score\"}\n    $recommendations | format-table $recommendationFormat\n\nTo use this script, you must have previously extracted the __ml-100k__ folder, in addition to having a local copy of the __part-r-00000__ output file that was generated by the Mahout job. The following is an example of running the script:\n\n    PS C:\\> show-recommendation.ps1 -userId 4 -userDataFile .\\ml-100k\\u.data -movieFile .\\ml-100k\\u.item -recommendationFile .\\output.txt\n\nThe output should appear similar to the following:\n\n    Reading movies descriptions\n    Reading rated movies\n    Reading recommendations\n    Rated movies\n    ---------------------------\n    Movie                                    Rating\n    -----                                    ------\n    Devil's Own, The (1997)                  1\n    Alien: Resurrection (1997)               3\n    187 (1997)                               2\n    (lines ommitted)\n\n    ---------------------------\n    Recommended movies\n    ---------------------------\n\n    Movie                                    Score\n    -----                                    -----\n    Good Will Hunting (1997)                 4.6504064\n    Swingers (1996)                          4.6862745\n    Wings of the Dove, The (1997)            4.6666665\n    People vs. Larry Flynt, The (1996)       4.834559\n    Everyone Says I Love You (1996)          4.707071\n    Secrets & Lies (1996)                    4.818182\n    That Thing You Do! (1996)                4.75\n    Grosse Pointe Blank (1997)               4.8235292\n    Donnie Brasco (1997)                     4.6792455\n    Lone Star (1996)                         4.7099237  \n\n##<a name=\"classify\"></a>Classify data by using the Hadoop command line\n\nOne of the classification methods available with Mahout is to build a [random forest][forest]. This is a multiple step process that involves using training data to generate decision trees, which are then used to classify data. This uses the __org.apache.mahout.classifier.df.tools.Describe__ class provided by Mahout. It currently must be run by using the Hadoop command line.\n\n###Load the data\n\n1. Download the following files from [The NSL-KDD Data Set](http://nsl.cs.unb.ca/NSL-KDD/).\n\n  * [KDDTrain+.ARFF](http://nsl.cs.unb.ca/NSL-KDD/KDDTrain+.arff): the training file\n\n  * [KDDTest+.ARFF](http://nsl.cs.unb.ca/NSL-KDD/KDDTest+.arff): the test data\n\n2. Open each file and remove the lines at the top that begin with '@', and then save the files. If these are not removed, you will receive error messages when using this data with Mahout.\n\n2. Upload the files to __example/data__. You can do this by using the `Add-HDInsightFile` function in the [HDInsight-Tools][tools] module.\n\n###Run the job\n\n1. This job requires the Hadoop command line. Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at [Connect to HDInsight clusters using RDP](hdinsight-administer-use-management-portal.md#rdp).\n\n3. After connecting, use the __Hadoop Command Line__ icon to open the Hadoop command line:\n\n    ![hadoop cli][hadoopcli]\n\n3. Use the following command to generate the file descriptor (__KDDTrain+.info__), which uses Mahout.\n\n        hadoop jar \"c:/apps/dist/mahout-0.9.0.2.1.3.0-1887/examples/target/mahout-examples-0.9.0.2.1.3.0-1887-job.jar\" org.apache.mahout.classifier.df.tools.Describe -p \"wasb:///example/data/KDDTrain+.arff\" -f \"wasb:///example/data/KDDTrain+.info\" -d N 3 C 2 N C 4 N C 8 N 2 C 19 N L\n\n    The `N 3 C 2 N C 4 N C 8 N 2 C 19 N L` describes the attributes of the data in the file. For example, L indicates a label.\n\n4. Build a forest of decision trees by using the following command:\n\n        hadoop jar c:/apps/dist/mahout-0.9.0.2.1.3.0-1887/examples/target/mahout-examples-0.9.0.2.1.3.0-1887-job.jar org.apache.mahout.classifier.df.mapreduce.BuildForest -Dmapred.max.split.size=1874231 -d wasb:///example/data/KDDTrain+.arff -ds wasb:///example/data/KDDTrain+.info -sl 5 -p -t 100 -o nsl-forest\n\n    The output of this operation is stored in the __nsl-forest__ directory, which is located in the storage for your HDInsight cluster at __wasb://user/&lt;username>/nsl-forest/nsl-forest.seq. The &lt;username> is the user name that you used for your Remote Desktop session. This file is not readable by humans.\n\n5. Test the forest by classifying the __KDDTest+.arff__ dataset. Use the following command:\n\n        hadoop jar c:/apps/dist/mahout-0.9.0.2.1.3.0-1887/examples/target/mahout-examples-0.9.0.2.1.3.0-1887-job.jar org.apache.mahout.classifier.df.mapreduce.TestForest -i wasb:///example/data/KDDTest+.arff -ds wasb:///example/data/KDDTrain+.info -m nsl-forest -a -mr -o wasb:///example/data/predictions\n\n    This command returns summary information about the classification process similar to the following:\n\n        14/07/02 14:29:28 INFO mapreduce.TestForest:\n\n        =======================================================\n        Summary\n        -------------------------------------------------------\n        Correctly Classified Instances          :      17560       77.8921%\n        Incorrectly Classified Instances        :       4984       22.1079%\n        Total Classified Instances              :      22544\n\n        =======================================================\n        Confusion Matrix\n        -------------------------------------------------------\n        a       b       <--Classified as\n        9437    274      |  9711        a     = normal\n        4710    8123     |  12833       b     = anomaly\n\n        =======================================================\n        Statistics\n        -------------------------------------------------------\n        Kappa                                       0.5728\n        Accuracy                                   77.8921%\n        Reliability                                53.4921%\n        Reliability (standard deviation)            0.4933\n\n  This job also produces a file located at __wasb:///example/data/predictions/KDDTest+.arff.out__. However, this file is not readable by humans.\n\n> [AZURE.NOTE] Mahout jobs do not overwrite files. If you want to run these jobs again, you must delete the files that were created by previous jobs.\n\n##<a name=\"troubleshooting\"></a>Troubleshooting\n\n###<a name=\"install\"></a>Install Mahout\n\nMahout is installed on HDInsight 3.1 clusters, and it can be installed manually on HDInsight 3.0 or HDInsight 2.1 clusters by using the following steps:\n\n1. The version of Mahout to use depends on the HDInsight version of your cluster. You can find the cluster version by using the following [Azure PowerShell][aps] command:\n\n        PS C:\\> Get-AzureHDInsightCluster -Name YourClusterName | Select version\n\n\n  * __For HDInsight 2.1__, you can download a Java Archive (JAR) file that contains [Mahout 0.9](http://repo2.maven.org/maven2/org/apache/mahout/mahout-core/0.9/mahout-core-0.9-job.jar).\n\n  * __For HDInsight 3.0__, you must [build Mahout from the source][build] and specify the Hadoop version provided by HDInsight. Install the prerequisites listed on the build page, download the source, and then use the following command to create the Mahout jar files:\n\n            mvn -Dhadoop2.version=2.2.0 -DskipTests clean package\n\n        After the build completes, you can find the JAR file at __mahout\\mrlegacy\\target\\mahout-mrlegacy-1.0-SNAPSHOT-job.jar__.\n\n        > [AZURE.NOTE] When Mahout 1.0 is released, you should be able to use the prebuilt packages with HDInsight 3.0.\n\n2. Upload the jar file to __example/jars__ in the default storage for your cluster. The following example uses add-hdinsightfile from the [HDInsight-Tools][tools] to upload the file:\n\n        PS C:\\> .\\Add-HDInsightFile -LocalPath \"path\\to\\mahout-core-0.9-job.jar\" -DestinationPath \"example/jars/mahout-core-0.9-job.jar\" -ClusterName \"your cluster name\"\n\n###Cannot overwrite files\n\nMahout jobs do not clean up temporary files that were created during processing. In addition, the jobs will not overwrite an existing output file.\n\nTo avoid errors when running Mahout jobs, delete temporary and output files between runs, or use unique temporary and output directory names.\n\n###Cannot find the JAR file\n\nHDInsight 3.1 clusters include Mahout. The path and file name include the version number of Mahout that is installed on the cluster. The Windows PowerShell example script in this tutorial uses a path that is valid as of July 2014, but the version number will change in future updates to HDInsight. To determine the current path to the Mahout JAR file for your cluster, use the following Windows PowerShell command, and then modify the script to reference the file path that is returned:\n\n    Use-AzureHDInsightCluster -Name $clusterName\n    $jarFile = Invoke-Hive -Query '!${env:COMSPEC} /c dir /b /s ${env:MAHOUT_HOME}\\examples\\target\\*-job.jar'\n\n###<a name=\"nopowershell\"></a>Classes that do not work with Windows PowerShell\n\nMahout jobs that use the following classes return a variety of error messages if they are used from Windows PowerShell:\n\n* org.apache.mahout.utils.clustering.ClusterDumper\n* org.apache.mahout.utils.SequenceFileDumper\n* org.apache.mahout.utils.vectors.lucene.Driver\n* org.apache.mahout.utils.vectors.arff.Driver\n* org.apache.mahout.text.WikipediaToSequenceFile\n* org.apache.mahout.clustering.streaming.tools.ResplitSequenceFiles\n* org.apache.mahout.clustering.streaming.tools.ClusterQualitySummarizer\n* org.apache.mahout.classifier.sgd.TrainLogistic\n* org.apache.mahout.classifier.sgd.RunLogistic\n* org.apache.mahout.classifier.sgd.TrainAdaptiveLogistic\n* org.apache.mahout.classifier.sgd.ValidateAdaptiveLogistic\n* org.apache.mahout.classifier.sgd.RunAdaptiveLogistic\n* org.apache.mahout.classifier.sequencelearning.hmm.BaumWelchTrainer\n* org.apache.mahout.classifier.sequencelearning.hmm.ViterbiEvaluator\n* org.apache.mahout.classifier.sequencelearning.hmm.RandomSequenceGenerator\n* org.apache.mahout.classifier.df.tools.Describe\n\nTo run jobs that use these classes, connect to the HDInsight cluster, and run the jobs by using the Hadoop command line. See [Classify data using the Hadoop command line](#classify) for an example.\n\n##Next steps\n\nNow that you have learned how to use Mahout, discover other ways of working with data on HDInsight:\n\n* [Hive with HDInsight](../hadoop-use-hive.md)\n* [Pig with HDInsight](../hadoop-use-pig.md)\n* [MapReduce with HDInsight](../hadoop-use-mapreduce.md)\n\n[build]: http://mahout.apache.org/developers/buildingmahout.html\n[aps]: ../powershell-install-configure.md\n[movielens]: http://grouplens.org/datasets/movielens/\n[100k]: http://files.grouplens.org/datasets/movielens/ml-100k.zip\n[getstarted]: ../hdinsight-get-started.md\n[upload]: hdinsight-upload-data.md\n[ml]: http://en.wikipedia.org/wiki/Machine_learning\n[forest]: http://en.wikipedia.org/wiki/Random_forest\n[management]: https://manage.windowsazure.com/\n[enableremote]: ./media/hdinsight-mahout/enableremote.png\n[connect]: ./media/hdinsight-mahout/connect.png\n[hadoopcli]: ./media/hdinsight-mahout/hadoopcli.png\n[tools]: https://github.com/Blackmist/hdinsight-tools\n \ntest\n"
}