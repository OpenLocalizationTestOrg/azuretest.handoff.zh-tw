{
  "nodes": [
    {
      "content": "Working with Channels that are Enabled to Perform Live Encoding with Azure Media Services",
      "pos": [
        28,
        117
      ]
    },
    {
      "content": "This topic describes how to set up a Channel that receives a single bitrate live stream from an on-premises encoder and then performs live encoding to adaptive bitrate stream with Media Services.",
      "pos": [
        137,
        332
      ]
    },
    {
      "content": "The stream can then be delivered to client playback applications through one or more Streaming Endpoints, using one of the following adaptive streaming protocols: HLS, Smooth Stream, MPEG DASH, HDS.",
      "pos": [
        333,
        531
      ]
    },
    {
      "content": "Working with Channels that are Enabled to Perform Live Encoding with Azure Media Services (Preview)",
      "pos": [
        843,
        942
      ]
    },
    {
      "content": "Overview",
      "pos": [
        946,
        954
      ]
    },
    {
      "content": "In Azure Media Services, a <bpt id=\"p1\">**</bpt>Channel<ept id=\"p1\">**</ept> represents a pipeline for processing live streaming content.",
      "pos": [
        956,
        1055
      ]
    },
    {
      "content": "A <bpt id=\"p1\">**</bpt>Channel<ept id=\"p1\">**</ept> receives live input streams in one of two ways:",
      "pos": [
        1056,
        1117
      ]
    },
    {
      "content": "An on-premises live encoder sends multi-bitrate <bpt id=\"p1\">**</bpt>RTMP<ept id=\"p1\">**</ept> or <bpt id=\"p2\">**</bpt>Smooth Streaming<ept id=\"p2\">**</ept> (Fragmented MP4) to the Channel.",
      "pos": [
        1121,
        1234
      ]
    },
    {
      "content": "You can use the following live encoders that output multi-bitrate Smooth Streaming: Elemental, Envivio, Cisco.",
      "pos": [
        1235,
        1345
      ]
    },
    {
      "content": "The following live encoders output RTMP: Adobe Flash Live, Telestream Wirecast, and Tricaster transcoders.",
      "pos": [
        1347,
        1453
      ]
    },
    {
      "content": "The ingested streams pass through <bpt id=\"p1\">**</bpt>Channel<ept id=\"p1\">**</ept>s without any further processing.",
      "pos": [
        1454,
        1532
      ]
    },
    {
      "content": "When requested, Media Services delivers the stream to customers.",
      "pos": [
        1533,
        1597
      ]
    },
    {
      "content": "A single bitrate stream (in one of the following formats: <bpt id=\"p1\">**</bpt>RTP<ept id=\"p1\">**</ept> (MPEG-TS)), <bpt id=\"p2\">**</bpt>RTMP<ept id=\"p2\">**</ept>, or <bpt id=\"p3\">**</bpt>Smooth Streaming<ept id=\"p3\">**</ept> (Fragmented MP4)) is sent to the <bpt id=\"p4\">**</bpt>Channel<ept id=\"p4\">**</ept> that is enabled to perform live encoding with Media Services.",
      "pos": [
        1600,
        1818
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>Channel<ept id=\"p1\">**</ept> then performs live encoding of the incoming single bitrate stream to a multi-bitrate (adaptive) video stream.",
      "pos": [
        1819,
        1944
      ]
    },
    {
      "content": "When requested, Media Services delivers the stream to customers.",
      "pos": [
        1945,
        2009
      ]
    },
    {
      "pos": [
        2016,
        2087
      ],
      "content": "Encoding a live stream with Media Services is currently in <bpt id=\"p1\">**</bpt>Preview<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Starting with the Media Services 2.10 release, when you create a Channel, you can specify in which way you want for your channel to receive the input stream and whether or not you want for the channel to perform live encoding of your stream.",
      "pos": [
        2089,
        2330
      ]
    },
    {
      "content": "You have two options:",
      "pos": [
        2331,
        2352
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>None<ept id=\"p1\">**</ept> – Specify this value, if you plan to use an on-premises live encoder which will output multi-bitrate stream.",
      "pos": [
        2360,
        2477
      ]
    },
    {
      "content": "In this case, the incoming stream passed through to the output without any encoding.",
      "pos": [
        2478,
        2562
      ]
    },
    {
      "content": "This is the behavior of a Channel prior to 2.10 release.",
      "pos": [
        2563,
        2619
      ]
    },
    {
      "content": "For more detailed information about working with channels of this type, see <bpt id=\"p1\">[</bpt>Working with Channels that Receive Multi-bitrate Live Stream from On-premises Encoders<ept id=\"p1\">](media-services-manage-channels-overview.md)</ept>.",
      "pos": [
        2621,
        2830
      ]
    },
    {
      "pos": [
        2834,
        2978
      ],
      "content": "<bpt id=\"p1\">**</bpt>Standard<ept id=\"p1\">**</ept> (Preview) – Choose this value, if you plan to use Media Services to encode your single bitrate live stream to multi-bitrate stream."
    },
    {
      "content": "Encoding a live stream with Media Services is currently in Preview.",
      "pos": [
        2985,
        3052
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>This topic discusses attributes of channels that are enabled to perform live encoding (<bpt id=\"p1\">**</bpt>Standard<ept id=\"p1\">**</ept> encoding type).",
      "pos": [
        3055,
        3182
      ]
    },
    {
      "content": "For information about working with channels that are not enabled to perform live encoding, see <bpt id=\"p1\">[</bpt>Working with Channels that Receive Multi-bitrate Live Stream from On-premises Encoders<ept id=\"p1\">](media-services-manage-channels-overview.md)</ept>.",
      "pos": [
        3183,
        3411
      ]
    },
    {
      "content": "The following diagram represents a live streaming workflow where a channel receives a single bitrate stream in one of the following protocols: RTMP, Smooth Streaming, or RTP (MPEG-TS); it then encodes the stream to a multi-bitrate stream.",
      "pos": [
        3413,
        3651
      ]
    },
    {
      "content": "Live workflow",
      "pos": [
        3656,
        3669
      ]
    },
    {
      "pos": [
        3688,
        3769
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>Not all data centers support Live Encoding with Azure Media Services."
    },
    {
      "content": "If you are using Azure Management Portal to create Channels, you will have two Channel encoding type options available: <bpt id=\"p1\">**</bpt>None<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Standard<ept id=\"p2\">**</ept>.",
      "pos": [
        3774,
        3920
      ]
    },
    {
      "content": "If you only see the <bpt id=\"p1\">**</bpt>None<ept id=\"p1\">**</ept> option, it means your data center does not support Live Encoding with AMS.",
      "pos": [
        3921,
        4024
      ]
    },
    {
      "content": "If you are using .NET SDK or REST API, do the following to check:",
      "pos": [
        4028,
        4093
      ]
    },
    {
      "content": "Try to create a Channel with encoding type set to Standard.",
      "pos": [
        4100,
        4159
      ]
    },
    {
      "pos": [
        4165,
        4394
      ],
      "content": "If the returned result HTTP Error Code 412 (Precondition Failed) with the following message: <bpt id=\"p1\">*</bpt>\"Live encoding is not supported in this region; EncodingType must be set to 'None'.\"<ept id=\"p1\">*</ept>, your data center does not support Live Encoding."
    },
    {
      "content": "In this topic",
      "pos": [
        4399,
        4412
      ]
    },
    {
      "pos": [
        4416,
        4527
      ],
      "content": "Overview of a <bpt id=\"p1\">[</bpt>common live streaming scenario<ept id=\"p1\">](media-services-manage-live-encoder-enabled-channels.md#scenario)</ept>"
    },
    {
      "content": "Description of a Channel and its related components",
      "pos": [
        4531,
        4582
      ]
    },
    {
      "content": "Considerations",
      "pos": [
        4651,
        4665
      ]
    },
    {
      "content": "Tasks related to Live Streaming",
      "pos": [
        4741,
        4772
      ]
    },
    {
      "pos": [
        4839,
        4890
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"scenario\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Common Live Streaming Scenario"
    },
    {
      "content": "The following are general steps involved in creating common live streaming applications.",
      "pos": [
        4892,
        4980
      ]
    },
    {
      "content": "Connect a video camera to a computer.",
      "pos": [
        4985,
        5022
      ]
    },
    {
      "content": "Launch and configure an on-premises live encoder that can output a <bpt id=\"p1\">**</bpt>single<ept id=\"p1\">**</ept> bitrate stream in one of the following protocols: RTMP, Smooth Streaming, or RTP (MPEG-TS).",
      "pos": [
        5023,
        5192
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Azure Media Services RTMP Support and Live Encoders<ept id=\"p1\">](http://go.microsoft.com/fwlink/?LinkId=532824)</ept>.",
      "pos": [
        5193,
        5320
      ]
    },
    {
      "content": "This step could also be performed after you create your Channel.",
      "pos": [
        5330,
        5394
      ]
    },
    {
      "content": "Create and start a Channel.",
      "pos": [
        5399,
        5426
      ]
    },
    {
      "content": "Retrieve the Channel ingest URL.",
      "pos": [
        5432,
        5464
      ]
    },
    {
      "content": "The ingest URL is used by the live encoder to send the stream to the Channel.",
      "pos": [
        5471,
        5548
      ]
    },
    {
      "content": "Retrieve the Channel preview URL.",
      "pos": [
        5552,
        5585
      ]
    },
    {
      "content": "Use this URL to verify that your channel is properly receiving the live stream.",
      "pos": [
        5592,
        5671
      ]
    },
    {
      "content": "Create a program.",
      "pos": [
        5676,
        5693
      ]
    },
    {
      "content": "When using the Azure Management Portal, creating a program also creates an asset.",
      "pos": [
        5700,
        5781
      ]
    },
    {
      "content": "When using .NET SDK or REST you need to create an asset and specify to use this asset when creating a Program.",
      "pos": [
        5788,
        5898
      ]
    },
    {
      "content": "Publish the asset associated with the program.",
      "pos": [
        5903,
        5949
      ]
    },
    {
      "content": "Make sure to have at least one streaming reserved unit on the streaming endpoint from which you want to stream content.",
      "pos": [
        5958,
        6077
      ]
    },
    {
      "content": "Start the program when you are ready to start streaming and archiving.",
      "pos": [
        6081,
        6151
      ]
    },
    {
      "content": "Optionally, the live encoder can be signaled to start an advertisement.",
      "pos": [
        6155,
        6226
      ]
    },
    {
      "content": "The advertisement is inserted in the output stream.",
      "pos": [
        6227,
        6278
      ]
    },
    {
      "content": "Stop the program whenever you want to stop streaming and archiving the event.",
      "pos": [
        6282,
        6359
      ]
    },
    {
      "content": "Delete the Program (and optionally delete the asset).",
      "pos": [
        6363,
        6416
      ]
    },
    {
      "pos": [
        6421,
        6576
      ],
      "content": "The <bpt id=\"p1\">[</bpt>live streaming tasks<ept id=\"p1\">](media-services-manage-channels-overview.md#tasks)</ept> section links to topics that demonstrate how to achieve tasks described above."
    },
    {
      "pos": [
        6581,
        6640
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"channel\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Channel's input (ingest) configurations"
    },
    {
      "pos": [
        6645,
        6699
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"Ingest_Protocols\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Ingest streaming protocol"
    },
    {
      "pos": [
        6701,
        6767
      ],
      "content": "If the <bpt id=\"p1\">**</bpt>Encoder Type<ept id=\"p1\">**</ept> is set to <bpt id=\"p2\">**</bpt>Standard<ept id=\"p2\">**</ept>, valid options are:"
    },
    {
      "pos": [
        6771,
        6823
      ],
      "content": "<bpt id=\"p1\">**</bpt>RTP<ept id=\"p1\">**</ept> (MPEG-TS): MPEG-2 Transport Stream over RTP."
    },
    {
      "pos": [
        6828,
        6851
      ],
      "content": "Single bitrate <bpt id=\"p1\">**</bpt>RTMP<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        6854,
        6906
      ],
      "content": "Single bitrate <bpt id=\"p1\">**</bpt>Fragmented MP4<ept id=\"p1\">**</ept> (Smooth Streaming)"
    },
    {
      "pos": [
        6908,
        7035
      ],
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Azure Media Services RTMP Support and Live Encoders<ept id=\"p1\">](http://go.microsoft.com/fwlink/?LinkId=532824)</ept>."
    },
    {
      "content": "RTP (MPEG-TS) - MPEG-2 Transport Stream over RTP.",
      "pos": [
        7041,
        7090
      ]
    },
    {
      "content": "Typical use case:",
      "pos": [
        7094,
        7111
      ]
    },
    {
      "content": "Professional broadcasters typically work with high-end on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme, Imagine or Envivio to send a stream.",
      "pos": [
        7114,
        7290
      ]
    },
    {
      "content": "Often used in conjunction with  an IT department and private networks.",
      "pos": [
        7291,
        7361
      ]
    },
    {
      "content": "Considerations:",
      "pos": [
        7363,
        7378
      ]
    },
    {
      "content": "The use of a single program transport stream (SPTS) input is strongly recommended.",
      "pos": [
        7382,
        7464
      ]
    },
    {
      "content": "The use of multiple language audio tracks, however, is supported",
      "pos": [
        7465,
        7529
      ]
    },
    {
      "content": "The video stream should have an average bitrate below 15 Mbps",
      "pos": [
        7532,
        7593
      ]
    },
    {
      "content": "The aggregate average bitrate of the audio streams should be below 1 Mbps",
      "pos": [
        7596,
        7669
      ]
    },
    {
      "content": "Following are the supported codecs:",
      "pos": [
        7672,
        7707
      ]
    },
    {
      "content": "MPEG-2 / H.262 Video",
      "pos": [
        7714,
        7734
      ]
    },
    {
      "content": "Main Profile (4:2:0)",
      "pos": [
        7755,
        7775
      ]
    },
    {
      "content": "High Profile (4:2:0, 4:2:2)",
      "pos": [
        7786,
        7813
      ]
    },
    {
      "content": "422 Profile (4:2:0, 4:2:2)",
      "pos": [
        7824,
        7850
      ]
    },
    {
      "content": "MPEG-4 AVC / H.264 Video",
      "pos": [
        7858,
        7882
      ]
    },
    {
      "content": "Baseline, Main, High Profile (8-bit 4:2:0)",
      "pos": [
        7900,
        7942
      ]
    },
    {
      "content": "High 10 Profile (10-bit 4:2:0)",
      "pos": [
        7953,
        7983
      ]
    },
    {
      "content": "High 422 Profile (10-bit 4:2:2)",
      "pos": [
        7994,
        8025
      ]
    },
    {
      "content": "Recommended broadcast encoders include:",
      "pos": [
        8299,
        8338
      ]
    },
    {
      "content": "Ateme AM2102",
      "pos": [
        8345,
        8357
      ]
    },
    {
      "content": "Ericsson AVP2000",
      "pos": [
        8364,
        8380
      ]
    },
    {
      "content": "eVertz 3480",
      "pos": [
        8387,
        8398
      ]
    },
    {
      "content": "Ericsson RX8200",
      "pos": [
        8405,
        8420
      ]
    },
    {
      "content": "Imagine Communications Selenio ENC 1",
      "pos": [
        8427,
        8463
      ]
    },
    {
      "content": "Imagine Communications Selenio ENC 2",
      "pos": [
        8470,
        8506
      ]
    },
    {
      "content": "AdTec EN-30",
      "pos": [
        8513,
        8524
      ]
    },
    {
      "content": "AdTec EN-91P",
      "pos": [
        8531,
        8543
      ]
    },
    {
      "content": "AdTec EN-100",
      "pos": [
        8550,
        8562
      ]
    },
    {
      "content": "Harmonic ProStream 1000",
      "pos": [
        8569,
        8592
      ]
    },
    {
      "content": "Thor H-2 4HD-EM",
      "pos": [
        8599,
        8614
      ]
    },
    {
      "content": "eVertz 7880 SLKE",
      "pos": [
        8621,
        8637
      ]
    },
    {
      "content": "Cisco Spinnaker",
      "pos": [
        8644,
        8659
      ]
    },
    {
      "content": "Elemental Live",
      "pos": [
        8666,
        8680
      ]
    },
    {
      "pos": [
        8686,
        8737
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"single_bitrate_RTMP\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Single bitrate RTMP"
    },
    {
      "content": "Considerations:",
      "pos": [
        8739,
        8754
      ]
    },
    {
      "content": "The incoming stream cannot contain multi-bitrate video",
      "pos": [
        8758,
        8812
      ]
    },
    {
      "content": "The video stream should have an average bitrate below 15 Mbps",
      "pos": [
        8815,
        8876
      ]
    },
    {
      "content": "The audio stream should have an average bitrate below 1 Mbps",
      "pos": [
        8879,
        8939
      ]
    },
    {
      "content": "Following are the supported codecs:",
      "pos": [
        8942,
        8977
      ]
    },
    {
      "content": "MPEG-4 AVC / H.264 Video",
      "pos": [
        8985,
        9009
      ]
    },
    {
      "content": "Baseline, Main, High Profile (8-bit 4:2:0)",
      "pos": [
        9027,
        9069
      ]
    },
    {
      "content": "High 10 Profile (10-bit 4:2:0)",
      "pos": [
        9080,
        9110
      ]
    },
    {
      "content": "High 422 Profile (10-bit 4:2:2)",
      "pos": [
        9121,
        9152
      ]
    },
    {
      "content": "MPEG-2 AAC-LC Audio",
      "pos": [
        9160,
        9179
      ]
    },
    {
      "content": "Mono, Stereo, Surround (5.1, 7.1)",
      "pos": [
        9191,
        9224
      ]
    },
    {
      "content": "44.1 kHz sampling rate",
      "pos": [
        9235,
        9257
      ]
    },
    {
      "content": "MPEG-2 style ADTS packaging",
      "pos": [
        9268,
        9295
      ]
    },
    {
      "content": "Recommended encoders include:",
      "pos": [
        9303,
        9332
      ]
    },
    {
      "content": "Telestream Wirecast",
      "pos": [
        9341,
        9360
      ]
    },
    {
      "content": "Flash Media Live Encoder",
      "pos": [
        9367,
        9391
      ]
    },
    {
      "content": "Tricaster",
      "pos": [
        9398,
        9407
      ]
    },
    {
      "content": "Single bitrate Fragmented MP4 (Smooth Streaming)",
      "pos": [
        9413,
        9461
      ]
    },
    {
      "content": "Typical use case:",
      "pos": [
        9463,
        9480
      ]
    },
    {
      "content": "Use on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme, Envivio to send the input stream over the open internet to a nearby Azure data center.",
      "pos": [
        9483,
        9658
      ]
    },
    {
      "content": "Considerations:",
      "pos": [
        9660,
        9675
      ]
    },
    {
      "pos": [
        9677,
        9787
      ],
      "content": "Same as for <bpt id=\"p1\">[</bpt>single bitrate RTMP<ept id=\"p1\">](media-services-manage-live-encoder-enabled-channels.md#single_bitrate_RTMP)</ept>."
    },
    {
      "content": "Other considerations",
      "pos": [
        9793,
        9813
      ]
    },
    {
      "content": "You cannot change the input protocol while the Channel or its associated programs are running.",
      "pos": [
        9817,
        9911
      ]
    },
    {
      "content": "If you require different protocols, you should create separate channels for each input protocol.",
      "pos": [
        9912,
        10008
      ]
    },
    {
      "content": "Maximum resolution for the incoming video stream is 1920x1080, and at most 60 fields/second if interlaced, or 30 frames/second if progressive.",
      "pos": [
        10012,
        10154
      ]
    },
    {
      "content": "Ingest URLs (endpoints)",
      "pos": [
        10160,
        10183
      ]
    },
    {
      "content": "A Channel provides an input endpoint (ingest URL) that you specify in the live encoder, so the encoder can push streams to your Channels.",
      "pos": [
        10186,
        10323
      ]
    },
    {
      "content": "You can get the ingest URLs once you create a Channel.",
      "pos": [
        10328,
        10382
      ]
    },
    {
      "content": "To get these URLs, the Channel does not have to be in the <bpt id=\"p1\">**</bpt>Running<ept id=\"p1\">**</ept> state.",
      "pos": [
        10383,
        10459
      ]
    },
    {
      "content": "When you are ready to start pushing data into the Channel, it must be in the <bpt id=\"p1\">**</bpt>Running<ept id=\"p1\">**</ept> state.",
      "pos": [
        10460,
        10555
      ]
    },
    {
      "content": "Once the Channel starts ingesting data, you can preview your stream through the preview URL.",
      "pos": [
        10556,
        10648
      ]
    },
    {
      "content": "You have an option of ingesting Fragmented MP4 (Smooth Streaming) live stream over an SSL connection.",
      "pos": [
        10650,
        10751
      ]
    },
    {
      "content": "To ingest over SSL, make sure to update the ingest URL to HTTPS.",
      "pos": [
        10752,
        10816
      ]
    },
    {
      "content": "Allowed IP addresses",
      "pos": [
        10822,
        10842
      ]
    },
    {
      "content": "You can define the IP addresses that are allowed to publish video to this channel.",
      "pos": [
        10844,
        10926
      ]
    },
    {
      "content": "Allowed IP addresses can be specified as either a single IP address (e.g. ‘10.0.0.1’), an IP range using an IP address and a CIDR subnet mask (e.g. ‘10.0.0.1/22’), or an IP range using an IP address and a dotted decimal subnet mask (e.g. ‘10.0.0.1(255.255.252.0)’).",
      "pos": [
        10927,
        11192
      ]
    },
    {
      "content": "If no IP addresses are specified and there is no rule definition then no IP address will be allowed.",
      "pos": [
        11195,
        11295
      ]
    },
    {
      "content": "To allow any IP address, create a rule and set 0.0.0.0/0.",
      "pos": [
        11296,
        11353
      ]
    },
    {
      "content": "Channel preview",
      "pos": [
        11358,
        11373
      ]
    },
    {
      "content": "Preview URLs",
      "pos": [
        11379,
        11391
      ]
    },
    {
      "content": "Channels provide a preview endpoint (preview URL) that you use to preview and validate your stream before further processing and delivery.",
      "pos": [
        11393,
        11531
      ]
    },
    {
      "content": "You can get the preview URL when you create the channel.",
      "pos": [
        11533,
        11589
      ]
    },
    {
      "content": "To get the URL, the channel does not have to be in the <bpt id=\"p1\">**</bpt>Running<ept id=\"p1\">**</ept> state.",
      "pos": [
        11590,
        11663
      ]
    },
    {
      "content": "Once the Channel starts ingesting data, you can preview your stream.",
      "pos": [
        11666,
        11734
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept> Currently the preview stream can only be delivered in Fragmented MP4 (Smooth Streaming) format regardless of the specified input type.",
      "pos": [
        11736,
        11879
      ]
    },
    {
      "content": "You can use the <bpt id=\"p1\">[</bpt>http://smf.cloudapp.net/healthmonitor<ept id=\"p1\">](http://smf.cloudapp.net/healthmonitor)</ept> player to test the Smooth Stream.",
      "pos": [
        11880,
        12008
      ]
    },
    {
      "content": "You can also use a player hosted in the Azure Management Portal to view your stream.",
      "pos": [
        12009,
        12093
      ]
    },
    {
      "content": "Allowed IP Addresses",
      "pos": [
        12098,
        12118
      ]
    },
    {
      "content": "You can define the IP addresses that are allowed to connect to the preview endpoint.",
      "pos": [
        12120,
        12204
      ]
    },
    {
      "content": "If no IP addresses are specified any IP address will be allowed.",
      "pos": [
        12205,
        12269
      ]
    },
    {
      "content": "Allowed IP addresses can be specified as either a single IP address (e.g. ‘10.0.0.1’), an IP range using an IP address and a CIDR subnet mask (e.g. ‘10.0.0.1/22’), or an IP range using an IP address and a dotted decimal subnet mask (e.g. ‘10.0.0.1(255.255.252.0)’).",
      "pos": [
        12270,
        12535
      ]
    },
    {
      "content": "Live encoding settings",
      "pos": [
        12539,
        12561
      ]
    },
    {
      "pos": [
        12563,
        12723
      ],
      "content": "This section describes how the settings for the live encoder within the Channel can be adjusted, when the <bpt id=\"p1\">**</bpt>Encoding Type<ept id=\"p1\">**</ept> of a Channel is set to <bpt id=\"p2\">**</bpt>Standard<ept id=\"p2\">**</ept>."
    },
    {
      "content": "Ad marker source",
      "pos": [
        12728,
        12744
      ]
    },
    {
      "content": "You can specify the source for ad markers signals.",
      "pos": [
        12746,
        12796
      ]
    },
    {
      "content": "Default value is <bpt id=\"p1\">**</bpt>Api<ept id=\"p1\">**</ept>, which indicates that the live encoder within the Channel should listen to an asynchronous <bpt id=\"p2\">**</bpt>Ad Marker API<ept id=\"p2\">**</ept>.",
      "pos": [
        12797,
        12931
      ]
    },
    {
      "content": "The other valid option is <bpt id=\"p1\">**</bpt>Scte35<ept id=\"p1\">**</ept> (allowed only if the ingest streaming protocol is set to RTP (MPEG-TS).",
      "pos": [
        12934,
        13042
      ]
    },
    {
      "content": "When Scte35 is specified, the live encoder will parse SCTE-35 signals from the input RTP (MPEG-TS) stream.",
      "pos": [
        13043,
        13149
      ]
    },
    {
      "content": "CEA 708 Closed Captions",
      "pos": [
        13155,
        13178
      ]
    },
    {
      "content": "An optional flag which tells the live encoder to ignore any CEA 708 captions data embedded in the incoming video.",
      "pos": [
        13180,
        13293
      ]
    },
    {
      "content": "When the flag is set to false (default), the encoder will detect and re-insert CEA 708 data into the output video streams.",
      "pos": [
        13294,
        13416
      ]
    },
    {
      "content": "Video Stream",
      "pos": [
        13421,
        13433
      ]
    },
    {
      "content": "Optional.",
      "pos": [
        13435,
        13444
      ]
    },
    {
      "content": "Describes the input video stream.",
      "pos": [
        13445,
        13478
      ]
    },
    {
      "content": "If this field is not specified, the default value is used.",
      "pos": [
        13479,
        13537
      ]
    },
    {
      "content": "This setting is allowed only if the input streaming protocol is set to RTP (MPEG-TS).",
      "pos": [
        13538,
        13623
      ]
    },
    {
      "content": "Index",
      "pos": [
        13629,
        13634
      ]
    },
    {
      "content": "A zero-based index that specifies which input video stream should be processed by the live encoder within the Channel.",
      "pos": [
        13636,
        13754
      ]
    },
    {
      "content": "This setting applies only if ingest streaming protocol is RTP (MPEG-TS).",
      "pos": [
        13755,
        13827
      ]
    },
    {
      "content": "Default value is zero.",
      "pos": [
        13830,
        13852
      ]
    },
    {
      "content": "It is recommended to send in a single program transport stream (SPTS).",
      "pos": [
        13853,
        13923
      ]
    },
    {
      "content": "If the input stream contains multiple programs, the live encoder parses the Program Map Table (PMT) in the input, identifies the inputs that have a stream type name of MPEG-2 Video or H.264, and arranges them in the order specified in the PMT.",
      "pos": [
        13924,
        14167
      ]
    },
    {
      "content": "The zero-based index is then used to pick up the n-th entry in that arrangement.",
      "pos": [
        14168,
        14248
      ]
    },
    {
      "content": "Audio Stream",
      "pos": [
        14254,
        14266
      ]
    },
    {
      "content": "Optional.",
      "pos": [
        14268,
        14277
      ]
    },
    {
      "content": "Describes the input audio streams.",
      "pos": [
        14278,
        14312
      ]
    },
    {
      "content": "If this field is not specified, the default values specified apply.",
      "pos": [
        14313,
        14380
      ]
    },
    {
      "content": "This setting is allowed only if the input streaming protocol is set to RTP (MPEG-TS).",
      "pos": [
        14381,
        14466
      ]
    },
    {
      "content": "Index",
      "pos": [
        14472,
        14477
      ]
    },
    {
      "content": "It is recommended to send in a single program transport stream (SPTS).",
      "pos": [
        14479,
        14549
      ]
    },
    {
      "content": "If the input stream contains multiple programs, the live encoder within the Channel parses the Program Map Table (PMT) in the input, identifies the inputs that have a stream type name of MPEG-2 AAC ADTS or AC-3 System-A or AC-3 System-B or MPEG-2 Private PES or MPEG-1 Audio or MPEG-2 Audio, and arranges them in the order specified in the PMT.",
      "pos": [
        14550,
        14894
      ]
    },
    {
      "content": "The zero-based index is then used to pick up the n-th entry in that arrangement.",
      "pos": [
        14895,
        14975
      ]
    },
    {
      "content": "Language",
      "pos": [
        14981,
        14989
      ]
    },
    {
      "content": "The language identifier of the audio stream, conforming to ISO 639-2, such as ENG.",
      "pos": [
        14991,
        15073
      ]
    },
    {
      "content": "If not present, the default is UND (undefined).",
      "pos": [
        15074,
        15121
      ]
    },
    {
      "content": "There can be up to 8 audio stream sets specified if the input to the Channel is MPEG-2 TS over RTP.",
      "pos": [
        15123,
        15222
      ]
    },
    {
      "content": "However, there can be no two entries with the same value of Index.",
      "pos": [
        15223,
        15289
      ]
    },
    {
      "pos": [
        15294,
        15326
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"preset\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>System Preset"
    },
    {
      "content": "Specifies the preset to be used by the live encoder within this Channel.",
      "pos": [
        15328,
        15400
      ]
    },
    {
      "content": "Currently, the only allowed value is <bpt id=\"p1\">**</bpt>Default720p<ept id=\"p1\">**</ept> (default).",
      "pos": [
        15401,
        15464
      ]
    },
    {
      "pos": [
        15466,
        15532
      ],
      "content": "<bpt id=\"p1\">**</bpt>Default720p<ept id=\"p1\">**</ept> will encode the video into the following 7 layers."
    },
    {
      "content": "Output Video Stream",
      "pos": [
        15539,
        15558
      ]
    },
    {
      "content": "BitRate",
      "pos": [
        15560,
        15567
      ]
    },
    {
      "content": "Width",
      "pos": [
        15568,
        15573
      ]
    },
    {
      "content": "Height",
      "pos": [
        15574,
        15580
      ]
    },
    {
      "content": "MaxFPS",
      "pos": [
        15581,
        15587
      ]
    },
    {
      "content": "Profile",
      "pos": [
        15588,
        15595
      ]
    },
    {
      "content": "Output Stream Name",
      "pos": [
        15596,
        15614
      ]
    },
    {
      "content": "3500",
      "pos": [
        15639,
        15643
      ]
    },
    {
      "content": "1280",
      "pos": [
        15644,
        15648
      ]
    },
    {
      "content": "720",
      "pos": [
        15649,
        15652
      ]
    },
    {
      "content": "30",
      "pos": [
        15653,
        15655
      ]
    },
    {
      "content": "High",
      "pos": [
        15656,
        15660
      ]
    },
    {
      "content": "Video_1280x720_30fps_3500kbps",
      "pos": [
        15661,
        15690
      ]
    },
    {
      "content": "2200",
      "pos": [
        15691,
        15695
      ]
    },
    {
      "content": "960",
      "pos": [
        15696,
        15699
      ]
    },
    {
      "content": "540",
      "pos": [
        15700,
        15703
      ]
    },
    {
      "content": "30",
      "pos": [
        15704,
        15706
      ]
    },
    {
      "content": "Main",
      "pos": [
        15707,
        15711
      ]
    },
    {
      "content": "Video_960x540_30fps_2200kbps",
      "pos": [
        15712,
        15740
      ]
    },
    {
      "content": "1350",
      "pos": [
        15741,
        15745
      ]
    },
    {
      "content": "704",
      "pos": [
        15746,
        15749
      ]
    },
    {
      "content": "396",
      "pos": [
        15750,
        15753
      ]
    },
    {
      "content": "30",
      "pos": [
        15754,
        15756
      ]
    },
    {
      "content": "Main",
      "pos": [
        15757,
        15761
      ]
    },
    {
      "content": "Video_704x396_30fps_1350kbps",
      "pos": [
        15762,
        15790
      ]
    },
    {
      "content": "850",
      "pos": [
        15791,
        15794
      ]
    },
    {
      "content": "512",
      "pos": [
        15795,
        15798
      ]
    },
    {
      "content": "288",
      "pos": [
        15799,
        15802
      ]
    },
    {
      "content": "30",
      "pos": [
        15803,
        15805
      ]
    },
    {
      "content": "Main",
      "pos": [
        15806,
        15810
      ]
    },
    {
      "content": "Video_512x288_30fps_850kbps",
      "pos": [
        15811,
        15838
      ]
    },
    {
      "content": "550",
      "pos": [
        15839,
        15842
      ]
    },
    {
      "content": "384",
      "pos": [
        15843,
        15846
      ]
    },
    {
      "content": "216",
      "pos": [
        15847,
        15850
      ]
    },
    {
      "content": "30",
      "pos": [
        15851,
        15853
      ]
    },
    {
      "content": "Main",
      "pos": [
        15854,
        15858
      ]
    },
    {
      "content": "Video_384x216_30fps_550kbps",
      "pos": [
        15859,
        15886
      ]
    },
    {
      "content": "350",
      "pos": [
        15887,
        15890
      ]
    },
    {
      "content": "340",
      "pos": [
        15891,
        15894
      ]
    },
    {
      "content": "192",
      "pos": [
        15895,
        15898
      ]
    },
    {
      "content": "30",
      "pos": [
        15899,
        15901
      ]
    },
    {
      "content": "Baseline",
      "pos": [
        15902,
        15910
      ]
    },
    {
      "content": "Video_340x192_30fps_350kbps",
      "pos": [
        15911,
        15938
      ]
    },
    {
      "content": "200",
      "pos": [
        15939,
        15942
      ]
    },
    {
      "content": "340",
      "pos": [
        15943,
        15946
      ]
    },
    {
      "content": "192",
      "pos": [
        15947,
        15950
      ]
    },
    {
      "content": "30",
      "pos": [
        15951,
        15953
      ]
    },
    {
      "content": "Baseline",
      "pos": [
        15954,
        15962
      ]
    },
    {
      "content": "Video_340x192_30fps_200kbps",
      "pos": [
        15963,
        15990
      ]
    },
    {
      "content": "Output Audio Stream",
      "pos": [
        15997,
        16016
      ]
    },
    {
      "content": "Audio is encoded to stereo AAC-LC at 64 kbps, sampling rate of 44.1 kHz.",
      "pos": [
        16018,
        16090
      ]
    },
    {
      "content": "Signaling Advertisements",
      "pos": [
        16094,
        16118
      ]
    },
    {
      "content": "When your Channel has Live Encoding enabled, you have a component in your pipeline that is processing video, and can manipulate it.",
      "pos": [
        16120,
        16251
      ]
    },
    {
      "content": "You can signal for the Channel to insert slates and/or advertisements into the outgoing adaptive bitrate stream.",
      "pos": [
        16252,
        16364
      ]
    },
    {
      "content": "Slates are still images that you can use to cover up the input live feed in certain cases (for example during a commercial break).",
      "pos": [
        16365,
        16495
      ]
    },
    {
      "content": "Advertising signals, are time-synchronized signals you embed into the outgoing stream to tell the video player to take special action – such as to switch to an advertisement at the appropriate time.",
      "pos": [
        16496,
        16694
      ]
    },
    {
      "content": "See this <bpt id=\"p1\">[</bpt>blog<ept id=\"p1\">](https://codesequoia.wordpress.com/2014/02/24/understanding-scte-35/)</ept> for an overview of the SCTE-35 signaling mechanism used for this purpose.",
      "pos": [
        16695,
        16853
      ]
    },
    {
      "content": "Below is a typical scenario you could implement in your live event.",
      "pos": [
        16854,
        16921
      ]
    },
    {
      "content": "Have your viewers get a PRE-EVENT image before the event starts.",
      "pos": [
        16926,
        16990
      ]
    },
    {
      "content": "Have your viewers get a POST-EVENT image after the event ends.",
      "pos": [
        16994,
        17056
      ]
    },
    {
      "content": "Have your viewers get an ERROR-EVENT image if there is a problem during the event (for example, power failure in the stadium).",
      "pos": [
        17060,
        17186
      ]
    },
    {
      "content": "Send an AD-BREAK image to hide the live event feed during a commercial break.",
      "pos": [
        17190,
        17267
      ]
    },
    {
      "content": "The following are the properties you can set when signaling advertisements.",
      "pos": [
        17269,
        17344
      ]
    },
    {
      "content": "Duration",
      "pos": [
        17350,
        17358
      ]
    },
    {
      "content": "The duration, in seconds, of the commercial break.",
      "pos": [
        17360,
        17410
      ]
    },
    {
      "content": "This has to be a non-zero positive value in order to start the commercial break.",
      "pos": [
        17411,
        17491
      ]
    },
    {
      "content": "When a commercial break is in progress, and the duration is set to zero with the CueId matching the on-going commercial break, then that break is canceled.",
      "pos": [
        17492,
        17647
      ]
    },
    {
      "content": "CueId",
      "pos": [
        17652,
        17657
      ]
    },
    {
      "content": "A Unique ID for the commercial break, to be used by downstream application to take appropriate action(s).",
      "pos": [
        17659,
        17764
      ]
    },
    {
      "content": "Needs to be a positive integer.",
      "pos": [
        17765,
        17796
      ]
    },
    {
      "content": "You can set this value to any random positive integer or use an upstream system to track the Cue Ids.",
      "pos": [
        17797,
        17898
      ]
    },
    {
      "content": "Make certain to normalize any ids to positive integers before submitting through the API.",
      "pos": [
        17899,
        17988
      ]
    },
    {
      "content": "Show slate",
      "pos": [
        17993,
        18003
      ]
    },
    {
      "content": "Optional.",
      "pos": [
        18005,
        18014
      ]
    },
    {
      "content": "Signals the live encoder to switch to the <bpt id=\"p1\">[</bpt>default slate<ept id=\"p1\">](media-services-manage-live-encoder-enabled-channels.md#default_slate)</ept> image during a commercial break and hide the incoming video feed.",
      "pos": [
        18015,
        18208
      ]
    },
    {
      "content": "Audio is also muted during slate.",
      "pos": [
        18209,
        18242
      ]
    },
    {
      "content": "Default is <bpt id=\"p1\">**</bpt>false<ept id=\"p1\">**</ept>.",
      "pos": [
        18243,
        18264
      ]
    },
    {
      "content": "The image used will be the one specified via the default slate asset Id property at the time of the channel creation.",
      "pos": [
        18268,
        18385
      ]
    },
    {
      "content": "The slate will be stretched to fit the display image size.",
      "pos": [
        18387,
        18445
      ]
    },
    {
      "content": "Insert Slate  images",
      "pos": [
        18451,
        18471
      ]
    },
    {
      "content": "The live encoder within the Channel can be signaled to switch to a slate image.",
      "pos": [
        18473,
        18552
      ]
    },
    {
      "content": "It can also be signaled to end an on-going slate.",
      "pos": [
        18553,
        18602
      ]
    },
    {
      "content": "The live encoder can be configured to switch to a slate image and hide the incoming video signal in certain situations – for example, during an ad break.",
      "pos": [
        18605,
        18758
      ]
    },
    {
      "content": "If such a slate is not configured, input video is not masked during that ad break.",
      "pos": [
        18759,
        18841
      ]
    },
    {
      "content": "Duration",
      "pos": [
        18846,
        18854
      ]
    },
    {
      "content": "The duration of the slate in seconds.",
      "pos": [
        18856,
        18893
      ]
    },
    {
      "content": "This has to be a non-zero positive value in order to start the slate.",
      "pos": [
        18894,
        18963
      ]
    },
    {
      "content": "If there is an on-going slate, and a duration of zero is specified, then that on-going slate will be terminated.",
      "pos": [
        18964,
        19076
      ]
    },
    {
      "content": "Insert slate on ad marker",
      "pos": [
        19081,
        19106
      ]
    },
    {
      "content": "When set to true, this setting configures the live encoder to insert a slate image during an ad break.",
      "pos": [
        19108,
        19210
      ]
    },
    {
      "content": "The default value is true.",
      "pos": [
        19211,
        19237
      ]
    },
    {
      "pos": [
        19243,
        19291
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"default_slate\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Default slate Asset Id"
    },
    {
      "content": "Optional.",
      "pos": [
        19293,
        19302
      ]
    },
    {
      "content": "Specifies the Asset Id of the Media Services Asset which contains the slate image.",
      "pos": [
        19303,
        19385
      ]
    },
    {
      "content": "Default is null.",
      "pos": [
        19386,
        19402
      ]
    },
    {
      "pos": [
        19405,
        19572
      ],
      "content": "<bpt id=\"p1\">**</bpt>Note<ept id=\"p1\">**</ept>: Before creating the Channel, the slate image with the following constraints should be uploaded as a dedicated asset (no other files should be in this asset)."
    },
    {
      "content": "At most 1920x1080 in resolution.",
      "pos": [
        19577,
        19609
      ]
    },
    {
      "content": "At most 3 Mbytes in size.",
      "pos": [
        19612,
        19637
      ]
    },
    {
      "content": "The file name must have a *.jpg extension.",
      "pos": [
        19640,
        19682
      ]
    },
    {
      "content": "The image must be uploaded into an Asset as the only AssetFile in that Asset and this AssetFile should be marked as the primary file.",
      "pos": [
        19685,
        19818
      ]
    },
    {
      "content": "The Asset cannot be storage encrypted.",
      "pos": [
        19819,
        19857
      ]
    },
    {
      "content": "If the <bpt id=\"p1\">**</bpt>default slate Asset Id<ept id=\"p1\">**</ept> is not specified, and <bpt id=\"p2\">**</bpt>insert slate on ad marker<ept id=\"p2\">**</ept> is set to <bpt id=\"p3\">**</bpt>true<ept id=\"p3\">**</ept>, a default Azure Media Services image will be used to hide the input video stream.",
      "pos": [
        19859,
        20046
      ]
    },
    {
      "content": "Audio is also muted during slate.",
      "pos": [
        20047,
        20080
      ]
    },
    {
      "content": "Channel's programs",
      "pos": [
        20086,
        20104
      ]
    },
    {
      "content": "A channel is associated with programs that enable you to control the publishing and storage of segments in a live stream.",
      "pos": [
        20106,
        20227
      ]
    },
    {
      "content": "Channels manage Programs.",
      "pos": [
        20228,
        20253
      ]
    },
    {
      "content": "The Channel and Program relationship is very similar to traditional media where a Channel has a constant stream of content and a program is scoped to some timed event on that Channel.",
      "pos": [
        20254,
        20437
      ]
    },
    {
      "content": "You can specify the number of hours you want to retain the recorded content for the program by setting the <bpt id=\"p1\">**</bpt>Archive Window<ept id=\"p1\">**</ept> length.",
      "pos": [
        20439,
        20572
      ]
    },
    {
      "content": "This value can be set from a minimum of 5 minutes to a maximum of 25 hours.",
      "pos": [
        20573,
        20648
      ]
    },
    {
      "content": "Archive window length also dictates the maximum amount of time clients can seek back in time from the current live position.",
      "pos": [
        20649,
        20773
      ]
    },
    {
      "content": "Programs can run over the specified amount of time, but content that falls behind the window length is continuously discarded.",
      "pos": [
        20774,
        20900
      ]
    },
    {
      "content": "This value of this property also determines how long the client manifests can grow.",
      "pos": [
        20901,
        20984
      ]
    },
    {
      "content": "Each program is associated with an Asset which stores the streamed content.",
      "pos": [
        20986,
        21061
      ]
    },
    {
      "content": "An asset is mapped to a blob container in the Azure Storage account and the files in the asset are stored as blobs in that container.",
      "pos": [
        21062,
        21195
      ]
    },
    {
      "content": "To publish the program so your customers can view the stream you must create an OnDemand locator for the associated asset.",
      "pos": [
        21196,
        21318
      ]
    },
    {
      "content": "Having this locator will enable you to build a streaming URL that you can provide to your clients.",
      "pos": [
        21319,
        21417
      ]
    },
    {
      "content": "A Channel supports up to three concurrently running programs so you can create multiple archives of the same incoming stream.",
      "pos": [
        21419,
        21544
      ]
    },
    {
      "content": "This allows you to publish and archive different parts of an event as needed.",
      "pos": [
        21545,
        21622
      ]
    },
    {
      "content": "For example, your business requirement is to archive 6 hours of a program, but to broadcast only last 10 minutes.",
      "pos": [
        21623,
        21736
      ]
    },
    {
      "content": "To accomplish this, you need to create two concurrently running programs.",
      "pos": [
        21737,
        21810
      ]
    },
    {
      "content": "One program is set to archive 6 hours of the event but the program is not published.",
      "pos": [
        21811,
        21895
      ]
    },
    {
      "content": "The other program is set to archive for 10 minutes and this program is published.",
      "pos": [
        21896,
        21977
      ]
    },
    {
      "content": "You should not reuse existing programs for new events.",
      "pos": [
        21979,
        22033
      ]
    },
    {
      "content": "Instead, create and start a new program for each event as described in the Programming Live Streaming Applications section.",
      "pos": [
        22034,
        22157
      ]
    },
    {
      "content": "Start the program when you are ready to start streaming and archiving.",
      "pos": [
        22159,
        22229
      ]
    },
    {
      "content": "Stop the program whenever you want to stop streaming and archiving the event.",
      "pos": [
        22230,
        22307
      ]
    },
    {
      "content": "To delete archived content, stop and delete the program and then delete the associated asset.",
      "pos": [
        22310,
        22403
      ]
    },
    {
      "content": "An asset cannot be deleted if it is used by a program; the program must be deleted first.",
      "pos": [
        22404,
        22493
      ]
    },
    {
      "content": "Even after you stop and delete the program, the users would be able to stream your archived content as a video on demand, for as long as you do not delete the asset.",
      "pos": [
        22496,
        22661
      ]
    },
    {
      "content": "If you do want to retain the archived content, but not have it available for streaming, delete the streaming locator.",
      "pos": [
        22663,
        22780
      ]
    },
    {
      "content": "Getting a thumbnail preview of a live feed",
      "pos": [
        22785,
        22827
      ]
    },
    {
      "content": "When Live Encoding is enabled, you can now get a preview of the live feed as it reaches the Channel.",
      "pos": [
        22829,
        22929
      ]
    },
    {
      "content": "This can be a valuable tool to check whether your live feed is actually reaching the Channel.",
      "pos": [
        22930,
        23023
      ]
    },
    {
      "pos": [
        23028,
        23100
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"states\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Channel states and how states map to the billing mode"
    },
    {
      "content": "The current state of a Channel.",
      "pos": [
        23103,
        23134
      ]
    },
    {
      "content": "Possible values include:",
      "pos": [
        23135,
        23159
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Stopped<ept id=\"p1\">**</ept>.",
      "pos": [
        23163,
        23175
      ]
    },
    {
      "content": "This is the initial state of the Channel after its creation.",
      "pos": [
        23176,
        23236
      ]
    },
    {
      "content": "In this state, the Channel properties can be updated but streaming is not allowed.",
      "pos": [
        23237,
        23319
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Starting<ept id=\"p1\">**</ept>.",
      "pos": [
        23322,
        23335
      ]
    },
    {
      "content": "The Channel is being started.",
      "pos": [
        23336,
        23365
      ]
    },
    {
      "content": "No updates or streaming is allowed during this state.",
      "pos": [
        23366,
        23419
      ]
    },
    {
      "content": "If an error occurs, the Channel returns to the Stopped state.",
      "pos": [
        23420,
        23481
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Running<ept id=\"p1\">**</ept>.",
      "pos": [
        23484,
        23496
      ]
    },
    {
      "content": "The Channel is capable of processing live streams.",
      "pos": [
        23497,
        23547
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Stopping<ept id=\"p1\">**</ept>.",
      "pos": [
        23550,
        23563
      ]
    },
    {
      "content": "The Channel is being stopped.",
      "pos": [
        23564,
        23593
      ]
    },
    {
      "content": "No updates or streaming is allowed during this state.",
      "pos": [
        23594,
        23647
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Deleting<ept id=\"p1\">**</ept>.",
      "pos": [
        23650,
        23663
      ]
    },
    {
      "content": "The Channel is being deleted.",
      "pos": [
        23664,
        23693
      ]
    },
    {
      "content": "No updates or streaming is allowed during this state.",
      "pos": [
        23694,
        23747
      ]
    },
    {
      "content": "The following table shows how Channel states map to the billing mode.",
      "pos": [
        23749,
        23818
      ]
    },
    {
      "content": "Channel state",
      "pos": [
        23822,
        23835
      ]
    },
    {
      "content": "Portal UI Indicators",
      "pos": [
        23836,
        23856
      ]
    },
    {
      "content": "Billed?",
      "pos": [
        23857,
        23864
      ]
    },
    {
      "content": "Starting",
      "pos": [
        23877,
        23885
      ]
    },
    {
      "content": "Starting",
      "pos": [
        23886,
        23894
      ]
    },
    {
      "content": "No (transient state)",
      "pos": [
        23895,
        23915
      ]
    },
    {
      "content": "Running",
      "pos": [
        23916,
        23923
      ]
    },
    {
      "content": "Ready (no running programs)",
      "pos": [
        23924,
        23951
      ]
    },
    {
      "content": "or",
      "pos": [
        23956,
        23958
      ]
    },
    {
      "content": "Streaming (at least one running program)",
      "pos": [
        23963,
        24003
      ]
    },
    {
      "content": "Yes",
      "pos": [
        24004,
        24007
      ]
    },
    {
      "content": "Stopping",
      "pos": [
        24008,
        24016
      ]
    },
    {
      "content": "Stopping",
      "pos": [
        24017,
        24025
      ]
    },
    {
      "content": "No (transient state)",
      "pos": [
        24026,
        24046
      ]
    },
    {
      "content": "Stopped",
      "pos": [
        24047,
        24054
      ]
    },
    {
      "content": "Stopped",
      "pos": [
        24055,
        24062
      ]
    },
    {
      "content": "No",
      "pos": [
        24063,
        24065
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Currently in Preview, the Channel start can take up to 20+ minutes.",
      "pos": [
        24069,
        24149
      ]
    },
    {
      "content": "Channel reset can take up to 5 minutes.",
      "pos": [
        24150,
        24189
      ]
    },
    {
      "pos": [
        24194,
        24235
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"Considerations\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Considerations"
    },
    {
      "content": "You cannot change the input protocol while the Channel or its associated programs are running.",
      "pos": [
        24239,
        24333
      ]
    },
    {
      "content": "If you require different protocols, you should create separate channels for each input protocol.",
      "pos": [
        24334,
        24430
      ]
    },
    {
      "content": "Every time you reconfigure the live encoder, call the <bpt id=\"p1\">**</bpt>Reset<ept id=\"p1\">**</ept> method on the channel.",
      "pos": [
        24434,
        24520
      ]
    },
    {
      "content": "Before you reset the channel, you have to stop the program.",
      "pos": [
        24521,
        24580
      ]
    },
    {
      "content": "After you reset the channel, restart the program.",
      "pos": [
        24581,
        24630
      ]
    },
    {
      "content": "A channel can be stopped only when it is in the Running state, and all programs on the channel have been stopped.",
      "pos": [
        24634,
        24747
      ]
    },
    {
      "content": "By default you can only add 5 channels to your Media Services account.",
      "pos": [
        24750,
        24820
      ]
    },
    {
      "content": "This is a soft quota on all new accounts.",
      "pos": [
        24821,
        24862
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Quotas and Limitations<ept id=\"p1\">](media-services-quotas-and-limitations.md)</ept>.",
      "pos": [
        24863,
        24956
      ]
    },
    {
      "content": "You cannot change the input protocol while the Channel or its associated programs are running.",
      "pos": [
        24959,
        25053
      ]
    },
    {
      "content": "If you require different protocols, you should create separate channels for each input protocol.",
      "pos": [
        25054,
        25150
      ]
    },
    {
      "content": "You are only billed when your Channel is in the <bpt id=\"p1\">**</bpt>Running<ept id=\"p1\">**</ept> state.",
      "pos": [
        25153,
        25219
      ]
    },
    {
      "content": "For more information, refer to <bpt id=\"p1\">[</bpt>this<ept id=\"p1\">](media-services-manage-live-encoder-enabled-channels.md#states)</ept> section.",
      "pos": [
        25220,
        25329
      ]
    },
    {
      "content": "Known Issues",
      "pos": [
        25333,
        25345
      ]
    },
    {
      "content": "Channel start up can take 20+ minutes.",
      "pos": [
        25349,
        25387
      ]
    },
    {
      "content": "RTP support is catered towards professional broadcasters.",
      "pos": [
        25390,
        25447
      ]
    },
    {
      "content": "Please review the notes on RTP in <bpt id=\"p1\">[</bpt>this<ept id=\"p1\">](http://azure.microsoft.com/blog/2015/04/13/an-introduction-to-live-encoding-with-azure-media-services/)</ept> blog.",
      "pos": [
        25448,
        25598
      ]
    },
    {
      "content": "Slate images should conform to restrictions described <bpt id=\"p1\">[</bpt>here<ept id=\"p1\">](media-services-manage-live-encoder-enabled-channels.md#default_slate)</ept>.",
      "pos": [
        25601,
        25732
      ]
    },
    {
      "content": "If you attempt create a Channel with a default slate that is larger than 1920x1080, the request will eventually error out.",
      "pos": [
        25733,
        25855
      ]
    },
    {
      "content": "How to create channels that perform live encoding from a singe bitrate to adaptive bitrate stream",
      "pos": [
        25860,
        25957
      ]
    },
    {
      "pos": [
        25960,
        26056
      ],
      "content": "Choose <bpt id=\"p1\">**</bpt>Portal<ept id=\"p1\">**</ept>, <bpt id=\"p2\">**</bpt>.NET<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>REST API<ept id=\"p3\">**</ept> to see how to create and manage channels and programs."
    },
    {
      "content": "[AZURE.SELECTOR]",
      "pos": [
        26060,
        26076
      ]
    },
    {
      "content": "Portal",
      "pos": [
        26080,
        26086
      ]
    },
    {
      "content": ".NET SDK",
      "pos": [
        26155,
        26163
      ]
    },
    {
      "content": "REST API",
      "pos": [
        26232,
        26240
      ]
    },
    {
      "content": "Related topics",
      "pos": [
        26301,
        26315
      ]
    },
    {
      "content": "Delivering Live Streaming Events with Azure Media Services",
      "pos": [
        26318,
        26376
      ]
    },
    {
      "content": "Media Services Concepts",
      "pos": [
        26423,
        26446
      ]
    },
    {
      "content": "Azure Media Services Fragmented MP4 Live Ingest Specification",
      "pos": [
        26478,
        26539
      ]
    },
    {
      "content": "test",
      "pos": [
        26705,
        26709
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Working with Channels that are Enabled to Perform Live Encoding with Azure Media Services\" \n    description=\"This topic describes how to set up a Channel that receives a single bitrate live stream from an on-premises encoder and then performs live encoding to adaptive bitrate stream with Media Services. The stream can then be delivered to client playback applications through one or more Streaming Endpoints, using one of the following adaptive streaming protocols: HLS, Smooth Stream, MPEG DASH, HDS.\" \n    services=\"media-services\" \n    documentationCenter=\"\" \n    authors=\"Juliako\" \n    manager=\"dwrede\" \n    editor=\"\"/>\n\n<tags \n    ms.service=\"media-services\" \n    ms.workload=\"media\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"ne\" \n    ms.topic=\"article\" \n    ms.date=\"08/20/2015\" \n    ms.author=\"juliako\"/>\n\n#Working with Channels that are Enabled to Perform Live Encoding with Azure Media Services (Preview)\n\n##Overview\n\nIn Azure Media Services, a **Channel** represents a pipeline for processing live streaming content. A **Channel** receives live input streams in one of two ways:\n\n- An on-premises live encoder sends multi-bitrate **RTMP** or **Smooth Streaming** (Fragmented MP4) to the Channel. You can use the following live encoders that output multi-bitrate Smooth Streaming: Elemental, Envivio, Cisco.  The following live encoders output RTMP: Adobe Flash Live, Telestream Wirecast, and Tricaster transcoders. The ingested streams pass through **Channel**s without any further processing. When requested, Media Services delivers the stream to customers.\n- A single bitrate stream (in one of the following formats: **RTP** (MPEG-TS)), **RTMP**, or **Smooth Streaming** (Fragmented MP4)) is sent to the **Channel** that is enabled to perform live encoding with Media Services. The **Channel** then performs live encoding of the incoming single bitrate stream to a multi-bitrate (adaptive) video stream. When requested, Media Services delivers the stream to customers. \n\n    Encoding a live stream with Media Services is currently in **Preview**.\n\nStarting with the Media Services 2.10 release, when you create a Channel, you can specify in which way you want for your channel to receive the input stream and whether or not you want for the channel to perform live encoding of your stream. You have two options:    \n\n- **None** – Specify this value, if you plan to use an on-premises live encoder which will output multi-bitrate stream. In this case, the incoming stream passed through to the output without any encoding. This is the behavior of a Channel prior to 2.10 release.  For more detailed information about working with channels of this type, see [Working with Channels that Receive Multi-bitrate Live Stream from On-premises Encoders](media-services-manage-channels-overview.md).\n\n- **Standard** (Preview) – Choose this value, if you plan to use Media Services to encode your single bitrate live stream to multi-bitrate stream. \n\n    Encoding a live stream with Media Services is currently in Preview.\n\n>[AZURE.NOTE]This topic discusses attributes of channels that are enabled to perform live encoding (**Standard** encoding type). For information about working with channels that are not enabled to perform live encoding, see [Working with Channels that Receive Multi-bitrate Live Stream from On-premises Encoders](media-services-manage-channels-overview.md).\n\nThe following diagram represents a live streaming workflow where a channel receives a single bitrate stream in one of the following protocols: RTMP, Smooth Streaming, or RTP (MPEG-TS); it then encodes the stream to a multi-bitrate stream. \n\n![Live workflow][live-overview]\n\n>[AZURE.NOTE]Not all data centers support Live Encoding with Azure Media Services. \n>\n>If you are using Azure Management Portal to create Channels, you will have two Channel encoding type options available: **None** and **Standard**. If you only see the **None** option, it means your data center does not support Live Encoding with AMS.\n>\n>If you are using .NET SDK or REST API, do the following to check:\n>\n>1. Try to create a Channel with encoding type set to Standard. \n>2. If the returned result HTTP Error Code 412 (Precondition Failed) with the following message: *\"Live encoding is not supported in this region; EncodingType must be set to 'None'.\"*, your data center does not support Live Encoding.\n\n\n##In this topic\n\n- Overview of a [common live streaming scenario](media-services-manage-live-encoder-enabled-channels.md#scenario)\n- [Description of a Channel and its related components](media-services-manage-live-encoder-enabled-channels.md#channel)\n- [Considerations](media-services-manage-live-encoder-enabled-channels.md#considerations)\n- [Tasks related to Live Streaming](media-services-manage-live-encoder-enabled-channels.md#tasks)\n\n##<a id=\"scenario\"></a>Common Live Streaming Scenario\n\nThe following are general steps involved in creating common live streaming applications.\n\n1. Connect a video camera to a computer. Launch and configure an on-premises live encoder that can output a **single** bitrate stream in one of the following protocols: RTMP, Smooth Streaming, or RTP (MPEG-TS). For more information, see [Azure Media Services RTMP Support and Live Encoders](http://go.microsoft.com/fwlink/?LinkId=532824).\n    \n    This step could also be performed after you create your Channel.\n\n1. Create and start a Channel. \n\n1. Retrieve the Channel ingest URL. \n\n    The ingest URL is used by the live encoder to send the stream to the Channel.\n1. Retrieve the Channel preview URL. \n\n    Use this URL to verify that your channel is properly receiving the live stream.\n\n3. Create a program. \n\n    When using the Azure Management Portal, creating a program also creates an asset. \n\n    When using .NET SDK or REST you need to create an asset and specify to use this asset when creating a Program. \n1. Publish the asset associated with the program.   \n\n    Make sure to have at least one streaming reserved unit on the streaming endpoint from which you want to stream content.\n1. Start the program when you are ready to start streaming and archiving.\n2. Optionally, the live encoder can be signaled to start an advertisement. The advertisement is inserted in the output stream.\n1. Stop the program whenever you want to stop streaming and archiving the event.\n1. Delete the Program (and optionally delete the asset).   \n\nThe [live streaming tasks](media-services-manage-channels-overview.md#tasks) section links to topics that demonstrate how to achieve tasks described above.\n\n\n##<a id=\"channel\"></a>Channel's input (ingest) configurations\n\n###<a id=\"Ingest_Protocols\"></a>Ingest streaming protocol\n\nIf the **Encoder Type** is set to **Standard**, valid options are:\n\n- **RTP** (MPEG-TS): MPEG-2 Transport Stream over RTP.  \n- Single bitrate **RTMP**\n- Single bitrate **Fragmented MP4** (Smooth Streaming)\n\nFor more information, see [Azure Media Services RTMP Support and Live Encoders](http://go.microsoft.com/fwlink/?LinkId=532824).\n\n####RTP (MPEG-TS) - MPEG-2 Transport Stream over RTP.  \n\nTypical use case: \n\nProfessional broadcasters typically work with high-end on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme, Imagine or Envivio to send a stream. Often used in conjunction with  an IT department and private networks.\n\nConsiderations:\n\n- The use of a single program transport stream (SPTS) input is strongly recommended. The use of multiple language audio tracks, however, is supported\n- The video stream should have an average bitrate below 15 Mbps\n- The aggregate average bitrate of the audio streams should be below 1 Mbps\n- Following are the supported codecs:\n    - MPEG-2 / H.262 Video \n        \n        - Main Profile (4:2:0)\n        - High Profile (4:2:0, 4:2:2)\n        - 422 Profile (4:2:0, 4:2:2)\n\n    - MPEG-4 AVC / H.264 Video  \n    \n        - Baseline, Main, High Profile (8-bit 4:2:0)\n        - High 10 Profile (10-bit 4:2:0)\n        - High 422 Profile (10-bit 4:2:2)\n\n\n    - MPEG-2 AAC-LC Audio \n    \n        - Mono, Stereo, Surround (5.1, 7.1)\n        - MPEG-2 style ADTS packaging\n\n    - Dolby Digital (AC-3) Audio \n\n        - Mono, Stereo, Surround (5.1, 7.1)\n\n    - MPEG Audio (Layer II and III) \n            \n        - Mono, Stereo\n\n- Recommended broadcast encoders include:\n    - Ateme AM2102\n    - Ericsson AVP2000\n    - eVertz 3480\n    - Ericsson RX8200\n    - Imagine Communications Selenio ENC 1\n    - Imagine Communications Selenio ENC 2\n    - AdTec EN-30\n    - AdTec EN-91P\n    - AdTec EN-100\n    - Harmonic ProStream 1000\n    - Thor H-2 4HD-EM\n    - eVertz 7880 SLKE\n    - Cisco Spinnaker\n    - Elemental Live\n\n####<a id=\"single_bitrate_RTMP\"></a>Single bitrate RTMP\n\nConsiderations:\n\n- The incoming stream cannot contain multi-bitrate video\n- The video stream should have an average bitrate below 15 Mbps\n- The audio stream should have an average bitrate below 1 Mbps\n- Following are the supported codecs:\n\n    - MPEG-4 AVC / H.264 Video  \n    \n        - Baseline, Main, High Profile (8-bit 4:2:0)\n        - High 10 Profile (10-bit 4:2:0)\n        - High 422 Profile (10-bit 4:2:2)\n\n    - MPEG-2 AAC-LC Audio\n\n        - Mono, Stereo, Surround (5.1, 7.1)\n        - 44.1 kHz sampling rate\n        - MPEG-2 style ADTS packaging\n    \n- Recommended encoders include: \n\n    - Telestream Wirecast\n    - Flash Media Live Encoder\n    - Tricaster\n\n####Single bitrate Fragmented MP4 (Smooth Streaming)\n\nTypical use case: \n\nUse on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme, Envivio to send the input stream over the open internet to a nearby Azure data center.\n\nConsiderations:\n\nSame as for [single bitrate RTMP](media-services-manage-live-encoder-enabled-channels.md#single_bitrate_RTMP).\n\n####Other considerations\n\n- You cannot change the input protocol while the Channel or its associated programs are running. If you require different protocols, you should create separate channels for each input protocol. \n- Maximum resolution for the incoming video stream is 1920x1080, and at most 60 fields/second if interlaced, or 30 frames/second if progressive.\n\n\n###Ingest URLs (endpoints) \n\nA Channel provides an input endpoint (ingest URL) that you specify in the live encoder, so the encoder can push streams to your Channels.   \n\nYou can get the ingest URLs once you create a Channel. To get these URLs, the Channel does not have to be in the **Running** state. When you are ready to start pushing data into the Channel, it must be in the **Running** state. Once the Channel starts ingesting data, you can preview your stream through the preview URL.\n\nYou have an option of ingesting Fragmented MP4 (Smooth Streaming) live stream over an SSL connection. To ingest over SSL, make sure to update the ingest URL to HTTPS. \n\n###Allowed IP addresses\n\nYou can define the IP addresses that are allowed to publish video to this channel. Allowed IP addresses can be specified as either a single IP address (e.g. ‘10.0.0.1’), an IP range using an IP address and a CIDR subnet mask (e.g. ‘10.0.0.1/22’), or an IP range using an IP address and a dotted decimal subnet mask (e.g. ‘10.0.0.1(255.255.252.0)’). \n\nIf no IP addresses are specified and there is no rule definition then no IP address will be allowed. To allow any IP address, create a rule and set 0.0.0.0/0.\n\n\n##Channel preview \n\n###Preview URLs\n\nChannels provide a preview endpoint (preview URL) that you use to preview and validate your stream before further processing and delivery.\n\nYou can get the preview URL when you create the channel. To get the URL, the channel does not have to be in the **Running** state. \n\nOnce the Channel starts ingesting data, you can preview your stream.\n\n**Note** Currently the preview stream can only be delivered in Fragmented MP4 (Smooth Streaming) format regardless of the specified input type. You can use the [http://smf.cloudapp.net/healthmonitor](http://smf.cloudapp.net/healthmonitor) player to test the Smooth Stream. You can also use a player hosted in the Azure Management Portal to view your stream.\n\n###Allowed IP Addresses\n\nYou can define the IP addresses that are allowed to connect to the preview endpoint. If no IP addresses are specified any IP address will be allowed. Allowed IP addresses can be specified as either a single IP address (e.g. ‘10.0.0.1’), an IP range using an IP address and a CIDR subnet mask (e.g. ‘10.0.0.1/22’), or an IP range using an IP address and a dotted decimal subnet mask (e.g. ‘10.0.0.1(255.255.252.0)’).\n\n##Live encoding settings\n\nThis section describes how the settings for the live encoder within the Channel can be adjusted, when the **Encoding Type** of a Channel is set to **Standard**.\n\n###Ad marker source\n\nYou can specify the source for ad markers signals. Default value is **Api**, which indicates that the live encoder within the Channel should listen to an asynchronous **Ad Marker API**. \n\nThe other valid option is **Scte35** (allowed only if the ingest streaming protocol is set to RTP (MPEG-TS). When Scte35 is specified, the live encoder will parse SCTE-35 signals from the input RTP (MPEG-TS) stream. \n\n###CEA 708 Closed Captions\n\nAn optional flag which tells the live encoder to ignore any CEA 708 captions data embedded in the incoming video. When the flag is set to false (default), the encoder will detect and re-insert CEA 708 data into the output video streams.\n\n###Video Stream\n\nOptional. Describes the input video stream. If this field is not specified, the default value is used. This setting is allowed only if the input streaming protocol is set to RTP (MPEG-TS).\n\n####Index\n\nA zero-based index that specifies which input video stream should be processed by the live encoder within the Channel. This setting applies only if ingest streaming protocol is RTP (MPEG-TS). \n\nDefault value is zero. It is recommended to send in a single program transport stream (SPTS). If the input stream contains multiple programs, the live encoder parses the Program Map Table (PMT) in the input, identifies the inputs that have a stream type name of MPEG-2 Video or H.264, and arranges them in the order specified in the PMT. The zero-based index is then used to pick up the n-th entry in that arrangement. \n\n###Audio Stream\n\nOptional. Describes the input audio streams. If this field is not specified, the default values specified apply. This setting is allowed only if the input streaming protocol is set to RTP (MPEG-TS).\n\n####Index\n\nIt is recommended to send in a single program transport stream (SPTS). If the input stream contains multiple programs, the live encoder within the Channel parses the Program Map Table (PMT) in the input, identifies the inputs that have a stream type name of MPEG-2 AAC ADTS or AC-3 System-A or AC-3 System-B or MPEG-2 Private PES or MPEG-1 Audio or MPEG-2 Audio, and arranges them in the order specified in the PMT. The zero-based index is then used to pick up the n-th entry in that arrangement.\n\n####Language\n\nThe language identifier of the audio stream, conforming to ISO 639-2, such as ENG. If not present, the default is UND (undefined).\n\nThere can be up to 8 audio stream sets specified if the input to the Channel is MPEG-2 TS over RTP. However, there can be no two entries with the same value of Index.\n\n###<a id=\"preset\"></a>System Preset\n\nSpecifies the preset to be used by the live encoder within this Channel. Currently, the only allowed value is **Default720p** (default).\n\n**Default720p** will encode the video into the following 7 layers.\n\n\n####Output Video Stream\n\nBitRate|Width|Height|MaxFPS|Profile|Output Stream Name\n---|---|---|---|---|---\n3500|1280|720|30|High|Video_1280x720_30fps_3500kbps\n2200|960|540|30|Main|Video_960x540_30fps_2200kbps\n1350|704|396|30|Main|Video_704x396_30fps_1350kbps\n850|512|288|30|Main|Video_512x288_30fps_850kbps\n550|384|216|30|Main|Video_384x216_30fps_550kbps\n350|340|192|30|Baseline|Video_340x192_30fps_350kbps\n200|340|192|30|Baseline|Video_340x192_30fps_200kbps\n\n\n####Output Audio Stream\n\nAudio is encoded to stereo AAC-LC at 64 kbps, sampling rate of 44.1 kHz.\n\n##Signaling Advertisements\n\nWhen your Channel has Live Encoding enabled, you have a component in your pipeline that is processing video, and can manipulate it. You can signal for the Channel to insert slates and/or advertisements into the outgoing adaptive bitrate stream. Slates are still images that you can use to cover up the input live feed in certain cases (for example during a commercial break). Advertising signals, are time-synchronized signals you embed into the outgoing stream to tell the video player to take special action – such as to switch to an advertisement at the appropriate time. See this [blog](https://codesequoia.wordpress.com/2014/02/24/understanding-scte-35/) for an overview of the SCTE-35 signaling mechanism used for this purpose. Below is a typical scenario you could implement in your live event.\n\n1. Have your viewers get a PRE-EVENT image before the event starts.\n1. Have your viewers get a POST-EVENT image after the event ends.\n1. Have your viewers get an ERROR-EVENT image if there is a problem during the event (for example, power failure in the stadium).\n1. Send an AD-BREAK image to hide the live event feed during a commercial break.\n\nThe following are the properties you can set when signaling advertisements. \n\n###Duration\n\nThe duration, in seconds, of the commercial break. This has to be a non-zero positive value in order to start the commercial break. When a commercial break is in progress, and the duration is set to zero with the CueId matching the on-going commercial break, then that break is canceled.\n\n###CueId\n\nA Unique ID for the commercial break, to be used by downstream application to take appropriate action(s). Needs to be a positive integer. You can set this value to any random positive integer or use an upstream system to track the Cue Ids. Make certain to normalize any ids to positive integers before submitting through the API.\n\n###Show slate\n\nOptional. Signals the live encoder to switch to the [default slate](media-services-manage-live-encoder-enabled-channels.md#default_slate) image during a commercial break and hide the incoming video feed. Audio is also muted during slate. Default is **false**. \n \nThe image used will be the one specified via the default slate asset Id property at the time of the channel creation. \nThe slate will be stretched to fit the display image size. \n\n\n##Insert Slate  images\n\nThe live encoder within the Channel can be signaled to switch to a slate image. It can also be signaled to end an on-going slate. \n\nThe live encoder can be configured to switch to a slate image and hide the incoming video signal in certain situations – for example, during an ad break. If such a slate is not configured, input video is not masked during that ad break.\n\n###Duration\n\nThe duration of the slate in seconds. This has to be a non-zero positive value in order to start the slate. If there is an on-going slate, and a duration of zero is specified, then that on-going slate will be terminated.\n\n###Insert slate on ad marker\n\nWhen set to true, this setting configures the live encoder to insert a slate image during an ad break. The default value is true. \n\n###<a id=\"default_slate\"></a>Default slate Asset Id\n\nOptional. Specifies the Asset Id of the Media Services Asset which contains the slate image. Default is null. \n\n**Note**: Before creating the Channel, the slate image with the following constraints should be uploaded as a dedicated asset (no other files should be in this asset). \n\n- At most 1920x1080 in resolution.\n- At most 3 Mbytes in size.\n- The file name must have a *.jpg extension.\n- The image must be uploaded into an Asset as the only AssetFile in that Asset and this AssetFile should be marked as the primary file. The Asset cannot be storage encrypted.\n\nIf the **default slate Asset Id** is not specified, and **insert slate on ad marker** is set to **true**, a default Azure Media Services image will be used to hide the input video stream. Audio is also muted during slate. \n\n\n##Channel's programs\n\nA channel is associated with programs that enable you to control the publishing and storage of segments in a live stream. Channels manage Programs. The Channel and Program relationship is very similar to traditional media where a Channel has a constant stream of content and a program is scoped to some timed event on that Channel.\n\nYou can specify the number of hours you want to retain the recorded content for the program by setting the **Archive Window** length. This value can be set from a minimum of 5 minutes to a maximum of 25 hours. Archive window length also dictates the maximum amount of time clients can seek back in time from the current live position. Programs can run over the specified amount of time, but content that falls behind the window length is continuously discarded. This value of this property also determines how long the client manifests can grow.\n\nEach program is associated with an Asset which stores the streamed content. An asset is mapped to a blob container in the Azure Storage account and the files in the asset are stored as blobs in that container. To publish the program so your customers can view the stream you must create an OnDemand locator for the associated asset. Having this locator will enable you to build a streaming URL that you can provide to your clients.\n\nA Channel supports up to three concurrently running programs so you can create multiple archives of the same incoming stream. This allows you to publish and archive different parts of an event as needed. For example, your business requirement is to archive 6 hours of a program, but to broadcast only last 10 minutes. To accomplish this, you need to create two concurrently running programs. One program is set to archive 6 hours of the event but the program is not published. The other program is set to archive for 10 minutes and this program is published.\n\nYou should not reuse existing programs for new events. Instead, create and start a new program for each event as described in the Programming Live Streaming Applications section.\n\nStart the program when you are ready to start streaming and archiving. Stop the program whenever you want to stop streaming and archiving the event. \n\nTo delete archived content, stop and delete the program and then delete the associated asset. An asset cannot be deleted if it is used by a program; the program must be deleted first. \n\nEven after you stop and delete the program, the users would be able to stream your archived content as a video on demand, for as long as you do not delete the asset.\n\nIf you do want to retain the archived content, but not have it available for streaming, delete the streaming locator.\n\n\n##Getting a thumbnail preview of a live feed\n\nWhen Live Encoding is enabled, you can now get a preview of the live feed as it reaches the Channel. This can be a valuable tool to check whether your live feed is actually reaching the Channel. \n\n##<a id=\"states\"></a>Channel states and how states map to the billing mode \n\nThe current state of a Channel. Possible values include:\n\n- **Stopped**. This is the initial state of the Channel after its creation. In this state, the Channel properties can be updated but streaming is not allowed.\n- **Starting**. The Channel is being started. No updates or streaming is allowed during this state. If an error occurs, the Channel returns to the Stopped state.\n- **Running**. The Channel is capable of processing live streams.\n- **Stopping**. The Channel is being stopped. No updates or streaming is allowed during this state.\n- **Deleting**. The Channel is being deleted. No updates or streaming is allowed during this state.\n\nThe following table shows how Channel states map to the billing mode. \n \nChannel state|Portal UI Indicators|Billed?\n---|---|---\nStarting|Starting|No (transient state)\nRunning|Ready (no running programs)<br/>or<br/>Streaming (at least one running program)|Yes\nStopping|Stopping|No (transient state)\nStopped|Stopped|No\n\n\n>[AZURE.NOTE] Currently in Preview, the Channel start can take up to 20+ minutes. Channel reset can take up to 5 minutes.\n\n\n##<a id=\"Considerations\"></a>Considerations\n\n- You cannot change the input protocol while the Channel or its associated programs are running. If you require different protocols, you should create separate channels for each input protocol. \n- Every time you reconfigure the live encoder, call the **Reset** method on the channel. Before you reset the channel, you have to stop the program. After you reset the channel, restart the program. \n- A channel can be stopped only when it is in the Running state, and all programs on the channel have been stopped.\n- By default you can only add 5 channels to your Media Services account. This is a soft quota on all new accounts. For more information, see [Quotas and Limitations](media-services-quotas-and-limitations.md).\n- You cannot change the input protocol while the Channel or its associated programs are running. If you require different protocols, you should create separate channels for each input protocol.\n- You are only billed when your Channel is in the **Running** state. For more information, refer to [this](media-services-manage-live-encoder-enabled-channels.md#states) section.\n\n##Known Issues\n\n- Channel start up can take 20+ minutes.\n- RTP support is catered towards professional broadcasters. Please review the notes on RTP in [this](http://azure.microsoft.com/blog/2015/04/13/an-introduction-to-live-encoding-with-azure-media-services/) blog.\n- Slate images should conform to restrictions described [here](media-services-manage-live-encoder-enabled-channels.md#default_slate). If you attempt create a Channel with a default slate that is larger than 1920x1080, the request will eventually error out.\n\n###How to create channels that perform live encoding from a singe bitrate to adaptive bitrate stream \n\nChoose **Portal**, **.NET**, **REST API** to see how to create and manage channels and programs.\n\n> [AZURE.SELECTOR]\n- [Portal](media-services-portal-creating-live-encoder-enabled-channel.md)\n- [.NET SDK](media-services-dotnet-creating-live-encoder-enabled-channel.md)\n- [REST API](https://msdn.microsoft.com/library/azure/dn783458.aspx)\n\n##Related topics\n\n[Delivering Live Streaming Events with Azure Media Services](media-services-live-streaming-workflow.md)\n\n[Media Services Concepts](media-services-concepts.md)\n\n[Azure Media Services Fragmented MP4 Live Ingest Specification](media-services-fmp4-live-ingest-overview.md)\n\n[live-overview]: ./media/media-services-manage-live-encoder-enabled-channels/media-services-live-streaming-new.png\n \n\ntest\n"
}