{
  "nodes": [
    {
      "content": "Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure",
      "pos": [
        28,
        128
      ]
    },
    {
      "content": "Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance.",
      "pos": [
        148,
        241
      ]
    },
    {
      "content": "Manage resources for the Apache Spark cluster in Azure HDInsight",
      "pos": [
        582,
        646
      ]
    },
    {
      "content": "Resource manager is a component of the Spark cluster dashboard that enables you to manage resources such as cores and RAM used by each application running on the cluster.",
      "pos": [
        648,
        818
      ]
    },
    {
      "pos": [
        823,
        883
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"launchrm\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>How do I launch the Resource Manager?"
    },
    {
      "content": "From the <bpt id=\"p1\">[</bpt>Azure Preview Portal<ept id=\"p1\">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).",
      "pos": [
        888,
        1047
      ]
    },
    {
      "content": "You can also navigate to your cluster under <bpt id=\"p1\">**</bpt>Browse All<ept id=\"p1\">**</ept> &gt; <bpt id=\"p2\">**</bpt>HDInsight Clusters<ept id=\"p2\">**</ept>.",
      "pos": [
        1048,
        1132
      ]
    },
    {
      "content": "From the Spark cluster blade, click <bpt id=\"p1\">**</bpt>Dashboard<ept id=\"p1\">**</ept>.",
      "pos": [
        1139,
        1189
      ]
    },
    {
      "content": "When prompted, enter the admin credentials for the Spark cluster.",
      "pos": [
        1190,
        1255
      ]
    },
    {
      "content": "Launch Resource Manager",
      "pos": [
        1263,
        1286
      ]
    },
    {
      "pos": [
        1401,
        1480
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"scenariosrm\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>How do I fix these issues using the Resource Manager?"
    },
    {
      "content": "Here are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Resource Manager.",
      "pos": [
        1482,
        1634
      ]
    },
    {
      "content": "My Spark cluster on HDInsight is slow",
      "pos": [
        1640,
        1677
      ]
    },
    {
      "content": "Apache Spark cluster in HDInsight is designed for multi-tenancy, so resources are split across multiple components (notebooks, job server, etc).",
      "pos": [
        1679,
        1823
      ]
    },
    {
      "content": "This allows you to use all Spark components concurrently without worrying about any component not able to get resources to run, but each component will be slower since resources are fragmented.",
      "pos": [
        1824,
        2017
      ]
    },
    {
      "content": "This can be adjusted based on your needs.",
      "pos": [
        2019,
        2060
      ]
    },
    {
      "content": "I only use the Jupyter notebook with the Spark cluster.",
      "pos": [
        2068,
        2123
      ]
    },
    {
      "content": "How can I allocate all resources to it?",
      "pos": [
        2124,
        2163
      ]
    },
    {
      "pos": [
        2168,
        2327
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>Spark Dashboard<ept id=\"p1\">**</ept>, click the <bpt id=\"p2\">**</bpt>Spark UI<ept id=\"p2\">**</ept> tab to find out the maximum number of cores and the maximum RAM that you can allocate to the applications."
    },
    {
      "content": "Resource allocation",
      "pos": [
        2335,
        2354
      ]
    },
    {
      "content": "Going by the screen capture above, the maximum cores that you can allocate is 7 (total 8 cores of which 1 is in use), and the maximum RAM that you can allocate is 9GB (total 12GB RAM, of which 2GB must be set aside for system use and 1GB that is in use by other applications).",
      "pos": [
        2482,
        2758
      ]
    },
    {
      "content": "You should also factor any applications that are running.",
      "pos": [
        2764,
        2821
      ]
    },
    {
      "content": "You can look at the running applications from the <bpt id=\"p1\">**</bpt>Spark UI<ept id=\"p1\">**</ept> tab.",
      "pos": [
        2822,
        2889
      ]
    },
    {
      "content": "Running applications",
      "pos": [
        2897,
        2917
      ]
    },
    {
      "content": "From the HDInsight Spark Dashboard, click the <bpt id=\"p1\">**</bpt>Resource Manager<ept id=\"p1\">**</ept> tab and specify the values for <bpt id=\"p2\">**</bpt>Default application core count<ept id=\"p2\">**</ept> and <bpt id=\"p3\">**</bpt>Default executor memory per worker node<ept id=\"p3\">**</ept>.",
      "pos": [
        3045,
        3226
      ]
    },
    {
      "content": "Set other properties to 0.",
      "pos": [
        3227,
        3253
      ]
    },
    {
      "content": "Resource allocation",
      "pos": [
        3261,
        3280
      ]
    },
    {
      "content": "I do not use BI tools with the Spark cluster.",
      "pos": [
        3414,
        3459
      ]
    },
    {
      "content": "How can I take resources back?",
      "pos": [
        3460,
        3490
      ]
    },
    {
      "content": "Specify thrift server core Count and thrift Server executor memory as 0.",
      "pos": [
        3493,
        3565
      ]
    },
    {
      "content": "With no core or memory allocated, the thrift server will go into a <bpt id=\"p1\">**</bpt>WAITING<ept id=\"p1\">**</ept> state.",
      "pos": [
        3566,
        3651
      ]
    },
    {
      "content": "Resource allocation",
      "pos": [
        3655,
        3674
      ]
    },
    {
      "pos": [
        3791,
        3821
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"seealso\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>See also"
    },
    {
      "content": "Overview: Apache Spark on Azure HDInsight",
      "pos": [
        3826,
        3867
      ]
    },
    {
      "content": "Provision a Spark on HDInsight cluster",
      "pos": [
        3908,
        3946
      ]
    },
    {
      "content": "Perform interactive data analysis using Spark in HDInsight with BI tools",
      "pos": [
        3997,
        4069
      ]
    },
    {
      "content": "Use Spark in HDInsight for building machine learning applications",
      "pos": [
        4114,
        4179
      ]
    },
    {
      "content": "Use Spark in HDInsight for building real-time streaming applications",
      "pos": [
        4245,
        4313
      ]
    },
    {
      "content": "test",
      "pos": [
        4895,
        4899
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure\" \n    description=\"Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"nitinme\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"07/31/2015\" \n    ms.author=\"nitinme\"/>\n\n\n# Manage resources for the Apache Spark cluster in Azure HDInsight\n\nResource manager is a component of the Spark cluster dashboard that enables you to manage resources such as cores and RAM used by each application running on the cluster.\n\n## <a name=\"launchrm\"></a>How do I launch the Resource Manager?\n\n1. From the [Azure Preview Portal](https://ms.portal.azure.com/), from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard). You can also navigate to your cluster under **Browse All** > **HDInsight Clusters**. \n \n2. From the Spark cluster blade, click **Dashboard**. When prompted, enter the admin credentials for the Spark cluster.\n\n    ![Launch Resource Manager](./media/hdinsight-apache-spark-resource-manager/HDI.Cluster.Launch.Dashboard.png \"Start Resource Manager\")   \n\n##<a name=\"scenariosrm\"></a>How do I fix these issues using the Resource Manager?\n\nHere are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Resource Manager.\n\n### My Spark cluster on HDInsight is slow\n\nApache Spark cluster in HDInsight is designed for multi-tenancy, so resources are split across multiple components (notebooks, job server, etc). This allows you to use all Spark components concurrently without worrying about any component not able to get resources to run, but each component will be slower since resources are fragmented.  This can be adjusted based on your needs. \n\n\n### I only use the Jupyter notebook with the Spark cluster. How can I allocate all resources to it?\n\n1. From the **Spark Dashboard**, click the **Spark UI** tab to find out the maximum number of cores and the maximum RAM that you can allocate to the applications.\n\n    ![Resource allocation](./media/hdinsight-apache-spark-resource-manager/HDI.Spark.UI.Resource.png \"Find resources allocated to a Spark cluster\")\n\n    Going by the screen capture above, the maximum cores that you can allocate is 7 (total 8 cores of which 1 is in use), and the maximum RAM that you can allocate is 9GB (total 12GB RAM, of which 2GB must be set aside for system use and 1GB that is in use by other applications).\n\n    You should also factor any applications that are running. You can look at the running applications from the **Spark UI** tab.\n\n    ![Running applications](./media/hdinsight-apache-spark-resource-manager/HDI.Spark.UI.Running.Apps.png \"Applications running on the cluster\")\n\n    \n2. From the HDInsight Spark Dashboard, click the **Resource Manager** tab and specify the values for **Default application core count** and **Default executor memory per worker node**. Set other properties to 0.\n\n    ![Resource allocation](./media/hdinsight-apache-spark-resource-manager/HDI.Spark.UI.Allocate.Resources.png \"Allocate resources to your applications\")\n\n### I do not use BI tools with the Spark cluster. How can I take resources back? \n\nSpecify thrift server core Count and thrift Server executor memory as 0. With no core or memory allocated, the thrift server will go into a **WAITING** state.\n\n![Resource allocation](./media/hdinsight-apache-spark-resource-manager/HDI.Spark.UI.No.Thrift.png \"No resources to the thrift server\")\n\n##<a name=\"seealso\"></a>See also\n\n* [Overview: Apache Spark on Azure HDInsight](hdinsight-apache-spark-overview.md)\n* [Provision a Spark on HDInsight cluster](hdinsight-apache-spark-provision-clusters.md)\n* [Perform interactive data analysis using Spark in HDInsight with BI tools](hdinsight-apache-spark-use-bi-tools.md)\n* [Use Spark in HDInsight for building machine learning applications](hdinsight-apache-spark-ipython-notebook-machine-learning.md)\n* [Use Spark in HDInsight for building real-time streaming applications](hdinsight-apache-spark-csharp-apache-zeppelin-eventhub-streaming.md)\n\n\n[hdinsight-versions]: ../hdinsight-component-versioning/\n[hdinsight-upload-data]: ../hdinsight-upload-data/\n[hdinsight-storage]: ../hdinsight-use-blob-storage/\n\n\n[azure-purchase-options]: http://azure.microsoft.com/pricing/purchase-options/\n[azure-member-offers]: http://azure.microsoft.com/pricing/member-offers/\n[azure-free-trial]: http://azure.microsoft.com/pricing/free-trial/\n[azure-management-portal]: https://manage.windowsazure.com/\n[azure-create-storageaccount]: ../storage-create-storage-account/ \n\ntest\n"
}