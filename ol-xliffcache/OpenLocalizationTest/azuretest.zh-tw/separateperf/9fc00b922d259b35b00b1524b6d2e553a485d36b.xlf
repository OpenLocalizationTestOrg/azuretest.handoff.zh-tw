<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Develop Python MapReduce jobs with HDInsight | Microsoft Azure</source>
          <target state="new">Develop Python MapReduce jobs with HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to create and run Python MapReduce jobs on Linux-based HDInsight clusters.</source>
          <target state="new">Learn how to create and run Python MapReduce jobs on Linux-based HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Develop Python streaming programs for HDInsight</source>
          <target state="new">Develop Python streaming programs for HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Hadoop provides a streaming API for MapReduce that enables you to write map and reduce functions in languages other than Java.</source>
          <target state="new">Hadoop provides a streaming API for MapReduce that enables you to write map and reduce functions in languages other than Java.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>In this article, you will learn how to use Python to perform MapReduce operations.</source>
          <target state="new">In this article, you will learn how to use Python to perform MapReduce operations.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> While the Python code in this document can be used with a Windows-based HDInsight cluster, the steps in this document are specific to Linux-based clusters.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> While the Python code in this document can be used with a Windows-based HDInsight cluster, the steps in this document are specific to Linux-based clusters.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>This article is based on information and examples published by Michael Noll at [http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/](Writing an Hadoop MapReduce Program in Python).</source>
          <target state="new">This article is based on information and examples published by Michael Noll at [http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/](Writing an Hadoop MapReduce Program in Python).</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following:</source>
          <target state="new">To complete the steps in this article, you will need the following:</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A Linux-based Hadoop on HDInsight cluster</source>
          <target state="new">A Linux-based Hadoop on HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>A text editor</source>
          <target state="new">A text editor</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>For Windows clients, PuTTY and PSCP.</source>
          <target state="new">For Windows clients, PuTTY and PSCP.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>These utilities are available from the <ph id="ph1">&lt;a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" target="_blank"&gt;</ph>PuTTY Download Page<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">These utilities are available from the <ph id="ph1">&lt;a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" target="_blank"&gt;</ph>PuTTY Download Page<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Word count</source>
          <target state="new">Word count</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>For this example, you will implement a basic word count by using a mapper and reducer.</source>
          <target state="new">For this example, you will implement a basic word count by using a mapper and reducer.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The mapper breaks sentences into individual words, and the reducer aggregates the words and counts to produce the output.</source>
          <target state="new">The mapper breaks sentences into individual words, and the reducer aggregates the words and counts to produce the output.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The following flowchart illustrates what happens during the map and reduce phases.</source>
          <target state="new">The following flowchart illustrates what happens during the map and reduce phases.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>illustration of map reduce</source>
          <target state="new">illustration of map reduce</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Why Python?</source>
          <target state="new">Why Python?</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Python is a general-purpose, high-level programming language that allows you to express concepts in fewer lines of code than many other languages.</source>
          <target state="new">Python is a general-purpose, high-level programming language that allows you to express concepts in fewer lines of code than many other languages.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>It has recently became popular with data scientists as a prototyping language because its interpreted nature, dynamic typing, and elegant syntax make it suitable for rapid application development.</source>
          <target state="new">It has recently became popular with data scientists as a prototyping language because its interpreted nature, dynamic typing, and elegant syntax make it suitable for rapid application development.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Python is installed on all HDInsight clusters.</source>
          <target state="new">Python is installed on all HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Streaming MapReduce</source>
          <target state="new">Streaming MapReduce</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Hadoop allows you to specify a file that contains the map and reduce logic that is used by a job.</source>
          <target state="new">Hadoop allows you to specify a file that contains the map and reduce logic that is used by a job.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The specific requirements for the map and reduce logic are:</source>
          <target state="new">The specific requirements for the map and reduce logic are:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Input<ept id="p1">**</ept>: The map and reduce components must read input data from STDIN.</source>
          <target state="new"><bpt id="p1">**</bpt>Input<ept id="p1">**</ept>: The map and reduce components must read input data from STDIN.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Output<ept id="p1">**</ept>: The map and reduce components must write output data to STDOUT.</source>
          <target state="new"><bpt id="p1">**</bpt>Output<ept id="p1">**</ept>: The map and reduce components must write output data to STDOUT.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Data format<ept id="p1">**</ept>: The data consumed and produced must be a key/value pair, separated by a tab character.</source>
          <target state="new"><bpt id="p1">**</bpt>Data format<ept id="p1">**</ept>: The data consumed and produced must be a key/value pair, separated by a tab character.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Python can easily handle these requirements by using the <bpt id="p1">**</bpt>sys<ept id="p1">**</ept> module to read from STDIN and using <bpt id="p2">**</bpt>print<ept id="p2">**</ept> to print to STDOUT.</source>
          <target state="new">Python can easily handle these requirements by using the <bpt id="p1">**</bpt>sys<ept id="p1">**</ept> module to read from STDIN and using <bpt id="p2">**</bpt>print<ept id="p2">**</ept> to print to STDOUT.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The remaining task is simply formatting the data with a tab (<ph id="ph1">`\t`</ph>) character between the key and value.</source>
          <target state="new">The remaining task is simply formatting the data with a tab (<ph id="ph1">`\t`</ph>) character between the key and value.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Create the mapper and reducer</source>
          <target state="new">Create the mapper and reducer</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>The mapper and reducer are text files, in this case <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept> (to make it clear which does what).</source>
          <target state="new">The mapper and reducer are text files, in this case <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept> (to make it clear which does what).</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>You can create these by using the editor of your choice.</source>
          <target state="new">You can create these by using the editor of your choice.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Mapper.py</source>
          <target state="new">Mapper.py</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Create a new file named <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and use the following code as the content:</source>
          <target state="new">Create a new file named <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and use the following code as the content:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Take a moment to read through the code so you can understand what it does.</source>
          <target state="new">Take a moment to read through the code so you can understand what it does.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Reducer.py</source>
          <target state="new">Reducer.py</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Create a new file named <bpt id="p1">**</bpt>reducer.py<ept id="p1">**</ept> and use the following code as the content:</source>
          <target state="new">Create a new file named <bpt id="p1">**</bpt>reducer.py<ept id="p1">**</ept> and use the following code as the content:</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Upload the files</source>
          <target state="new">Upload the files</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Both <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept> must be on the head node of the cluster before we can run them.</source>
          <target state="new">Both <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept> must be on the head node of the cluster before we can run them.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The easiest way to upload them is to use <bpt id="p1">**</bpt>scp<ept id="p1">**</ept> (<bpt id="p2">**</bpt>pscp<ept id="p2">**</ept> if you are using a Windows client).</source>
          <target state="new">The easiest way to upload them is to use <bpt id="p1">**</bpt>scp<ept id="p1">**</ept> (<bpt id="p2">**</bpt>pscp<ept id="p2">**</ept> if you are using a Windows client).</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>From the client, in the same directory as <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept>, use the following command.</source>
          <target state="new">From the client, in the same directory as <bpt id="p1">**</bpt>mapper.py<ept id="p1">**</ept> and <bpt id="p2">**</bpt>reducer.py<ept id="p2">**</ept>, use the following command.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p1">**</bpt>username<ept id="p1">**</ept> with an SSH user, and <bpt id="p2">**</bpt>clustername<ept id="p2">**</ept> with the name of your cluster.</source>
          <target state="new">Replace <bpt id="p1">**</bpt>username<ept id="p1">**</ept> with an SSH user, and <bpt id="p2">**</bpt>clustername<ept id="p2">**</ept> with the name of your cluster.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>This copies the files from the local system to the head node.</source>
          <target state="new">This copies the files from the local system to the head node.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key, for example, <ph id="ph2">`scp -i /path/to/private/key mapper.py reducer.py username@clustername-ssh.azurehdinsight.net:`</ph>.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key, for example, <ph id="ph2">`scp -i /path/to/private/key mapper.py reducer.py username@clustername-ssh.azurehdinsight.net:`</ph>.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Run MapReduce</source>
          <target state="new">Run MapReduce</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Connect to the cluster by using SSH:</source>
          <target state="new">Connect to the cluster by using SSH:</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key, for example, <ph id="ph2">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph>.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key, for example, <ph id="ph2">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph>.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Use the following command to start the MapReduce job.</source>
          <target state="new">Use the following command to start the MapReduce job.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>This command has the following parts:</source>
          <target state="new">This command has the following parts:</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>hadoop-streaming.jar<ept id="p1">**</ept>: Used when performing streaming MapReduce operations.</source>
          <target state="new"><bpt id="p1">**</bpt>hadoop-streaming.jar<ept id="p1">**</ept>: Used when performing streaming MapReduce operations.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>It interfaces Hadoop with the external MapReduce code you provide.</source>
          <target state="new">It interfaces Hadoop with the external MapReduce code you provide.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-files<ept id="p1">**</ept>: Tells Hadoop that the specified files are needed for this MapReduce job, and they should be copied to all the worker nodes.</source>
          <target state="new"><bpt id="p1">**</bpt>-files<ept id="p1">**</ept>: Tells Hadoop that the specified files are needed for this MapReduce job, and they should be copied to all the worker nodes.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-mapper<ept id="p1">**</ept>: Tells Hadoop which file to use as the mapper.</source>
          <target state="new"><bpt id="p1">**</bpt>-mapper<ept id="p1">**</ept>: Tells Hadoop which file to use as the mapper.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-reducer<ept id="p1">**</ept>: Tells Hadoop which file to use as the reducer.</source>
          <target state="new"><bpt id="p1">**</bpt>-reducer<ept id="p1">**</ept>: Tells Hadoop which file to use as the reducer.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-input<ept id="p1">**</ept>: The input file that we should count words from.</source>
          <target state="new"><bpt id="p1">**</bpt>-input<ept id="p1">**</ept>: The input file that we should count words from.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-output<ept id="p1">**</ept>: The directory that the output will be written to.</source>
          <target state="new"><bpt id="p1">**</bpt>-output<ept id="p1">**</ept>: The directory that the output will be written to.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This directory will be created by the job.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This directory will be created by the job.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>You should see a bunch of <bpt id="p1">**</bpt>INFO<ept id="p1">**</ept> statements as the job starts, and finally see the <bpt id="p2">**</bpt>map<ept id="p2">**</ept> and <bpt id="p3">**</bpt>reduce<ept id="p3">**</ept> operation displayed as percentages.</source>
          <target state="new">You should see a bunch of <bpt id="p1">**</bpt>INFO<ept id="p1">**</ept> statements as the job starts, and finally see the <bpt id="p2">**</bpt>map<ept id="p2">**</ept> and <bpt id="p3">**</bpt>reduce<ept id="p3">**</ept> operation displayed as percentages.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>You will receive status information about the job when it completes.</source>
          <target state="new">You will receive status information about the job when it completes.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>View the output</source>
          <target state="new">View the output</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>When the job is complete, use the following command to view the output:</source>
          <target state="new">When the job is complete, use the following command to view the output:</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>This should display a list of words and how many times the word occurred.</source>
          <target state="new">This should display a list of words and how many times the word occurred.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>The following is an sample of the output data:</source>
          <target state="new">The following is an sample of the output data:</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Now that you have learned how to use streaming MapRedcue jobs with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
          <target state="new">Now that you have learned how to use streaming MapRedcue jobs with HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Use MapReduce jobs with HDInsight</source>
          <target state="new">Use MapReduce jobs with HDInsight</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9fc00b922d259b35b00b1524b6d2e553a485d36b</xliffext:olfilehash>
  </header>
</xliff>