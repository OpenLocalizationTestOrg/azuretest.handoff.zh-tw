{
  "nodes": [
    {
      "content": "Filters and Dynamic Manifests",
      "pos": [
        28,
        57
      ]
    },
    {
      "content": "This topic describes how to create filters so your client can use them to stream specific sections of a stream.",
      "pos": [
        77,
        188
      ]
    },
    {
      "content": "Media Services creates dynamic manifests to achive this selective streaming.",
      "pos": [
        189,
        265
      ]
    },
    {
      "content": "Filters and Dynamic Manifests",
      "pos": [
        577,
        606
      ]
    },
    {
      "content": "Starting with 2.11 release, Media Services enables you to define filters for your assets.",
      "pos": [
        608,
        697
      ]
    },
    {
      "content": "These filters are server side rules that will allow your customers to choose to do things like: playback only a section of a video (instead of playing the whole video), or specify only a subset of audio and video renditions that your customer's device can handle (instead of all the renditions that are associated with the asset).",
      "pos": [
        698,
        1028
      ]
    },
    {
      "content": "This filtering of your assets is achieved through <bpt id=\"p1\">**</bpt>Dynamic Manifest<ept id=\"p1\">**</ept>s that are created upon your customer's request to stream a video based on specified filter(s).",
      "pos": [
        1029,
        1194
      ]
    },
    {
      "content": "This topics discusses common scenarios in which using filters would be very beneficial to your customers and links to topics that demonstrate how to create filters programmatically (currently, you can create filters with REST APIs only).",
      "pos": [
        1196,
        1433
      ]
    },
    {
      "content": "Overview",
      "pos": [
        1437,
        1445
      ]
    },
    {
      "content": "When delivering your content to customers (streaming live events or video-on-demand) your goal is to deliver a high quality video to various devices under different network conditions.",
      "pos": [
        1447,
        1631
      ]
    },
    {
      "content": "To achieve this goal do the following:",
      "pos": [
        1632,
        1670
      ]
    },
    {
      "pos": [
        1674,
        1860
      ],
      "content": "encode your stream to multi-bitrate (<bpt id=\"p1\">[</bpt>adaptive bitrate<ept id=\"p1\">](http://en.wikipedia.org/wiki/Adaptive_bitrate_streaming)</ept>) video stream (this will take care of quality and network conditions) and"
    },
    {
      "content": "use Media Services <bpt id=\"p1\">[</bpt>Dynamic Packaging<ept id=\"p1\">](media-services-dynamic-packaging-overview.md)</ept> to dynamically re-package your stream into different protocols (this will take care of streaming on different devices).",
      "pos": [
        1864,
        2068
      ]
    },
    {
      "content": "Media Services supports delivery of the following adaptive bitrate streaming technologies: HTTP Live Streaming (HLS), Smooth Streaming, MPEG DASH, and HDS (for Adobe PrimeTime/Access licensees only).",
      "pos": [
        2069,
        2268
      ]
    },
    {
      "content": "Manifest files",
      "pos": [
        2274,
        2288
      ]
    },
    {
      "content": "When you encode an asset for adaptive bitrate streaming, a <bpt id=\"p1\">**</bpt>manifest<ept id=\"p1\">**</ept> (playlist) file is created (the file is text-based or XML-based).",
      "pos": [
        2291,
        2428
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>manifest<ept id=\"p1\">**</ept> file includes streaming metadata such as: track type (audio, video, or text), track name, start and end time, bitrate (qualities), track languages, presentation window (sliding window of fixed duration), video codec (FourCC).",
      "pos": [
        2429,
        2671
      ]
    },
    {
      "content": "It also instructs the player to retrieve the next fragment by providing information about the next playable video fragments available and their location.",
      "pos": [
        2672,
        2825
      ]
    },
    {
      "content": "Fragments (or segments) are the actual “chunks” of a video content.",
      "pos": [
        2826,
        2893
      ]
    },
    {
      "content": "Here is an example of a manifest file:",
      "pos": [
        2896,
        2934
      ]
    },
    {
      "content": "Dynamic manifests",
      "pos": [
        6748,
        6765
      ]
    },
    {
      "content": "There are <bpt id=\"p1\">[</bpt>scenarios<ept id=\"p1\">](media-services-dynamic-manifest-overview.md#scenarios)</ept> when your client needs more flexibility than what's described in the default asset's manifest file.",
      "pos": [
        6767,
        6943
      ]
    },
    {
      "content": "For example:",
      "pos": [
        6944,
        6956
      ]
    },
    {
      "content": "Device specific: deliver only the specified renditions and\\or specified language tracks that are supported by the device that is used to playback the content (\"rendition filtering\").",
      "pos": [
        6960,
        7142
      ]
    },
    {
      "content": "Reduce the manifest to show a sub-clip of a live event (\"sub-clip filtering\").",
      "pos": [
        7146,
        7224
      ]
    },
    {
      "content": "Trim the start of a video (\"trimming a video\").",
      "pos": [
        7227,
        7274
      ]
    },
    {
      "content": "Adjust Presentation Window (DVR) in order to provide a limited length of the DVR window in the player (\"adjusting presentation window\") .",
      "pos": [
        7277,
        7414
      ]
    },
    {
      "content": "To achieve this flexibility, Media Services offers <bpt id=\"p1\">**</bpt>Dynamic Manifests<ept id=\"p1\">**</ept> based on pre-defined <bpt id=\"p2\">[</bpt>filters<ept id=\"p2\">](media-services-dynamic-manifest-overview.md#filters)</ept>.",
      "pos": [
        7417,
        7574
      ]
    },
    {
      "content": "Once you define the filters, your clients could use them to stream a specific rendition or sub-clips of your video.",
      "pos": [
        7576,
        7691
      ]
    },
    {
      "content": "They would specify filter(s) in the streaming URL.",
      "pos": [
        7692,
        7742
      ]
    },
    {
      "content": "Filters could be applied to adaptive bitrate streaming protocols supported by <bpt id=\"p1\">[</bpt>Dynamic Packaging<ept id=\"p1\">](media-services-dynamic-packaging-overview.md)</ept>: HLS, MPEG-DASH, Smooth Streaming, and HDS.",
      "pos": [
        7743,
        7930
      ]
    },
    {
      "content": "For example:",
      "pos": [
        7931,
        7943
      ]
    },
    {
      "content": "MPEG DASH URL with filter",
      "pos": [
        7945,
        7970
      ]
    },
    {
      "content": "Smooth Streaming URL with filter",
      "pos": [
        8150,
        8182
      ]
    },
    {
      "pos": [
        8343,
        8500
      ],
      "content": "For more information about how to deliver your content and build streaming URLs, see <bpt id=\"p1\">[</bpt>Delivering content overview<ept id=\"p1\">](media-services-deliver-content-overview/)</ept>."
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>Note that Dynamic Manifests do not change the asset and the default manifest for that asset.",
      "pos": [
        8504,
        8608
      ]
    },
    {
      "content": "Your client can choose to request a stream with or without filters.",
      "pos": [
        8609,
        8676
      ]
    },
    {
      "pos": [
        8683,
        8710
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"filters\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Filters"
    },
    {
      "content": "There are two types of asset filters:",
      "pos": [
        8713,
        8750
      ]
    },
    {
      "content": "Global filters (can be applied to any asset in the Azure Media Services account, have a lifetime of the account) and",
      "pos": [
        8755,
        8871
      ]
    },
    {
      "content": "Local filters (can only be applied to an asset with which the filter was associated upon creation, have a lifetime of the asset).",
      "pos": [
        8875,
        9004
      ]
    },
    {
      "content": "Global and local filter types have exactly the same properties.",
      "pos": [
        9007,
        9070
      ]
    },
    {
      "content": "The main difference between the two is for which scenarios what type of a filer is more suitable.",
      "pos": [
        9071,
        9168
      ]
    },
    {
      "content": "Global filters are generally suitable for device profiles (rendition filtering) where local filters could be used to trim a specific asset.",
      "pos": [
        9169,
        9308
      ]
    },
    {
      "pos": [
        9313,
        9351
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"scenarios\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Common scenarios"
    },
    {
      "content": "As was mentioned before, when delivering your content to customers (streaming live events or video-on-demand) your goal is to deliver a high quality video to various devices under different network conditions.",
      "pos": [
        9354,
        9563
      ]
    },
    {
      "content": "In addition, your might have other requirements that involve filtering your assets and using of <bpt id=\"p1\">**</bpt>Dynamic Manifest<ept id=\"p1\">**</ept>s.",
      "pos": [
        9564,
        9682
      ]
    },
    {
      "content": "The following sections give a short overview of different filtering scenarios.",
      "pos": [
        9683,
        9761
      ]
    },
    {
      "content": "Specify only a subset of audio and video renditions that certain devices can handle (instead of all the renditions that are associated with the asset).",
      "pos": [
        9765,
        9916
      ]
    },
    {
      "content": "Playing back only a section of a video (instead of playing the whole video).",
      "pos": [
        9920,
        9996
      ]
    },
    {
      "content": "Adjust DVR presentation window.",
      "pos": [
        9999,
        10030
      ]
    },
    {
      "content": "Rendition filtering",
      "pos": [
        10035,
        10054
      ]
    },
    {
      "content": "You may choose to encode your asset to multiple encoding profiles (H.264 Baseline, H.264 High, AACL, AACH, Dolby Digital Plus) and multiple quality bitrates.",
      "pos": [
        10057,
        10214
      ]
    },
    {
      "content": "However, not all client devices will support all your asset's profiles and bitrates.",
      "pos": [
        10215,
        10299
      ]
    },
    {
      "content": "For example, older Android devices only supports H.264 Baseline+AACL.",
      "pos": [
        10300,
        10369
      ]
    },
    {
      "content": "Sending higher bitrates to a device which cannot get the benefits, wastes bandwidth and device computation.",
      "pos": [
        10370,
        10477
      ]
    },
    {
      "content": "Such device must decode all the given information, only to scale it down for display.",
      "pos": [
        10478,
        10563
      ]
    },
    {
      "content": "With Dynamic Manifest, you can create device profiles such as mobile, console, HD/SD, etc. and include the tracks and qualities which you want to be a part of each profile.",
      "pos": [
        10565,
        10737
      ]
    },
    {
      "content": "Rendition filtering example",
      "pos": [
        10743,
        10770
      ]
    },
    {
      "content": "In the following example, Azure Media Encoder was used to encode a mezzanine asset into seven ISO MP4s video renditions (from 180p to 1080p).",
      "pos": [
        10786,
        10927
      ]
    },
    {
      "content": "The encoded asset can be dynamically packaged into any of the following streaming protocols: HLS, Smooth, MPEG DASH, and HDS.",
      "pos": [
        10928,
        11053
      ]
    },
    {
      "content": "At the top of the diagram, the HLS manifest for the asset with no filters is shown (it contains all seven renditions).",
      "pos": [
        11055,
        11173
      ]
    },
    {
      "content": "In the bottom left, the HLS manifest to which a filter named \"ott\" was applied is shown.",
      "pos": [
        11175,
        11263
      ]
    },
    {
      "content": "The \"ott\" filter specifies to remove all bitrates below 1Mbps, which resulted in the bottom two quality levels being stripped off in the response.",
      "pos": [
        11264,
        11410
      ]
    },
    {
      "content": "In the bottom right,   the HLS manifest to which a filter named \"mobile\" was applied is shown.",
      "pos": [
        11412,
        11506
      ]
    },
    {
      "content": "The \"mobile\" filter specifies to remove renditions where the resolution is larger than 720p, which resulted in the two 1080p renditions being stripped off.",
      "pos": [
        11507,
        11662
      ]
    },
    {
      "content": "Rendition filtering",
      "pos": [
        11666,
        11685
      ]
    },
    {
      "content": "Removing language tracks",
      "pos": [
        11704,
        11728
      ]
    },
    {
      "content": "Your assets might include multiple audio languages such as English, Spanish, French, etc. Usually, the Player SDK managers default audio track selection and available audio tracks per user selection.",
      "pos": [
        11730,
        11929
      ]
    },
    {
      "content": "It is challenging to develop such Player SDKs, it requires different implementations across device-specific player-frameworks.",
      "pos": [
        11930,
        12056
      ]
    },
    {
      "content": "Also, on some platforms, Player APIs are limited and do not include audio selection feature where users cannot select or change the default audio track.",
      "pos": [
        12057,
        12209
      ]
    },
    {
      "content": "With asset filters, you can control the behavior by creating filters that only include desired audio languages.",
      "pos": [
        12210,
        12321
      ]
    },
    {
      "content": "Language tracks filtering",
      "pos": [
        12325,
        12350
      ]
    },
    {
      "content": "Trimming start of an asset",
      "pos": [
        12374,
        12400
      ]
    },
    {
      "content": "In most live streaming events, operators run some tests before the actual event.",
      "pos": [
        12403,
        12483
      ]
    },
    {
      "content": "For example, they might include a slate like this before the start of the event: \"Program will begin momentarily\".",
      "pos": [
        12484,
        12598
      ]
    },
    {
      "content": "If the program is archiving, the test and slate data are also archived and will be included in the presentation.",
      "pos": [
        12599,
        12711
      ]
    },
    {
      "content": "However, this information should not be shown to the clients.",
      "pos": [
        12712,
        12773
      ]
    },
    {
      "content": "With Dynamic Manifest, you can create a start time filter and remove the unwanted data from the manifest.",
      "pos": [
        12774,
        12879
      ]
    },
    {
      "content": "Trimming start",
      "pos": [
        12883,
        12897
      ]
    },
    {
      "content": "Creating sub-clips (views) from a live archive",
      "pos": [
        12916,
        12962
      ]
    },
    {
      "content": "Many live events are long running and live archive might include multiple events.",
      "pos": [
        12964,
        13045
      ]
    },
    {
      "content": "After the live event ends broadcasters may want to break up the live archive into logical program start and stop sequences.",
      "pos": [
        13046,
        13169
      ]
    },
    {
      "content": "Then, publish these virtual programs separately without post processing the live archive and not creating separate assets (which will not get benefit of the existing cached fragments in the CDNs).",
      "pos": [
        13170,
        13366
      ]
    },
    {
      "content": "Examples of such virtual programs (sub-clips) are the quarters of a football or basketball game, the innings in baseball, or individual events of an afternoon of Olympics program.",
      "pos": [
        13367,
        13546
      ]
    },
    {
      "content": "With Dynamic Manifest, you can create filters using start/end times and create virtual views over the top of your live archive.",
      "pos": [
        13548,
        13675
      ]
    },
    {
      "content": "Subclip filter",
      "pos": [
        13680,
        13694
      ]
    },
    {
      "content": "Filtered Asset:",
      "pos": [
        13713,
        13728
      ]
    },
    {
      "content": "Skiing",
      "pos": [
        13732,
        13738
      ]
    },
    {
      "content": "Adjusting Presentation Window (DVR)",
      "pos": [
        13752,
        13787
      ]
    },
    {
      "content": "Currently, Azure Media Services offers circular archive where the duration can be configured between 5 minutes - 25 hours.",
      "pos": [
        13789,
        13911
      ]
    },
    {
      "content": "Manifest filtering can be used to create a rolling DVR window over the top of the archive, without deleting media.",
      "pos": [
        13912,
        14026
      ]
    },
    {
      "content": "There are many scenarios where broadcasters want to provide a limited DVR window which moves with the live edge and at the same time keep a bigger archiving window.",
      "pos": [
        14027,
        14191
      ]
    },
    {
      "content": "A broadcaster may want to use the data that is out of the DVR window to highlight clips, or he\\she may want to provide different DVR windows for different devices.",
      "pos": [
        14192,
        14355
      ]
    },
    {
      "content": "For example, most of the mobile devices don’t handle big DVR windows (you can have a 2 minute DVR window for mobile devices and 1 hour for desktop clients).",
      "pos": [
        14356,
        14512
      ]
    },
    {
      "content": "DVR window",
      "pos": [
        14516,
        14526
      ]
    },
    {
      "content": "Adjusting LiveBackoff (live position)",
      "pos": [
        14544,
        14581
      ]
    },
    {
      "content": "Manifest filtering can be used to remove several seconds from the live edge of a live program.",
      "pos": [
        14583,
        14677
      ]
    },
    {
      "content": "This allows broadcasters to watch the presentation on the preview publication point and create advertisement insertion points before the viewers receive the stream (usually backed-off by 30 seconds).",
      "pos": [
        14678,
        14877
      ]
    },
    {
      "content": "Broadcasters can then push these advertisements to their client frameworks in time for them to received and process the information before the advertisement opportunity.",
      "pos": [
        14878,
        15047
      ]
    },
    {
      "content": "In addition to the advertisement support, LiveBackoff can be used for adjusting client live download position so that when clients drift and hit the live edge they can still get fragments from server instead of getting 404 or 412 HTTP errors.",
      "pos": [
        15049,
        15291
      ]
    },
    {
      "content": "livebackoff_filter",
      "pos": [
        15297,
        15315
      ]
    },
    {
      "content": "Combining multiple rules in a single filter",
      "pos": [
        15342,
        15385
      ]
    },
    {
      "content": "You can combine multiple filtering rules in a single filter.",
      "pos": [
        15387,
        15447
      ]
    },
    {
      "content": "As an example you can define a range rule to remove slate from a live archive and also filter available bitrates.",
      "pos": [
        15448,
        15561
      ]
    },
    {
      "content": "For multiple filtering rules the end result is the composition (intersection only) of these rules.",
      "pos": [
        15562,
        15660
      ]
    },
    {
      "content": "multiple-rules",
      "pos": [
        15664,
        15678
      ]
    },
    {
      "content": "Create filters programmatically",
      "pos": [
        15699,
        15730
      ]
    },
    {
      "content": "The following topic discusses Media Services entities that are related to filters.",
      "pos": [
        15732,
        15814
      ]
    },
    {
      "content": "The topic also shows how to programmatically create filters.",
      "pos": [
        15815,
        15875
      ]
    },
    {
      "pos": [
        15879,
        15952
      ],
      "content": "<bpt id=\"p1\">[</bpt>Create filters with REST APIs<ept id=\"p1\">](media-services-rest-dynamic-manifest.md)</ept>."
    },
    {
      "content": "Know issues and limitations",
      "pos": [
        15956,
        15983
      ]
    },
    {
      "content": "Dynamic manifest operates in GOP boundaries (Key Frames) hence trimming has GOP accuracy.",
      "pos": [
        15987,
        16076
      ]
    },
    {
      "content": "You can use same filter name for local and global filters.",
      "pos": [
        16080,
        16138
      ]
    },
    {
      "content": "Note that local filter have higher precedence and will override global filters.",
      "pos": [
        16139,
        16218
      ]
    },
    {
      "content": "If you update a filter, it can take up to 2 minutes for streaming endpoint to refresh the rules.",
      "pos": [
        16221,
        16317
      ]
    },
    {
      "content": "If the content was served using some filters (and cached in proxies and CDN caches), updating these filters can result in player failures.",
      "pos": [
        16318,
        16456
      ]
    },
    {
      "content": "It is recommend to clear the cache after updating the filter.",
      "pos": [
        16457,
        16518
      ]
    },
    {
      "content": "If this option is not possible, consider using a different filter.",
      "pos": [
        16519,
        16585
      ]
    },
    {
      "content": "See Also",
      "pos": [
        16590,
        16598
      ]
    },
    {
      "content": "test",
      "pos": [
        18098,
        18102
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Filters and Dynamic Manifests\" \n    description=\"This topic describes how to create filters so your client can use them to stream specific sections of a stream. Media Services creates dynamic manifests to achive this selective streaming.\" \n    services=\"media-services\" \n    documentationCenter=\"\" \n    authors=\"Juliako\" \n    manager=\"dwrede\" \n    editor=\"\"/>\n\n<tags \n    ms.service=\"media-services\" \n    ms.workload=\"media\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"ne\" \n    ms.topic=\"article\" \n    ms.date=\"08/11/2015\" \n    ms.author=\"juliako\"/>\n\n#Filters and Dynamic Manifests\n\nStarting with 2.11 release, Media Services enables you to define filters for your assets. These filters are server side rules that will allow your customers to choose to do things like: playback only a section of a video (instead of playing the whole video), or specify only a subset of audio and video renditions that your customer's device can handle (instead of all the renditions that are associated with the asset). This filtering of your assets is achieved through **Dynamic Manifest**s that are created upon your customer's request to stream a video based on specified filter(s).\n\nThis topics discusses common scenarios in which using filters would be very beneficial to your customers and links to topics that demonstrate how to create filters programmatically (currently, you can create filters with REST APIs only).\n\n##Overview\n\nWhen delivering your content to customers (streaming live events or video-on-demand) your goal is to deliver a high quality video to various devices under different network conditions. To achieve this goal do the following:\n\n- encode your stream to multi-bitrate ([adaptive bitrate](http://en.wikipedia.org/wiki/Adaptive_bitrate_streaming)) video stream (this will take care of quality and network conditions) and \n- use Media Services [Dynamic Packaging](media-services-dynamic-packaging-overview.md) to dynamically re-package your stream into different protocols (this will take care of streaming on different devices). Media Services supports delivery of the following adaptive bitrate streaming technologies: HTTP Live Streaming (HLS), Smooth Streaming, MPEG DASH, and HDS (for Adobe PrimeTime/Access licensees only). \n\n###Manifest files \n\nWhen you encode an asset for adaptive bitrate streaming, a **manifest** (playlist) file is created (the file is text-based or XML-based). The **manifest** file includes streaming metadata such as: track type (audio, video, or text), track name, start and end time, bitrate (qualities), track languages, presentation window (sliding window of fixed duration), video codec (FourCC). It also instructs the player to retrieve the next fragment by providing information about the next playable video fragments available and their location. Fragments (or segments) are the actual “chunks” of a video content.\n\n\nHere is an example of a manifest file: \n\n    \n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>  \n    <SmoothStreamingMedia MajorVersion=\"2\" MinorVersion=\"0\" Duration=\"330187755\" TimeScale=\"10000000\">\n    \n    <StreamIndex Chunks=\"17\" Type=\"video\" Url=\"QualityLevels({bitrate})/Fragments(video={start time})\" QualityLevels=\"8\">\n    <QualityLevel Index=\"0\" Bitrate=\"5860941\" FourCC=\"H264\" MaxWidth=\"1920\" MaxHeight=\"1080\" CodecPrivateData=\"0000000167640028AC2CA501E0089F97015202020280000003008000001931300016E360000E4E1FF8C7076850A4580000000168E9093525\" />\n    <QualityLevel Index=\"1\" Bitrate=\"4602724\" FourCC=\"H264\" MaxWidth=\"1920\" MaxHeight=\"1080\" CodecPrivateData=\"0000000167640028AC2CA501E0089F97015202020280000003008000001931100011EDC00002CD29FF8C7076850A45800000000168E9093525\" />\n    <QualityLevel Index=\"2\" Bitrate=\"3319311\" FourCC=\"H264\" MaxWidth=\"1280\" MaxHeight=\"720\" CodecPrivateData=\"000000016764001FAC2CA5014016EC054808080A00000300020000030064C0800067C28000103667F8C7076850A4580000000168E9093525\" />\n    <QualityLevel Index=\"3\" Bitrate=\"2195119\" FourCC=\"H264\" MaxWidth=\"960\" MaxHeight=\"540\" CodecPrivateData=\"000000016764001FAC2CA503C045FBC054808080A000000300200000064C1000044AA0000ABA9FE31C1DA14291600000000168E9093525\" />\n    <QualityLevel Index=\"4\" Bitrate=\"1469881\" FourCC=\"H264\" MaxWidth=\"960\" MaxHeight=\"540\" CodecPrivateData=\"000000016764001FAC2CA503C045FBC054808080A000000300200000064C04000B71A0000E4E1FF8C7076850A4580000000168E9093525\" />\n    <QualityLevel Index=\"5\" Bitrate=\"978815\" FourCC=\"H264\" MaxWidth=\"640\" MaxHeight=\"360\" CodecPrivateData=\"000000016764001EAC2CA50280BFE5C0548303032000000300200000064C08001E8480004C4B7F8C7076850A45800000000168E9093525\" />\n    <QualityLevel Index=\"6\" Bitrate=\"638374\" FourCC=\"H264\" MaxWidth=\"640\" MaxHeight=\"360\" CodecPrivateData=\"000000016764001EAC2CA50280BFE5C0548303032000000300200000064C080013D60000C65DFE31C1DA1429160000000168E9093525\" />\n    <QualityLevel Index=\"7\" Bitrate=\"388851\" FourCC=\"H264\" MaxWidth=\"320\" MaxHeight=\"180\" CodecPrivateData=\"000000016764000DAC2CA505067E7C054830303200000300020000030064C040030D40003D093F8C7076850A45800000000168E9093525\" />\n    \n    <c t=\"0\" d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"20000000\" /><c d=\"9600000\"/>\n    </StreamIndex>\n    \n    \n    <StreamIndex Chunks=\"17\" Type=\"audio\" Url=\"QualityLevels({bitrate})/Fragments(AAC_und_ch2_128kbps={start time})\" QualityLevels=\"1\" Name=\"AAC_und_ch2_128kbps\">\n    <QualityLevel AudioTag=\"255\" Index=\"0\" BitsPerSample=\"16\" Bitrate=\"125658\" FourCC=\"AACL\" CodecPrivateData=\"1210\" Channels=\"2\" PacketSize=\"4\" SamplingRate=\"44100\" />\n    \n    <c t=\"0\" d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"6965987\" /></StreamIndex>\n    \n    \n    <StreamIndex Chunks=\"17\" Type=\"audio\" Url=\"QualityLevels({bitrate})/Fragments(AAC_und_ch2_56kbps={start time})\" QualityLevels=\"1\" Name=\"AAC_und_ch2_56kbps\">\n    <QualityLevel AudioTag=\"255\" Index=\"0\" BitsPerSample=\"16\" Bitrate=\"53655\" FourCC=\"AACL\" CodecPrivateData=\"1210\" Channels=\"2\" PacketSize=\"4\" SamplingRate=\"44100\" />\n    \n    <c t=\"0\" d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"20201361\" /><c d=\"20201360\" /><c d=\"6965987\" /></StreamIndex>\n    \n    </SmoothStreamingMedia>\n    \n###Dynamic manifests\n\nThere are [scenarios](media-services-dynamic-manifest-overview.md#scenarios) when your client needs more flexibility than what's described in the default asset's manifest file. For example:\n\n- Device specific: deliver only the specified renditions and\\or specified language tracks that are supported by the device that is used to playback the content (\"rendition filtering\"). \n- Reduce the manifest to show a sub-clip of a live event (\"sub-clip filtering\").\n- Trim the start of a video (\"trimming a video\").\n- Adjust Presentation Window (DVR) in order to provide a limited length of the DVR window in the player (\"adjusting presentation window\") .\n \nTo achieve this flexibility, Media Services offers **Dynamic Manifests** based on pre-defined [filters](media-services-dynamic-manifest-overview.md#filters).  Once you define the filters, your clients could use them to stream a specific rendition or sub-clips of your video. They would specify filter(s) in the streaming URL. Filters could be applied to adaptive bitrate streaming protocols supported by [Dynamic Packaging](media-services-dynamic-packaging-overview.md): HLS, MPEG-DASH, Smooth Streaming, and HDS. For example:\n\nMPEG DASH URL with filter\n\n    http://testendpoint-testaccount.streaming.mediaservices.windows.net/fecebb23-46f6-490d-8b70-203e86b0df58/BigBuckBunny.ism/Manifest(format=mpd-time-csf,filter=MyLocalFilter)\n\nSmooth Streaming URL with filter\n\n    http://testendpoint-testaccount.streaming.mediaservices.windows.net/fecebb23-46f6-490d-8b70-203e86b0df58/BigBuckBunny.ism/Manifest(filter=MyLocalFilter)\n\n\nFor more information about how to deliver your content and build streaming URLs, see [Delivering content overview](media-services-deliver-content-overview/).\n\n\n>[AZURE.NOTE]Note that Dynamic Manifests do not change the asset and the default manifest for that asset. Your client can choose to request a stream with or without filters. \n\n\n###<a id=\"filters\"></a>Filters \n\nThere are two types of asset filters: \n\n- Global filters (can be applied to any asset in the Azure Media Services account, have a lifetime of the account) and \n- Local filters (can only be applied to an asset with which the filter was associated upon creation, have a lifetime of the asset). \n\nGlobal and local filter types have exactly the same properties. The main difference between the two is for which scenarios what type of a filer is more suitable. Global filters are generally suitable for device profiles (rendition filtering) where local filters could be used to trim a specific asset.\n\n\n##<a id=\"scenarios\"></a>Common scenarios \n\nAs was mentioned before, when delivering your content to customers (streaming live events or video-on-demand) your goal is to deliver a high quality video to various devices under different network conditions. In addition, your might have other requirements that involve filtering your assets and using of **Dynamic Manifest**s. The following sections give a short overview of different filtering scenarios.\n\n- Specify only a subset of audio and video renditions that certain devices can handle (instead of all the renditions that are associated with the asset). \n- Playing back only a section of a video (instead of playing the whole video).\n- Adjust DVR presentation window.\n\n###Rendition filtering \n\nYou may choose to encode your asset to multiple encoding profiles (H.264 Baseline, H.264 High, AACL, AACH, Dolby Digital Plus) and multiple quality bitrates. However, not all client devices will support all your asset's profiles and bitrates. For example, older Android devices only supports H.264 Baseline+AACL. Sending higher bitrates to a device which cannot get the benefits, wastes bandwidth and device computation. Such device must decode all the given information, only to scale it down for display.\n\nWith Dynamic Manifest, you can create device profiles such as mobile, console, HD/SD, etc. and include the tracks and qualities which you want to be a part of each profile.\n\n \n![Rendition filtering example][renditions2]\n\nIn the following example, Azure Media Encoder was used to encode a mezzanine asset into seven ISO MP4s video renditions (from 180p to 1080p). The encoded asset can be dynamically packaged into any of the following streaming protocols: HLS, Smooth, MPEG DASH, and HDS.  At the top of the diagram, the HLS manifest for the asset with no filters is shown (it contains all seven renditions).  In the bottom left, the HLS manifest to which a filter named \"ott\" was applied is shown. The \"ott\" filter specifies to remove all bitrates below 1Mbps, which resulted in the bottom two quality levels being stripped off in the response.  In the bottom right,   the HLS manifest to which a filter named \"mobile\" was applied is shown. The \"mobile\" filter specifies to remove renditions where the resolution is larger than 720p, which resulted in the two 1080p renditions being stripped off.\n\n![Rendition filtering][renditions1]\n\n###Removing language tracks\n\nYour assets might include multiple audio languages such as English, Spanish, French, etc. Usually, the Player SDK managers default audio track selection and available audio tracks per user selection. It is challenging to develop such Player SDKs, it requires different implementations across device-specific player-frameworks. Also, on some platforms, Player APIs are limited and do not include audio selection feature where users cannot select or change the default audio track. With asset filters, you can control the behavior by creating filters that only include desired audio languages.\n\n![Language tracks filtering][language_filter]\n\n\n###Trimming start of an asset \n\nIn most live streaming events, operators run some tests before the actual event. For example, they might include a slate like this before the start of the event: \"Program will begin momentarily\". If the program is archiving, the test and slate data are also archived and will be included in the presentation. However, this information should not be shown to the clients. With Dynamic Manifest, you can create a start time filter and remove the unwanted data from the manifest.\n\n![Trimming start][trim_filter]\n\n###Creating sub-clips (views) from a live archive\n\nMany live events are long running and live archive might include multiple events. After the live event ends broadcasters may want to break up the live archive into logical program start and stop sequences. Then, publish these virtual programs separately without post processing the live archive and not creating separate assets (which will not get benefit of the existing cached fragments in the CDNs). Examples of such virtual programs (sub-clips) are the quarters of a football or basketball game, the innings in baseball, or individual events of an afternoon of Olympics program.\n\nWith Dynamic Manifest, you can create filters using start/end times and create virtual views over the top of your live archive. \n\n![Subclip filter][subclip_filter]\n\nFiltered Asset:\n\n![Skiing][skiing]\n\n###Adjusting Presentation Window (DVR)\n\nCurrently, Azure Media Services offers circular archive where the duration can be configured between 5 minutes - 25 hours. Manifest filtering can be used to create a rolling DVR window over the top of the archive, without deleting media. There are many scenarios where broadcasters want to provide a limited DVR window which moves with the live edge and at the same time keep a bigger archiving window. A broadcaster may want to use the data that is out of the DVR window to highlight clips, or he\\she may want to provide different DVR windows for different devices. For example, most of the mobile devices don’t handle big DVR windows (you can have a 2 minute DVR window for mobile devices and 1 hour for desktop clients).\n\n![DVR window][dvr_filter]\n\n###Adjusting LiveBackoff (live position)\n\nManifest filtering can be used to remove several seconds from the live edge of a live program. This allows broadcasters to watch the presentation on the preview publication point and create advertisement insertion points before the viewers receive the stream (usually backed-off by 30 seconds). Broadcasters can then push these advertisements to their client frameworks in time for them to received and process the information before the advertisement opportunity.\n\nIn addition to the advertisement support, LiveBackoff can be used for adjusting client live download position so that when clients drift and hit the live edge they can still get fragments from server instead of getting 404 or 412 HTTP errors.\n\n\n\n![livebackoff_filter][livebackoff_filter]\n\n\n###Combining multiple rules in a single filter\n\nYou can combine multiple filtering rules in a single filter. As an example you can define a range rule to remove slate from a live archive and also filter available bitrates. For multiple filtering rules the end result is the composition (intersection only) of these rules.\n\n![multiple-rules][multiple-rules]\n\n##Create filters programmatically\n\nThe following topic discusses Media Services entities that are related to filters. The topic also shows how to programmatically create filters.  \n\n[Create filters with REST APIs](media-services-rest-dynamic-manifest.md).\n\n##Know issues and limitations\n\n- Dynamic manifest operates in GOP boundaries (Key Frames) hence trimming has GOP accuracy. \n- You can use same filter name for local and global filters. Note that local filter have higher precedence and will override global filters.\n- If you update a filter, it can take up to 2 minutes for streaming endpoint to refresh the rules. If the content was served using some filters (and cached in proxies and CDN caches), updating these filters can result in player failures. It is recommend to clear the cache after updating the filter. If this option is not possible, consider using a different filter.\n\n\n##See Also\n\n\n\n[renditions1]: ./media/media-services-dynamic-manifest-overview/media-services-rendition-filter.png\n[renditions2]: ./media/media-services-dynamic-manifest-overview/media-services-rendition-filter2.png\n\n[rendered_subclip]: ./media/media-services-dynamic-manifests/media-services-rendered-subclip.png\n[timeline_trim_event]: ./media/media-services-dynamic-manifests/media-services-timeline-trim-event.png\n[timeline_trim_subclip]: ./media/media-services-dynamic-manifests/media-services-timeline-trim-subclip.png\n\n[multiple-rules]:./media/media-services-dynamic-manifest-overview/media-services-multiple-rules-filters.png\n\n[subclip_filter]: ./media/media-services-dynamic-manifest-overview/media-services-subclips-filter.png\n[trim_event]: ./media/media-services-dynamic-manifests/media-services-timeline-trim-event.png\n[trim_subclip]: ./media/media-services-dynamic-manifests/media-services-timeline-trim-subclip.png\n[trim_filter]: ./media/media-services-dynamic-manifest-overview/media-services-trim-filter.png\n[redered_subclip]: ./media/media-services-dynamic-manifests/media-services-rendered-subclip.png\n[livebackoff_filter]: ./media/media-services-dynamic-manifest-overview/media-services-livebackoff-filter.png\n[language_filter]: ./media/media-services-dynamic-manifest-overview/media-services-language-filter.png\n[dvr_filter]: ./media/media-services-dynamic-manifest-overview/media-services-dvr-filter.png\n[skiing]: ./media/media-services-dynamic-manifest-overview/media-services-skiing.png\n \ntest\n"
}