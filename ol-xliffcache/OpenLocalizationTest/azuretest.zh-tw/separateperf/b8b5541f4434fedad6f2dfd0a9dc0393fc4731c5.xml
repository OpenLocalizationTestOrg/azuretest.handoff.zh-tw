{
  "nodes": [
    {
      "content": "MapReduce and Remote Desktop with Hadoop in HDInsight | Microsoft Azure",
      "pos": [
        26,
        97
      ]
    },
    {
      "content": "Learn how to use Remote Desktop to connect to Hadoop on HDInsight and run MapReduce jobs.",
      "pos": [
        115,
        204
      ]
    },
    {
      "content": "Use MapReduce in Hadoop on HDInsight with Remote Desktop",
      "pos": [
        522,
        578
      ]
    },
    {
      "content": "In this article, you will learn how to connect to a Hadoop on HDInsight cluster by using Remote Desktop and then run MapReduce jobs by using the Hadoop command.",
      "pos": [
        670,
        830
      ]
    },
    {
      "pos": [
        834,
        866
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"prereq\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Prerequisites"
    },
    {
      "content": "To complete the steps in this article, you will need the following:",
      "pos": [
        868,
        935
      ]
    },
    {
      "content": "A Windows-based HDInsight (Hadoop on HDInsight) cluster",
      "pos": [
        939,
        994
      ]
    },
    {
      "content": "A client computer running Windows 10, Windows 8, or Windows 7",
      "pos": [
        998,
        1059
      ]
    },
    {
      "pos": [
        1063,
        1110
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"connect\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Connect with Remote Desktop"
    },
    {
      "pos": [
        1112,
        1306
      ],
      "content": "Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id=\"p1\">[</bpt>Connect to HDInsight clusters using RDP<ept id=\"p1\">](hdinsight-administer-use-management-portal.md#rdp)</ept>."
    },
    {
      "pos": [
        1310,
        1351
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"hadoop\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Use the Hadoop command"
    },
    {
      "content": "When you are connected to the desktop for the HDInsight cluster, use the following steps to run a MapReduce job by using the Hadoop command:",
      "pos": [
        1353,
        1493
      ]
    },
    {
      "content": "From the HDInsight desktop, start the <bpt id=\"p1\">**</bpt>Hadoop Command Line<ept id=\"p1\">**</ept>.",
      "pos": [
        1498,
        1560
      ]
    },
    {
      "content": "This opens a new command prompt in the <bpt id=\"p1\">**</bpt>c:\\apps\\dist\\hadoop-&amp;lt;version number&gt;<ept id=\"p1\">**</ept> directory.",
      "pos": [
        1561,
        1654
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The version number changes as Hadoop is updated.",
      "pos": [
        1662,
        1723
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>HADOOP_HOME<ept id=\"p1\">**</ept> environment variable can be used to find the path.",
      "pos": [
        1724,
        1794
      ]
    },
    {
      "content": "For example, <ph id=\"ph1\">`cd %HADOOP_HOME%`</ph> changes directories to the Hadoop directory, without requiring you to know the version number.",
      "pos": [
        1795,
        1921
      ]
    },
    {
      "pos": [
        1926,
        2015
      ],
      "content": "To use the <bpt id=\"p1\">**</bpt>Hadoop<ept id=\"p1\">**</ept> command to run an example MapReduce job, use the following command:"
    },
    {
      "content": "This starts the <bpt id=\"p1\">**</bpt>wordcount<ept id=\"p1\">**</ept> class, which is contained in the <bpt id=\"p2\">**</bpt>hadoop-mapreduce-examples.jar<ept id=\"p2\">**</ept> file in the current directory.",
      "pos": [
        2161,
        2288
      ]
    },
    {
      "content": "As input, it uses the <bpt id=\"p1\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p1\">**</ept> document, and output is stored at: <bpt id=\"p2\">**</bpt>wasb:///example/data/WordCountOutput<ept id=\"p2\">**</ept>.",
      "pos": [
        2289,
        2433
      ]
    },
    {
      "pos": [
        2441,
        2601
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> for more information about this MapReduce job and the example data, see <ph id=\"ph2\">&lt;a href=\"hdinsight-use-mapreduce.md\"&gt;</ph>Use MapReduce in HDInsight Hadoop<ph id=\"ph3\">&lt;/a&gt;</ph>."
    },
    {
      "content": "The job emits details as it is processed, and it returns information similar to the following when the job is complete:",
      "pos": [
        2606,
        2725
      ]
    },
    {
      "pos": [
        2858,
        2985
      ],
      "content": "When the job is complete, use the following command to list the output files stored at <bpt id=\"p1\">**</bpt>wasb://example/data/WordCountOutput<ept id=\"p1\">**</ept>:"
    },
    {
      "content": "This should display two files, <bpt id=\"p1\">**</bpt>_SUCCESS<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>part-r-00000<ept id=\"p2\">**</ept>.",
      "pos": [
        3051,
        3116
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>part-r-00000<ept id=\"p1\">**</ept> file contains the output for this job.",
      "pos": [
        3117,
        3176
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Some MapReduce jobs may split the results across multiple <bpt id=\"p1\">**</bpt>part-r-#####<ept id=\"p1\">**</ept> files.",
      "pos": [
        3184,
        3278
      ]
    },
    {
      "content": "If so, use the ##### suffix to indicate the order of the files.",
      "pos": [
        3279,
        3342
      ]
    },
    {
      "content": "To view the output, use the following command:",
      "pos": [
        3347,
        3393
      ]
    },
    {
      "content": "This displays a list of the words that are contained in the <bpt id=\"p1\">**</bpt>wasb://example/data/gutenberg/davinci.txt<ept id=\"p1\">**</ept> file, along with the number of times each word occured.",
      "pos": [
        3473,
        3634
      ]
    },
    {
      "content": "The following is an example of the data that will be contained in the file:",
      "pos": [
        3635,
        3710
      ]
    },
    {
      "pos": [
        3897,
        3924
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"summary\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Summary"
    },
    {
      "content": "As you can see, the Hadoop command provides an easy way to run MapReduce jobs on an HDInsight cluster and then view the job output.",
      "pos": [
        3926,
        4057
      ]
    },
    {
      "pos": [
        4061,
        4093
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Next steps"
    },
    {
      "content": "For general information about MapReduce jobs in HDInsight:",
      "pos": [
        4095,
        4153
      ]
    },
    {
      "content": "Use MapReduce on HDInsight Hadoop",
      "pos": [
        4158,
        4191
      ]
    },
    {
      "content": "For information about other ways you can work with Hadoop on HDInsight:",
      "pos": [
        4222,
        4293
      ]
    },
    {
      "content": "Use Hive with Hadoop on HDInsight",
      "pos": [
        4298,
        4331
      ]
    },
    {
      "content": "Use Pig with Hadoop on HDInsight",
      "pos": [
        4360,
        4392
      ]
    },
    {
      "content": "test",
      "pos": [
        4417,
        4421
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"MapReduce and Remote Desktop with Hadoop in HDInsight | Microsoft Azure\"\n   description=\"Learn how to use Remote Desktop to connect to Hadoop on HDInsight and run MapReduce jobs.\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"07/06/2015\"\n   ms.author=\"larryfr\"/>\n\n# Use MapReduce in Hadoop on HDInsight with Remote Desktop\n\n[AZURE.INCLUDE [mapreduce-selector](../../includes/hdinsight-selector-use-mapreduce.md)]\n\nIn this article, you will learn how to connect to a Hadoop on HDInsight cluster by using Remote Desktop and then run MapReduce jobs by using the Hadoop command.\n\n##<a id=\"prereq\"></a>Prerequisites\n\nTo complete the steps in this article, you will need the following:\n\n* A Windows-based HDInsight (Hadoop on HDInsight) cluster\n\n* A client computer running Windows 10, Windows 8, or Windows 7\n\n##<a id=\"connect\"></a>Connect with Remote Desktop\n\nEnable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at [Connect to HDInsight clusters using RDP](hdinsight-administer-use-management-portal.md#rdp).\n\n##<a id=\"hadoop\"></a>Use the Hadoop command\n\nWhen you are connected to the desktop for the HDInsight cluster, use the following steps to run a MapReduce job by using the Hadoop command:\n\n1. From the HDInsight desktop, start the **Hadoop Command Line**. This opens a new command prompt in the **c:\\apps\\dist\\hadoop-&lt;version number>** directory.\n\n    > [AZURE.NOTE] The version number changes as Hadoop is updated. The **HADOOP_HOME** environment variable can be used to find the path. For example, `cd %HADOOP_HOME%` changes directories to the Hadoop directory, without requiring you to know the version number.\n\n2. To use the **Hadoop** command to run an example MapReduce job, use the following command:\n\n        hadoop jar hadoop-mapreduce-examples.jar wordcount wasb:///example/data/gutenberg/davinci.txt wasb:///example/data/WordCountOutput\n\n    This starts the **wordcount** class, which is contained in the **hadoop-mapreduce-examples.jar** file in the current directory. As input, it uses the **wasb://example/data/gutenberg/davinci.txt** document, and output is stored at: **wasb:///example/data/WordCountOutput**.\n\n    > [AZURE.NOTE] for more information about this MapReduce job and the example data, see <a href=\"hdinsight-use-mapreduce.md\">Use MapReduce in HDInsight Hadoop</a>.\n\n2. The job emits details as it is processed, and it returns information similar to the following when the job is complete:\n\n        File Input Format Counters\n        Bytes Read=1395666\n        File Output Format Counters\n        Bytes Written=337623\n\n3. When the job is complete, use the following command to list the output files stored at **wasb://example/data/WordCountOutput**:\n\n        hadoop fs -ls wasb:///example/data/WordCountOutput\n\n    This should display two files, **_SUCCESS** and **part-r-00000**. The **part-r-00000** file contains the output for this job.\n\n    > [AZURE.NOTE] Some MapReduce jobs may split the results across multiple **part-r-#####** files. If so, use the ##### suffix to indicate the order of the files.\n\n4. To view the output, use the following command:\n\n        hadoop fs -cat wasb:///example/data/WordCountOutput/part-r-00000\n\n    This displays a list of the words that are contained in the **wasb://example/data/gutenberg/davinci.txt** file, along with the number of times each word occured. The following is an example of the data that will be contained in the file:\n\n        wreathed        3\n        wreathing       1\n        wreaths         1\n        wrecked         3\n        wrenching       1\n        wretched        6\n        wriggling       1\n\n##<a id=\"summary\"></a>Summary\n\nAs you can see, the Hadoop command provides an easy way to run MapReduce jobs on an HDInsight cluster and then view the job output.\n\n##<a id=\"nextsteps\"></a>Next steps\n\nFor general information about MapReduce jobs in HDInsight:\n\n* [Use MapReduce on HDInsight Hadoop](hdinsight-use-mapreduce.md)\n\nFor information about other ways you can work with Hadoop on HDInsight:\n\n* [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md)\n\n* [Use Pig with Hadoop on HDInsight](hdinsight-use-pig.md)\n\ntest\n"
}