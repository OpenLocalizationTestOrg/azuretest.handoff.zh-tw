<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Develop Scalding MapReduce jobs with Maven | Microsoft Azure</source>
          <target state="new">Develop Scalding MapReduce jobs with Maven | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.</source>
          <target state="new">Learn how to use Maven to create a Scalding MapReduce job, then deploy and run the job on a Hadoop on HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</source>
          <target state="new">Develop Scalding MapReduce jobs with Apache Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</source>
          <target state="new">Scalding is a Scala library that makes it easy to create Hadoop MapReduce jobs.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>It offers a concise syntax, as well as tight integration with Scala.</source>
          <target state="new">It offers a concise syntax, as well as tight integration with Scala.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</source>
          <target state="new">In this document, learn how to use Maven to create a basic word count MapReduce job written in Scalding.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>You will then learn how to deploy and run this job on an HDInsight cluster.</source>
          <target state="new">You will then learn how to deploy and run this job on an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>A Windows or Linux based Hadoop on HDInsight cluster<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Provision Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-provision-linux-clusters.md)</ept> or <bpt id="p2">[</bpt>Provision Windows-based Hadoop on HDInsight<ept id="p2">](hdinsight-provision-clusters.md)</ept> for more information.</source>
          <target state="new">See <bpt id="p1">[</bpt>Provision Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-provision-linux-clusters.md)</ept> or <bpt id="p2">[</bpt>Provision Windows-based Hadoop on HDInsight<ept id="p2">](hdinsight-provision-clusters.md)</ept> for more information.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Maven</source>
          <target state="new">Maven</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Java platform JDK<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/index.html)</ept> 7 or later</source>
          <target state="new"><bpt id="p1">[</bpt>Java platform JDK<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/index.html)</ept> 7 or later</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Create and build the project</source>
          <target state="new">Create and build the project</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Use the following command to create a new Maven project:</source>
          <target state="new">Use the following command to create a new Maven project:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>This command will create a new directory named <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept>, and create the scaffolding for an Scala application.</source>
          <target state="new">This command will create a new directory named <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept>, and create the scaffolding for an Scala application.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept> directory, open the <bpt id="p2">**</bpt>pom.xml<ept id="p2">**</ept> file and replace the contents with the following:</source>
          <target state="new">In the <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept> directory, open the <bpt id="p2">**</bpt>pom.xml<ept id="p2">**</ept> file and replace the contents with the following:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>This file describes the project, dependencies, and plugins.</source>
          <target state="new">This file describes the project, dependencies, and plugins.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Here are the important entries:</source>
          <target state="new">Here are the important entries:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>maven.compiler.source<ept id="p1">**</ept> and <bpt id="p2">**</bpt>maven.compiler.target<ept id="p2">**</ept>: sets the Java version for this project</source>
          <target state="new"><bpt id="p1">**</bpt>maven.compiler.source<ept id="p1">**</ept> and <bpt id="p2">**</bpt>maven.compiler.target<ept id="p2">**</ept>: sets the Java version for this project</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>repositories<ept id="p1">**</ept>: the repositories that contain the dependency files used by this project</source>
          <target state="new"><bpt id="p1">**</bpt>repositories<ept id="p1">**</ept>: the repositories that contain the dependency files used by this project</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>scalding-core_2.11<ept id="p1">**</ept> and <bpt id="p2">**</bpt>hadoop-core<ept id="p2">**</ept>: this project depends on both Scalding and Hadoop core packages</source>
          <target state="new"><bpt id="p1">**</bpt>scalding-core_2.11<ept id="p1">**</ept> and <bpt id="p2">**</bpt>hadoop-core<ept id="p2">**</ept>: this project depends on both Scalding and Hadoop core packages</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>maven-scala-plugin<ept id="p1">**</ept>: plugin to compile scala applications</source>
          <target state="new"><bpt id="p1">**</bpt>maven-scala-plugin<ept id="p1">**</ept>: plugin to compile scala applications</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>maven-shade-plugin<ept id="p1">**</ept>: plugin to create shaded (fat) jars.</source>
          <target state="new"><bpt id="p1">**</bpt>maven-shade-plugin<ept id="p1">**</ept>: plugin to create shaded (fat) jars.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>This plugin applies filters and transformations; specificially:</source>
          <target state="new">This plugin applies filters and transformations; specificially:</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>filters<ept id="p1">**</ept>: The filters applied modify the meta information included with in the jar file.</source>
          <target state="new"><bpt id="p1">**</bpt>filters<ept id="p1">**</ept>: The filters applied modify the meta information included with in the jar file.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</source>
          <target state="new">To prevent signing exceptions at runtime, this excludes various signature files that may be included with dependencies.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>executions<ept id="p1">**</ept>: The package phase execution configuration specifies the <bpt id="p2">**</bpt>com.twitter.scalding.Tool<ept id="p2">**</ept> class as the main class for the package.</source>
          <target state="new"><bpt id="p1">**</bpt>executions<ept id="p1">**</ept>: The package phase execution configuration specifies the <bpt id="p2">**</bpt>com.twitter.scalding.Tool<ept id="p2">**</ept> class as the main class for the package.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</source>
          <target state="new">Without this, you would need to specify com.twitter.scalding.Tool, as well as the class that contains the application logic, when running the job with the hadoop command.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Delete the <bpt id="p1">**</bpt>src/test<ept id="p1">**</ept> directory, as you will not be creating tests with this example.</source>
          <target state="new">Delete the <bpt id="p1">**</bpt>src/test<ept id="p1">**</ept> directory, as you will not be creating tests with this example.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Open the <bpt id="p1">**</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="p1">**</ept> file and replace the contents with the following:</source>
          <target state="new">Open the <bpt id="p1">**</bpt>src/main/scala/com/microsoft/example/app.scala<ept id="p1">**</ept> file and replace the contents with the following:</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>This implements a basic word count job.</source>
          <target state="new">This implements a basic word count job.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Save and close the files.</source>
          <target state="new">Save and close the files.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Use the following command from the <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept> directory to build and package the application:</source>
          <target state="new">Use the following command from the <bpt id="p1">**</bpt>scaldingwordcount<ept id="p1">**</ept> directory to build and package the application:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Once this job completes, the package containing the WordCount application can be found at <bpt id="p1">**</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p1">**</ept>.</source>
          <target state="new">Once this job completes, the package containing the WordCount application can be found at <bpt id="p1">**</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Run the job on a Linux-based cluster</source>
          <target state="new">Run the job on a Linux-based cluster</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The following steps use SSH and the Hadoop command.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The following steps use SSH and the Hadoop command.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>For other methods of running MapReduce jobs, see <bpt id="p1">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p1">](hdinsight-use-mapreduce.md)</ept>.</source>
          <target state="new">For other methods of running MapReduce jobs, see <bpt id="p1">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p1">](hdinsight-use-mapreduce.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Use the following command to upload the package to your HDInsight cluster:</source>
          <target state="new">Use the following command to upload the package to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>This copies the files from the local system to the head node.</source>
          <target state="new">This copies the files from the local system to the head node.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph1">`scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.`</ph></source>
          <target state="new">For example, <ph id="ph1">`scp -i /path/to/private/key target/scaldingwordcount-1.0-SNAPSHOT.jar username@clustername-ssh.azurehdinsight.net:.`</ph></target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Use the following command to connect to the cluster head node:</source>
          <target state="new">Use the following command to connect to the cluster head node:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you used a password to secure your SSH account, you will be prompted for the password.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key.</source>
          <target state="new">If you used an SSH key, you may have to use the <ph id="ph1">`-i`</ph> parameter and the path to the private key.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph1">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph></source>
          <target state="new">For example, <ph id="ph1">`ssh -i /path/to/private/key username@clustername-ssh.azurehdinsight.net`</ph></target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Once connected to the head node, use the following command to run the word cound job</source>
          <target state="new">Once connected to the head node, use the following command to run the word cound job</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>This runs the WordCount class you implemented earlier.</source>
          <target state="new">This runs the WordCount class you implemented earlier.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`--hdfs`</ph> instructs the job to use HDFS.</source>
          <target state="new"><ph id="ph1">`--hdfs`</ph> instructs the job to use HDFS.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`--input`</ph> specifies the input text file, while <ph id="ph2">`--output`</ph> specifies the output location.</source>
          <target state="new"><ph id="ph1">`--input`</ph> specifies the input text file, while <ph id="ph2">`--output`</ph> specifies the output location.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>After the job completes, use the following to view the output.</source>
          <target state="new">After the job completes, use the following to view the output.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>This will display information similar to the following:</source>
          <target state="new">This will display information similar to the following:</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Run the job on a Windows-based cluster</source>
          <target state="new">Run the job on a Windows-based cluster</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The following steps use Windows PowerShell.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The following steps use Windows PowerShell.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>For other methods of running MapReduce jobs, see <bpt id="p1">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p1">](hdinsight-use-mapreduce.md)</ept>.</source>
          <target state="new">For other methods of running MapReduce jobs, see <bpt id="p1">[</bpt>Use MapReduce in Hadoop on HDInsight<ept id="p1">](hdinsight-use-mapreduce.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../install-configure-powershell.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">](../install-configure-powershell.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Download <bpt id="p1">[</bpt>hdinsight-tools.psm1<ept id="p1">](https://github.com/Blackmist/hdinsight-tools/blob/master/hdinsight-tools.psm1)</ept> and save to a file named <bpt id="p2">**</bpt>hdinsight-tools.psm1<ept id="p2">**</ept>.</source>
          <target state="new">Download <bpt id="p1">[</bpt>hdinsight-tools.psm1<ept id="p1">](https://github.com/Blackmist/hdinsight-tools/blob/master/hdinsight-tools.psm1)</ept> and save to a file named <bpt id="p2">**</bpt>hdinsight-tools.psm1<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Open a new <bpt id="p1">**</bpt>Azure PoweShell<ept id="p1">**</ept> session and enter the following command.</source>
          <target state="new">Open a new <bpt id="p1">**</bpt>Azure PoweShell<ept id="p1">**</ept> session and enter the following command.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>If hdinsight-tools.psm1 isn't in the current directory, provide the path to the file:</source>
          <target state="new">If hdinsight-tools.psm1 isn't in the current directory, provide the path to the file:</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>This imports several functions for working with files in HDInsight.</source>
          <target state="new">This imports several functions for working with files in HDInsight.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Use the following commands to upload the jar file containing the WordCount job.</source>
          <target state="new">Use the following commands to upload the jar file containing the WordCount job.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Replace <ph id="ph1">`CLUSTERNAME`</ph> with the name of your HDInsight cluster:</source>
          <target state="new">Replace <ph id="ph1">`CLUSTERNAME`</ph> with the name of your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Once the upload has completed, use the following commands to run the job:</source>
          <target state="new">Once the upload has completed, use the following commands to run the job:</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Once the job completes, use the following to download the job output:</source>
          <target state="new">Once the job completes, use the following to download the job output:</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>The output consists of tab delimited word and count values.</source>
          <target state="new">The output consists of tab delimited word and count values.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>use the following command to display the results.</source>
          <target state="new">use the following command to display the results.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>The file should contain values similar to the following:</source>
          <target state="new">The file should contain values similar to the following:</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>If the output is empty, or the file doesn't exist, you can use the following to view any errors that occurred when running the job:</source>
          <target state="new">If the output is empty, or the file doesn't exist, you can use the following to view any errors that occurred when running the job:</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</source>
          <target state="new">Now that you have learned how to use Scalding to create MapReduce jobs for HDInsight, use the following links to explore other ways to work with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Use MapReduce jobs with HDInsight</source>
          <target state="new">Use MapReduce jobs with HDInsight</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bc076aae9ae42f2ae36b6d7043cdd0ff195fc2eb</xliffext:olfilehash>
  </header>
</xliff>