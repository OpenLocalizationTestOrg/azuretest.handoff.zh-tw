<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Build your first Azure Data Factory pipeline using Azure PowerShell</source>
          <target state="new">Build your first Azure Data Factory pipeline using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will create a sample Azure Data Factory pipeline using Azure PowerShell.</source>
          <target state="new">In this tutorial, you will create a sample Azure Data Factory pipeline using Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Build your first Azure Data Factory pipeline using Azure PowerShell</source>
          <target state="new">Build your first Azure Data Factory pipeline using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>[AZURE.SELECTOR]</source>
          <target state="new">[AZURE.SELECTOR]</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Tutorial Overview</source>
          <target state="new">Tutorial Overview</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Using Data Factory Editor</source>
          <target state="new">Using Data Factory Editor</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Using PowerShell</source>
          <target state="new">Using PowerShell</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Using Visual Studio</source>
          <target state="new">Using Visual Studio</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In this article, you will learn how to use Azure PowerShell to create your first pipeline.</source>
          <target state="new">In this article, you will learn how to use Azure PowerShell to create your first pipeline.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>This tutorial consists of the following steps:</source>
          <target state="new">This tutorial consists of the following steps:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Creating the data factory.</source>
          <target state="new">Creating the data factory.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Creating the linked services (data stores, computes) and datasets.</source>
          <target state="new">Creating the linked services (data stores, computes) and datasets.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Creating the pipeline.</source>
          <target state="new">Creating the pipeline.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>This article does not provide a conceptual overview of the Azure Data Factory service.</source>
          <target state="new">This article does not provide a conceptual overview of the Azure Data Factory service.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>For a detailed overview of the service, see the <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">](data-factory-introduction.md)</ept> article.</source>
          <target state="new">For a detailed overview of the service, see the <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">](data-factory-introduction.md)</ept> article.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Step 1: Creating the data factory</source>
          <target state="new">Step 1: Creating the data factory</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>In this step, you use Azure PowerShell to create an Azure Data Factory named ADFTutorialDataFactoryPSH.</source>
          <target state="new">In this step, you use Azure PowerShell to create an Azure Data Factory named ADFTutorialDataFactoryPSH.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Start Azure PowerShell and run the following commands.</source>
          <target state="new">Start Azure PowerShell and run the following commands.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Keep Azure PowerShell open until the end of this tutorial.</source>
          <target state="new">Keep Azure PowerShell open until the end of this tutorial.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>If you close and reopen, you need to run these commands again.</source>
          <target state="new">If you close and reopen, you need to run these commands again.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign in to the Azure preview portal.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign in to the Azure preview portal.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>This subscription should be the same as the one you used in the preview portal.</source>
          <target state="new">This subscription should be the same as the one you used in the preview portal.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Switch to AzureResourceManager mode as the Azure Data Factory cmdlets are available in this mode.</source>
          <target state="new">Switch to AzureResourceManager mode as the Azure Data Factory cmdlets are available in this mode.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Create an Azure resource group named <bpt id="p1">*</bpt>ADFTutorialResourceGroup<ept id="p1">*</ept> by running the following command.</source>
          <target state="new">Create an Azure resource group named <bpt id="p1">*</bpt>ADFTutorialResourceGroup<ept id="p1">*</ept> by running the following command.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Some of the steps in this tutorial assume that you use the resource group named ADFTutorialResourceGroup.</source>
          <target state="new">Some of the steps in this tutorial assume that you use the resource group named ADFTutorialResourceGroup.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>If you use a different resource group, you will need to use it in place of ADFTutorialResourceGroup in this tutorial.</source>
          <target state="new">If you use a different resource group, you will need to use it in place of ADFTutorialResourceGroup in this tutorial.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Run the <bpt id="p1">**</bpt>New-AzureDataFactory<ept id="p1">**</ept> cmdlet to create a data factory named DataFactoryMyFirstPipelinePSH.</source>
          <target state="new">Run the <bpt id="p1">**</bpt>New-AzureDataFactory<ept id="p1">**</ept> cmdlet to create a data factory named DataFactoryMyFirstPipelinePSH.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The name of the Azure Data Factory must be globally unique.</source>
          <target state="new">The name of the Azure Data Factory must be globally unique.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>If you receive the error <bpt id="p1">**</bpt>Data factory name “DataFactoryMyFirstPipelinePSH” is not available<ept id="p1">**</ept>, change the name (for example, yournameADFTutorialDataFactoryPSH).</source>
          <target state="new">If you receive the error <bpt id="p1">**</bpt>Data factory name “DataFactoryMyFirstPipelinePSH” is not available<ept id="p1">**</ept>, change the name (for example, yournameADFTutorialDataFactoryPSH).</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Use this name in place of ADFTutorialFactoryPSH while performing steps in this tutorial.</source>
          <target state="new">Use this name in place of ADFTutorialFactoryPSH while performing steps in this tutorial.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>In the subsequent steps, you will learn how to create the linked services, datasets and pipeline that you will use in this tutorial.</source>
          <target state="new">In the subsequent steps, you will learn how to create the linked services, datasets and pipeline that you will use in this tutorial.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Step 2: Create linked services and datasets</source>
          <target state="new">Step 2: Create linked services and datasets</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>In this step, you will link your Azure Storage account and an on-demand Azure HDInsight cluster to your data factory and then create a dataset to represent the output data from Hive processing.</source>
          <target state="new">In this step, you will link your Azure Storage account and an on-demand Azure HDInsight cluster to your data factory and then create a dataset to represent the output data from Hive processing.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Create Azure Storage linked service</source>
          <target state="new">Create Azure Storage linked service</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Create a JSON file named StorageLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</source>
          <target state="new">Create a JSON file named StorageLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Create the folder ADFGetStartedPSH if it does not already exist.</source>
          <target state="new">Create the folder ADFGetStartedPSH if it does not already exist.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p1">**</bpt>account name<ept id="p1">**</ept> with the name of your Azure storage account and <bpt id="p2">**</bpt>account key<ept id="p2">**</ept> with the access key of the Azure storage account.</source>
          <target state="new">Replace <bpt id="p1">**</bpt>account name<ept id="p1">**</ept> with the name of your Azure storage account and <bpt id="p2">**</bpt>account key<ept id="p2">**</ept> with the access key of the Azure storage account.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>To learn how to get your storage access key, see <bpt id="p1">[</bpt>View, copy and regenerate storage access keys<ept id="p1">](http://azure.microsoft.com/documentation/articles/storage-create-storage-account/#view-copy-and-regenerate-storage-access-keys)</ept>.</source>
          <target state="new">To learn how to get your storage access key, see <bpt id="p1">[</bpt>View, copy and regenerate storage access keys<ept id="p1">](http://azure.microsoft.com/documentation/articles/storage-create-storage-account/#view-copy-and-regenerate-storage-access-keys)</ept>.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>In Azure PowerShell, switch to the ADFGetStartedPSH folder.</source>
          <target state="new">In Azure PowerShell, switch to the ADFGetStartedPSH folder.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>You can use the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create a linked service.</source>
          <target state="new">You can use the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create a linked service.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>This cmdlet and other Data Factory cmdlets you use in this tutorial require you to pass values for the <bpt id="p1">*</bpt>ResourceGroupName<ept id="p1">*</ept> and <bpt id="p2">*</bpt>DataFactoryName<ept id="p2">*</ept> parameters.</source>
          <target state="new">This cmdlet and other Data Factory cmdlets you use in this tutorial require you to pass values for the <bpt id="p1">*</bpt>ResourceGroupName<ept id="p1">*</ept> and <bpt id="p2">*</bpt>DataFactoryName<ept id="p2">*</ept> parameters.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Alternatively, you can use <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> to get a <bpt id="p2">**</bpt>DataFactory<ept id="p2">**</ept> object and pass the object without typing <bpt id="p3">*</bpt>ResourceGroupName<ept id="p3">*</ept> and <bpt id="p4">*</bpt>DataFactoryName<ept id="p4">*</ept> each time you run a cmdlet.</source>
          <target state="new">Alternatively, you can use <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> to get a <bpt id="p2">**</bpt>DataFactory<ept id="p2">**</ept> object and pass the object without typing <bpt id="p3">*</bpt>ResourceGroupName<ept id="p3">*</ept> and <bpt id="p4">*</bpt>DataFactoryName<ept id="p4">*</ept> each time you run a cmdlet.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Run the following command to assign the output of the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet to a <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable.</source>
          <target state="new">Run the following command to assign the output of the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet to a <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Now, run the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create the linked <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> service.</source>
          <target state="new">Now, run the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create the linked <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> service.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>If you hadn't run the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet and assigned the output to the <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable, you would have to specify values for the <bpt id="p3">*</bpt>ResourceGroupName<ept id="p3">*</ept> and <bpt id="p4">*</bpt>DataFactoryName<ept id="p4">*</ept> parameters as follows.</source>
          <target state="new">If you hadn't run the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet and assigned the output to the <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable, you would have to specify values for the <bpt id="p3">*</bpt>ResourceGroupName<ept id="p3">*</ept> and <bpt id="p4">*</bpt>DataFactoryName<ept id="p4">*</ept> parameters as follows.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>If you close Azure PowerShell in the middle of the tutorial, you will have run the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet next time you start Azure PowerShell to complete the tutorial.</source>
          <target state="new">If you close Azure PowerShell in the middle of the tutorial, you will have run the <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> cmdlet next time you start Azure PowerShell to complete the tutorial.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Create Azure HDInsight linked service</source>
          <target state="new">Create Azure HDInsight linked service</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Now, you will create a linked service for an on-demand Azure HDInsight cluster that will be used to run the Hive script.</source>
          <target state="new">Now, you will create a linked service for an on-demand Azure HDInsight cluster that will be used to run the Hive script.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Create a JSON file named HDInsightOnDemandLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</source>
          <target state="new">Create a JSON file named HDInsightOnDemandLinkedService.json in the C:\ADFGetStartedPSH folder with the following content.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Run the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create the linked service called HDInsightOnDemandLinkedService.</source>
          <target state="new">Run the <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> cmdlet to create the linked service called HDInsightOnDemandLinkedService.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Create the output dataset</source>
          <target state="new">Create the output dataset</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Now, you will create the output dataset to represent the data stored in the Azure Blob storage.</source>
          <target state="new">Now, you will create the output dataset to represent the data stored in the Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Create a JSON file named OutputTable.json in the C:\ADFGetStartedPSH folder with the following content:</source>
          <target state="new">Create a JSON file named OutputTable.json in the C:\ADFGetStartedPSH folder with the following content:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>In the previous example, you are creating a dataset called <bpt id="p1">**</bpt>AzureBlobOutput<ept id="p1">**</ept>, and specifying the structure of the data that will be produced by the Hive script.</source>
          <target state="new">In the previous example, you are creating a dataset called <bpt id="p1">**</bpt>AzureBlobOutput<ept id="p1">**</ept>, and specifying the structure of the data that will be produced by the Hive script.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>In addition, you specify that the results are stored in the blob container called <bpt id="p1">**</bpt>data<ept id="p1">**</ept> and the folder called <bpt id="p2">**</bpt>partitioneddata<ept id="p2">**</ept>.</source>
          <target state="new">In addition, you specify that the results are stored in the blob container called <bpt id="p1">**</bpt>data<ept id="p1">**</ept> and the folder called <bpt id="p2">**</bpt>partitioneddata<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>availability<ept id="p1">**</ept> section specifies that the output dataset is produced on a monthly basis.</source>
          <target state="new">The <bpt id="p1">**</bpt>availability<ept id="p1">**</ept> section specifies that the output dataset is produced on a monthly basis.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Run the following command in Azure PowerShell to create the Data Factory table.</source>
          <target state="new">Run the following command in Azure PowerShell to create the Data Factory table.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Step 3: Creating your first pipeline</source>
          <target state="new">Step 3: Creating your first pipeline</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>In this step, you will create your first pipeline.</source>
          <target state="new">In this step, you will create your first pipeline.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Create a JSON file named MyFirstPipelinePSH.json in the C:\ADFGetStartedPSH folder with the following content:</source>
          <target state="new">Create a JSON file named MyFirstPipelinePSH.json in the C:\ADFGetStartedPSH folder with the following content:</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.IMPORTANT]</ph> Replace <bpt id="p1">**</bpt>storageaccountname<ept id="p1">**</ept> with the name of your storage account in the  JSON.</source>
          <target state="new"><ph id="ph1">[AZURE.IMPORTANT]</ph> Replace <bpt id="p1">**</bpt>storageaccountname<ept id="p1">**</ept> with the name of your storage account in the  JSON.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>In the previous example, you are creating a pipeline that consists of a single activity that uses Hive to process data on an HDInsight cluster.</source>
          <target state="new">In the previous example, you are creating a pipeline that consists of a single activity that uses Hive to process data on an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The Hive script file, partitionweblogs.hql, is stored in the Azure storage account (specified by the scriptLinkedService, called StorageLinkedService), and in a container called <bpt id="p1">**</bpt>script<ept id="p1">**</ept>.</source>
          <target state="new">The Hive script file, partitionweblogs.hql, is stored in the Azure storage account (specified by the scriptLinkedService, called StorageLinkedService), and in a container called <bpt id="p1">**</bpt>script<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>extendedProperties<ept id="p1">**</ept> section is used to specify the runtime settings that will be passed to the hive script as Hive configuration values (for example, ${hiveconf:PartitionedData}).</source>
          <target state="new">The <bpt id="p1">**</bpt>extendedProperties<ept id="p1">**</ept> section is used to specify the runtime settings that will be passed to the hive script as Hive configuration values (for example, ${hiveconf:PartitionedData}).</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>start<ept id="p1">**</ept> and <bpt id="p2">**</bpt>end<ept id="p2">**</ept> properties of the pipeline specifies the active period of the pipeline.</source>
          <target state="new">The <bpt id="p1">**</bpt>start<ept id="p1">**</ept> and <bpt id="p2">**</bpt>end<ept id="p2">**</ept> properties of the pipeline specifies the active period of the pipeline.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>In the activity JSON, you specify that the Hive script runs on the computer specified by the linked service – <bpt id="p1">**</bpt>HDInsightOnDemandLinkedService<ept id="p1">**</ept>.</source>
          <target state="new">In the activity JSON, you specify that the Hive script runs on the computer specified by the linked service – <bpt id="p1">**</bpt>HDInsightOnDemandLinkedService<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Run the following command to create the Data Factory table.</source>
          <target state="new">Run the following command to create the Data Factory table.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Congratulations, you have successfully created your first pipeline using Azure PowerShell!</source>
          <target state="new">Congratulations, you have successfully created your first pipeline using Azure PowerShell!</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MonitorDataSetsAndPipeline"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Monitor the datasets and pipeline</source>
          <target state="new"><ph id="ph1">&lt;a name="MonitorDataSetsAndPipeline"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Monitor the datasets and pipeline</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>In this step, you will use Azure PowerShell to monitor what’s going on in an Azure data factory.</source>
          <target state="new">In this step, you will use Azure PowerShell to monitor what’s going on in an Azure data factory.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> and assign the output to a <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureDataFactory<ept id="p1">**</ept> and assign the output to a <bpt id="p2">**</bpt>$df<ept id="p2">**</ept> variable.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureDataFactorySlice<ept id="p1">**</ept> to get details about all slices of the <bpt id="p2">**</bpt>EmpSQLTable<ept id="p2">**</ept>, which is the output table of the pipeline.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureDataFactorySlice<ept id="p1">**</ept> to get details about all slices of the <bpt id="p2">**</bpt>EmpSQLTable<ept id="p2">**</ept>, which is the output table of the pipeline.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Notice that the StartDateTime you specify here is the same start time specified in the pipeline JSON.</source>
          <target state="new">Notice that the StartDateTime you specify here is the same start time specified in the pipeline JSON.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>You should see output similar to the following.</source>
          <target state="new">You should see output similar to the following.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureDataFactoryRun<ept id="p1">**</ept> to get the details of activity runs for a specific slice.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureDataFactoryRun<ept id="p1">**</ept> to get the details of activity runs for a specific slice.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>You should see output similar to the following.</source>
          <target state="new">You should see output similar to the following.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>You can keep running this cmdlet until you see the slice in Ready state or Failed state.</source>
          <target state="new">You can keep running this cmdlet until you see the slice in Ready state or Failed state.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>When the slice is in Ready state, check the partitioneddata folder in the data container in your blob storage for the output data.</source>
          <target state="new">When the slice is in Ready state, check the partitioneddata folder in the data container in your blob storage for the output data.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Note that the creation of an on-demand HDInsight cluster usually takes some time.</source>
          <target state="new">Note that the creation of an on-demand HDInsight cluster usually takes some time.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Data Factory Cmdlet Reference<ept id="p1">](https://msdn.microsoft.com/library/azure/dn820234.aspx)</ept> for comprehensive documentation on Data Factory cmdlets.</source>
          <target state="new">See <bpt id="p1">[</bpt>Data Factory Cmdlet Reference<ept id="p1">](https://msdn.microsoft.com/library/azure/dn820234.aspx)</ept> for comprehensive documentation on Data Factory cmdlets.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand Azure HDInsight cluster.</source>
          <target state="new">In this article, you have created a pipeline with a transformation activity (HDInsight Activity) that runs a Hive script on an on-demand Azure HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see <bpt id="p1">[</bpt>Tutorial: Copy data from an Azure Blob to Azure SQL<ept id="p1">](./data-factory-get-started.md)</ept>.</source>
          <target state="new">To see how to use a Copy Activity to copy data from an Azure Blob to Azure SQL, see <bpt id="p1">[</bpt>Tutorial: Copy data from an Azure Blob to Azure SQL<ept id="p1">](./data-factory-get-started.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Send Feedback</source>
          <target state="new">Send Feedback</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>We would really appreciate your feedback on this article.</source>
          <target state="new">We would really appreciate your feedback on this article.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Please take a few minutes to submit your feedback via <bpt id="p1">[</bpt>email<ept id="p1">](mailto:adfdocfeedback@microsoft.com?subject=data-factory-build-your-first-pipeline-using-powershell.md)</ept>.</source>
          <target state="new">Please take a few minutes to submit your feedback via <bpt id="p1">[</bpt>email<ept id="p1">](mailto:adfdocfeedback@microsoft.com?subject=data-factory-build-your-first-pipeline-using-powershell.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1d8982bbe9baa29877de174db2507ef8eef8f820</xliffext:olfilehash>
  </header>
</xliff>