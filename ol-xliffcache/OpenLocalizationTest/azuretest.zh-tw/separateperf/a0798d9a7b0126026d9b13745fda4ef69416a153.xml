{
  "nodes": [
    {
      "content": "How to use blob storage from Node.js | Microsoft Azure",
      "pos": [
        27,
        81
      ]
    },
    {
      "content": "Learn how to use the Azure Blob service to upload, download, list, and delete blob content.",
      "pos": [
        100,
        191
      ]
    },
    {
      "content": "Samples written in Node.js.",
      "pos": [
        192,
        219
      ]
    },
    {
      "content": "How to use blob storage from Node.js",
      "pos": [
        525,
        561
      ]
    },
    {
      "content": "Overview",
      "pos": [
        664,
        672
      ]
    },
    {
      "content": "This article shows you how to perform common scenarios using the Azure Blob service.",
      "pos": [
        674,
        758
      ]
    },
    {
      "content": "The samples are written using the Node.js API.",
      "pos": [
        759,
        805
      ]
    },
    {
      "content": "The scenarios covered include <bpt id=\"p1\">**</bpt>uploading<ept id=\"p1\">**</ept>, <bpt id=\"p2\">**</bpt>listing<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>downloading<ept id=\"p3\">**</ept>, and <bpt id=\"p4\">**</bpt>deleting<ept id=\"p4\">**</ept> blobs.",
      "pos": [
        806,
        904
      ]
    },
    {
      "content": "Create a Node.js application",
      "pos": [
        1107,
        1135
      ]
    },
    {
      "content": "Create a blank Node.js application.",
      "pos": [
        1137,
        1172
      ]
    },
    {
      "content": "For instructions creating a Node.js application, see <bpt id=\"p1\">[</bpt><ept id=\"p1\">Create and deploy a Node.js application to an Azure web site]</ept>, <bpt id=\"p2\">[</bpt>Node.js Cloud Service<ept id=\"p2\">][Node.js Cloud Service]</ept> (using Windows PowerShell), or <bpt id=\"p3\">[</bpt><ept id=\"p3\">Web Site with WebMatrix]</ept>.",
      "pos": [
        1173,
        1394
      ]
    },
    {
      "content": "Configure your application to access storage",
      "pos": [
        1399,
        1443
      ]
    },
    {
      "content": "To use Azure storage, you need the Azure Storage SDK for Node.js, which includes a set of convenience libraries that communicate with the storage REST services.",
      "pos": [
        1445,
        1605
      ]
    },
    {
      "content": "Use Node Package Manager (NPM) to obtain the package",
      "pos": [
        1611,
        1663
      ]
    },
    {
      "pos": [
        1669,
        1840
      ],
      "content": "Use a command-line interface such as <bpt id=\"p1\">**</bpt>PowerShell<ept id=\"p1\">**</ept> (Windows), <bpt id=\"p2\">**</bpt>Terminal<ept id=\"p2\">**</ept> (Mac), or <bpt id=\"p3\">**</bpt>Bash<ept id=\"p3\">**</ept> (Unix), to navigate to the folder where you created your sample application."
    },
    {
      "content": "Type <bpt id=\"p1\">**</bpt>npm install azure-storage<ept id=\"p1\">**</ept> in the command window.",
      "pos": [
        1846,
        1903
      ]
    },
    {
      "content": "Output from the command is similar to the following code example.",
      "pos": [
        1904,
        1969
      ]
    },
    {
      "content": "You can manually run the <bpt id=\"p1\">**</bpt>ls<ept id=\"p1\">**</ept> command to verify that a <bpt id=\"p2\">**</bpt>node\\_modules<ept id=\"p2\">**</ept> folder was created.",
      "pos": [
        2682,
        2776
      ]
    },
    {
      "content": "Inside that folder find the <bpt id=\"p1\">**</bpt>azure-storage<ept id=\"p1\">**</ept> package, which contains the libraries you need to access storage.",
      "pos": [
        2777,
        2888
      ]
    },
    {
      "content": "Import the package",
      "pos": [
        2894,
        2912
      ]
    },
    {
      "content": "Using Notepad or another text editor, add the following to the top the",
      "pos": [
        2914,
        2984
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>server.js<ept id=\"p1\">**</ept> file of the application where you intend to use storage:",
      "pos": [
        2985,
        3055
      ]
    },
    {
      "content": "Set up an Azure Storage connection",
      "pos": [
        3103,
        3137
      ]
    },
    {
      "content": "The Azure module will read the environment variables <ph id=\"ph1\">`AZURE_STORAGE_ACCOUNT`</ph> and <ph id=\"ph2\">`AZURE_STORAGE_ACCESS_KEY`</ph>, or <ph id=\"ph3\">`AZURE_STORAGE_CONNECTION_STRING`</ph> for information required to connect to your Azure storage account.",
      "pos": [
        3139,
        3351
      ]
    },
    {
      "content": "If these environment variables are not set, you must specify the account information when calling <bpt id=\"p1\">**</bpt>createBlobService<ept id=\"p1\">**</ept>.",
      "pos": [
        3352,
        3472
      ]
    },
    {
      "pos": [
        3474,
        3615
      ],
      "content": "For an example of setting the environment variables in the management portal for an Azure Website, see <bpt id=\"p1\">[</bpt><ept id=\"p1\">Node.js Web Application with Storage]</ept>"
    },
    {
      "content": "Create a container",
      "pos": [
        3620,
        3638
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>BlobService<ept id=\"p1\">**</ept> object lets you work with containers and blobs.",
      "pos": [
        3640,
        3707
      ]
    },
    {
      "content": "The following code creates a <bpt id=\"p1\">**</bpt>BlobService<ept id=\"p1\">**</ept> object.",
      "pos": [
        3708,
        3760
      ]
    },
    {
      "content": "Add the following near the top of <bpt id=\"p1\">**</bpt>server.js<ept id=\"p1\">**</ept>:",
      "pos": [
        3761,
        3809
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You can access a blob anonymously by using <bpt id=\"p1\">**</bpt>createBlobServiceAnonymous<ept id=\"p1\">**</ept> and providing the host address.",
      "pos": [
        3859,
        3977
      ]
    },
    {
      "content": "For example, <ph id=\"ph1\">`var blobSvc = azure.createBlobServiceAnonymous('https://myblob.blob.core.windows.net/');`</ph>.",
      "pos": [
        3978,
        4082
      ]
    },
    {
      "content": "To create a new container, use <bpt id=\"p1\">**</bpt>createContainerIfNotExists<ept id=\"p1\">**</ept>.",
      "pos": [
        4200,
        4262
      ]
    },
    {
      "content": "The following code example creates a new container named 'mycontainer'",
      "pos": [
        4263,
        4333
      ]
    },
    {
      "content": "If the container is newly created, <ph id=\"ph1\">`result`</ph> is true.",
      "pos": [
        4593,
        4645
      ]
    },
    {
      "content": "If the container already exists, <ph id=\"ph1\">`result`</ph> is false.",
      "pos": [
        4646,
        4697
      ]
    },
    {
      "content": "<ph id=\"ph1\">`response`</ph> contains information about the operation, including the <bpt id=\"p1\">[</bpt>ETag<ept id=\"p1\">](http://en.wikipedia.org/wiki/HTTP_ETag)</ept> information for the container.",
      "pos": [
        4698,
        4842
      ]
    },
    {
      "content": "Container security",
      "pos": [
        4848,
        4866
      ]
    },
    {
      "content": "By default, new containers are private and cannot be accessed anonymously.",
      "pos": [
        4868,
        4942
      ]
    },
    {
      "content": "To make the container public so that you can access them anonymously, you can set the container's access level to <bpt id=\"p1\">**</bpt>blob<ept id=\"p1\">**</ept> or <bpt id=\"p2\">**</bpt>container<ept id=\"p2\">**</ept>.",
      "pos": [
        4943,
        5083
      ]
    },
    {
      "pos": [
        5087,
        5253
      ],
      "content": "<bpt id=\"p1\">**</bpt>blob<ept id=\"p1\">**</ept> - allows anonymous read access to blob content and metadata within this container, but not to container metadata such as listing all blobs within a container"
    },
    {
      "pos": [
        5257,
        5360
      ],
      "content": "<bpt id=\"p1\">**</bpt>container<ept id=\"p1\">**</ept> - allows anonymous read access to blob content and metadata as well as container metadata"
    },
    {
      "pos": [
        5362,
        5439
      ],
      "content": "The following code example demonstrates setting the access level to <bpt id=\"p1\">**</bpt>blob<ept id=\"p1\">**</ept>:"
    },
    {
      "content": "Alternatively, you can modify the access level of a container by using <bpt id=\"p1\">**</bpt>setContainerAcl<ept id=\"p1\">**</ept> to specify the access level.",
      "pos": [
        5638,
        5757
      ]
    },
    {
      "content": "The following code example changes the access level to container:",
      "pos": [
        5758,
        5823
      ]
    },
    {
      "pos": [
        6057,
        6159
      ],
      "content": "The result contains information about the operation, including the current <bpt id=\"p1\">**</bpt>ETag<ept id=\"p1\">**</ept> for the container."
    },
    {
      "content": "Filters",
      "pos": [
        6165,
        6172
      ]
    },
    {
      "content": "You can apply optional filtering operations to operations performed using <bpt id=\"p1\">**</bpt>BlobService<ept id=\"p1\">**</ept>.",
      "pos": [
        6174,
        6264
      ]
    },
    {
      "content": "Filtering operations can include logging, automatically retrying, etc. Filters are objects that implement a method with the signature:",
      "pos": [
        6265,
        6399
      ]
    },
    {
      "content": "After doing its preprocessing on the request options, the method needs to call \"next\" passing a callback with the following signature:",
      "pos": [
        6449,
        6583
      ]
    },
    {
      "content": "In this callback, and after processing the returnObject (the response from the request to the server), the callback needs to either invoke next if it exists to continue processing other filters or simply invoke finalCallback to end the service invocation.",
      "pos": [
        6639,
        6894
      ]
    },
    {
      "content": "Two filters that implement retry logic are included with the Azure SDK for Node.js, <bpt id=\"p1\">**</bpt>ExponentialRetryPolicyFilter<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>LinearRetryPolicyFilter<ept id=\"p2\">**</ept>.",
      "pos": [
        6896,
        7045
      ]
    },
    {
      "content": "The following creates a <bpt id=\"p1\">**</bpt>BlobService<ept id=\"p1\">**</ept> object that uses the <bpt id=\"p2\">**</bpt>ExponentialRetryPolicyFilter<ept id=\"p2\">**</ept>:",
      "pos": [
        7046,
        7140
      ]
    },
    {
      "content": "Upload a blob into a container",
      "pos": [
        7287,
        7317
      ]
    },
    {
      "content": "A blob can be either block or page based.",
      "pos": [
        7319,
        7360
      ]
    },
    {
      "content": "Block blobs allow you to more efficiently upload large data, while page blobs are optimized for read/write operations.",
      "pos": [
        7361,
        7479
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Understanding block blobs and page blobs<ept id=\"p1\">](http://msdn.microsoft.com/library/azure/ee691964.aspx)</ept>.",
      "pos": [
        7480,
        7604
      ]
    },
    {
      "content": "Block blobs",
      "pos": [
        7610,
        7621
      ]
    },
    {
      "content": "To upload data to a block blob, use the following:",
      "pos": [
        7623,
        7673
      ]
    },
    {
      "pos": [
        7677,
        7771
      ],
      "content": "<bpt id=\"p1\">**</bpt>createBlockBlobFromLocalFile<ept id=\"p1\">**</ept> - creates a new block blob and uploads the contents of a file"
    },
    {
      "pos": [
        7775,
        7868
      ],
      "content": "<bpt id=\"p1\">**</bpt>createBlockBlobFromStream<ept id=\"p1\">**</ept> - creates a new block blob and uploads the contents of a stream"
    },
    {
      "pos": [
        7872,
        7963
      ],
      "content": "<bpt id=\"p1\">**</bpt>createBlockBlobFromText<ept id=\"p1\">**</ept> - creates a new block blob and uploads the contents of a string"
    },
    {
      "pos": [
        7967,
        8041
      ],
      "content": "<bpt id=\"p1\">**</bpt>createWriteStreamToBlockBlob<ept id=\"p1\">**</ept> - provides a write stream to a block blob"
    },
    {
      "pos": [
        8043,
        8132
      ],
      "content": "The following code example uploads the contents of the <bpt id=\"p1\">**</bpt>test.txt<ept id=\"p1\">**</ept> file into <bpt id=\"p2\">**</bpt>myblob<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        8307,
        8418
      ],
      "content": "The <ph id=\"ph1\">`result`</ph> returned by these methods contains information on the operation, such as the <bpt id=\"p1\">**</bpt>ETag<ept id=\"p1\">**</ept> of the blob."
    },
    {
      "content": "Page blobs",
      "pos": [
        8424,
        8434
      ]
    },
    {
      "content": "To upload data to a page blob, use the following:",
      "pos": [
        8436,
        8485
      ]
    },
    {
      "pos": [
        8489,
        8554
      ],
      "content": "<bpt id=\"p1\">**</bpt>createPageBlob<ept id=\"p1\">**</ept> - creates a new page blob of a specific length"
    },
    {
      "pos": [
        8558,
        8650
      ],
      "content": "<bpt id=\"p1\">**</bpt>createPageBlobFromLocalFile<ept id=\"p1\">**</ept> - creates a new page blob and uploads the contents of a file"
    },
    {
      "pos": [
        8654,
        8745
      ],
      "content": "<bpt id=\"p1\">**</bpt>createPageBlobFromStream<ept id=\"p1\">**</ept> - creates a new page blob and uploads the contents of a stream"
    },
    {
      "pos": [
        8749,
        8839
      ],
      "content": "<bpt id=\"p1\">**</bpt>createWriteStreamToExistingPageBlob<ept id=\"p1\">**</ept> - provides a write stream to an existing page blob"
    },
    {
      "pos": [
        8843,
        8940
      ],
      "content": "<bpt id=\"p1\">**</bpt>createWriteStreamToNewPageBlob<ept id=\"p1\">**</ept> - creates a new blob and then provides a stream to write to it"
    },
    {
      "pos": [
        8942,
        9035
      ],
      "content": "The following code example uploads the contents of the <bpt id=\"p1\">**</bpt>test.txt<ept id=\"p1\">**</ept> file into <bpt id=\"p2\">**</bpt>mypageblob<ept id=\"p2\">**</ept>."
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Page blobs consist of 512-byte 'pages'.",
      "pos": [
        9215,
        9267
      ]
    },
    {
      "content": "You may receive an error when uploading data with a size that is not a multiple of 512.",
      "pos": [
        9268,
        9355
      ]
    },
    {
      "content": "List the blobs in a container",
      "pos": [
        9360,
        9389
      ]
    },
    {
      "content": "To list the blobs in a container, use the <bpt id=\"p1\">**</bpt>listBlobsSegmented<ept id=\"p1\">**</ept> method.",
      "pos": [
        9391,
        9463
      ]
    },
    {
      "content": "If you would like to return blobs with a specific prefix, use <bpt id=\"p1\">**</bpt>listBlobsSegmentedWithPrefix<ept id=\"p1\">**</ept>.",
      "pos": [
        9464,
        9559
      ]
    },
    {
      "content": "The <ph id=\"ph1\">`result`</ph> contains an <ph id=\"ph2\">`entries`</ph> collection, which is an array of objects describing each blob.",
      "pos": [
        9826,
        9923
      ]
    },
    {
      "content": "If all blobs cannot be returned, the <ph id=\"ph1\">`result`</ph> also provides a <ph id=\"ph2\">`continuationToken`</ph>, which you may use as the second parameter to retrieve additional entries.",
      "pos": [
        9924,
        10080
      ]
    },
    {
      "content": "Download blobs",
      "pos": [
        10085,
        10099
      ]
    },
    {
      "content": "To download data from a blob, use the following:",
      "pos": [
        10101,
        10149
      ]
    },
    {
      "pos": [
        10153,
        10205
      ],
      "content": "<bpt id=\"p1\">**</bpt>getBlobToFile<ept id=\"p1\">**</ept> - writes the blob contents to file"
    },
    {
      "pos": [
        10209,
        10267
      ],
      "content": "<bpt id=\"p1\">**</bpt>getBlobToStream<ept id=\"p1\">**</ept> - writes the blob contents to a stream"
    },
    {
      "pos": [
        10271,
        10327
      ],
      "content": "<bpt id=\"p1\">**</bpt>getBlobToText<ept id=\"p1\">**</ept> - writes the blob contents to a string"
    },
    {
      "pos": [
        10331,
        10393
      ],
      "content": "<bpt id=\"p1\">**</bpt>createReadStream<ept id=\"p1\">**</ept> - provides a stream to read from the blob"
    },
    {
      "pos": [
        10395,
        10564
      ],
      "content": "The following code example demonstrates using <bpt id=\"p1\">**</bpt>getBlobToStream<ept id=\"p1\">**</ept> to download the contents of the <bpt id=\"p2\">**</bpt>myblob<ept id=\"p2\">**</ept> blob and store it to the <bpt id=\"p3\">**</bpt>output.txt<ept id=\"p3\">**</ept> file using a stream:"
    },
    {
      "pos": [
        10779,
        10860
      ],
      "content": "The <ph id=\"ph1\">`result`</ph> contains information about the blob, including <bpt id=\"p1\">**</bpt>ETag<ept id=\"p1\">**</ept> information."
    },
    {
      "content": "Delete a blob",
      "pos": [
        10865,
        10878
      ]
    },
    {
      "content": "Finally, to delete a blob, call <bpt id=\"p1\">**</bpt>deleteBlob<ept id=\"p1\">**</ept>.",
      "pos": [
        10880,
        10927
      ]
    },
    {
      "content": "The following code example deletes the blob named <bpt id=\"p1\">**</bpt>myblob<ept id=\"p1\">**</ept>.",
      "pos": [
        10928,
        10989
      ]
    },
    {
      "content": "Concurrent access",
      "pos": [
        11137,
        11154
      ]
    },
    {
      "pos": [
        11156,
        11284
      ],
      "content": "To support concurrent access to a blob from multiple clients or multiple process instances, you can use <bpt id=\"p1\">**</bpt>ETags<ept id=\"p1\">**</ept> or <bpt id=\"p2\">**</bpt>leases<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        11288,
        11387
      ],
      "content": "<bpt id=\"p1\">**</bpt>Etag<ept id=\"p1\">**</ept> - provides a way to detect that the blob or container has been modified by another process"
    },
    {
      "pos": [
        11391,
        11503
      ],
      "content": "<bpt id=\"p1\">**</bpt>Lease<ept id=\"p1\">**</ept> - provides a way to obtain exclusive, renewable, write or delete access to a blob for a period of time"
    },
    {
      "content": "ETag",
      "pos": [
        11509,
        11513
      ]
    },
    {
      "content": "Use ETags if you need to allow multiple clients or instances to write to the blob simultaneously.",
      "pos": [
        11515,
        11612
      ]
    },
    {
      "content": "The ETag allows you to determine if the container or blob has been modified since you initially read or created it, which allows you to avoid overwriting changes committed by another client or process.",
      "pos": [
        11613,
        11814
      ]
    },
    {
      "content": "You can set ETag conditions by using the optional <ph id=\"ph1\">`options.accessConditions`</ph> parameter.",
      "pos": [
        11816,
        11903
      ]
    },
    {
      "content": "The following code example only uploads the <bpt id=\"p1\">**</bpt>test.txt<ept id=\"p1\">**</ept> file if the blob already exists and has the ETag value contained by <ph id=\"ph1\">`etagToMatch`</ph>.",
      "pos": [
        11904,
        12043
      ]
    },
    {
      "content": "The general pattern when using ETags is:",
      "pos": [
        12268,
        12308
      ]
    },
    {
      "content": "Obtain the ETag as the result of a create, list, or get operation.",
      "pos": [
        12313,
        12379
      ]
    },
    {
      "content": "Perform an action, checking that the ETag value has not been modified.",
      "pos": [
        12384,
        12454
      ]
    },
    {
      "content": "If the value has been modified, this indicates that another client or instance has modified the blob or container since you obtained the ETag value.",
      "pos": [
        12456,
        12604
      ]
    },
    {
      "content": "Lease",
      "pos": [
        12610,
        12615
      ]
    },
    {
      "content": "You can acquire a new lease by using the <bpt id=\"p1\">**</bpt>acquireLease<ept id=\"p1\">**</ept> method, specifying the blob or container that you wish to obtain a lease on.",
      "pos": [
        12617,
        12751
      ]
    },
    {
      "content": "For example, the following code acquires a lease on <bpt id=\"p1\">**</bpt>myblob<ept id=\"p1\">**</ept>.",
      "pos": [
        12752,
        12815
      ]
    },
    {
      "content": "Subsequent operations on <bpt id=\"p1\">**</bpt>myblob<ept id=\"p1\">**</ept> must provide <ph id=\"ph1\">`options.leaseId`</ph> parameter.",
      "pos": [
        12984,
        13061
      ]
    },
    {
      "content": "The lease ID is returned as <ph id=\"ph1\">`result.id`</ph> from <bpt id=\"p1\">**</bpt>acquireLease<ept id=\"p1\">**</ept>.",
      "pos": [
        13062,
        13124
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> By default, the lease duration is infinite.",
      "pos": [
        13128,
        13184
      ]
    },
    {
      "content": "You can specify a non-infinite duration (between 15 and 60 seconds,) by providing the <ph id=\"ph1\">`options.leaseDuration`</ph> parameter.",
      "pos": [
        13185,
        13305
      ]
    },
    {
      "content": "To remove a lease, use <bpt id=\"p1\">**</bpt>releaseLease<ept id=\"p1\">**</ept>.",
      "pos": [
        13307,
        13347
      ]
    },
    {
      "content": "To break a lease, but prevent others from obtaining a new lease until the original duration has expired, use <bpt id=\"p1\">**</bpt>breakLease<ept id=\"p1\">**</ept>.",
      "pos": [
        13348,
        13472
      ]
    },
    {
      "content": "Work with shared access signatures",
      "pos": [
        13477,
        13511
      ]
    },
    {
      "content": "Shared Access Signatures (SAS) are a secure way to provide granular access to blobs and containers without providing your storage account name or keys.",
      "pos": [
        13513,
        13664
      ]
    },
    {
      "content": "SAS are often used to provide limited access to your data, such as allowing a mobile app to access blobs.",
      "pos": [
        13665,
        13770
      ]
    },
    {
      "pos": [
        13774,
        13918
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> While you can also allow anonymous access to blobs, SAS allows you to provide more controlled access, as you must generate the SAS."
    },
    {
      "content": "A trusted application such as a cloud-based service generates a SAS using the <bpt id=\"p1\">**</bpt>generateSharedAccessSignature<ept id=\"p1\">**</ept> of the <bpt id=\"p2\">**</bpt>BlobService<ept id=\"p2\">**</ept>, and provides it to an untrusted or semi-trusted application such as a mobile app.",
      "pos": [
        13920,
        14137
      ]
    },
    {
      "content": "The SAS is generated using a policy, which describes the start and end dates during which the SAS is valid, as well as the access level granted to the SAS holder.",
      "pos": [
        14138,
        14300
      ]
    },
    {
      "pos": [
        14302,
        14497
      ],
      "content": "The following code example generates a new shared access policy that allows the SAS holder to perform read operations on the <bpt id=\"p1\">**</bpt>myblob<ept id=\"p1\">**</ept> blob, and expires 100 minutes after the time it is created."
    },
    {
      "content": "Note that the host information must be provided also, as it is required when the SAS holder attempts to access the container.",
      "pos": [
        15013,
        15138
      ]
    },
    {
      "content": "The client application then uses the SAS with <bpt id=\"p1\">**</bpt>BlobServiceWithSAS<ept id=\"p1\">**</ept> to perform operations against the blob.",
      "pos": [
        15140,
        15248
      ]
    },
    {
      "content": "The following gets information about <bpt id=\"p1\">**</bpt>myblob<ept id=\"p1\">**</ept>.",
      "pos": [
        15249,
        15297
      ]
    },
    {
      "content": "Since the SAS was generated with only read access, if an attempt were made to modify the blob, an error would be returned.",
      "pos": [
        15530,
        15652
      ]
    },
    {
      "content": "Access control lists",
      "pos": [
        15658,
        15678
      ]
    },
    {
      "content": "You can also use an Access Control List (ACL) to set the access policy for a SAS.",
      "pos": [
        15680,
        15761
      ]
    },
    {
      "content": "This is useful if you wish to allow multiple clients to access a container, but provide different access policies for each client.",
      "pos": [
        15762,
        15892
      ]
    },
    {
      "content": "An ACL is implemented using an array of access policies, with an ID associated with each policy.",
      "pos": [
        15894,
        15990
      ]
    },
    {
      "content": "The following code example defines two policies; one for 'user1' and one for 'user2':",
      "pos": [
        15991,
        16076
      ]
    },
    {
      "content": "The following code example gets the current ACL for <bpt id=\"p1\">**</bpt>mycontainer<ept id=\"p1\">**</ept>, then adds the new policies using <bpt id=\"p2\">**</bpt>setBlobAcl<ept id=\"p2\">**</ept>.",
      "pos": [
        16521,
        16638
      ]
    },
    {
      "content": "This approach allows:",
      "pos": [
        16639,
        16660
      ]
    },
    {
      "content": "Once the ACL has been set, you can then create a SAS based on the ID for a policy.",
      "pos": [
        17037,
        17119
      ]
    },
    {
      "content": "The following code example creates a new SAS for 'user2':",
      "pos": [
        17120,
        17177
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        17268,
        17278
      ]
    },
    {
      "content": "Now that you've learned the basics of blob storage, follow these links",
      "pos": [
        17280,
        17350
      ]
    },
    {
      "content": "to learn how to do more complex storage tasks.",
      "pos": [
        17351,
        17397
      ]
    },
    {
      "pos": [
        17403,
        17456
      ],
      "content": "Read the <bpt id=\"p1\">[</bpt>Azure Storage SDK for Node API Reference<ept id=\"p1\">][]</ept>"
    },
    {
      "pos": [
        17461,
        17525
      ],
      "content": "See the MSDN Reference: <bpt id=\"p1\">[</bpt>Storing and accessing data in Azure<ept id=\"p1\">][]</ept>."
    },
    {
      "pos": [
        17530,
        17568
      ],
      "content": "Visit the <bpt id=\"p1\">[</bpt>Azure Storage Team Blog<ept id=\"p1\">][]</ept>."
    },
    {
      "pos": [
        17573,
        17635
      ],
      "content": "Visit the <bpt id=\"p1\">[</bpt>Azure Storage SDK for Node<ept id=\"p1\">][]</ept> repository on GitHub."
    }
  ],
  "content": "<properties\n    pageTitle=\"How to use blob storage from Node.js | Microsoft Azure\"\n    description=\"Learn how to use the Azure Blob service to upload, download, list, and delete blob content. Samples written in Node.js.\"\n    services=\"storage\"\n    documentationCenter=\"nodejs\"\n    authors=\"MikeWasson\"\n    manager=\"wpickett\"\n    editor=\"\"/>\n\n<tags\n    ms.service=\"storage\"\n    ms.workload=\"storage\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"nodejs\"\n    ms.topic=\"article\"\n    ms.date=\"09/01/2015\"\n    ms.author=\"mwasson\"/>\n\n\n\n# How to use blob storage from Node.js\n\n[AZURE.INCLUDE [storage-selector-blob-include](../../includes/storage-selector-blob-include.md)]\n\n## Overview\n\nThis article shows you how to perform common scenarios using the Azure Blob service. The samples are written using the Node.js API. The scenarios covered include **uploading**, **listing**, **downloading**, and **deleting** blobs.\n\n[AZURE.INCLUDE [storage-blob-concepts-include](../../includes/storage-blob-concepts-include.md)]\n\n[AZURE.INCLUDE [storage-create-account-include](../../includes/storage-create-account-include.md)]\n\n## Create a Node.js application\n\nCreate a blank Node.js application. For instructions creating a Node.js application, see [Create and deploy a Node.js application to an Azure web site], [Node.js Cloud Service][Node.js Cloud Service] (using Windows PowerShell), or [Web Site with WebMatrix].\n\n## Configure your application to access storage\n\nTo use Azure storage, you need the Azure Storage SDK for Node.js, which includes a set of convenience libraries that communicate with the storage REST services.\n\n### Use Node Package Manager (NPM) to obtain the package\n\n1.  Use a command-line interface such as **PowerShell** (Windows), **Terminal** (Mac), or **Bash** (Unix), to navigate to the folder where you created your sample application.\n\n2.  Type **npm install azure-storage** in the command window. Output from the command is similar to the following code example.\n\n        azure-storage@0.5.0 node_modules\\azure-storage\n        +-- extend@1.2.1\n        +-- xmlbuilder@0.4.3\n        +-- mime@1.2.11\n        +-- node-uuid@1.4.3\n        +-- validator@3.22.2\n        +-- underscore@1.4.4\n        +-- readable-stream@1.0.33 (string_decoder@0.10.31, isarray@0.0.1, inherits@2.0.1, core-util-is@1.0.1)\n        +-- xml2js@0.2.7 (sax@0.5.2)\n        +-- request@2.57.0 (caseless@0.10.0, aws-sign2@0.5.0, forever-agent@0.6.1, stringstream@0.0.4, oauth-sign@0.8.0, tunnel-agent@0.4.1, isstream@0.1.2, json-stringify-safe@5.0.1, bl@0.9.4, combined-stream@1.0.5, qs@3.1.0, mime-types@2.0.14, form-data@0.2.0, http-signature@0.11.0, tough-cookie@2.0.0, hawk@2.3.1, har-validator@1.8.0)\n\n3.  You can manually run the **ls** command to verify that a **node\\_modules** folder was created. Inside that folder find the **azure-storage** package, which contains the libraries you need to access storage.\n\n### Import the package\n\nUsing Notepad or another text editor, add the following to the top the\n**server.js** file of the application where you intend to use storage:\n\n    var azure = require('azure-storage');\n\n## Set up an Azure Storage connection\n\nThe Azure module will read the environment variables `AZURE_STORAGE_ACCOUNT` and `AZURE_STORAGE_ACCESS_KEY`, or `AZURE_STORAGE_CONNECTION_STRING` for information required to connect to your Azure storage account. If these environment variables are not set, you must specify the account information when calling **createBlobService**.\n\nFor an example of setting the environment variables in the management portal for an Azure Website, see [Node.js Web Application with Storage]\n\n## Create a container\n\nThe **BlobService** object lets you work with containers and blobs. The following code creates a **BlobService** object. Add the following near the top of **server.js**:\n\n    var blobSvc = azure.createBlobService();\n\n> [AZURE.NOTE] You can access a blob anonymously by using **createBlobServiceAnonymous** and providing the host address. For example, `var blobSvc = azure.createBlobServiceAnonymous('https://myblob.blob.core.windows.net/');`.\n\n[AZURE.INCLUDE [storage-container-naming-rules-include](../../includes/storage-container-naming-rules-include.md)]\n\nTo create a new container, use **createContainerIfNotExists**. The following code example creates a new container named 'mycontainer'\n\n    blobSvc.createContainerIfNotExists('mycontainer', function(error, result, response){\n      if(!error){\n        // Container exists and allows\n        // anonymous read access to blob\n        // content and metadata within this container\n      }\n    });\n\nIf the container is newly created, `result` is true. If the container already exists, `result` is false. `response` contains information about the operation, including the [ETag](http://en.wikipedia.org/wiki/HTTP_ETag) information for the container.\n\n### Container security\n\nBy default, new containers are private and cannot be accessed anonymously. To make the container public so that you can access them anonymously, you can set the container's access level to **blob** or **container**.\n\n* **blob** - allows anonymous read access to blob content and metadata within this container, but not to container metadata such as listing all blobs within a container\n\n* **container** - allows anonymous read access to blob content and metadata as well as container metadata\n\nThe following code example demonstrates setting the access level to **blob**:\n\n    blobSvc.createContainerIfNotExists('mycontainer', {publicAccessLevel : 'blob'}, function(error, result, response){\n      if(!error){\n        // Container exists and is private\n      }\n    });\n\nAlternatively, you can modify the access level of a container by using **setContainerAcl** to specify the access level. The following code example changes the access level to container:\n\n    blobSvc.setContainerAcl('mycontainer', null /* signedIdentifiers */, 'container' /* publicAccessLevel*/, function(error, result, response){\n      if(!error){\n        // Container access level set to 'container'\n      }\n    });\n\nThe result contains information about the operation, including the current **ETag** for the container.\n\n### Filters\n\nYou can apply optional filtering operations to operations performed using **BlobService**. Filtering operations can include logging, automatically retrying, etc. Filters are objects that implement a method with the signature:\n\n        function handle (requestOptions, next)\n\nAfter doing its preprocessing on the request options, the method needs to call \"next\" passing a callback with the following signature:\n\n        function (returnObject, finalCallback, next)\n\nIn this callback, and after processing the returnObject (the response from the request to the server), the callback needs to either invoke next if it exists to continue processing other filters or simply invoke finalCallback to end the service invocation.\n\nTwo filters that implement retry logic are included with the Azure SDK for Node.js, **ExponentialRetryPolicyFilter** and **LinearRetryPolicyFilter**. The following creates a **BlobService** object that uses the **ExponentialRetryPolicyFilter**:\n\n    var retryOperations = new azure.ExponentialRetryPolicyFilter();\n    var blobSvc = azure.createBlobService().withFilter(retryOperations);\n\n## Upload a blob into a container\n\nA blob can be either block or page based. Block blobs allow you to more efficiently upload large data, while page blobs are optimized for read/write operations. For more information, see [Understanding block blobs and page blobs](http://msdn.microsoft.com/library/azure/ee691964.aspx).\n\n### Block blobs\n\nTo upload data to a block blob, use the following:\n\n* **createBlockBlobFromLocalFile** - creates a new block blob and uploads the contents of a file\n\n* **createBlockBlobFromStream** - creates a new block blob and uploads the contents of a stream\n\n* **createBlockBlobFromText** - creates a new block blob and uploads the contents of a string\n\n* **createWriteStreamToBlockBlob** - provides a write stream to a block blob\n\nThe following code example uploads the contents of the **test.txt** file into **myblob**.\n\n    blobSvc.createBlockBlobFromLocalFile('mycontainer', 'myblob', 'test.txt', function(error, result, response){\n      if(!error){\n        // file uploaded\n      }\n    });\n\nThe `result` returned by these methods contains information on the operation, such as the **ETag** of the blob.\n\n### Page blobs\n\nTo upload data to a page blob, use the following:\n\n* **createPageBlob** - creates a new page blob of a specific length\n\n* **createPageBlobFromLocalFile** - creates a new page blob and uploads the contents of a file\n\n* **createPageBlobFromStream** - creates a new page blob and uploads the contents of a stream\n\n* **createWriteStreamToExistingPageBlob** - provides a write stream to an existing page blob\n\n* **createWriteStreamToNewPageBlob** - creates a new blob and then provides a stream to write to it\n\nThe following code example uploads the contents of the **test.txt** file into **mypageblob**.\n\n    blobSvc.createPageBlobFromLocalFile('mycontainer', 'mypageblob', 'test.txt', function(error, result, response){\n      if(!error){\n        // file uploaded\n      }\n    });\n\n> [AZURE.NOTE] Page blobs consist of 512-byte 'pages'. You may receive an error when uploading data with a size that is not a multiple of 512.\n\n## List the blobs in a container\n\nTo list the blobs in a container, use the **listBlobsSegmented** method. If you would like to return blobs with a specific prefix, use **listBlobsSegmentedWithPrefix**.\n\n    blobSvc.listBlobsSegmented('mycontainer', null, function(error, result, response){\n      if(!error){\n        // result.entries contains the entries\n        // If not all blobs were returned, result.continuationToken has the continuation token.\n      }\n    });\n\nThe `result` contains an `entries` collection, which is an array of objects describing each blob. If all blobs cannot be returned, the `result` also provides a `continuationToken`, which you may use as the second parameter to retrieve additional entries.\n\n## Download blobs\n\nTo download data from a blob, use the following:\n\n* **getBlobToFile** - writes the blob contents to file\n\n* **getBlobToStream** - writes the blob contents to a stream\n\n* **getBlobToText** - writes the blob contents to a string\n\n* **createReadStream** - provides a stream to read from the blob\n\nThe following code example demonstrates using **getBlobToStream** to download the contents of the **myblob** blob and store it to the **output.txt** file using a stream:\n\n    var fs = require('fs');\n    blobSvc.getBlobToStream('mycontainer', 'myblob', fs.createWriteStream('output.txt'), function(error, result, response){\n      if(!error){\n        // blob retrieved\n      }\n    });\n\nThe `result` contains information about the blob, including **ETag** information.\n\n## Delete a blob\n\nFinally, to delete a blob, call **deleteBlob**. The following code example deletes the blob named **myblob**.\n\n    blobSvc.deleteBlob(containerName, 'myblob', function(error, response){\n      if(!error){\n        // Blob has been deleted\n      }\n    });\n\n## Concurrent access\n\nTo support concurrent access to a blob from multiple clients or multiple process instances, you can use **ETags** or **leases**.\n\n* **Etag** - provides a way to detect that the blob or container has been modified by another process\n\n* **Lease** - provides a way to obtain exclusive, renewable, write or delete access to a blob for a period of time\n\n### ETag\n\nUse ETags if you need to allow multiple clients or instances to write to the blob simultaneously. The ETag allows you to determine if the container or blob has been modified since you initially read or created it, which allows you to avoid overwriting changes committed by another client or process.\n\nYou can set ETag conditions by using the optional `options.accessConditions` parameter. The following code example only uploads the **test.txt** file if the blob already exists and has the ETag value contained by `etagToMatch`.\n\n    blobSvc.createBlockBlobFromLocalFile('mycontainer', 'myblob', 'test.txt', { accessConditions: { 'if-match': etagToMatch} }, function(error, result, response){\n      if(!error){\n        // file uploaded\n      }\n    });\n\nThe general pattern when using ETags is:\n\n1. Obtain the ETag as the result of a create, list, or get operation.\n\n2. Perform an action, checking that the ETag value has not been modified.\n\nIf the value has been modified, this indicates that another client or instance has modified the blob or container since you obtained the ETag value.\n\n### Lease\n\nYou can acquire a new lease by using the **acquireLease** method, specifying the blob or container that you wish to obtain a lease on. For example, the following code acquires a lease on **myblob**.\n\n    blobSvc.acquireLease('mycontainer', 'myblob', function(error, result, response){\n      if(!error) {\n        console.log('leaseId: ' + result.id);\n      }\n    });\n\nSubsequent operations on **myblob** must provide `options.leaseId` parameter. The lease ID is returned as `result.id` from **acquireLease**.\n\n> [AZURE.NOTE] By default, the lease duration is infinite. You can specify a non-infinite duration (between 15 and 60 seconds,) by providing the `options.leaseDuration` parameter.\n\nTo remove a lease, use **releaseLease**. To break a lease, but prevent others from obtaining a new lease until the original duration has expired, use **breakLease**.\n\n## Work with shared access signatures\n\nShared Access Signatures (SAS) are a secure way to provide granular access to blobs and containers without providing your storage account name or keys. SAS are often used to provide limited access to your data, such as allowing a mobile app to access blobs.\n\n> [AZURE.NOTE] While you can also allow anonymous access to blobs, SAS allows you to provide more controlled access, as you must generate the SAS.\n\nA trusted application such as a cloud-based service generates a SAS using the **generateSharedAccessSignature** of the **BlobService**, and provides it to an untrusted or semi-trusted application such as a mobile app. The SAS is generated using a policy, which describes the start and end dates during which the SAS is valid, as well as the access level granted to the SAS holder.\n\nThe following code example generates a new shared access policy that allows the SAS holder to perform read operations on the **myblob** blob, and expires 100 minutes after the time it is created.\n\n    var startDate = new Date();\n    var expiryDate = new Date(startDate);\n    expiryDate.setMinutes(startDate.getMinutes() + 100);\n    startDate.setMinutes(startDate.getMinutes() - 100);\n\n    var sharedAccessPolicy = {\n      AccessPolicy: {\n        Permissions: azure.BlobUtilities.SharedAccessPermissions.READ,\n        Start: startDate,\n        Expiry: expiryDate\n      },\n    };\n\n    var blobSAS = blobSvc.generateSharedAccessSignature('mycontainer', 'myblob', sharedAccessPolicy);\n    var host = blobSvc.host;\n\nNote that the host information must be provided also, as it is required when the SAS holder attempts to access the container.\n\nThe client application then uses the SAS with **BlobServiceWithSAS** to perform operations against the blob. The following gets information about **myblob**.\n\n    var sharedBlobSvc = azure.createBlobServiceWithSas(host, blobSAS);\n    sharedBlobSvc.getBlobProperties('mycontainer', 'myblob', function (error, result, response) {\n      if(!error) {\n        // retrieved info\n      }\n    });\n\nSince the SAS was generated with only read access, if an attempt were made to modify the blob, an error would be returned.\n\n### Access control lists\n\nYou can also use an Access Control List (ACL) to set the access policy for a SAS. This is useful if you wish to allow multiple clients to access a container, but provide different access policies for each client.\n\nAn ACL is implemented using an array of access policies, with an ID associated with each policy. The following code example defines two policies; one for 'user1' and one for 'user2':\n\n    var sharedAccessPolicy = [\n      {\n        AccessPolicy: {\n          Permissions: azure.BlobUtilities.SharedAccessPermissions.READ,\n          Start: startDate,\n          Expiry: expiryDate\n        },\n        Id: 'user1'\n      },\n      {\n        AccessPolicy: {\n          Permissions: azure.BlobUtilities.SharedAccessPermissions.WRITE,\n          Start: startDate,\n          Expiry: expiryDate\n        },\n        Id: 'user2'\n      }\n    ];\n\nThe following code example gets the current ACL for **mycontainer**, then adds the new policies using **setBlobAcl**. This approach allows:\n\n    blobSvc.getBlobAcl('mycontainer', function(error, result, response) {\n      if(!error){\n        //push the new policy into signedIdentifiers\n        result.signedIdentifiers.push(sharedAccessPolicy);\n        blobSvc.setBlobAcl('mycontainer', result, function(error, result, response){\n          if(!error){\n            // ACL set\n          }\n        });\n      }\n    });\n\nOnce the ACL has been set, you can then create a SAS based on the ID for a policy. The following code example creates a new SAS for 'user2':\n\n    blobSAS = blobSvc.generateSharedAccessSignature('mycontainer', { Id: 'user2' });\n\n## Next steps\n\nNow that you've learned the basics of blob storage, follow these links\nto learn how to do more complex storage tasks.\n\n-   Read the [Azure Storage SDK for Node API Reference][]\n-   See the MSDN Reference: [Storing and accessing data in Azure][].\n-   Visit the [Azure Storage Team Blog][].\n-   Visit the [Azure Storage SDK for Node][] repository on GitHub.\n\n[Azure Storage SDK for Node]: https://github.com/Azure/azure-storage-node\n[Create and deploy a Node.js application to an Azure Web Site]: /develop/nodejs/tutorials/create-a-website-(mac)/\n[Node.js Cloud Service with Storage]: ../storage-nodejs-use-table-storage-cloud-service-app.md\n[Node.js Web Application with Storage]: ../storage-nodejs-use-table-storage-web-site.md\n[Web Site with WebMatrix]: ../web-sites-nodejs-use-webmatrix.md\n[using the REST API]: http://msdn.microsoft.com/library/azure/hh264518.aspx\n[Azure Management Portal]: http://manage.windowsazure.com\n[Node.js Cloud Service]: ../cloud-services-nodejs-develop-deploy-app.md\n[Storing and Accessing Data in Azure]: http://msdn.microsoft.com/library/azure/gg433040.aspx\n[Azure Storage Team Blog]: http://blogs.msdn.com/b/windowsazurestorage/\n[Azure Storage SDK for Node API Reference]: http://dl.windowsazure.com/nodestoragedocs/index.html\n"
}