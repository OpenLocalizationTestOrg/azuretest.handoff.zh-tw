{
  "nodes": [
    {
      "content": "Data Transformation Activities | Microsoft Azure",
      "pos": [
        28,
        76
      ]
    },
    {
      "content": "Learn how you can use the Azure Data Factory service to transform and analyze data.",
      "pos": [
        96,
        179
      ]
    },
    {
      "content": "Transform and analyze using Azure Data Factory",
      "pos": [
        507,
        553
      ]
    },
    {
      "content": "Overview",
      "pos": [
        558,
        566
      ]
    },
    {
      "content": "Transformation activities in Azure Data Factory transform and process your raw data into predictions and insights.",
      "pos": [
        567,
        681
      ]
    },
    {
      "content": "The transformation activity executes in a computing environment such as Azure HDInsight cluster or an Azure Batch.",
      "pos": [
        682,
        796
      ]
    },
    {
      "content": "Azure Data Factory supports the following transformation activities that can be added to <bpt id=\"p1\">[</bpt>pipelines<ept id=\"p1\">](data-factory-create-pipelines.md)</ept> either individually or chained with another activity.",
      "pos": [
        797,
        985
      ]
    },
    {
      "content": "Transformation activity",
      "pos": [
        988,
        1011
      ]
    },
    {
      "content": "Compute environment",
      "pos": [
        1015,
        1034
      ]
    },
    {
      "content": "Hive",
      "pos": [
        1084,
        1088
      ]
    },
    {
      "content": "HDInsight [Hadoop]",
      "pos": [
        1123,
        1141
      ]
    },
    {
      "content": "Pig",
      "pos": [
        1144,
        1147
      ]
    },
    {
      "content": "HDInsight [Hadoop]",
      "pos": [
        1181,
        1199
      ]
    },
    {
      "content": "MapReduce",
      "pos": [
        1203,
        1212
      ]
    },
    {
      "content": "HDInsight [Hadoop]",
      "pos": [
        1244,
        1262
      ]
    },
    {
      "content": "Hadoop Streaming",
      "pos": [
        1266,
        1282
      ]
    },
    {
      "content": "HDInsight [Hadoop]",
      "pos": [
        1336,
        1354
      ]
    },
    {
      "content": "Machine Learning Batch Execution",
      "pos": [
        1356,
        1388
      ]
    },
    {
      "content": "Azure VM",
      "pos": [
        1443,
        1451
      ]
    },
    {
      "content": "Stored Procedure",
      "pos": [
        1454,
        1470
      ]
    },
    {
      "content": "Azure SQL",
      "pos": [
        1512,
        1521
      ]
    },
    {
      "content": "DotNet",
      "pos": [
        1526,
        1532
      ]
    },
    {
      "content": "HDInsight [Hadoop] or Azure Batch",
      "pos": [
        1575,
        1608
      ]
    },
    {
      "content": "You need to create a linked service for the compute environment and then use the linked service when defining a transformation activity.",
      "pos": [
        1614,
        1750
      ]
    },
    {
      "content": "There are two types of compute environments supported by Data Factory.",
      "pos": [
        1751,
        1821
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>On-Demand<ept id=\"p1\">**</ept>:  In this case, the computing environment is fully managed by Data Factory.",
      "pos": [
        1827,
        1916
      ]
    },
    {
      "content": "It is automatically created by the Data Factory service before a job is submitted to process data and removed when the job is completed.",
      "pos": [
        1917,
        2053
      ]
    },
    {
      "content": "Users can configure and control granular settings of the on-demand compute environment for job execution, cluster management, and bootstrapping actions.",
      "pos": [
        2054,
        2206
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Bring Your Own<ept id=\"p1\">**</ept>: In this case, you can register your own computing environment (for example HDInsight cluster) as a linked service in Data Factory.",
      "pos": [
        2211,
        2361
      ]
    },
    {
      "content": "The computing environment is managed by you and the Data Factory service uses it to execute the activities.",
      "pos": [
        2362,
        2469
      ]
    },
    {
      "pos": [
        2472,
        2616
      ],
      "content": "See <bpt id=\"p1\">[</bpt>Compute Linked Services<ept id=\"p1\">](data-factory-compute-linked-services.md)</ept> article to learn about compute linked services supported by Data Factory."
    },
    {
      "content": "Send Feedback",
      "pos": [
        2622,
        2635
      ]
    },
    {
      "content": "We would really appreciate your feedback on this article.",
      "pos": [
        2636,
        2693
      ]
    },
    {
      "content": "Please take a few minutes to submit your feedback via <bpt id=\"p1\">[</bpt>email<ept id=\"p1\">](mailto:adfdocfeedback@microsoft.com?subject=data-factory-data-transformation-activities.md)</ept>.",
      "pos": [
        2694,
        2848
      ]
    },
    {
      "content": "test",
      "pos": [
        2850,
        2854
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Data Transformation Activities | Microsoft Azure\" \n    description=\"Learn how you can use the Azure Data Factory service to transform and analyze data.\" \n    services=\"data-factory\" \n    documentationCenter=\"\" \n    authors=\"spelluru\" \n    manager=\"jhubbard\" \n    editor=\"monicar\"/>\n\n<tags \n    ms.service=\"data-factory\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"07/26/2015\" \n    ms.author=\"spelluru\"/>\n\n# Transform and analyze using Azure Data Factory\n\n## Overview\nTransformation activities in Azure Data Factory transform and process your raw data into predictions and insights. The transformation activity executes in a computing environment such as Azure HDInsight cluster or an Azure Batch. Azure Data Factory supports the following transformation activities that can be added to [pipelines](data-factory-create-pipelines.md) either individually or chained with another activity.\n\n\nTransformation activity |  Compute environment \n----------------------- | --------------------\n[Hive](data-factory-hive-activity.md) | HDInsight [Hadoop] \n[Pig](data-factory-pig-activity.md) | HDInsight [Hadoop]  \n[MapReduce](data-factory-map-reduce.md) | HDInsight [Hadoop]  \n[Hadoop Streaming](https://msdn.microsoft.com/library/mt185698.aspx) | HDInsight [Hadoop]\n[Machine Learning Batch Execution](data-factory-azure-ml-batch-execution-activity.md) | Azure VM \n[Stored Procedure](data-factory-stored-proc-activity.md) | Azure SQL | \n[DotNet](data-factory-use-custom-activities.md) | HDInsight [Hadoop] or Azure Batch    \n\nYou need to create a linked service for the compute environment and then use the linked service when defining a transformation activity. There are two types of compute environments supported by Data Factory. \n\n1. **On-Demand**:  In this case, the computing environment is fully managed by Data Factory. It is automatically created by the Data Factory service before a job is submitted to process data and removed when the job is completed. Users can configure and control granular settings of the on-demand compute environment for job execution, cluster management, and bootstrapping actions. \n2. **Bring Your Own**: In this case, you can register your own computing environment (for example HDInsight cluster) as a linked service in Data Factory. The computing environment is managed by you and the Data Factory service uses it to execute the activities. \n\nSee [Compute Linked Services](data-factory-compute-linked-services.md) article to learn about compute linked services supported by Data Factory. \n\n## Send Feedback\nWe would really appreciate your feedback on this article. Please take a few minutes to submit your feedback via [email](mailto:adfdocfeedback@microsoft.com?subject=data-factory-data-transformation-activities.md). \ntest\n"
}