<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Move and process log files using Azure Data Factory (Azure PowerShell)</source>
          <target state="new">Move and process log files using Azure Data Factory (Azure PowerShell)</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>This advanced tutorial describes a near real-world scenario and implements the scenario using Azure Data Factory service and Azure PowerShell.</source>
          <target state="new">This advanced tutorial describes a near real-world scenario and implements the scenario using Azure Data Factory service and Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Tutorial: Move and process log files using Data Factory [PowerShell]</source>
          <target state="new">Tutorial: Move and process log files using Data Factory [PowerShell]</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This article provides an end-to-end walkthrough of a canonical scenario of log processing using Azure Data Factory to transform data from log files into insights.</source>
          <target state="new">This article provides an end-to-end walkthrough of a canonical scenario of log processing using Azure Data Factory to transform data from log files into insights.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Scenario</source>
          <target state="new">Scenario</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Contoso is a gaming company that creates games for multiple platforms: game consoles, hand held devices, and personal computers (PCs).</source>
          <target state="new">Contoso is a gaming company that creates games for multiple platforms: game consoles, hand held devices, and personal computers (PCs).</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Each of these games produces tons of logs.</source>
          <target state="new">Each of these games produces tons of logs.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Contoso’s goal is to collect and analyze the logs produced by these games to get usage information, identify up-sell and cross-sell opportunities, develop new compelling features etc. to improve business and provide better experience to customers.</source>
          <target state="new">Contoso’s goal is to collect and analyze the logs produced by these games to get usage information, identify up-sell and cross-sell opportunities, develop new compelling features etc. to improve business and provide better experience to customers.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In this walkthrough, we will collect sample logs, process and enrich them with reference data, and transform the data to evaluate the effectiveness of a marketing campaign that Contoso has recently launched.</source>
          <target state="new">In this walkthrough, we will collect sample logs, process and enrich them with reference data, and transform the data to evaluate the effectiveness of a marketing campaign that Contoso has recently launched.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Getting ready for the tutorial</source>
          <target state="new">Getting ready for the tutorial</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Read <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">][adfintroduction]</ept> to get an overview of Azure Data Factory and understanding of the top level concepts.</source>
          <target state="new">Read <bpt id="p1">[</bpt>Introduction to Azure Data Factory<ept id="p1">][adfintroduction]</ept> to get an overview of Azure Data Factory and understanding of the top level concepts.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>You must have an Azure subscription to perform this tutorial.</source>
          <target state="new">You must have an Azure subscription to perform this tutorial.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>For information about obtaining a subscription, see <bpt id="p1">[</bpt>Purchase Options<ept id="p1">] [azure-purchase-options]</ept>, <bpt id="p2">[</bpt>Member Offers<ept id="p2">][azure-member-offers]</ept>, or <bpt id="p3">[</bpt>Free Trial<ept id="p3">][azure-free-trial]</ept>.</source>
          <target state="new">For information about obtaining a subscription, see <bpt id="p1">[</bpt>Purchase Options<ept id="p1">] [azure-purchase-options]</ept>, <bpt id="p2">[</bpt>Member Offers<ept id="p2">][azure-member-offers]</ept>, or <bpt id="p3">[</bpt>Free Trial<ept id="p3">][azure-free-trial]</ept>.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>You must download and install <bpt id="p1">[</bpt>Azure PowerShell<ept id="p1">][download-azure-powershell]</ept> on your computer.</source>
          <target state="new">You must download and install <bpt id="p1">[</bpt>Azure PowerShell<ept id="p1">][download-azure-powershell]</ept> on your computer.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>(recommended)<ept id="p1">**</ept> Review and practice the tutorial in the <bpt id="p2">[</bpt>Get started with Azure Data Factory<ept id="p2">][adfgetstarted]</ept> article for a simple tutorial to get familiar with the portal and cmdlets.</source>
          <target state="new"><bpt id="p1">**</bpt>(recommended)<ept id="p1">**</ept> Review and practice the tutorial in the <bpt id="p2">[</bpt>Get started with Azure Data Factory<ept id="p2">][adfgetstarted]</ept> article for a simple tutorial to get familiar with the portal and cmdlets.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>(recommended)<ept id="p1">**</ept> Review and practice the walkthrough in the <bpt id="p2">[</bpt>Use Pig and Hive with Azure Data Factory<ept id="p2">][usepigandhive]</ept> article for a walkthrough on creating a pipeline to move data from on-premises data source to an Azure blob store.</source>
          <target state="new"><bpt id="p1">**</bpt>(recommended)<ept id="p1">**</ept> Review and practice the walkthrough in the <bpt id="p2">[</bpt>Use Pig and Hive with Azure Data Factory<ept id="p2">][usepigandhive]</ept> article for a walkthrough on creating a pipeline to move data from on-premises data source to an Azure blob store.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Download <bpt id="p1">[</bpt>ADFWalkthrough<ept id="p1">][adfwalkthrough-download]</ept> files to <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> folder <bpt id="p3">**</bpt>preserving the folder structure<ept id="p3">**</ept>:</source>
          <target state="new">Download <bpt id="p1">[</bpt>ADFWalkthrough<ept id="p1">][adfwalkthrough-download]</ept> files to <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> folder <bpt id="p3">**</bpt>preserving the folder structure<ept id="p3">**</ept>:</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Pipelines:<ept id="p1">**</ept> It includes  JSON files containing the definition of the pipelines.</source>
          <target state="new"><bpt id="p1">**</bpt>Pipelines:<ept id="p1">**</ept> It includes  JSON files containing the definition of the pipelines.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Tables:<ept id="p1">**</ept> It includes  JSON files containing the definition of the Tables.</source>
          <target state="new"><bpt id="p1">**</bpt>Tables:<ept id="p1">**</ept> It includes  JSON files containing the definition of the Tables.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>LinkedServices:<ept id="p1">**</ept> It includes JSON files containing the definition of your storage and compute (HDInsight) cluster</source>
          <target state="new"><bpt id="p1">**</bpt>LinkedServices:<ept id="p1">**</ept> It includes JSON files containing the definition of your storage and compute (HDInsight) cluster</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Scripts:<ept id="p1">**</ept> It includes Hive and Pig scripts that are used for processing the data and invoked from the pipelines</source>
          <target state="new"><bpt id="p1">**</bpt>Scripts:<ept id="p1">**</ept> It includes Hive and Pig scripts that are used for processing the data and invoked from the pipelines</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SampleData:<ept id="p1">**</ept> It includes sample data for this walkthrough</source>
          <target state="new"><bpt id="p1">**</bpt>SampleData:<ept id="p1">**</ept> It includes sample data for this walkthrough</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>OnPremises:<ept id="p1">**</ept> It includes JSON files and script that are used for demonstrating accessing your on-premises data</source>
          <target state="new"><bpt id="p1">**</bpt>OnPremises:<ept id="p1">**</ept> It includes JSON files and script that are used for demonstrating accessing your on-premises data</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1:<ept id="p1">**</ept> This script uploads the sample data &amp; scripts to Azure.</source>
          <target state="new"><bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1:<ept id="p1">**</ept> This script uploads the sample data &amp; scripts to Azure.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Make sure you have created the following Azure Resources:</source>
          <target state="new">Make sure you have created the following Azure Resources:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Azure Storage Account.</source>
          <target state="new">Azure Storage Account.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Azure SQL Database</source>
          <target state="new">Azure SQL Database</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Azure HDInsight Cluster of version 3.1 or above (or use an on-demand HDInsight cluster that the Data Factory service will create automatically)</source>
          <target state="new">Azure HDInsight Cluster of version 3.1 or above (or use an on-demand HDInsight cluster that the Data Factory service will create automatically)</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Once the Azure Resources are created, make sure you have the information needed to connect to each of these resources.</source>
          <target state="new">Once the Azure Resources are created, make sure you have the information needed to connect to each of these resources.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure Storage Account<ept id="p1">**</ept> - Account name and account key.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure Storage Account<ept id="p1">**</ept> - Account name and account key.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure SQL Database<ept id="p1">**</ept> - Server, database, user name, and password.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure SQL Database<ept id="p1">**</ept> - Server, database, user name, and password.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure HDInsight Cluster<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure HDInsight Cluster<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>- Name of the HDInsight cluster, user name, password, and account name and account key for the Azure storage associated with this cluster.</source>
          <target state="new">- Name of the HDInsight cluster, user name, password, and account name and account key for the Azure storage associated with this cluster.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>If you want to use an on-demand HDInsight cluster instead of your own HDInsight cluster you can skip this step.</source>
          <target state="new">If you want to use an on-demand HDInsight cluster instead of your own HDInsight cluster you can skip this step.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Launch <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept> and execute the following commands.</source>
          <target state="new">Launch <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept> and execute the following commands.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Keep the Azure PowerShell open.</source>
          <target state="new">Keep the Azure PowerShell open.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>If you close and reopen, you need to run these commands again.</source>
          <target state="new">If you close and reopen, you need to run these commands again.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign-in to the Azure Preview Portal.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign-in to the Azure Preview Portal.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>This subscription should be the same as the one you used in the Azure Preview Portal.</source>
          <target state="new">This subscription should be the same as the one you used in the Azure Preview Portal.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Overview</source>
          <target state="new">Overview</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The end-to-end workflow is depicted below:</source>
          <target state="new">The end-to-end workflow is depicted below:</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Tutorial End to End Flow</source>
          <target state="new">Tutorial End to End Flow</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> reads the raw game events from a blob storage (RawGameEventsTable) and creates partitions based on year, month, and day (PartitionedGameEventsTable).</source>
          <target state="new">The <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> reads the raw game events from a blob storage (RawGameEventsTable) and creates partitions based on year, month, and day (PartitionedGameEventsTable).</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>EnrichGameLogsPipeline<ept id="p1">**</ept> joins partitioned game events (PartitionedGameEvents table, which is an output of the PartitionGameLogsPipeline) with geo code (RefGetoCodeDictionaryTable) and enriches the data by mapping an IP address to the corresponding geo-location (EnrichedGameEventsTable).</source>
          <target state="new">The <bpt id="p1">**</bpt>EnrichGameLogsPipeline<ept id="p1">**</ept> joins partitioned game events (PartitionedGameEvents table, which is an output of the PartitionGameLogsPipeline) with geo code (RefGetoCodeDictionaryTable) and enriches the data by mapping an IP address to the corresponding geo-location (EnrichedGameEventsTable).</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p1">**</ept> pipeline leverages the enriched data (EnrichedGameEventTable produced by the EnrichGameLogsPipeline) and processes it with the advertising data (RefMarketingCampaignnTable) to create the final output of marketing campaign effectiveness, which is copied to the Azure SQL database (MarketingCampainEffectivensessSQLTable) and an Azure blob storage (MarketingCampaignEffectivenessBlobTable) for analytics.</source>
          <target state="new">The <bpt id="p1">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p1">**</ept> pipeline leverages the enriched data (EnrichedGameEventTable produced by the EnrichGameLogsPipeline) and processes it with the advertising data (RefMarketingCampaignnTable) to create the final output of marketing campaign effectiveness, which is copied to the Azure SQL database (MarketingCampainEffectivensessSQLTable) and an Azure blob storage (MarketingCampaignEffectivenessBlobTable) for analytics.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Walkthrough: Creating, deploying, and monitoring workflows</source>
          <target state="new">Walkthrough: Creating, deploying, and monitoring workflows</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 1: Upload sample data and scripts<ept id="p1">](#MainStep1)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 1: Upload sample data and scripts<ept id="p1">](#MainStep1)</ept>.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>In this step, you will upload all the sample data (including all the logs and reference data) and Hive/Pig scripts that will be executed by the workflows.</source>
          <target state="new">In this step, you will upload all the sample data (including all the logs and reference data) and Hive/Pig scripts that will be executed by the workflows.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>The scripts you execute also create an Azure SQL database (named MarketingCampaigns), tables, user-defined types, and stored procedures.</source>
          <target state="new">The scripts you execute also create an Azure SQL database (named MarketingCampaigns), tables, user-defined types, and stored procedures.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 2: Create an Azure data factory<ept id="p1">](#MainStep2)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 2: Create an Azure data factory<ept id="p1">](#MainStep2)</ept>.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>In this step, you will create an Azure data factory named LogProcessingFactory.</source>
          <target state="new">In this step, you will create an Azure data factory named LogProcessingFactory.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 3: Create linked services<ept id="p1">](#MainStep3)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 3: Create linked services<ept id="p1">](#MainStep3)</ept>.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following linked services:</source>
          <target state="new">In this step, you will create the following linked services:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Links the Azure storage location that contains raw game events, partitioned game events, enriched game events, marketing campaign effective information, reference geo-code data, and reference marketing campaign data to the LogProcessingFactory</source>
          <target state="new">Links the Azure storage location that contains raw game events, partitioned game events, enriched game events, marketing campaign effective information, reference geo-code data, and reference marketing campaign data to the LogProcessingFactory</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>AzureSqlLinkedService<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>AzureSqlLinkedService<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Links an Azure SQL database that contains marketing campaign effectiveness information.</source>
          <target state="new">Links an Azure SQL database that contains marketing campaign effectiveness information.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>HDInsightStorageLinkedService<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>HDInsightStorageLinkedService<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Links an Azure blob storage that is associated with the HDInsight cluster that the HDInsightLinkedService refers to.</source>
          <target state="new">Links an Azure blob storage that is associated with the HDInsight cluster that the HDInsightLinkedService refers to.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>HDInsightLinkedService<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>HDInsightLinkedService<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Links an Azure HDInsight cluster to the LogProcessingFactory.</source>
          <target state="new">Links an Azure HDInsight cluster to the LogProcessingFactory.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>This cluster is used to perform pig/hive processing on the data.</source>
          <target state="new">This cluster is used to perform pig/hive processing on the data.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 4: Create tables<ept id="p1">](#MainStep4)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 4: Create tables<ept id="p1">](#MainStep4)</ept>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following tables:</source>
          <target state="new">In this step, you will create the following tables:</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the raw game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/rawgameevents/) .</source>
          <target state="new">This table specifies the location of the raw game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/rawgameevents/) .</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>PartitionedGameEventsTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>PartitionedGameEventsTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the partitioned game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/partitionedgameevents/) .</source>
          <target state="new">This table specifies the location of the partitioned game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/partitionedgameevents/) .</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>RefGeoCodeDictionaryTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>RefGeoCodeDictionaryTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the refernce geo-code data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/refdata/refgeocodedictionary/).</source>
          <target state="new">This table specifies the location of the refernce geo-code data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/refdata/refgeocodedictionary/).</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>RefMarketingCampaignTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>RefMarketingCampaignTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the refernce marketing campaign data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/refdata/refmarketingcampaign/).</source>
          <target state="new">This table specifies the location of the refernce marketing campaign data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/refdata/refmarketingcampaign/).</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>EnrichedGameEventsTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>EnrichedGameEventsTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the enriched game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/enrichedgameevents/).</source>
          <target state="new">This table specifies the location of the enriched game event data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/logs/enrichedgameevents/).</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>MarketingCampaignEffectivenessSQLTable<ept id="p1">**</ept>.This table specifies the SQL table (MarketingCampaignEffectiveness) in the Azure SQL Database defined by AzureSqlLinkedService that contains the marketing campaign effectiveness data.</source>
          <target state="new"><bpt id="p1">**</bpt>MarketingCampaignEffectivenessSQLTable<ept id="p1">**</ept>.This table specifies the SQL table (MarketingCampaignEffectiveness) in the Azure SQL Database defined by AzureSqlLinkedService that contains the marketing campaign effectiveness data.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>MarketingCampaignEffectivenessBlobTable<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>MarketingCampaignEffectivenessBlobTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>This table specifies the location of the marketing campaign effectiveness data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/marketingcampaigneffectiveness/).</source>
          <target state="new">This table specifies the location of the marketing campaign effectiveness data within the Azure blob storage defined by StorageLinkedService (adfwalkthrough/marketingcampaigneffectiveness/).</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 5: Create and schedule pipelines<ept id="p1">](#MainStep5)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 5: Create and schedule pipelines<ept id="p1">](#MainStep5)</ept>.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following pipelines:</source>
          <target state="new">In this step, you will create the following pipelines:</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>This pipeline reads the raw game events from a blob storage (RawGameEventsTable) and creates partitions based on year, month, and day (PartitionedGameEventsTable).</source>
          <target state="new">This pipeline reads the raw game events from a blob storage (RawGameEventsTable) and creates partitions based on year, month, and day (PartitionedGameEventsTable).</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Step 6: Monitor pipelines and data slices<ept id="p1">](#MainStep6)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Step 6: Monitor pipelines and data slices<ept id="p1">](#MainStep6)</ept>.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>In this step, you will monitor the pipelines, tables, and data slices by using the Azure Portal.</source>
          <target state="new">In this step, you will monitor the pipelines, tables, and data slices by using the Azure Portal.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep1"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 1: Upload sample data and scripts</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep1"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 1: Upload sample data and scripts</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>In this step, you upload all the sample data (including all the logs and reference data) and Hive/Pig scripts that are invoked by the workflows.</source>
          <target state="new">In this step, you upload all the sample data (including all the logs and reference data) and Hive/Pig scripts that are invoked by the workflows.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>The scripts you execute also create an Azure SQL database called <bpt id="p1">**</bpt>MarketingCampaigns<ept id="p1">**</ept>, tables, user-defined types, and stored procedures.</source>
          <target state="new">The scripts you execute also create an Azure SQL database called <bpt id="p1">**</bpt>MarketingCampaigns<ept id="p1">**</ept>, tables, user-defined types, and stored procedures.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The tables, user-defined types and stored procedures are used when moving the Marketing Campaign Effectiveness results from Azure blob storage to the Azure SQL database.</source>
          <target state="new">The tables, user-defined types and stored procedures are used when moving the Marketing Campaign Effectiveness results from Azure blob storage to the Azure SQL database.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1<ept id="p1">**</ept> from <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> folder (or the folder that contains the extracted files) in your favorite editor, replace the highlighted with your cluster information, and save the file.</source>
          <target state="new">Open <bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1<ept id="p1">**</ept> from <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> folder (or the folder that contains the extracted files) in your favorite editor, replace the highlighted with your cluster information, and save the file.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Confirm that your local machine is allowed to access the Azure SQL Database.</source>
          <target state="new">Confirm that your local machine is allowed to access the Azure SQL Database.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>To enable access, use the <bpt id="p1">**</bpt>Azure Management Portal<ept id="p1">**</ept> or <bpt id="p2">**</bpt>sp_set_firewall_rule<ept id="p2">**</ept> on the master database to create a firewall rule for the IP address of your machine.</source>
          <target state="new">To enable access, use the <bpt id="p1">**</bpt>Azure Management Portal<ept id="p1">**</ept> or <bpt id="p2">**</bpt>sp_set_firewall_rule<ept id="p2">**</ept> on the master database to create a firewall rule for the IP address of your machine.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>It may take up to five minutes for this change to take effect.</source>
          <target state="new">It may take up to five minutes for this change to take effect.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Setting firewall rules for Azure SQL<ept id="p1">][azure-sql-firewall]</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Setting firewall rules for Azure SQL<ept id="p1">][azure-sql-firewall]</ept>.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>In Azure PowerShell, navigate to the location where you have extracted the samples (for example: <bpt id="p1">**</bpt>C:\ADFWalkthrough<ept id="p1">**</ept>)</source>
          <target state="new">In Azure PowerShell, navigate to the location where you have extracted the samples (for example: <bpt id="p1">**</bpt>C:\ADFWalkthrough<ept id="p1">**</ept>)</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1<ept id="p1">**</ept></source>
          <target state="new">Run <bpt id="p1">**</bpt>uploadSampleDataAndScripts.ps1<ept id="p1">**</ept></target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Once the script executes successfully, you will see the following:</source>
          <target state="new">Once the script executes successfully, you will see the following:</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 2: Create an Azure data factory</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 2: Create an Azure data factory</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>In this step, you create an Azure data factory named <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept>.</source>
          <target state="new">In this step, you create an Azure data factory named <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>After logging into the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">][azure-preview-portal]</ept>, click <bpt id="p2">**</bpt>NEW<ept id="p2">**</ept> from the bottom-left corner, and click <bpt id="p3">**</bpt>Data Factory<ept id="p3">**</ept> on the <bpt id="p4">**</bpt>New<ept id="p4">**</ept> blade.</source>
          <target state="new">After logging into the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">][azure-preview-portal]</ept>, click <bpt id="p2">**</bpt>NEW<ept id="p2">**</ept> from the bottom-left corner, and click <bpt id="p3">**</bpt>Data Factory<ept id="p3">**</ept> on the <bpt id="p4">**</bpt>New<ept id="p4">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>New-&gt;DataFactory</source>
          <target state="new">New-&gt;DataFactory</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>If you do not see <bpt id="p1">**</bpt>Data Factory<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>New<ept id="p2">**</ept> blade, scroll down.</source>
          <target state="new">If you do not see <bpt id="p1">**</bpt>Data Factory<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>New<ept id="p2">**</ept> blade, scroll down.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Name<ept id="p3">**</ept>.</source>
          <target state="new">In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Name<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Data Factory Blade</source>
          <target state="new">Data Factory Blade</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>If you haven’t created an Azure resource group named <bpt id="p1">**</bpt>ADF<ept id="p1">**</ept> already, do the following:</source>
          <target state="new">If you haven’t created an Azure resource group named <bpt id="p1">**</bpt>ADF<ept id="p1">**</ept> already, do the following:</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>RESOURCE GROUP NAME<ept id="p1">**</ept>, and click <bpt id="p2">**</bpt>Create a new resource group<ept id="p2">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>RESOURCE GROUP NAME<ept id="p1">**</ept>, and click <bpt id="p2">**</bpt>Create a new resource group<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Resource Group Blade</source>
          <target state="new">Resource Group Blade</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Create resource group<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>ADF<ept id="p2">**</ept> for the name of the resource group, and click <bpt id="p3">**</bpt>OK<ept id="p3">**</ept>.</source>
          <target state="new">In the <bpt id="p1">**</bpt>Create resource group<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>ADF<ept id="p2">**</ept> for the name of the resource group, and click <bpt id="p3">**</bpt>OK<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Create Resource Group</source>
          <target state="new">Create Resource Group</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>ADF<ept id="p1">**</ept> for the <bpt id="p2">**</bpt>RESOURCE GROUP NAME<ept id="p2">**</ept>.</source>
          <target state="new">Select <bpt id="p1">**</bpt>ADF<ept id="p1">**</ept> for the <bpt id="p2">**</bpt>RESOURCE GROUP NAME<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, notice that <bpt id="p2">**</bpt>Add to Startboard<ept id="p2">**</ept> is selected by default.</source>
          <target state="new">In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, notice that <bpt id="p2">**</bpt>Add to Startboard<ept id="p2">**</ept> is selected by default.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>This add a link to data factory on the startboard (what you see when you login to Azure Preview Portal).</source>
          <target state="new">This add a link to data factory on the startboard (what you see when you login to Azure Preview Portal).</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>Create Data Factory Blade</source>
          <target state="new">Create Data Factory Blade</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Create<ept id="p2">**</ept> to create the data factory.</source>
          <target state="new">In the <bpt id="p1">**</bpt>New data factory<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Create<ept id="p2">**</ept> to create the data factory.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>After the data factory is created, you should see the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> blade titled <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>.</source>
          <target state="new">After the data factory is created, you should see the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> blade titled <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Data Factory Homepage</source>
          <target state="new">Data Factory Homepage</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep3"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 3: Create linked services</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep3"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 3: Create linked services</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This articles uses the Azure PowerShell to create linked services, tables, and pipelines.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This articles uses the Azure PowerShell to create linked services, tables, and pipelines.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Tutorial using Data Factory Editor<ept id="p1">][adftutorial-using-editor]</ept> if you want to perform this tutorial using Azure Portal, specifically Data Factory Editor.</source>
          <target state="new">See <bpt id="p1">[</bpt>Tutorial using Data Factory Editor<ept id="p1">][adftutorial-using-editor]</ept> if you want to perform this tutorial using Azure Portal, specifically Data Factory Editor.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following linked services: StorageLinkedService, AzureSqlLinkedService, HDInsightStorageLinkedService, and HDInsightLinkedService.</source>
          <target state="new">In this step, you will create the following linked services: StorageLinkedService, AzureSqlLinkedService, HDInsightStorageLinkedService, and HDInsightLinkedService.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Linked Services<ept id="p2">**</ept> tile.</source>
          <target state="new">In the <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Linked Services<ept id="p2">**</ept> tile.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Linked Services Tile</source>
          <target state="new">Linked Services Tile</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>+ Data Store<ept id="p2">**</ept> from the command bar.</source>
          <target state="new">In the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>+ Data Store<ept id="p2">**</ept> from the command bar.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Linked Services - Add Store</source>
          <target state="new">Linked Services - Add Store</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Name<ept id="p3">**</ept>, click <bpt id="p4">**</bpt>TYPE (settings required)<ept id="p4">**</ept>, and select <bpt id="p5">**</bpt>Azure storage account<ept id="p5">**</ept>.</source>
          <target state="new">In the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade, enter <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Name<ept id="p3">**</ept>, click <bpt id="p4">**</bpt>TYPE (settings required)<ept id="p4">**</ept>, and select <bpt id="p5">**</bpt>Azure storage account<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Data Store Type - Azure Storage</source>
          <target state="new">Data Store Type - Azure Storage</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade, you will see two new fields: <bpt id="p2">**</bpt>Account Name<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Account Key<ept id="p3">**</ept>.</source>
          <target state="new">In the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade, you will see two new fields: <bpt id="p2">**</bpt>Account Name<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Account Key<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Enter account name and account key for your <bpt id="p1">**</bpt>Azure Storage Account<ept id="p1">**</ept>.</source>
          <target state="new">Enter account name and account key for your <bpt id="p1">**</bpt>Azure Storage Account<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Azure Storage Settings</source>
          <target state="new">Azure Storage Settings</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>You can get account name and account key your Azure storage account from the portal as shown below:</source>
          <target state="new">You can get account name and account key your Azure storage account from the portal as shown below:</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Storage Key</source>
          <target state="new">Storage Key</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>After you click <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> on the New data store blade, you should see <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> in the list of <bpt id="p3">**</bpt>DATA STORES<ept id="p3">**</ept> on the <bpt id="p4">**</bpt>Linked Services<ept id="p4">**</ept> blade.</source>
          <target state="new">After you click <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> on the New data store blade, you should see <bpt id="p2">**</bpt>StorageLinkedService<ept id="p2">**</ept> in the list of <bpt id="p3">**</bpt>DATA STORES<ept id="p3">**</ept> on the <bpt id="p4">**</bpt>Linked Services<ept id="p4">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Check <bpt id="p1">**</bpt>NOTIFICATIONS<ept id="p1">**</ept> Hub (on the left) to see any messages.</source>
          <target state="new">Check <bpt id="p1">**</bpt>NOTIFICATIONS<ept id="p1">**</ept> Hub (on the left) to see any messages.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Linked Services Blade with Storage</source>
          <target state="new">Linked Services Blade with Storage</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Repeat <bpt id="p1">**</bpt>steps 2-5<ept id="p1">**</ept> to create another linked service named: <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept>.</source>
          <target state="new">Repeat <bpt id="p1">**</bpt>steps 2-5<ept id="p1">**</ept> to create another linked service named: <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>This is the storage used by your HDInsight cluster.</source>
          <target state="new">This is the storage used by your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Confirm that you see both <bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept> and <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept> in the list in the Linked Services blade.</source>
          <target state="new">Confirm that you see both <bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept> and <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept> in the list in the Linked Services blade.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Add (+) Data Store<ept id="p2">**</ept> from the command bar.</source>
          <target state="new">In the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade, click <bpt id="p2">**</bpt>Add (+) Data Store<ept id="p2">**</ept> from the command bar.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Enter <bpt id="p1">**</bpt>AzureSqlLinkedService<ept id="p1">**</ept> for the name.</source>
          <target state="new">Enter <bpt id="p1">**</bpt>AzureSqlLinkedService<ept id="p1">**</ept> for the name.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>TYPE (settings required)<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Azure SQL Database<ept id="p2">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>TYPE (settings required)<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Azure SQL Database<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Now, you should the following additional fields on the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade.</source>
          <target state="new">Now, you should the following additional fields on the <bpt id="p1">**</bpt>New data store<ept id="p1">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>Enter name of the Azure SQL Database <bpt id="p1">**</bpt>server<ept id="p1">**</ept>, <bpt id="p2">**</bpt>database<ept id="p2">**</ept> name, <bpt id="p3">**</bpt>user name<ept id="p3">**</ept>, and <bpt id="p4">**</bpt>password<ept id="p4">**</ept>, and click <bpt id="p5">**</bpt>OK<ept id="p5">**</ept>.</source>
          <target state="new">Enter name of the Azure SQL Database <bpt id="p1">**</bpt>server<ept id="p1">**</ept>, <bpt id="p2">**</bpt>database<ept id="p2">**</ept> name, <bpt id="p3">**</bpt>user name<ept id="p3">**</ept>, and <bpt id="p4">**</bpt>password<ept id="p4">**</ept>, and click <bpt id="p5">**</bpt>OK<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Enter <bpt id="p1">**</bpt>MarketingCampaigns<ept id="p1">**</ept> for the <bpt id="p2">**</bpt>database<ept id="p2">**</ept>.</source>
          <target state="new">Enter <bpt id="p1">**</bpt>MarketingCampaigns<ept id="p1">**</ept> for the <bpt id="p2">**</bpt>database<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>This is the Azure SQL database created by the scripts you ran in Step 1.</source>
          <target state="new">This is the Azure SQL database created by the scripts you ran in Step 1.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>You should confirm that this database was indeed created by the scripts (in case there were errors).</source>
          <target state="new">You should confirm that this database was indeed created by the scripts (in case there were errors).</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>Azure SQL Settings</source>
          <target state="new">Azure SQL Settings</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>To get these values from the Azure Management Portal: click View SQL Database connection strings for MarketingCampaigns database</source>
          <target state="new">To get these values from the Azure Management Portal: click View SQL Database connection strings for MarketingCampaigns database</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Azure SQL Database Connection String</source>
          <target state="new">Azure SQL Database Connection String</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Confirm that you see all the three data stores you have created: <bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept>, <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>AzureSqlLinkedService<ept id="p3">**</ept>.</source>
          <target state="new">Confirm that you see all the three data stores you have created: <bpt id="p1">**</bpt>StorageLinkedService<ept id="p1">**</ept>, <bpt id="p2">**</bpt>HDInsightStorageLinkedService<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>AzureSqlLinkedService<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>You need to create another linked service, but this one is to a Compute service, specifically <bpt id="p1">**</bpt>Azure HDInsight cluster<ept id="p1">**</ept>.</source>
          <target state="new">You need to create another linked service, but this one is to a Compute service, specifically <bpt id="p1">**</bpt>Azure HDInsight cluster<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>The portal does not support creating a compute linked service yet.</source>
          <target state="new">The portal does not support creating a compute linked service yet.</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Therefore, you need to use Azure PowerShell to create this linked service.</source>
          <target state="new">Therefore, you need to use Azure PowerShell to create this linked service.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Switch to <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept> if you have it already open (or) launch <bpt id="p2">**</bpt>Azure PowerShell<ept id="p2">**</ept>.</source>
          <target state="new">Switch to <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept> if you have it already open (or) launch <bpt id="p2">**</bpt>Azure PowerShell<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>If you had closed and reopened Azure PowerShell, you need to run the following commands:</source>
          <target state="new">If you had closed and reopened Azure PowerShell, you need to run the following commands:</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign-in to the Azure Preview Portal.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Add-AzureAccount<ept id="p1">**</ept> and enter the  user name and password that you use to sign-in to the Azure Preview Portal.</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Get-AzureSubscription<ept id="p1">**</ept> to view all the subscriptions for this account.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</source>
          <target state="new">Run <bpt id="p1">**</bpt>Select-AzureSubscription<ept id="p1">**</ept> to select the subscription that you want to work with.</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>This subscription should be the same as the one you used in the Azure Preview Portal.</source>
          <target state="new">This subscription should be the same as the one you used in the Azure Preview Portal.</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Switch to <bpt id="p1">**</bpt>AzureResourceManager<ept id="p1">**</ept> mode as the Azure Data Factory cmdlets are available in this mode.</source>
          <target state="new">Switch to <bpt id="p1">**</bpt>AzureResourceManager<ept id="p1">**</ept> mode as the Azure Data Factory cmdlets are available in this mode.</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Navigate to the <bpt id="p1">**</bpt>LinkedServices<ept id="p1">**</ept> subfolder in <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> (or) from the folder from the location where you have extracted the files.</source>
          <target state="new">Navigate to the <bpt id="p1">**</bpt>LinkedServices<ept id="p1">**</ept> subfolder in <bpt id="p2">**</bpt>C:\ADFWalkthrough<ept id="p2">**</ept> (or) from the folder from the location where you have extracted the files.</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p1">**</bpt>HDInsightLinkedService.json<ept id="p1">**</ept> in your favorite editor and notice that the type is set to <bpt id="p2">**</bpt>HDInsightOnDemandLinkedService<ept id="p2">**</ept>.</source>
          <target state="new">Open <bpt id="p1">**</bpt>HDInsightLinkedService.json<ept id="p1">**</ept> in your favorite editor and notice that the type is set to <bpt id="p2">**</bpt>HDInsightOnDemandLinkedService<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Use the following command to set $df variable to the name of the data factory.</source>
          <target state="new">Use the following command to set $df variable to the name of the data factory.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> to create a Linked Service as follows.</source>
          <target state="new">Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryLinkedService<ept id="p1">**</ept> to create a Linked Service as follows.</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Start with the storage account:</source>
          <target state="new">Start with the storage account:</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>If you are using a different name for ResourceGroupName, DataFactoryName or LinkedService name, refer them in the above cmdlet.</source>
          <target state="new">If you are using a different name for ResourceGroupName, DataFactoryName or LinkedService name, refer them in the above cmdlet.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Also, provide the full file path of the Linked Service JSON file if the file cannot be found.</source>
          <target state="new">Also, provide the full file path of the Linked Service JSON file if the file cannot be found.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>You should see all the four linked services in the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade as shown below.</source>
          <target state="new">You should see all the four linked services in the <bpt id="p1">**</bpt>Linked Services<ept id="p1">**</ept> blade as shown below.</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>If the Linked services blade is not open, click Linked Services in the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> page for <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>.</source>
          <target state="new">If the Linked services blade is not open, click Linked Services in the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> page for <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>It may take a few seconds for the Linked services blade to refresh.</source>
          <target state="new">It may take a few seconds for the Linked services blade to refresh.</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>Linked Services All</source>
          <target state="new">Linked Services All</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep4"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 4: Create tables</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep4"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 4: Create tables</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following tables:</source>
          <target state="new">In this step, you will create the following tables:</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>RawGameEventsTable</source>
          <target state="new">RawGameEventsTable</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>PartitionedGameEventsTable</source>
          <target state="new">PartitionedGameEventsTable</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>RefGeoCodeDictionaryTable</source>
          <target state="new">RefGeoCodeDictionaryTable</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>RefMarketingCampaignTable</source>
          <target state="new">RefMarketingCampaignTable</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>EnrichedGameEventsTable</source>
          <target state="new">EnrichedGameEventsTable</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>MarketingCampaignEffectivenessSQLTable</source>
          <target state="new">MarketingCampaignEffectivenessSQLTable</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>MarketingCampaignEffectivenessBlobTable</source>
          <target state="new">MarketingCampaignEffectivenessBlobTable</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>Tutorial End-to-End Flow</source>
          <target state="new">Tutorial End-to-End Flow</target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>The picture above displays pipelines in the middle row and tables in the top and bottom rows.</source>
          <target state="new">The picture above displays pipelines in the middle row and tables in the top and bottom rows.</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>The Azure Portal does not support creating data sets/tables yet, so you will need to use Azure PowerShell to create tables in this release.</source>
          <target state="new">The Azure Portal does not support creating data sets/tables yet, so you will need to use Azure PowerShell to create tables in this release.</target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>To create the tables</source>
          <target state="new">To create the tables</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>In the Azure PowerShell, navigate to the <bpt id="p1">**</bpt>Tables<ept id="p1">**</ept> folder (*<bpt id="p2">*</bpt>C:\ADFWalkthrough\Tables\*<ept id="p2">*</ept>) from the location where you have extracted the samples.</source>
          <target state="new">In the Azure PowerShell, navigate to the <bpt id="p1">**</bpt>Tables<ept id="p1">**</ept> folder (*<bpt id="p2">*</bpt>C:\ADFWalkthrough\Tables\*<ept id="p2">*</ept>) from the location where you have extracted the samples.</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryTable<ept id="p1">**</ept> to create the Tables as follows for <bpt id="p2">**</bpt>RawGameEventsTable<ept id="p2">**</ept>.json</source>
          <target state="new">Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryTable<ept id="p1">**</ept> to create the Tables as follows for <bpt id="p2">**</bpt>RawGameEventsTable<ept id="p2">**</ept>.json</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>Repeat the previous step to create the following tables:</source>
          <target state="new">Repeat the previous step to create the following tables:</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Datasets<ept id="p2">**</ept> in the <bpt id="p3">**</bpt>DATA FACTORY<ept id="p3">**</ept> blade for <bpt id="p4">**</bpt>LogProcessingFactory<ept id="p4">**</ept> and confirm that you see all the datasets (tables are rectangular datasets).</source>
          <target state="new">In the <bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Datasets<ept id="p2">**</ept> in the <bpt id="p3">**</bpt>DATA FACTORY<ept id="p3">**</ept> blade for <bpt id="p4">**</bpt>LogProcessingFactory<ept id="p4">**</ept> and confirm that you see all the datasets (tables are rectangular datasets).</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>Data Sets All</source>
          <target state="new">Data Sets All</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>You can also use the following command from Azure PowerShell:</source>
          <target state="new">You can also use the following command from Azure PowerShell:</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep5"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 5: Create and schedule pipelines</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep5"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 5: Create and schedule pipelines</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>In this step, you will create the following pipelines: PartitionGameLogsPipeline, EnrichGameLogsPipeline, and AnalyzeMarketingCampaignPipeline.</source>
          <target state="new">In this step, you will create the following pipelines: PartitionGameLogsPipeline, EnrichGameLogsPipeline, and AnalyzeMarketingCampaignPipeline.</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">**</bpt>Windows Explorer<ept id="p1">**</ept>, navigate to the <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> sub folder in <bpt id="p3">**</bpt>C:\ADFWalkthrough<ept id="p3">**</ept> folder (or from the location where you have extracted the samples).</source>
          <target state="new">In <bpt id="p1">**</bpt>Windows Explorer<ept id="p1">**</ept>, navigate to the <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> sub folder in <bpt id="p3">**</bpt>C:\ADFWalkthrough<ept id="p3">**</ept> folder (or from the location where you have extracted the samples).</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p1">**</bpt>PartitionGameLogsPipeline.json<ept id="p1">**</ept> in your favorite editor, replace the highlighted with your storage account for the data storage account information and save the file.</source>
          <target state="new">Open <bpt id="p1">**</bpt>PartitionGameLogsPipeline.json<ept id="p1">**</ept> in your favorite editor, replace the highlighted with your storage account for the data storage account information and save the file.</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source>Repeat the step to create the following pipelines:</source>
          <target state="new">Repeat the step to create the following pipelines:</target>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>EnrichGameLogsPipeline<ept id="p1">**</ept>.json (3 occurrences)</source>
          <target state="new"><bpt id="p1">**</bpt>EnrichGameLogsPipeline<ept id="p1">**</ept>.json (3 occurrences)</target>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p1">**</ept>.json (3 occurrences)</source>
          <target state="new"><bpt id="p1">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p1">**</ept>.json (3 occurrences)</target>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>IMPORTANT:<ept id="p1">**</ept> Confirm that you have replaced all</source>
          <target state="new"><bpt id="p1">**</bpt>IMPORTANT:<ept id="p1">**</ept> Confirm that you have replaced all</target>
        </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve">
          <source>with your storage account name.</source>
          <target state="new">with your storage account name.</target>
        </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept>, navigate to the <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> sub folder in <bpt id="p3">**</bpt>C:\ADFWalkthrough<ept id="p3">**</ept> folder (or from the location where you have extracted the samples).</source>
          <target state="new">In <bpt id="p1">**</bpt>Azure PowerShell<ept id="p1">**</ept>, navigate to the <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> sub folder in <bpt id="p3">**</bpt>C:\ADFWalkthrough<ept id="p3">**</ept> folder (or from the location where you have extracted the samples).</target>
        </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve">
          <source>Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryPipeline<ept id="p1">**</ept> to create the Pipelines as follows for <bpt id="p2">**</bpt>PartitionGameLogspeline<ept id="p2">**</ept>.json</source>
          <target state="new">Use the cmdlet <bpt id="p1">**</bpt>New-AzureDataFactoryPipeline<ept id="p1">**</ept> to create the Pipelines as follows for <bpt id="p2">**</bpt>PartitionGameLogspeline<ept id="p2">**</ept>.json</target>
        </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve">
          <source>If you are using a different name for ResourceGroupName, DataFactoryName or Pipeline name, refer them in the above cmdlet.</source>
          <target state="new">If you are using a different name for ResourceGroupName, DataFactoryName or Pipeline name, refer them in the above cmdlet.</target>
        </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>Also, provide the full file path of the Pipeline JSON file.</source>
          <target state="new">Also, provide the full file path of the Pipeline JSON file.</target>
        </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Repeat the previous step to create the following pipelines:</source>
          <target state="new">Repeat the previous step to create the following pipelines:</target>
        </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve">
          <source>EnrichGameLogsPipeline</source>
          <target state="new">EnrichGameLogsPipeline</target>
        </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve">
          <source>AnalyzeMarketingCampaignPipeline</source>
          <target state="new">AnalyzeMarketingCampaignPipeline</target>
        </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve">
          <source>Use the cmdlet <bpt id="p1">**</bpt>Get-AzureDataFactoryPipeline<ept id="p1">**</ept> to get the listing of the Pipelines.</source>
          <target state="new">Use the cmdlet <bpt id="p1">**</bpt>Get-AzureDataFactoryPipeline<ept id="p1">**</ept> to get the listing of the Pipelines.</target>
        </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve">
          <source>Once the pipelines are created, you can specify the duration in which data processing will occur.</source>
          <target state="new">Once the pipelines are created, you can specify the duration in which data processing will occur.</target>
        </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve">
          <source>By specifying the active period for a pipeline, you are defining the time duration in which the data slices will be processed based on the Availability properties that were defined for each ADF table.</source>
          <target state="new">By specifying the active period for a pipeline, you are defining the time duration in which the data slices will be processed based on the Availability properties that were defined for each ADF table.</target>
        </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve">
          <source>To specify the active period for the pipeline, you can use the cmdlet Set-AzureDataFactoryPipelineActivePeriod.</source>
          <target state="new">To specify the active period for the pipeline, you can use the cmdlet Set-AzureDataFactoryPipelineActivePeriod.</target>
        </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>In this walkthrough, the sample data is from 05/01 to 05/05.</source>
          <target state="new">In this walkthrough, the sample data is from 05/01 to 05/05.</target>
        </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>Use 2014-05-01 as the StartDateTime.</source>
          <target state="new">Use 2014-05-01 as the StartDateTime.</target>
        </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve">
          <source>EndDateTime is optional.</source>
          <target state="new">EndDateTime is optional.</target>
        </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve">
          <source>Confirm to set the active period for the pipeline.</source>
          <target state="new">Confirm to set the active period for the pipeline.</target>
        </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve">
          <source>Repeat the previous two steps to set active period for the following pipelines.</source>
          <target state="new">Repeat the previous two steps to set active period for the following pipelines.</target>
        </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve">
          <source>EnrichGameLogsPipeline</source>
          <target state="new">EnrichGameLogsPipeline</target>
        </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve">
          <source>AnalyzeMarketingCampaignPipeline</source>
          <target state="new">AnalyzeMarketingCampaignPipeline</target>
        </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> tile (not on the names of the pipelines) in the <bpt id="p3">**</bpt>DATA FACTORY<ept id="p3">**</ept> blade for the <bpt id="p4">**</bpt>LogProcessingFactory<ept id="p4">**</ept>, you should see the pipelines you created.</source>
          <target state="new">In the <bpt id="p1">**</bpt>Azure Preview Portal<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Pipelines<ept id="p2">**</ept> tile (not on the names of the pipelines) in the <bpt id="p3">**</bpt>DATA FACTORY<ept id="p3">**</ept> blade for the <bpt id="p4">**</bpt>LogProcessingFactory<ept id="p4">**</ept>, you should see the pipelines you created.</target>
        </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve">
          <source>All Pipelines</source>
          <target state="new">All Pipelines</target>
        </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> blade for the <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>, click <bpt id="p3">**</bpt>Diagram<ept id="p3">**</ept>.</source>
          <target state="new">In the <bpt id="p1">**</bpt>DATA FACTORY<ept id="p1">**</ept> blade for the <bpt id="p2">**</bpt>LogProcessingFactory<ept id="p2">**</ept>, click <bpt id="p3">**</bpt>Diagram<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve">
          <source>Diagram Link</source>
          <target state="new">Diagram Link</target>
        </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve">
          <source>You can rearrange the diagram you see and here is a rearranged diagram that shows direct inputs at the top and outputs at the bottom.</source>
          <target state="new">You can rearrange the diagram you see and here is a rearranged diagram that shows direct inputs at the top and outputs at the bottom.</target>
        </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>You can see that the output of the <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> is passed in as an input to the EnrichGameLogsPipeline and output of the <bpt id="p2">**</bpt>EnrichGameLogsPipeline<ept id="p2">**</ept> is passed to the <bpt id="p3">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p3">**</ept>.</source>
          <target state="new">You can see that the output of the <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> is passed in as an input to the EnrichGameLogsPipeline and output of the <bpt id="p2">**</bpt>EnrichGameLogsPipeline<ept id="p2">**</ept> is passed to the <bpt id="p3">**</bpt>AnalyzeMarketingCampaignPipeline<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve">
          <source>Double-click on a title to see details about the artifact that the blade represents.</source>
          <target state="new">Double-click on a title to see details about the artifact that the blade represents.</target>
        </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve">
          <source>Diagram View</source>
          <target state="new">Diagram View</target>
        </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Congratulations!<ept id="p1">**</ept> You have successfully created the Azure Data Factory, Linked Services, Pipelines, Tables and started the workflow.</source>
          <target state="new"><bpt id="p1">**</bpt>Congratulations!<ept id="p1">**</ept> You have successfully created the Azure Data Factory, Linked Services, Pipelines, Tables and started the workflow.</target>
        </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="MainStep6"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 6: Monitor pipelines and data slices</source>
          <target state="new"><ph id="ph1">&lt;a name="MainStep6"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Step 6: Monitor pipelines and data slices</target>
        </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve">
          <source>If you do not have the DATA FACTORY blade for the LogProcessingFactory open, you can do one of the following:</source>
          <target state="new">If you do not have the DATA FACTORY blade for the LogProcessingFactory open, you can do one of the following:</target>
        </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>Startboard<ept id="p2">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>LogProcessingFactory<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>Startboard<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve">
          <source>While creating the data factory, the <bpt id="p1">**</bpt>Add to Startboard<ept id="p1">**</ept> option was automatically checked.</source>
          <target state="new">While creating the data factory, the <bpt id="p1">**</bpt>Add to Startboard<ept id="p1">**</ept> option was automatically checked.</target>
        </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve">
          <source>Monitoring Startboard</source>
          <target state="new">Monitoring Startboard</target>
        </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>BROWSE<ept id="p1">**</ept> hub, and click <bpt id="p2">**</bpt>Everything<ept id="p2">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>BROWSE<ept id="p1">**</ept> hub, and click <bpt id="p2">**</bpt>Everything<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve">
          <source>Monitoring Hub Everything</source>
          <target state="new">Monitoring Hub Everything</target>
        </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Browse<ept id="p1">**</ept> blade, select <bpt id="p2">**</bpt>Data factories<ept id="p2">**</ept> and select <bpt id="p3">**</bpt>LogProcessingFactory<ept id="p3">**</ept> in the <bpt id="p4">**</bpt>Data factories<ept id="p4">**</ept> blade.</source>
          <target state="new">In the <bpt id="p1">**</bpt>Browse<ept id="p1">**</ept> blade, select <bpt id="p2">**</bpt>Data factories<ept id="p2">**</ept> and select <bpt id="p3">**</bpt>LogProcessingFactory<ept id="p3">**</ept> in the <bpt id="p4">**</bpt>Data factories<ept id="p4">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve">
          <source>Monitoring Browse Datafactories</source>
          <target state="new">Monitoring Browse Datafactories</target>
        </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve">
          <source>You can monitor your data factory in several ways.</source>
          <target state="new">You can monitor your data factory in several ways.</target>
        </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve">
          <source>You can start with pipelines or data sets.</source>
          <target state="new">You can start with pipelines or data sets.</target>
        </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve">
          <source>Let’s start with Pipelines and drill further.</source>
          <target state="new">Let’s start with Pipelines and drill further.</target>
        </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Pipelines<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>DATA FACTORY<ept id="p2">**</ept> blade.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Pipelines<ept id="p1">**</ept> on the <bpt id="p2">**</bpt>DATA FACTORY<ept id="p2">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> in the Pipelines blade.</source>
          <target state="new">Click <bpt id="p1">**</bpt>PartitionGameLogsPipeline<ept id="p1">**</ept> in the Pipelines blade.</target>
        </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>PIPELINE<ept id="p1">**</ept> blade for <bpt id="p2">**</bpt>PartitionGameLogsPipeline<ept id="p2">**</ept>, you see that the pipeline consumes <bpt id="p3">**</bpt>RawGameEventsTable<ept id="p3">**</ept> dataset.</source>
          <target state="new">In the <bpt id="p1">**</bpt>PIPELINE<ept id="p1">**</ept> blade for <bpt id="p2">**</bpt>PartitionGameLogsPipeline<ept id="p2">**</ept>, you see that the pipeline consumes <bpt id="p3">**</bpt>RawGameEventsTable<ept id="p3">**</ept> dataset.</target>
        </trans-unit>
        <trans-unit id="341" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="342" translate="yes" xml:space="preserve">
          <source>Pipeline Consumed and Produced</source>
          <target state="new">Pipeline Consumed and Produced</target>
        </trans-unit>
        <trans-unit id="343" translate="yes" xml:space="preserve">
          <source>In the TABLE blade for <bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>, you see all the slices.</source>
          <target state="new">In the TABLE blade for <bpt id="p1">**</bpt>RawGameEventsTable<ept id="p1">**</ept>, you see all the slices.</target>
        </trans-unit>
        <trans-unit id="344" translate="yes" xml:space="preserve">
          <source>In the following screen shot, all the slices are in <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> state and there are no problem slices.</source>
          <target state="new">In the following screen shot, all the slices are in <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> state and there are no problem slices.</target>
        </trans-unit>
        <trans-unit id="345" translate="yes" xml:space="preserve">
          <source>It means that the data is ready to be processed.</source>
          <target state="new">It means that the data is ready to be processed.</target>
        </trans-unit>
        <trans-unit id="346" translate="yes" xml:space="preserve">
          <source>RawGameEventsTable TABLE blade</source>
          <target state="new">RawGameEventsTable TABLE blade</target>
        </trans-unit>
        <trans-unit id="347" translate="yes" xml:space="preserve">
          <source>Now, on the <bpt id="p1">**</bpt>PIPELINE<ept id="p1">**</ept> blade for <bpt id="p2">**</bpt>PartiionGameLogsPipeline<ept id="p2">**</ept>, click <bpt id="p3">**</bpt>Produced<ept id="p3">**</ept>.</source>
          <target state="new">Now, on the <bpt id="p1">**</bpt>PIPELINE<ept id="p1">**</ept> blade for <bpt id="p2">**</bpt>PartiionGameLogsPipeline<ept id="p2">**</ept>, click <bpt id="p3">**</bpt>Produced<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="348" translate="yes" xml:space="preserve">
          <source>You should see the list of data sets that this pipeline produces:</source>
          <target state="new">You should see the list of data sets that this pipeline produces:</target>
        </trans-unit>
        <trans-unit id="349" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>PartitionedGameEvents<ept id="p1">**</ept> table in the <bpt id="p2">**</bpt>Produced datasets<ept id="p2">**</ept> blade.</source>
          <target state="new">Click <bpt id="p1">**</bpt>PartitionedGameEvents<ept id="p1">**</ept> table in the <bpt id="p2">**</bpt>Produced datasets<ept id="p2">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="350" translate="yes" xml:space="preserve">
          <source>Confirm that the <bpt id="p1">**</bpt>status<ept id="p1">**</ept> of all slices is set to <bpt id="p2">**</bpt>Ready<ept id="p2">**</ept>.</source>
          <target state="new">Confirm that the <bpt id="p1">**</bpt>status<ept id="p1">**</ept> of all slices is set to <bpt id="p2">**</bpt>Ready<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="351" translate="yes" xml:space="preserve">
          <source>Click on one of the slices that is <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> to see the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade for that slice.</source>
          <target state="new">Click on one of the slices that is <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept> to see the <bpt id="p2">**</bpt>DATA SLICE<ept id="p2">**</ept> blade for that slice.</target>
        </trans-unit>
        <trans-unit id="352" translate="yes" xml:space="preserve">
          <source>RawGameEventsTable DATA SLICE blade</source>
          <target state="new">RawGameEventsTable DATA SLICE blade</target>
        </trans-unit>
        <trans-unit id="353" translate="yes" xml:space="preserve">
          <source>If there was an error, you would see a **Failed **status here.</source>
          <target state="new">If there was an error, you would see a **Failed **status here.</target>
        </trans-unit>
        <trans-unit id="354" translate="yes" xml:space="preserve">
          <source>You might also see either both slices with status <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept>, or both with status <bpt id="p2">**</bpt>PendingValidation<ept id="p2">**</ept>, depending on how quickly the slices are processed.</source>
          <target state="new">You might also see either both slices with status <bpt id="p1">**</bpt>Ready<ept id="p1">**</ept>, or both with status <bpt id="p2">**</bpt>PendingValidation<ept id="p2">**</ept>, depending on how quickly the slices are processed.</target>
        </trans-unit>
        <trans-unit id="355" translate="yes" xml:space="preserve">
          <source>Refer to the <bpt id="p1">[</bpt>Azure Data Factory Developer Reference<ept id="p1">][developer-reference]</ept> to get an understanding of all possible slice statuses.</source>
          <target state="new">Refer to the <bpt id="p1">[</bpt>Azure Data Factory Developer Reference<ept id="p1">][developer-reference]</ept> to get an understanding of all possible slice statuses.</target>
        </trans-unit>
        <trans-unit id="356" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>DATA SLICE<ept id="p1">**</ept> blade, click the run from the <bpt id="p2">**</bpt>Activity Runs<ept id="p2">**</ept> list.</source>
          <target state="new">In the <bpt id="p1">**</bpt>DATA SLICE<ept id="p1">**</ept> blade, click the run from the <bpt id="p2">**</bpt>Activity Runs<ept id="p2">**</ept> list.</target>
        </trans-unit>
        <trans-unit id="357" translate="yes" xml:space="preserve">
          <source>You should see the Activity Run blade for that slice.</source>
          <target state="new">You should see the Activity Run blade for that slice.</target>
        </trans-unit>
        <trans-unit id="358" translate="yes" xml:space="preserve">
          <source>You should see the following <bpt id="p1">**</bpt>ACTIVITY RUN DETAILS<ept id="p1">**</ept> blade.</source>
          <target state="new">You should see the following <bpt id="p1">**</bpt>ACTIVITY RUN DETAILS<ept id="p1">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="359" translate="yes" xml:space="preserve">
          <source>Activity Run Details blade</source>
          <target state="new">Activity Run Details blade</target>
        </trans-unit>
        <trans-unit id="360" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Download<ept id="p1">**</ept> to download the files.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Download<ept id="p1">**</ept> to download the files.</target>
        </trans-unit>
        <trans-unit id="361" translate="yes" xml:space="preserve">
          <source>This screen is especially useful when you are troubleshooting errors from HDInsight processing.</source>
          <target state="new">This screen is especially useful when you are troubleshooting errors from HDInsight processing.</target>
        </trans-unit>
        <trans-unit id="362" translate="yes" xml:space="preserve">
          <source>When all the pipeline have completed execution, you can look into the <bpt id="p1">**</bpt>MarketingCampaignEffectivenessTable<ept id="p1">**</ept> in the <bpt id="p2">**</bpt>MarketingCampaigns<ept id="p2">**</ept> Azure SQL database to view the results.</source>
          <target state="new">When all the pipeline have completed execution, you can look into the <bpt id="p1">**</bpt>MarketingCampaignEffectivenessTable<ept id="p1">**</ept> in the <bpt id="p2">**</bpt>MarketingCampaigns<ept id="p2">**</ept> Azure SQL database to view the results.</target>
        </trans-unit>
        <trans-unit id="363" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Congratulations!<ept id="p1">**</ept> You can now monitor and troubleshoot the workflows.</source>
          <target state="new"><bpt id="p1">**</bpt>Congratulations!<ept id="p1">**</ept> You can now monitor and troubleshoot the workflows.</target>
        </trans-unit>
        <trans-unit id="364" translate="yes" xml:space="preserve">
          <source>You have learned how to use Azure Data Factory to process data and get analytics.</source>
          <target state="new">You have learned how to use Azure Data Factory to process data and get analytics.</target>
        </trans-unit>
        <trans-unit id="365" translate="yes" xml:space="preserve">
          <source>Extend the tutorial to use on-premises data</source>
          <target state="new">Extend the tutorial to use on-premises data</target>
        </trans-unit>
        <trans-unit id="366" translate="yes" xml:space="preserve">
          <source>In the last step of log processing scenario from the walkthrough in this article, the marketing campaign effectiveness output was copied to an Azure SQL database.</source>
          <target state="new">In the last step of log processing scenario from the walkthrough in this article, the marketing campaign effectiveness output was copied to an Azure SQL database.</target>
        </trans-unit>
        <trans-unit id="367" translate="yes" xml:space="preserve">
          <source>You could also move this data to on-premises SQL Server for analytics within your organization.</source>
          <target state="new">You could also move this data to on-premises SQL Server for analytics within your organization.</target>
        </trans-unit>
        <trans-unit id="368" translate="yes" xml:space="preserve">
          <source>In order to copy the marketing campaign effectiveness data from Azure Blob to on-premises SQL Server, you need to create additional on-premises Linked Service, Table and Pipeline introduced in the walkthrough in this article.</source>
          <target state="new">In order to copy the marketing campaign effectiveness data from Azure Blob to on-premises SQL Server, you need to create additional on-premises Linked Service, Table and Pipeline introduced in the walkthrough in this article.</target>
        </trans-unit>
        <trans-unit id="369" translate="yes" xml:space="preserve">
          <source>Practice the <bpt id="p1">[</bpt>Walkthrough: Using on-premises data source<ept id="p1">][tutorial-onpremises-using-powershell]</ept> to learn how to create a pipeline to copy marketing campaign effectiveness data to an on-premises SQL Server database.</source>
          <target state="new">Practice the <bpt id="p1">[</bpt>Walkthrough: Using on-premises data source<ept id="p1">][tutorial-onpremises-using-powershell]</ept> to learn how to create a pipeline to copy marketing campaign effectiveness data to an on-premises SQL Server database.</target>
        </trans-unit>
        <trans-unit id="370" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">0ad89733116dc2a8fa3695a7ba2f4a57535a48c2</xliffext:olfilehash>
  </header>
</xliff>