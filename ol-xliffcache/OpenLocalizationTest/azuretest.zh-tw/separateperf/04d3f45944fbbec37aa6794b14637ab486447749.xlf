<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Run the Hadoop samples in HDInsight | Microsoft Azure</source>
          <target state="new">Run the Hadoop samples in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Get started using the Azure HDInsight service with the samples provided.</source>
          <target state="new">Get started using the Azure HDInsight service with the samples provided.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use PowerShell scripts that run MapReduce programs on data clusters.</source>
          <target state="new">Use PowerShell scripts that run MapReduce programs on data clusters.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Run the Hadoop samples in HDInsight</source>
          <target state="new">Run the Hadoop samples in HDInsight</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>A set of samples are provided to help you get started running MapReduce jobs on Hadoop clusters using Azure HDInsight.</source>
          <target state="new">A set of samples are provided to help you get started running MapReduce jobs on Hadoop clusters using Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>These samples are made available on each of the HDInsight managed clusters that you create.</source>
          <target state="new">These samples are made available on each of the HDInsight managed clusters that you create.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Running these samples will familiarize you with using Azure PowerShell cmdlets to run jobs on Hadoop clusters.</source>
          <target state="new">Running these samples will familiarize you with using Azure PowerShell cmdlets to run jobs on Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>MapReduce programs can also be run programmatically from an application by using the Microsoft .NET API for HDInsight.</source>
          <target state="new">MapReduce programs can also be run programmatically from an application by using the Microsoft .NET API for HDInsight.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>For more information about using the HDInsight APIs for job submission, see <bpt id="p1">[</bpt>Submit Hadoop Jobs in HDInsight<ept id="p1">] [hdinsight-submit-jobs]</ept>.</source>
          <target state="new">For more information about using the HDInsight APIs for job submission, see <bpt id="p1">[</bpt>Submit Hadoop Jobs in HDInsight<ept id="p1">] [hdinsight-submit-jobs]</ept>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Much additional documentation exists on the web for Hadoop-related technologies, such as Java-based MapReduce programming and streaming, and documentation about the cmdlets that are used in Windows PowerShell scripting.</source>
          <target state="new">Much additional documentation exists on the web for Hadoop-related technologies, such as Java-based MapReduce programming and streaming, and documentation about the cmdlets that are used in Windows PowerShell scripting.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>For more information about these resources, see the final <bpt id="p1">**</bpt>Resources for HDInsight<ept id="p1">**</ept> section of <bpt id="p2">[</bpt>Introduction to Azure HDInsight<ept id="p2">][hdinsight-introduction]</ept>.</source>
          <target state="new">For more information about these resources, see the final <bpt id="p1">**</bpt>Resources for HDInsight<ept id="p1">**</ept> section of <bpt id="p2">[</bpt>Introduction to Azure HDInsight<ept id="p2">][hdinsight-introduction]</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>What these samples are</source>
          <target state="new">What these samples are</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>These samples are intended to get you up to speed quickly on how to deploy Hadoop jobs and to provide you with an extensible testing bed to work with the concepts and scripting procedures that are used by the service.</source>
          <target state="new">These samples are intended to get you up to speed quickly on how to deploy Hadoop jobs and to provide you with an extensible testing bed to work with the concepts and scripting procedures that are used by the service.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>They provide you with examples of common tasks, such as creating and importing data sets of various sizes, running and composing jobs sequentially, and examining the results of your jobs.</source>
          <target state="new">They provide you with examples of common tasks, such as creating and importing data sets of various sizes, running and composing jobs sequentially, and examining the results of your jobs.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The data sets that you use can be varied in size, which allows you to observe the effects that data sets of various size have on job performance.</source>
          <target state="new">The data sets that you use can be varied in size, which allows you to observe the effects that data sets of various size have on job performance.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Prerequisites<ept id="p1">**</ept>:</source>
          <target state="new"><bpt id="p1">**</bpt>Prerequisites<ept id="p1">**</ept>:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>an HDInsight cluster<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>an HDInsight cluster<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>For instructions on the various ways in which such clusters can be created, see <bpt id="p1">[</bpt>Provision HDInsight Clusters<ept id="p1">](hdinsight-provision-clusters.md)</ept>.</source>
          <target state="new">For instructions on the various ways in which such clusters can be created, see <bpt id="p1">[</bpt>Provision HDInsight Clusters<ept id="p1">](hdinsight-provision-clusters.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>A workstation with Azure PowerShell<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>A workstation with Azure PowerShell<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Install and use Azure PowerShell<ept id="p1">](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Install and use Azure PowerShell<ept id="p1">](http://azure.microsoft.com/documentation/videos/install-and-use-azure-powershell/)</ept>.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The samples</source>
          <target state="new">The samples</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>HDInsight ships with the following samples:</source>
          <target state="new">HDInsight ships with the following samples:</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The pi estimator Hadoop sample<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-pi-estimator]</ept>: Shows how to run a MapReduce program with HDInsight that uses a statistical (quasi-Monte Carlo) method to estimate the value of pi.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The pi estimator Hadoop sample<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-pi-estimator]</ept>: Shows how to run a MapReduce program with HDInsight that uses a statistical (quasi-Monte Carlo) method to estimate the value of pi.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Run a MapReduce word count example on an Hadoop cluster<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-wordcount]</ept>: Shows how to use an HDInsight cluster to run a MapReduce program that counts word occurrences in a text file.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Run a MapReduce word count example on an Hadoop cluster<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-wordcount]</ept>: Shows how to use an HDInsight cluster to run a MapReduce program that counts word occurrences in a text file.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The 10-GB Graysort Hadoop sample<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-10gb-graysort]</ept>: Shows how to run a general purpose GraySort on a 10 GB file by using HDInsight.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The 10-GB Graysort Hadoop sample<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-10gb-graysort]</ept>: Shows how to run a general purpose GraySort on a 10 GB file by using HDInsight.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>There are three jobs to run: Teragen to generate the data, Terasort to sort the data, and Teravalidate to confirm that the data has been properly sorted.</source>
          <target state="new">There are three jobs to run: Teragen to generate the data, Terasort to sort the data, and Teravalidate to confirm that the data has been properly sorted.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The C# streaming wordcount MapReduce sample in Hadoop<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-csharp-streaming]</ept>: Shows how to use C# to write a MapReduce program that uses the Hadoop streaming interface.</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>The C# streaming wordcount MapReduce sample in Hadoop<ept id="p2">**</ept><ept id="p1">][hdinsight-sample-csharp-streaming]</ept>: Shows how to use C# to write a MapReduce program that uses the Hadoop streaming interface.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>How to run the samples</source>
          <target state="new">How to run the samples</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>The samples can be run by using Azure PowerShell.</source>
          <target state="new">The samples can be run by using Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Instructions about how to do this are provided for each of the previous samples.</source>
          <target state="new">Instructions about how to do this are provided for each of the previous samples.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>From this article and the articles in each of the samples, you learned how to run the samples included with the HDInsight clusters by using Azure PowerShell.</source>
          <target state="new">From this article and the articles in each of the samples, you learned how to run the samples included with the HDInsight clusters by using Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>For tutorials about using Pig, Hive, and MapReduce with HDInsight, see the following topics:</source>
          <target state="new">For tutorials about using Pig, Hive, and MapReduce with HDInsight, see the following topics:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Get started using Hadoop with Hive in HDInsight to analyze mobile handset use</source>
          <target state="new">Get started using Hadoop with Hive in HDInsight to analyze mobile handset use</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Use Pig with Hadoop on HDInsight</source>
          <target state="new">Use Pig with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Use Hive with Hadoop on HDInsight</source>
          <target state="new">Use Hive with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Submit Hadoop Jobs in HDInsight</source>
          <target state="new">Submit Hadoop Jobs in HDInsight</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Azure HDInsight SDK documentation</source>
          <target state="new">Azure HDInsight SDK documentation</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Debug Hadoop in HDInsight: Error messages</source>
          <target state="new">Debug Hadoop in HDInsight: Error messages</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04d3f45944fbbec37aa6794b14637ab486447749</xliffext:olfilehash>
  </header>
</xliff>