{
  "nodes": [
    {
      "content": "Microsoft Azure Security and Audit Log Management | Microsoft Azure",
      "pos": [
        26,
        93
      ]
    },
    {
      "content": "Article provides an introduction for generating, collecting, and analyzing security logs from services hosted on Azure.",
      "pos": [
        111,
        230
      ]
    },
    {
      "content": "It is intended for IT professionals and security analysts who deal with information asset management on a daily basis, including those responsible for their organization's security and compliance efforts.",
      "pos": [
        232,
        436
      ]
    },
    {
      "content": "Microsoft Azure security and audit log management",
      "pos": [
        774,
        823
      ]
    },
    {
      "content": "Azure enables customers to perform security event generation and collection from Azure Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) roles to central storage in their subscriptions.",
      "pos": [
        825,
        1028
      ]
    },
    {
      "content": "Customers can then use <bpt id=\"p1\">[</bpt>HDInsight<ept id=\"p1\">](http://azure.microsoft.com/documentation/services/hdinsight/)</ept> to aggregate and analyze the collected events.",
      "pos": [
        1029,
        1172
      ]
    },
    {
      "content": "In addition, these collected events can be exported to on-premises security information and event management (SIEM) systems for ongoing monitoring.",
      "pos": [
        1173,
        1320
      ]
    },
    {
      "content": "The Azure security logging, analysis, and monitoring lifecycle includes:",
      "pos": [
        1322,
        1394
      ]
    },
    {
      "pos": [
        1398,
        1476
      ],
      "content": "<bpt id=\"p1\">**</bpt>Generation<ept id=\"p1\">**</ept>: Instrument applications and the infrastructure to raise events"
    },
    {
      "pos": [
        1479,
        1568
      ],
      "content": "<bpt id=\"p1\">**</bpt>Collection<ept id=\"p1\">**</ept>: Configure Azure to collect the various security logs in a storage account"
    },
    {
      "pos": [
        1571,
        1698
      ],
      "content": "<bpt id=\"p1\">**</bpt>Analysis<ept id=\"p1\">**</ept>: Use Azure tools such as HDInsight and on-premises SIEM systems to analyze the logs and generate security insights"
    },
    {
      "pos": [
        1701,
        1840
      ],
      "content": "<bpt id=\"p1\">**</bpt>Monitoring and reporting<ept id=\"p1\">**</ept>: Azure offers centralized monitoring and analysis systems that provide continuous visibility and timely alerts"
    },
    {
      "content": "This article focuses on the generation and collection phases of the lifecycle.",
      "pos": [
        1842,
        1920
      ]
    },
    {
      "content": "Log generation",
      "pos": [
        1925,
        1939
      ]
    },
    {
      "content": "Security events are raised in the Windows Event Log for the <bpt id=\"p1\">**</bpt>System<ept id=\"p1\">**</ept>, <bpt id=\"p2\">**</bpt>Security<ept id=\"p2\">**</ept>, and <bpt id=\"p3\">**</bpt>Application<ept id=\"p3\">**</ept> channels in virtual machines.",
      "pos": [
        1940,
        2075
      ]
    },
    {
      "content": "To ensure that events are logged without potential data loss, it is important to appropriately configure the size of the event log.",
      "pos": [
        2076,
        2207
      ]
    },
    {
      "content": "Base the size of the event log on the number of events that auditing policy settings generate and the event collection policies defined.",
      "pos": [
        2208,
        2344
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Planning for security audit monitoring and management<ept id=\"p1\">](http://technet.microsoft.com/library/ee513968.aspx#BKMK_4)</ept>.",
      "pos": [
        2345,
        2486
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> When using Windows Event Forwarding (WEF) or Azure Diagnostics (explained in the <bpt id=\"p1\">[</bpt>Log Collection<ept id=\"p1\">](#log-collection)</ept> section) to pull logs from Cloud Services or virtual machines, consider the potential impact of system outages.",
      "pos": [
        2489,
        2728
      ]
    },
    {
      "content": "For example, if your WEF environment goes down for some time, you either need to make sure the log size is big enough to account for a longer time duration or be prepared for possible log data loss.",
      "pos": [
        2729,
        2927
      ]
    },
    {
      "content": "For Cloud Services applications that are deployed in Azure and virtual machines created from the <bpt id=\"p1\">[</bpt>Azure Virtual Machines Marketplace<ept id=\"p1\">](http://azure.microsoft.com/marketplace/virtual-machines/#microsoft)</ept>, a set of operating system security events are enabled by default.",
      "pos": [
        2929,
        3197
      ]
    },
    {
      "content": "Customers can add, remove, or modify events to be audited by customizing the operating system audit policy.",
      "pos": [
        3198,
        3305
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Security Policy Settings Reference<ept id=\"p1\">](http://technet.microsoft.com/library/jj852210.aspx)</ept>.",
      "pos": [
        3306,
        3421
      ]
    },
    {
      "content": "You can use the following methods to generate additional logs from operating system (such as audit policy changes) and Windows components (such as IIS):",
      "pos": [
        3423,
        3575
      ]
    },
    {
      "content": "Group Policy to roll out policy settings for virtual machines in Azure that are domain-joined",
      "pos": [
        3579,
        3672
      ]
    },
    {
      "content": "Desired State Configuration (DSC) to push and manage policy settings.",
      "pos": [
        3675,
        3744
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Azure PowerShell DSC<ept id=\"p1\">](http://blogs.msdn.com/b/powershell/archive/2014/08/07/introducing-the-azure-powershell-dsc-desired-state-configuration-extension.aspx)</ept>",
      "pos": [
        3745,
        3928
      ]
    },
    {
      "content": "Service Deployment role startup code to roll out settings for Cloud Services (PaaS scenario)",
      "pos": [
        3931,
        4023
      ]
    },
    {
      "content": "Configuring Azure role startup tasks enables code to run before a role starts.",
      "pos": [
        4025,
        4103
      ]
    },
    {
      "content": "You can define a startup task for a role by adding the <bpt id=\"p1\">**</bpt>Startup<ept id=\"p1\">**</ept> element to the definition of the role in the service definition file, as shown in the following example.",
      "pos": [
        4104,
        4275
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Run Startup Tasks in Azure<ept id=\"p1\">](http://msdn.microsoft.com/library/azure/hh180155.aspx)</ept>.",
      "pos": [
        4276,
        4386
      ]
    },
    {
      "content": "The task file that is to be run as a Startup task (EnableLogOnAudit.cmd in the following example) needs to be included in your build package.",
      "pos": [
        4388,
        4529
      ]
    },
    {
      "content": "If you are using Visual Studio, add the file to your cloud project, right-click the file name, click <bpt id=\"p1\">**</bpt>Properties<ept id=\"p1\">**</ept>, and then set <bpt id=\"p2\">**</bpt>Copy to output Directory<ept id=\"p2\">**</ept> to <bpt id=\"p3\">**</bpt>Copy always<ept id=\"p3\">**</ept>.",
      "pos": [
        4530,
        4708
      ]
    },
    {
      "content": "Contents of EnableLogOnAudit.cmd:",
      "pos": [
        4838,
        4871
      ]
    },
    {
      "pos": [
        4981,
        5193
      ],
      "content": "<bpt id=\"p1\">[</bpt>Auditpol.exe<ept id=\"p1\">](https://technet.microsoft.com/library/cc731451.aspx)</ept> used in the previous example is a command-line tool included in Windows Server operating system that allows you to manage audit policy settings."
    },
    {
      "content": "In addition to generating Windows event logs, various Windows operating system components can be configured to generate logs that are important for security analysis and monitoring.",
      "pos": [
        5195,
        5376
      ]
    },
    {
      "content": "For example, Internet Information Services (IIS) logs and http.err logs are automatically generated for web roles, and they can be configured for collection.",
      "pos": [
        5377,
        5534
      ]
    },
    {
      "content": "These logs provide valuable information that can be used to identify unauthorized access or attacks against your web role.",
      "pos": [
        5535,
        5657
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Configure Logging in IIS<ept id=\"p1\">](http://technet.microsoft.com/library/hh831775.aspx)</ept> and <bpt id=\"p2\">[</bpt>Advanced Logging for IIS â€“ Custom Logging<ept id=\"p2\">](http://www.iis.net/learn/extensions/advanced-logging-module/advanced-logging-for-iis-custom-logging)</ept>.",
      "pos": [
        5658,
        5912
      ]
    },
    {
      "content": "To change IIS logging in a web role, customers can add a startup task to the web role service definition file.",
      "pos": [
        5914,
        6024
      ]
    },
    {
      "content": "The following example enables HTTP logging for a website named Contoso, and it specifies that IIS should log all requests for the Contoso website.",
      "pos": [
        6025,
        6171
      ]
    },
    {
      "content": "The task that updates the IIS configuration needs to be included within the service definition file of the web role.",
      "pos": [
        6173,
        6289
      ]
    },
    {
      "content": "The following changes to the service definition file runs a startup task that configures IIS logging by running a script called ConfigureIISLogging.cmd.",
      "pos": [
        6290,
        6442
      ]
    },
    {
      "content": "Contents of ConfigureIISLogging:cmd",
      "pos": [
        6575,
        6610
      ]
    },
    {
      "pos": [
        6860,
        6903
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"log-collection\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Log collection"
    },
    {
      "content": "Collection of security events and logs from Cloud Services or virtual machines in Azure occurs through two primary methods:",
      "pos": [
        6904,
        7027
      ]
    },
    {
      "content": "Azure Diagnostics, collects events in a customerâ€™s Azure storage account",
      "pos": [
        7031,
        7103
      ]
    },
    {
      "content": "Windows Event Forwarding (WEF), a technology in computers running Windows",
      "pos": [
        7106,
        7179
      ]
    },
    {
      "content": "Some key differences between these two technologies are included in the table below.",
      "pos": [
        7181,
        7265
      ]
    },
    {
      "content": "Based on your requirements and these key differences, the appropriate method needs to be chosen to implement log collection.",
      "pos": [
        7266,
        7390
      ]
    },
    {
      "content": "Azure Diagnostics",
      "pos": [
        7394,
        7411
      ]
    },
    {
      "content": "Windows Event Forwarding",
      "pos": [
        7414,
        7438
      ]
    },
    {
      "content": "Supports Azure Virtual Machines and Azure Cloud Services",
      "pos": [
        7456,
        7512
      ]
    },
    {
      "content": "Supports domain-joined Azure Virtual Machines only",
      "pos": [
        7515,
        7565
      ]
    },
    {
      "content": "Supports a variety of log formats, such as Windows event logs, <bpt id=\"p1\">[</bpt>Event Tracing for Windows<ept id=\"p1\">](https://msdn.microsoft.com/library/windows/desktop/bb968803.aspx)</ept> (ETW) traces, and IIS logs.",
      "pos": [
        7569,
        7753
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Azure Diagnostics supported data sources<ept id=\"p1\">](#diagnostics)</ept>",
      "pos": [
        7754,
        7836
      ]
    },
    {
      "content": "Supports Windows event logs only",
      "pos": [
        7838,
        7870
      ]
    },
    {
      "content": "Pushes collected data to Azure Storage",
      "pos": [
        7874,
        7912
      ]
    },
    {
      "content": "Moves collected data to central collector servers",
      "pos": [
        7914,
        7963
      ]
    },
    {
      "content": "Security event data collection with Windows Event Forwarding",
      "pos": [
        7971,
        8031
      ]
    },
    {
      "content": "For domain-joined Azure Virtual Machines, you can configure WEF by using Group Policy settings in the same manner as for on-premises domain-joined computers.",
      "pos": [
        8032,
        8189
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Hybrid Cloud<ept id=\"p1\">](http://www.microsoft.com/server-cloud/solutions/hybrid-cloud.aspx)</ept>.",
      "pos": [
        8190,
        8298
      ]
    },
    {
      "content": "Using this approach, an organization could purchase an IaaS subscription, connect it to their corporate network by using <bpt id=\"p1\">[</bpt>ExpressRoute<ept id=\"p1\">](http://azure.microsoft.com/services/expressroute/)</ept> or site-to-site VPN, and then join the virtual machines that you have in Azure to the corporate domain.",
      "pos": [
        8300,
        8590
      ]
    },
    {
      "content": "Afterwards, you can configure WEF from the domain-joined machines.",
      "pos": [
        8591,
        8657
      ]
    },
    {
      "content": "Event forwarding is broken into two parts: the source and the collector.",
      "pos": [
        8659,
        8731
      ]
    },
    {
      "content": "The source is the computer in which the security logs are generated.",
      "pos": [
        8732,
        8800
      ]
    },
    {
      "content": "The collector is the centralized server that collects and consolidates the event logs.",
      "pos": [
        8801,
        8887
      ]
    },
    {
      "content": "IT administrators can subscribe to events so that they can receive and store events that are forwarded from remote computers (the event source).",
      "pos": [
        8888,
        9032
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Configure Computers to Forward and Collect Events<ept id=\"p1\">](http://technet.microsoft.com/library/cc748890.aspx)</ept>.",
      "pos": [
        9033,
        9163
      ]
    },
    {
      "content": "Collected Windows events can be sent to on-premises analysis tools, such as a SIEM, for further analysis.",
      "pos": [
        9165,
        9270
      ]
    },
    {
      "content": "Security data collection with Azure Diagnostics",
      "pos": [
        9275,
        9322
      ]
    },
    {
      "content": "Azure Diagnostics enables you to collect diagnostic data from a cloud service worker role or web role, or from virtual machines running in Azure.",
      "pos": [
        9323,
        9468
      ]
    },
    {
      "content": "It is a predefined guest agent extension that needs to be enabled and configured for data collection.",
      "pos": [
        9469,
        9570
      ]
    },
    {
      "content": "A customer's subscription can include pushing the data to Azure Storage.",
      "pos": [
        9571,
        9643
      ]
    },
    {
      "content": "The data is encrypted in-transit (by using HTTPS).",
      "pos": [
        9645,
        9695
      ]
    },
    {
      "content": "The examples provided in this document are using Azure Diagnostics 1.2.",
      "pos": [
        9696,
        9767
      ]
    },
    {
      "content": "We recommend that you upgrade to version 1.2 or higher for security data collection.",
      "pos": [
        9768,
        9852
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Collect Logging Data by Using Azure Diagnostics<ept id=\"p1\">](http://msdn.microsoft.com/library/gg433048.aspx)</ept>.",
      "pos": [
        9853,
        9978
      ]
    },
    {
      "content": "The following diagram shows a high-level data flow for security data collection that uses Azure Diagnostics and further analysis and monitoring.",
      "pos": [
        9980,
        10124
      ]
    },
    {
      "content": "![][1]",
      "pos": [
        10126,
        10132
      ]
    },
    {
      "content": "Azure Diagnostics moves logs from customer Cloud Services applications and <bpt id=\"p1\">[</bpt>Azure Virtual Machines<ept id=\"p1\">](virtual-machines-about.md)</ept> to Azure Storage.",
      "pos": [
        10134,
        10278
      ]
    },
    {
      "content": "Based on a log format, some data is stored in Azure tables and some in blobs.",
      "pos": [
        10279,
        10356
      ]
    },
    {
      "content": "Data that is collected in <bpt id=\"p1\">[</bpt>Azure Storage<ept id=\"p1\">](storage-introduction.md)</ept> can be downloaded to on-premises SIEM systems by using Azure Storage client library for monitoring and analysis.",
      "pos": [
        10357,
        10536
      ]
    },
    {
      "content": "Additionally, HDInsight can be used for further analysis of the data in the cloud.",
      "pos": [
        10538,
        10620
      ]
    },
    {
      "content": "Following are some examples of security data collection that use Azure Diagnostics.",
      "pos": [
        10621,
        10704
      ]
    },
    {
      "content": "Security data collection from Azure Virtual Machines by using Azure Diagnostics",
      "pos": [
        10710,
        10789
      ]
    },
    {
      "content": "The following examples use Azure Diagnostics 1.2 and Azure PowerShell cmdlets to enable security data collection from virtual machines.",
      "pos": [
        10791,
        10926
      ]
    },
    {
      "content": "The data is collected from virtual machines on a scheduled interval (that is configurable) and pushed to Azure Storage within a customerâ€™s subscription.",
      "pos": [
        10927,
        11079
      ]
    },
    {
      "content": "In this section, we will walk through two log collection scenarios using Azure Diagnostics:",
      "pos": [
        11080,
        11171
      ]
    },
    {
      "content": "Set up a new instance of a security log collection pipeline on a virtual machine.",
      "pos": [
        11176,
        11257
      ]
    },
    {
      "content": "Update an existing security log collection pipeline with a new configuration on a virtual machine.",
      "pos": [
        11261,
        11359
      ]
    },
    {
      "content": "Set up a new instance of a security log collection pipeline on a virtual machine",
      "pos": [
        11366,
        11446
      ]
    },
    {
      "content": "In this example, we set up a new instance of a security log collection pipeline that uses Azure Diagnostics, and we detect logon failure events (event IDs 4624 and 4625) from the virtual machines.",
      "pos": [
        11447,
        11643
      ]
    },
    {
      "content": "You can implement the following steps from your development environment, or you can use a Remote Desktop session through Remote Desktop Protocol (RDP) to the node in the cloud.",
      "pos": [
        11644,
        11820
      ]
    },
    {
      "content": "Step 1: Install the Azure PowerShell SDK",
      "pos": [
        11828,
        11868
      ]
    },
    {
      "content": "The Azure PowerShell SDK provides cmdlets to configure Azure Diagnostics on Azure Virtual Machines.",
      "pos": [
        11869,
        11968
      ]
    },
    {
      "content": "The necessary cmdlets are available in Azure PowerShell version 0.8.7 or later.",
      "pos": [
        11969,
        12048
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>How to install and configure Azure PowerShell<ept id=\"p1\">](powershell-install-configure.md)</ept>.",
      "pos": [
        12049,
        12156
      ]
    },
    {
      "content": "Step 2: Prepare the configuration file",
      "pos": [
        12164,
        12202
      ]
    },
    {
      "content": "Prepare the configuration file based on the events you would like to collect.",
      "pos": [
        12203,
        12280
      ]
    },
    {
      "content": "Following is an example of an Azure Diagnostics configuration file to collect Windows events from the <bpt id=\"p1\">**</bpt>Security<ept id=\"p1\">**</ept> channel, with filters added to collect only logon success and failure events.",
      "pos": [
        12281,
        12473
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Azure Diagnostics 1.2 Configuration Schema<ept id=\"p1\">](http://msdn.microsoft.com/library/azure/dn782207.aspx)</ept>.",
      "pos": [
        12474,
        12600
      ]
    },
    {
      "content": "The storage account can be specified in the configuration file, or it can be specified as a parameter when you run the Azure PowerShell cmdlets to set up Azure Diagnostics.",
      "pos": [
        12602,
        12774
      ]
    },
    {
      "content": "When you save the previous contents as an XML file, set the encoding to <bpt id=\"p1\">**</bpt>UTF-8<ept id=\"p1\">**</ept>.",
      "pos": [
        13289,
        13371
      ]
    },
    {
      "content": "If you are using Notepad, you'll see the encoding option available in the \"Save As\" dialog box.",
      "pos": [
        13372,
        13467
      ]
    },
    {
      "content": "The table below lists some key attributes to note in the configuration file.",
      "pos": [
        13468,
        13544
      ]
    },
    {
      "content": "Attribute",
      "pos": [
        13548,
        13557
      ]
    },
    {
      "content": "Description",
      "pos": [
        13560,
        13571
      ]
    },
    {
      "content": "overallQuotaInMB",
      "pos": [
        13591,
        13607
      ]
    },
    {
      "content": "The maximum amount of local disk space that can be consumed by Azure Diagnostics (value is configurable).",
      "pos": [
        13610,
        13715
      ]
    },
    {
      "content": "scheduledTransferPeriod",
      "pos": [
        13720,
        13743
      ]
    },
    {
      "content": "The interval between scheduled transfers to Azure Storage, rounded up to the nearest minute.",
      "pos": [
        13746,
        13838
      ]
    },
    {
      "content": "Name",
      "pos": [
        13843,
        13847
      ]
    },
    {
      "content": "In WindowsEventLog, this attibute is the XPath query that describes the Windows events to be collected.",
      "pos": [
        13850,
        13953
      ]
    },
    {
      "content": "You can filter the data collection by adding a filter such as Event ID, Provider Name, or Channel.",
      "pos": [
        13954,
        14052
      ]
    },
    {
      "content": "All Windows Event log data is moved to a table named <bpt id=\"p1\">**</bpt>WADWindowsEventLogsTable<ept id=\"p1\">**</ept>.",
      "pos": [
        14056,
        14138
      ]
    },
    {
      "content": "Currently, Azure Diagnostics does not support renaming the table.",
      "pos": [
        14139,
        14204
      ]
    },
    {
      "pos": [
        14212,
        14272
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"step3\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> Step 3: Validate configuration XML file"
    },
    {
      "content": "Use the following procedure to validate that there is no error in the configuration XML file, and that it is compatible with the Azure Diagnostic schema:",
      "pos": [
        14273,
        14426
      ]
    },
    {
      "content": "To download the schema file, run the following command, and then save the file.",
      "pos": [
        14431,
        14510
      ]
    },
    {
      "content": "(Get-AzureServiceAvailableExtension  -ExtensionName 'PaaSDiagnostics' -ProviderNamespace 'Microsoft.Azure.Diagnostics').PublicConfigurationSchema | Out-File -Encoding utf8 -FilePath 'WadConfigSchema.xsd'",
      "pos": [
        14516,
        14719
      ]
    },
    {
      "content": "After you download the schema file, you can validate the configuration XML file against the schema.",
      "pos": [
        14724,
        14823
      ]
    },
    {
      "content": "To validate the file by using Visual Studio:",
      "pos": [
        14824,
        14868
      ]
    },
    {
      "content": "Open the XML file in Visual Studio",
      "pos": [
        14873,
        14907
      ]
    },
    {
      "pos": [
        14912,
        14943
      ],
      "content": "Press F4 to open <bpt id=\"p1\">**</bpt>Properties<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        14948,
        15068
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>Schema<ept id=\"p1\">**</ept>, click <bpt id=\"p2\">**</bpt>Add<ept id=\"p2\">**</ept>, select the schema file that you downloaded (WadConfigSchema.XSD), and then click <bpt id=\"p3\">**</bpt>OK<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        15074,
        15159
      ],
      "content": "On the <bpt id=\"p1\">**</bpt>View<ept id=\"p1\">**</ept> menu, click <bpt id=\"p2\">**</bpt>Error List<ept id=\"p2\">**</ept> to see if there are any validation errors."
    },
    {
      "pos": [
        15167,
        15223
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"step4\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> Step 4: Configure Azure Diagnostics"
    },
    {
      "content": "Use the following steps to enable Azure Diagnostics and start the data collection:",
      "pos": [
        15225,
        15307
      ]
    },
    {
      "pos": [
        15313,
        15382
      ],
      "content": "To open Azure PowerShell, type <bpt id=\"p1\">**</bpt>Add-AzureAccount<ept id=\"p1\">**</ept>, and press ENTER."
    },
    {
      "content": "Sign in with your Azure account.",
      "pos": [
        15387,
        15419
      ]
    },
    {
      "content": "Run the following PowerShell script.",
      "pos": [
        15424,
        15460
      ]
    },
    {
      "content": "Make sure to update the storage_name, key, config_path, service_name, and vm_name.",
      "pos": [
        15461,
        15543
      ]
    },
    {
      "content": "Step 5: Generate events",
      "pos": [
        16125,
        16148
      ]
    },
    {
      "content": "For demonstration purposes, we will create some logon events and verify that data is flowing to Azure Storage.",
      "pos": [
        16149,
        16259
      ]
    },
    {
      "content": "As shown previously in Step 2, the XML file is configured to collect Event ID 4624 (Logon Success) and Event ID 4625 (Logon Failure) from the <bpt id=\"p1\">**</bpt>Security<ept id=\"p1\">**</ept> channel.",
      "pos": [
        16260,
        16423
      ]
    },
    {
      "content": "To generate these events:",
      "pos": [
        16426,
        16451
      ]
    },
    {
      "content": "Open an RDP session to your virtual machine.",
      "pos": [
        16457,
        16501
      ]
    },
    {
      "content": "Enter incorrect credentials to generate some failed logon events (Event ID 4625).",
      "pos": [
        16506,
        16587
      ]
    },
    {
      "content": "After a few failed logon attempts, enter the correct credentials to generate a successful logon event (EventID 4624).",
      "pos": [
        16592,
        16709
      ]
    },
    {
      "content": "Step 6: View data",
      "pos": [
        16717,
        16734
      ]
    },
    {
      "content": "About five minutes after you complete the previous steps, data should start flowing to the customer storage account based on the configuration in the XML file.",
      "pos": [
        16735,
        16894
      ]
    },
    {
      "content": "There are many tools available to view data from Azure Storage.",
      "pos": [
        16895,
        16958
      ]
    },
    {
      "content": "For more information, see:",
      "pos": [
        16959,
        16985
      ]
    },
    {
      "content": "Browsing Storage Resources with Server Explorer",
      "pos": [
        16990,
        17037
      ]
    },
    {
      "content": "Azure Storage Explorer 6 Preview 3 (August 2014)",
      "pos": [
        17097,
        17145
      ]
    },
    {
      "content": "To view your data:",
      "pos": [
        17191,
        17209
      ]
    },
    {
      "pos": [
        17215,
        17315
      ],
      "content": "In Visual Studio (2013, 2012 and 2010 with SP1), click <bpt id=\"p1\">**</bpt>View<ept id=\"p1\">**</ept>, and then click <bpt id=\"p2\">**</bpt>Server Explorer<ept id=\"p2\">**</ept>."
    },
    {
      "content": "Navigate to the storage account.",
      "pos": [
        17320,
        17352
      ]
    },
    {
      "content": "Click <bpt id=\"p1\">**</bpt>Tables<ept id=\"p1\">**</ept> and then double-click the appropriate tables to view the security logs collected from the virtual machines.",
      "pos": [
        17357,
        17481
      ]
    },
    {
      "content": "![][2]",
      "pos": [
        17482,
        17488
      ]
    },
    {
      "pos": [
        17494,
        17610
      ],
      "content": "Right-click the table named WADWindowsEventLogsTable, then click <bpt id=\"p1\">**</bpt>View Data<ept id=\"p1\">**</ept> to open the table view as shown here:"
    },
    {
      "content": "![][3]",
      "pos": [
        17612,
        17618
      ]
    },
    {
      "pos": [
        17620,
        17721
      ],
      "content": "In the previous storage table, <bpt id=\"p1\">**</bpt>PartitionKey<ept id=\"p1\">**</ept>, <bpt id=\"p2\">**</bpt>RowKey<ept id=\"p2\">**</ept>, and <bpt id=\"p3\">**</bpt>Timestamp<ept id=\"p3\">**</ept> are system properties."
    },
    {
      "pos": [
        17725,
        17835
      ],
      "content": "<bpt id=\"p1\">**</bpt>PartitionKey<ept id=\"p1\">**</ept> is a time stamp in seconds, and it is a unique identifier for the partition within the table."
    },
    {
      "pos": [
        17838,
        17905
      ],
      "content": "<bpt id=\"p1\">**</bpt>RowKey<ept id=\"p1\">**</ept> is a unique identifier for an entity within a partition."
    },
    {
      "pos": [
        17907,
        17995
      ],
      "content": "Together, <bpt id=\"p1\">**</bpt>PartitionKey<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>RowKey<ept id=\"p2\">**</ept> uniquely identify every entity within a table."
    },
    {
      "content": "Timestamp is a date/time value that is maintained on the server to track when an entity was last modified.",
      "pos": [
        17999,
        18105
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The maximum row size in an Azure Storage table is limited to 1 MB.",
      "pos": [
        18108,
        18187
      ]
    },
    {
      "content": "A storage account can contain up to 200 TB of data from blobs, queues, and tables if the account was created after June 2012.",
      "pos": [
        18188,
        18313
      ]
    },
    {
      "content": "Thus, your table size can grow up to 200 TB if blobs and queues do not take any storage space.",
      "pos": [
        18314,
        18408
      ]
    },
    {
      "content": "Accounts created before June 2012 have a limit of 100 TB.",
      "pos": [
        18409,
        18466
      ]
    },
    {
      "content": "Storage Explorer also gives you the option to edit table data.",
      "pos": [
        18468,
        18530
      ]
    },
    {
      "content": "Double-click a particular row in the Table view to open the Edit Entity window as shown here:",
      "pos": [
        18531,
        18624
      ]
    },
    {
      "content": "![][4]",
      "pos": [
        18626,
        18632
      ]
    },
    {
      "content": "Update an existing security log collection pipeline with a new configuration on a virtual machine",
      "pos": [
        18639,
        18736
      ]
    },
    {
      "content": "In this section, we update an existing Azure Diagnostics security log collection pipeline on a virtual machine, and we detect Windows application event log errors.",
      "pos": [
        18737,
        18900
      ]
    },
    {
      "content": "Step 1: Update configuration file to include events of interest",
      "pos": [
        18908,
        18971
      ]
    },
    {
      "content": "The Azure Diagnostics file created in the previous example needs to be updated to include Windows application event log error types.",
      "pos": [
        18972,
        19104
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Any existing Azure Diagnostics configuration settings need to be merged with the new configuration file.",
      "pos": [
        19107,
        19224
      ]
    },
    {
      "content": "The settings defined in the new file will overwrite the existing configurations.",
      "pos": [
        19225,
        19305
      ]
    },
    {
      "content": "To retrieve the existing configuration setting, you can use the <bpt id=\"p1\">**</bpt>Get-AzureVMDiagnosticsExtension<ept id=\"p1\">**</ept> cmdlet.",
      "pos": [
        19307,
        19414
      ]
    },
    {
      "content": "The following is a sample Azure PowerShell script to retrieve the existing configuration:",
      "pos": [
        19415,
        19504
      ]
    },
    {
      "content": "Update the Azure Diagnostics configuration to collect Windows application event log errors and critical events as follows:",
      "pos": [
        19845,
        19967
      ]
    },
    {
      "pos": [
        20526,
        20652
      ],
      "content": "Validate the configuration file by using the same steps as shown earlier in <bpt id=\"p1\">[</bpt>Step 3: Validate configuration XML file<ept id=\"p1\">](#step3)</ept>."
    },
    {
      "content": "Step 2: Update Azure Diagnostics to use new configuration file",
      "pos": [
        20660,
        20722
      ]
    },
    {
      "pos": [
        20723,
        20892
      ],
      "content": "Use the <bpt id=\"p1\">**</bpt>Set-AzureVMDiagnosticsExtension<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Update-AzureVM<ept id=\"p2\">**</ept> cmdlets to update the configuration as shown earlier in <bpt id=\"p3\">[</bpt>Step 4: Configure Azure Diagnostics<ept id=\"p3\">](#step4)</ept>."
    },
    {
      "content": "Step 3: Verify configuration settings",
      "pos": [
        20900,
        20937
      ]
    },
    {
      "content": "Run the following command to verify that the configuration settings have been updated:",
      "pos": [
        20938,
        21024
      ]
    },
    {
      "content": "Step 4: Generate events",
      "pos": [
        21158,
        21181
      ]
    },
    {
      "pos": [
        21182,
        21285
      ],
      "content": "For this example, run the following command to generate an application event log of the type <bpt id=\"p1\">**</bpt>Error<ept id=\"p1\">**</ept>:"
    },
    {
      "content": "![][5]",
      "pos": [
        21390,
        21396
      ]
    },
    {
      "content": "Open the Event viewer to verify that event is created.",
      "pos": [
        21398,
        21452
      ]
    },
    {
      "content": "![][6]",
      "pos": [
        21454,
        21460
      ]
    },
    {
      "content": "Step 5: View data",
      "pos": [
        21468,
        21485
      ]
    },
    {
      "content": "Open Server Explorer in Visual Studio to view the log data.",
      "pos": [
        21486,
        21545
      ]
    },
    {
      "content": "You should see an <bpt id=\"p1\">**</bpt>EventID 100<ept id=\"p1\">**</ept> created on <bpt id=\"p2\">**</bpt>ContosoDesktop<ept id=\"p2\">**</ept> as shown here:",
      "pos": [
        21546,
        21624
      ]
    },
    {
      "content": "![][7]",
      "pos": [
        21626,
        21632
      ]
    },
    {
      "content": "Security data collection from Azure Cloud Services by using Azure Diagnostics",
      "pos": [
        21637,
        21714
      ]
    },
    {
      "content": "We will now use Azure Diagnostics to explore the same two log collection scenarios from Azure Cloud Services as in the previous Virtual Machines (IaaS) section:",
      "pos": [
        21716,
        21876
      ]
    },
    {
      "content": "Set up a new instance of security log pipeline in a cloud service.",
      "pos": [
        21882,
        21948
      ]
    },
    {
      "content": "Update an existing log collection pipeline with a new configuration in a cloud service.",
      "pos": [
        21953,
        22040
      ]
    },
    {
      "content": "The step-by-step walkthrough in this section includes:",
      "pos": [
        22042,
        22096
      ]
    },
    {
      "content": "Build a cloud service.",
      "pos": [
        22102,
        22124
      ]
    },
    {
      "content": "Configure the cloud service for security log collection by using Azure Diagnostics.",
      "pos": [
        22129,
        22212
      ]
    },
    {
      "content": "Illustrate the generation and collection of security events on the Cloud Service:",
      "pos": [
        22217,
        22298
      ]
    },
    {
      "content": "Add an administrator to a local group with an elevation of privilege",
      "pos": [
        22306,
        22374
      ]
    },
    {
      "content": "New process creation",
      "pos": [
        22381,
        22401
      ]
    },
    {
      "content": "Update an existing log collection pipeline in a cloud service:",
      "pos": [
        22406,
        22468
      ]
    },
    {
      "content": "Enable auditing of host firewall events (as an example of network security events) by using Auditpol",
      "pos": [
        22476,
        22576
      ]
    },
    {
      "content": "Configure firewall audit data to be collected, and show the collected events in the customer storage account",
      "pos": [
        22583,
        22691
      ]
    },
    {
      "content": "Show Windows security event distribution and spike detection.",
      "pos": [
        22696,
        22757
      ]
    },
    {
      "content": "Configure the collection of IIS logs and verify the data.",
      "pos": [
        22762,
        22819
      ]
    },
    {
      "content": "All of the events and logs are collected into a customer storage account in Azure.",
      "pos": [
        22821,
        22903
      ]
    },
    {
      "content": "The events can be viewed and exported by the customer to on-premises SIEM systems.",
      "pos": [
        22904,
        22986
      ]
    },
    {
      "content": "They can also be aggregated and analyzed by using HDInsight.",
      "pos": [
        22987,
        23047
      ]
    },
    {
      "content": "Set up a new instance of a log collection pipeline on a cloud service",
      "pos": [
        23053,
        23122
      ]
    },
    {
      "content": "In this example, we set up a new instance of a security log collection pipeline that uses Azure Diagnostics, and we detect user addition to a local group, and new process creation events on a cloud service instance.",
      "pos": [
        23123,
        23338
      ]
    },
    {
      "content": "Step 1: Create a cloud service (web role) and deploy",
      "pos": [
        23345,
        23397
      ]
    },
    {
      "content": "On your development computer, launch Visual Studio 2013.",
      "pos": [
        23403,
        23459
      ]
    },
    {
      "content": "Create a new cloud service project (our example uses ContosoWebRole).",
      "pos": [
        23464,
        23533
      ]
    },
    {
      "pos": [
        23538,
        23570
      ],
      "content": "Select the <bpt id=\"p1\">**</bpt>ASP.NET<ept id=\"p1\">**</ept> web role."
    },
    {
      "pos": [
        23575,
        23602
      ],
      "content": "Select the <bpt id=\"p1\">**</bpt>MVC<ept id=\"p1\">**</ept> project."
    },
    {
      "pos": [
        23607,
        23722
      ],
      "content": "In Solution Explorer, click <bpt id=\"p1\">**</bpt>Roles<ept id=\"p1\">**</ept>, then double-click the web role (WebRole1) to open the <bpt id=\"p2\">**</bpt>Properties<ept id=\"p2\">**</ept> window."
    },
    {
      "content": "On the <bpt id=\"p1\">**</bpt>Configuration<ept id=\"p1\">**</ept> tab, clear the <bpt id=\"p2\">**</bpt>Enable Diagnostics<ept id=\"p2\">**</ept> check box to disable the version of Azure Diagnostics that ships with Visual Studio 2013.",
      "pos": [
        23727,
        23879
      ]
    },
    {
      "content": "![][8]",
      "pos": [
        23880,
        23886
      ]
    },
    {
      "content": "Build your solution to verify that you have no errors.",
      "pos": [
        23892,
        23946
      ]
    },
    {
      "content": "Open the file WebRole1/Controllers/HomeController.cs.",
      "pos": [
        23951,
        24004
      ]
    },
    {
      "content": "Add the following method to enable the sample application to log HTTP status code 500 as a sample IIS log event (this will be used in the IIS example later):",
      "pos": [
        24009,
        24166
      ]
    },
    {
      "pos": [
        24329,
        24402
      ],
      "content": "Right-click the name of the cloud service project, and click <bpt id=\"p1\">**</bpt>Publish<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Step 2: Prepare the configuration file",
      "pos": [
        24409,
        24447
      ]
    },
    {
      "content": "We will now prepare the Azure Diagnostics configuration file to add the events that can help detect the following situations:",
      "pos": [
        24448,
        24573
      ]
    },
    {
      "content": "New user addition to a local group",
      "pos": [
        24577,
        24611
      ]
    },
    {
      "content": "New process creation",
      "pos": [
        24614,
        24634
      ]
    },
    {
      "content": "Step 3: Validate configuration XML file",
      "pos": [
        25137,
        25176
      ]
    },
    {
      "pos": [
        25177,
        25303
      ],
      "content": "Validate the configuration file by using the same steps as shown earlier in <bpt id=\"p1\">[</bpt>Step 3: Validate configuration XML file<ept id=\"p1\">](#step3)</ept>."
    },
    {
      "content": "Step 4: Configure Azure Diagnostics",
      "pos": [
        25311,
        25346
      ]
    },
    {
      "content": "Run the following Azure PowerShell script to enable Azure Diagnostics (make sure to update the storage_name, key, config_path, and service_name).",
      "pos": [
        25347,
        25492
      ]
    },
    {
      "content": "To verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:",
      "pos": [
        25908,
        26020
      ]
    },
    {
      "content": "Step 5: Generate events",
      "pos": [
        26096,
        26119
      ]
    },
    {
      "content": "To generate events:",
      "pos": [
        26120,
        26139
      ]
    },
    {
      "content": "To start a Remote Desktop session to your cloud service instance, in Visual Studio, open Server Explorer, right-click the role instance, and click Connect using Remote Desktop.",
      "pos": [
        26145,
        26321
      ]
    },
    {
      "content": "Open an elevated command prompt and run the following commands to create a local administrator account on the virtual machine:",
      "pos": [
        26326,
        26452
      ]
    },
    {
      "pos": [
        26561,
        26673
      ],
      "content": "Open Event Viewer, open the <bpt id=\"p1\">**</bpt>Security<ept id=\"p1\">**</ept> channel, and notice that an Event 4732 has been created, as shown here:"
    },
    {
      "content": "![][9]",
      "pos": [
        26675,
        26681
      ]
    },
    {
      "content": "Step 6: View data",
      "pos": [
        26688,
        26705
      ]
    },
    {
      "content": "Wait about five minutes to allow the Azure Diagnostics agent to push events to the storage table.",
      "pos": [
        26706,
        26803
      ]
    },
    {
      "content": "![][10]",
      "pos": [
        26805,
        26812
      ]
    },
    {
      "content": "To validate the Process Creation event, open a Notepad.",
      "pos": [
        26814,
        26869
      ]
    },
    {
      "content": "As shown here, a Process Creation event was logged in the Security channel.",
      "pos": [
        26870,
        26945
      ]
    },
    {
      "content": "![][11]",
      "pos": [
        26947,
        26954
      ]
    },
    {
      "content": "You can now view the same event in your storage account as shown here:",
      "pos": [
        26956,
        27026
      ]
    },
    {
      "content": "![][12]",
      "pos": [
        27028,
        27035
      ]
    },
    {
      "content": "Update an existing log collection pipeline in a cloud service with a new configuration",
      "pos": [
        27041,
        27127
      ]
    },
    {
      "content": "In this section, we update an existing Azure Diagnostics security log collection pipeline, and detect Windows Firewall Change Events in a Cloud Service instance.",
      "pos": [
        27128,
        27289
      ]
    },
    {
      "content": "To detect firewall changes, we will update the existing configuration to include firewall change events.",
      "pos": [
        27291,
        27395
      ]
    },
    {
      "content": "Step 1: Get existing configuration",
      "pos": [
        27402,
        27436
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The new configuration settings will overwrite the existing configuration.",
      "pos": [
        27438,
        27524
      ]
    },
    {
      "content": "Thus, it is important that any existing Azure Diagnostics configuration settings be merged with the new configuration file.",
      "pos": [
        27525,
        27648
      ]
    },
    {
      "pos": [
        27650,
        27762
      ],
      "content": "To retrieve the existing configuration setting, you can use the <bpt id=\"p1\">**</bpt>Get-AzureServiceDiagnosticsExtension<ept id=\"p1\">**</ept> cmdlet:"
    },
    {
      "content": "Step 2: Update configuration XML to include firewall events",
      "pos": [
        27838,
        27897
      ]
    },
    {
      "pos": [
        28485,
        28622
      ],
      "content": "Validate the XML contents by using the same validation process as described earlier in <bpt id=\"p1\">[</bpt>Step 3: Validate configuration XML file<ept id=\"p1\">](#step3)</ept>."
    },
    {
      "content": "Step 3: Update Azure Diagnostics to use new configuration",
      "pos": [
        28629,
        28686
      ]
    },
    {
      "content": "Run the following Azure PowerShell script to update Azure Diagnostics to use the new configuration (make sure to update the storage_name, key, config_path, and service_name with your cloud service information).",
      "pos": [
        28688,
        28898
      ]
    },
    {
      "content": "To verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:",
      "pos": [
        29402,
        29514
      ]
    },
    {
      "content": "Step 4: Enable firewall events",
      "pos": [
        29590,
        29620
      ]
    },
    {
      "content": "Open a Remote Desktop session to your cloud service instance.",
      "pos": [
        29626,
        29687
      ]
    },
    {
      "content": "Open an elevated command prompt and run the following command:",
      "pos": [
        29692,
        29754
      ]
    },
    {
      "content": "Step 5: Generate events",
      "pos": [
        29905,
        29928
      ]
    },
    {
      "pos": [
        29934,
        29985
      ],
      "content": "Open Windows Firewall, and click <bpt id=\"p1\">**</bpt>Inbound Rules<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        29990,
        30038
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>Add New Rule<ept id=\"p1\">**</ept>, and then click <bpt id=\"p2\">**</bpt>Port<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        30043,
        30124
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Local Ports<ept id=\"p1\">**</ept> field, type <bpt id=\"p2\">**</bpt>5000<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Next<ept id=\"p3\">**</ept> three times."
    },
    {
      "pos": [
        30129,
        30197
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Name<ept id=\"p1\">**</ept> field, type <bpt id=\"p2\">**</bpt>Test5000<ept id=\"p2\">**</ept>, and then click <bpt id=\"p3\">**</bpt>Finish<ept id=\"p3\">**</ept>."
    },
    {
      "pos": [
        30202,
        30316
      ],
      "content": "Open Event Viewer, open the <bpt id=\"p1\">**</bpt>Security<ept id=\"p1\">**</ept> channel, and notice that an Event ID 4946 has been created as shown here:"
    },
    {
      "content": "![][13]",
      "pos": [
        30318,
        30325
      ]
    },
    {
      "content": "Step 6: View data",
      "pos": [
        30332,
        30349
      ]
    },
    {
      "content": "Wait about five minutes to allow the Azure Diagnostics agent to push the event data to the storage table.",
      "pos": [
        30350,
        30455
      ]
    },
    {
      "content": "![][14]",
      "pos": [
        30457,
        30464
      ]
    },
    {
      "content": "Security event distribution and spike detection",
      "pos": [
        30470,
        30517
      ]
    },
    {
      "content": "After the events are in the customerâ€™s storage account, applications can use the storage client libraries to access and perform event aggregation.",
      "pos": [
        30518,
        30664
      ]
    },
    {
      "content": "For sample code to access table data, see <bpt id=\"p1\">[</bpt>How to: Retrieve table data<ept id=\"p1\">](storage-dotnet-how-to-use-tables.md)</ept>.",
      "pos": [
        30665,
        30774
      ]
    },
    {
      "content": "Following is an example of event aggregation.",
      "pos": [
        30776,
        30821
      ]
    },
    {
      "content": "Any spikes in event distribution can be investigated further for anomalous activity.",
      "pos": [
        30822,
        30906
      ]
    },
    {
      "content": "![][15]",
      "pos": [
        30908,
        30915
      ]
    },
    {
      "content": "IIS log collection and processing by using HDInsight",
      "pos": [
        30921,
        30973
      ]
    },
    {
      "content": "In this section, we collect IIS logs from your web role instance and move the logs to an Azure blob in the customerâ€™s storage account.",
      "pos": [
        30974,
        31108
      ]
    },
    {
      "content": "Step 1: Update configuration file to include IIS log collection",
      "pos": [
        31115,
        31178
      ]
    },
    {
      "pos": [
        31886,
        32042
      ],
      "content": "In the previous Azure Diagnostics configuration, <bpt id=\"p1\">**</bpt>containerName<ept id=\"p1\">**</ept> is the blob container name to which logs will be moved within customerâ€™s storage account."
    },
    {
      "pos": [
        32044,
        32170
      ],
      "content": "Validate the configuration file by using the same steps as shown earlier in <bpt id=\"p1\">[</bpt>Step 3: Validate configuration XML file<ept id=\"p1\">](#step3)</ept>."
    },
    {
      "content": "Step 2: Update Azure Diagnostics to use a new configuration",
      "pos": [
        32178,
        32237
      ]
    },
    {
      "content": "Run the following Azure PowerShell script to update Azure Diagnostics to use the new configuration (make sure to update the storage_name, key, config_path, and service_name with your cloud service information).",
      "pos": [
        32238,
        32448
      ]
    },
    {
      "content": "To verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:",
      "pos": [
        32952,
        33064
      ]
    },
    {
      "content": "Step 3: Generate IIS logs",
      "pos": [
        33140,
        33165
      ]
    },
    {
      "content": "Open a web browser and navigate to the cloud service web role (for example, http://contosowebrole.cloudapp.net/).",
      "pos": [
        33171,
        33284
      ]
    },
    {
      "pos": [
        33289,
        33363
      ],
      "content": "Navigate to the <bpt id=\"p1\">**</bpt>About<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Contact<ept id=\"p2\">**</ept> pages to create some log events."
    },
    {
      "content": "Navigate to a page that generates a status code 500 (for example, http://contosowebrole.cloudapp.net/Home/StatusCode500).",
      "pos": [
        33368,
        33489
      ]
    },
    {
      "content": "You should see an error such as the one that follows.",
      "pos": [
        33490,
        33543
      ]
    },
    {
      "content": "Remember that we added code for <bpt id=\"p1\">**</bpt>StatusCode500<ept id=\"p1\">**</ept> in Step 1 of section titled Set up new instance of log collection pipeline on a cloud ServiceName.",
      "pos": [
        33544,
        33692
      ]
    },
    {
      "content": "![][16]",
      "pos": [
        33693,
        33700
      ]
    },
    {
      "content": "Open a Remote Desktop session to your cloud service instance.",
      "pos": [
        33705,
        33766
      ]
    },
    {
      "content": "Open IIS Manager.",
      "pos": [
        33771,
        33788
      ]
    },
    {
      "content": "IIS Logging is enabled by default and it is set to hourly generate files that contain all fields in W3C format.",
      "pos": [
        33793,
        33904
      ]
    },
    {
      "content": "Click <bpt id=\"p1\">**</bpt>Browse<ept id=\"p1\">**</ept>, and there will be at least one log file, as shown here:",
      "pos": [
        33905,
        33978
      ]
    },
    {
      "content": "![][17]",
      "pos": [
        33979,
        33986
      ]
    },
    {
      "content": "Wait for about five minutes for the Azure Diagnostics agent to push the log file to the blob container.",
      "pos": [
        33992,
        34095
      ]
    },
    {
      "content": "To validate the data, open <bpt id=\"p1\">**</bpt>Server Explorer<ept id=\"p1\">**</ept> &gt; <bpt id=\"p2\">**</bpt>Storage<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Storage Account<ept id=\"p3\">**</ept> &gt; <bpt id=\"p4\">**</bpt>Blobs<ept id=\"p4\">**</ept>.",
      "pos": [
        34096,
        34191
      ]
    },
    {
      "content": "As shown here, the blob <bpt id=\"p1\">**</bpt>iislogs<ept id=\"p1\">**</ept> is created:",
      "pos": [
        34192,
        34239
      ]
    },
    {
      "content": "![][18]",
      "pos": [
        34240,
        34247
      ]
    },
    {
      "content": "Right-click and select <bpt id=\"p1\">**</bpt>View Blob Container<ept id=\"p1\">**</ept> to display the IIS log file stored in the blob:",
      "pos": [
        34253,
        34347
      ]
    },
    {
      "content": "![][19]",
      "pos": [
        34348,
        34355
      ]
    },
    {
      "content": "After the IIS events are in the customerâ€™s storage account, applications that leverage HDInsight analysis can be used to perform event aggregation.",
      "pos": [
        34360,
        34507
      ]
    },
    {
      "content": "The following line chart is an example of an event aggregation task that shows HTTP Status Code 500:",
      "pos": [
        34508,
        34608
      ]
    },
    {
      "content": "![][20]",
      "pos": [
        34609,
        34616
      ]
    },
    {
      "content": "Security log collection recommendations",
      "pos": [
        34621,
        34660
      ]
    },
    {
      "content": "When you are collecting security logs, we recommend that you:",
      "pos": [
        34661,
        34722
      ]
    },
    {
      "content": "Collect your own service application-specific audit log events.",
      "pos": [
        34726,
        34789
      ]
    },
    {
      "content": "Configure only the data that you need for analysis and monitoring.",
      "pos": [
        34792,
        34858
      ]
    },
    {
      "content": "Capturing too much data can make it harder to troubleshoot and can impact your service or storage costs.",
      "pos": [
        34859,
        34963
      ]
    },
    {
      "content": "Merge existing Azure Diagnostics configuration settings with changes you make.",
      "pos": [
        34966,
        35044
      ]
    },
    {
      "content": "The new configuration file overwrites the existing configuration settings.",
      "pos": [
        35045,
        35119
      ]
    },
    {
      "content": "Choose the <bpt id=\"p1\">**</bpt>Scheduled Transfer Period<ept id=\"p1\">**</ept> interval wisely.",
      "pos": [
        35122,
        35179
      ]
    },
    {
      "content": "Shorter transfer times will increase data relevance, but that can increase storage costs and processing overhead.",
      "pos": [
        35180,
        35293
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The other variable that will significantly impact the amount of data collected is the logging level.",
      "pos": [
        35296,
        35409
      ]
    },
    {
      "content": "The following is an example of how to filter logs by logging level:",
      "pos": [
        35410,
        35477
      ]
    },
    {
      "content": "The logging level is cumulative.",
      "pos": [
        35513,
        35545
      ]
    },
    {
      "content": "If the filter is set to <bpt id=\"p1\">**</bpt>Warning<ept id=\"p1\">**</ept>, then <bpt id=\"p2\">**</bpt>Error<ept id=\"p2\">**</ept> and <bpt id=\"p3\">**</bpt>Critical<ept id=\"p3\">**</ept> events will also be collected.",
      "pos": [
        35546,
        35645
      ]
    },
    {
      "content": "Periodically clear the diagnostic data from Azure Storage if it is no longer needed.",
      "pos": [
        35649,
        35733
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> To learn more about diagnostic data see <bpt id=\"p1\">[</bpt>Store and View Diagnostic Data in Azure Storage<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/hh411534.aspx)</ept>.",
      "pos": [
        35736,
        35895
      ]
    },
    {
      "content": "The containers and tables that store diagnostic data are just like other containers and tables, you can delete blobs and entities from them in the same way you would for other data.",
      "pos": [
        35897,
        36078
      ]
    },
    {
      "content": "You can delete the diagnostic data programmatically via one of the storage client libraries or visually via a <bpt id=\"p1\">[</bpt>storage explorer client<ept id=\"p1\">](http://blogs.msdn.com/b/windowsazurestorage/archive/2014/03/11/windows-azure-storage-explorers-2014.aspx)</ept>.",
      "pos": [
        36079,
        36321
      ]
    },
    {
      "content": "It is a best practice to store service data and security log data in separate storage accounts.",
      "pos": [
        36325,
        36420
      ]
    },
    {
      "content": "This isolation ensures that saving security log data does not impact the storage performance for production service data.",
      "pos": [
        36421,
        36542
      ]
    },
    {
      "content": "Choose the log retention duration based on your organizationâ€™s compliance policy and data analysis and monitoring requirements.",
      "pos": [
        36545,
        36672
      ]
    },
    {
      "content": "Exporting security logs to another system",
      "pos": [
        36677,
        36718
      ]
    },
    {
      "content": "You can download blob data by using the Azure Storage Client Library, and then export it to your on-premises system for processing.",
      "pos": [
        36719,
        36850
      ]
    },
    {
      "content": "For sample code to manage blob data, see <bpt id=\"p1\">[</bpt>How to use Blob Storage from .NET<ept id=\"p1\">](storage-dotnet-how-to-use-blobs.md)</ept>.",
      "pos": [
        36851,
        36964
      ]
    },
    {
      "content": "Similarly, you can download security data stored in Azure tables by using the Azure Storage Client Library.",
      "pos": [
        36966,
        37073
      ]
    },
    {
      "content": "To learn more about accessing data that is stored in tables, see <bpt id=\"p1\">[</bpt>How to use Table Storage from .NET<ept id=\"p1\">](storage-dotnet-how-to-use-tables.md)</ept>.",
      "pos": [
        37074,
        37213
      ]
    },
    {
      "content": "Azure Active Directory reports",
      "pos": [
        37218,
        37248
      ]
    },
    {
      "content": "Azure Active Directory (Azure AD) includes a set of security, usage, and audit log reports that provide visibility into the integrity and security of your Azure AD tenant.",
      "pos": [
        37249,
        37420
      ]
    },
    {
      "content": "For example, Azure AD has the capability to automatically analyze user activity and surface anomalous access, and then make it available through customer-visible reports.",
      "pos": [
        37421,
        37591
      ]
    },
    {
      "content": "These reports are available through the <bpt id=\"p1\">[</bpt>Azure Management Portal<ept id=\"p1\">](https://manage.windowsazure.com/)</ept> under <bpt id=\"p2\">**</bpt>Active Directory<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Directory<ept id=\"p3\">**</ept>.",
      "pos": [
        37593,
        37736
      ]
    },
    {
      "content": "Some of these reports are free, and others are offered as part of an Azure AD Premium edition.",
      "pos": [
        37737,
        37831
      ]
    },
    {
      "content": "For more information about Azure AD reports, see <bpt id=\"p1\">[</bpt>View your access and usage reports<ept id=\"p1\">](http://msdn.microsoft.com/library/azure/dn283934.aspx)</ept>.",
      "pos": [
        37832,
        37973
      ]
    },
    {
      "content": "Azure Operation Logs",
      "pos": [
        37978,
        37998
      ]
    },
    {
      "pos": [
        37999,
        38147
      ],
      "content": "Logs for operations related to your Azure subscription resources are also available through the <bpt id=\"p1\">**</bpt>Operation Logs<ept id=\"p1\">**</ept> feature in the management portal."
    },
    {
      "pos": [
        38149,
        38316
      ],
      "content": "To view the <bpt id=\"p1\">**</bpt>Operation Logs<ept id=\"p1\">**</ept>, open the <bpt id=\"p2\">[</bpt>Azure Management Portal<ept id=\"p2\">](https://manage.windowsazure.com/)</ept>, click <bpt id=\"p3\">**</bpt>Management Services<ept id=\"p3\">**</ept>, and then click <bpt id=\"p4\">**</bpt>Operation Logs<ept id=\"p4\">**</ept>."
    },
    {
      "pos": [
        38321,
        38388
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"diagnostics\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> Azure Diagnostics supported data sources"
    },
    {
      "content": "Data Source",
      "pos": [
        38392,
        38403
      ]
    },
    {
      "content": "Description",
      "pos": [
        38406,
        38417
      ]
    },
    {
      "content": "IIS Logs",
      "pos": [
        38439,
        38447
      ]
    },
    {
      "content": "Information about IIS websites",
      "pos": [
        38450,
        38480
      ]
    },
    {
      "content": "Azure Diagnostic infrastructure logs",
      "pos": [
        38485,
        38521
      ]
    },
    {
      "content": "Information about Azure Diagnostics",
      "pos": [
        38524,
        38559
      ]
    },
    {
      "content": "IIS Failed Request logs",
      "pos": [
        38564,
        38587
      ]
    },
    {
      "content": "Information about failed requests to an IIS website or application",
      "pos": [
        38590,
        38656
      ]
    },
    {
      "content": "Windows Event logs",
      "pos": [
        38661,
        38679
      ]
    },
    {
      "content": "Information sent to the Windows event logging system",
      "pos": [
        38682,
        38734
      ]
    },
    {
      "content": "Performance counters",
      "pos": [
        38739,
        38759
      ]
    },
    {
      "content": "Operating system and custom performance counters",
      "pos": [
        38762,
        38810
      ]
    },
    {
      "content": "Crash dumps",
      "pos": [
        38815,
        38826
      ]
    },
    {
      "content": "Information about the state of the process in the event of an application crash",
      "pos": [
        38829,
        38908
      ]
    },
    {
      "content": "Custom error logs",
      "pos": [
        38913,
        38930
      ]
    },
    {
      "content": "Logs created by your application or service",
      "pos": [
        38933,
        38976
      ]
    },
    {
      "content": ".NET EventSource",
      "pos": [
        38981,
        38997
      ]
    },
    {
      "content": "Events generated by your code by using the .NET EventSource class",
      "pos": [
        39000,
        39065
      ]
    },
    {
      "content": "Manifest-based ETW",
      "pos": [
        39070,
        39088
      ]
    },
    {
      "content": "Event Tracing for Windows events generated by any process",
      "pos": [
        39091,
        39148
      ]
    },
    {
      "content": "Additional resources",
      "pos": [
        39155,
        39175
      ]
    },
    {
      "content": "The following resources provide general information about Microsoft Azure and related Microsoft services:",
      "pos": [
        39176,
        39281
      ]
    },
    {
      "content": "Microsoft Azure Trust Center",
      "pos": [
        39286,
        39314
      ]
    },
    {
      "content": "Information on how security and privacy are embedded into the development of Azure and how Azure meets a broad set of international and industry-specific compliance standards",
      "pos": [
        39371,
        39545
      ]
    },
    {
      "content": "Microsoft Azure home page",
      "pos": [
        39550,
        39575
      ]
    },
    {
      "content": "General information and links about Microsoft Azure",
      "pos": [
        39622,
        39673
      ]
    },
    {
      "content": "Microsoft Azure Documentation Center",
      "pos": [
        39678,
        39714
      ]
    },
    {
      "content": "Guidance for Azure services and automation scripts",
      "pos": [
        39774,
        39824
      ]
    },
    {
      "content": "Microsoft Security Response Center (MSRC)",
      "pos": [
        39829,
        39870
      ]
    },
    {
      "content": "The MSRC works with partners and security researchers around the world to help prevent security incidents and to advance Microsoft product security",
      "pos": [
        39930,
        40077
      ]
    },
    {
      "content": "Microsoft Security Response Center email",
      "pos": [
        40082,
        40122
      ]
    },
    {
      "content": "Email to report Microsoft security vulnerabilities, including Microsoft Azure",
      "pos": [
        40158,
        40235
      ]
    },
    {
      "content": "test",
      "pos": [
        41761,
        41765
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"Microsoft Azure Security and Audit Log Management | Microsoft Azure\"\n   description=\"Article provides an introduction for generating, collecting, and analyzing security logs from services hosted on Azure.  It is intended for IT professionals and security analysts who deal with information asset management on a daily basis, including those responsible for their organization's security and compliance efforts.\"\n   services=\"virtual-machines, cloud-services, storage\"\n   documentationCenter=\"na\"\n   authors=\"TerryLanfear\"\n   manager=\"msStevenPo\"\n   editor=\"\"/>\n\n<tags\n   ms.service=\"azure-security\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"na\"\n   ms.date=\"08/13/2015\"\n   ms.author=\"mnayak;tomsh;terrylan\"/>\n\n# Microsoft Azure security and audit log management\n\nAzure enables customers to perform security event generation and collection from Azure Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) roles to central storage in their subscriptions. Customers can then use [HDInsight](http://azure.microsoft.com/documentation/services/hdinsight/) to aggregate and analyze the collected events. In addition, these collected events can be exported to on-premises security information and event management (SIEM) systems for ongoing monitoring.\n\nThe Azure security logging, analysis, and monitoring lifecycle includes:\n\n- **Generation**: Instrument applications and the infrastructure to raise events\n- **Collection**: Configure Azure to collect the various security logs in a storage account\n- **Analysis**: Use Azure tools such as HDInsight and on-premises SIEM systems to analyze the logs and generate security insights\n- **Monitoring and reporting**: Azure offers centralized monitoring and analysis systems that provide continuous visibility and timely alerts\n\nThis article focuses on the generation and collection phases of the lifecycle.\n\n## Log generation\nSecurity events are raised in the Windows Event Log for the **System**, **Security**, and **Application** channels in virtual machines. To ensure that events are logged without potential data loss, it is important to appropriately configure the size of the event log. Base the size of the event log on the number of events that auditing policy settings generate and the event collection policies defined. For more information, see [Planning for security audit monitoring and management](http://technet.microsoft.com/library/ee513968.aspx#BKMK_4).\n\n>[AZURE.NOTE] When using Windows Event Forwarding (WEF) or Azure Diagnostics (explained in the [Log Collection](#log-collection) section) to pull logs from Cloud Services or virtual machines, consider the potential impact of system outages. For example, if your WEF environment goes down for some time, you either need to make sure the log size is big enough to account for a longer time duration or be prepared for possible log data loss.\n\nFor Cloud Services applications that are deployed in Azure and virtual machines created from the [Azure Virtual Machines Marketplace](http://azure.microsoft.com/marketplace/virtual-machines/#microsoft), a set of operating system security events are enabled by default. Customers can add, remove, or modify events to be audited by customizing the operating system audit policy. For more information, see [Security Policy Settings Reference](http://technet.microsoft.com/library/jj852210.aspx).\n\nYou can use the following methods to generate additional logs from operating system (such as audit policy changes) and Windows components (such as IIS):\n\n- Group Policy to roll out policy settings for virtual machines in Azure that are domain-joined\n- Desired State Configuration (DSC) to push and manage policy settings. For more information, see [Azure PowerShell DSC](http://blogs.msdn.com/b/powershell/archive/2014/08/07/introducing-the-azure-powershell-dsc-desired-state-configuration-extension.aspx)\n- Service Deployment role startup code to roll out settings for Cloud Services (PaaS scenario)\n\nConfiguring Azure role startup tasks enables code to run before a role starts. You can define a startup task for a role by adding the **Startup** element to the definition of the role in the service definition file, as shown in the following example. For more information, see [Run Startup Tasks in Azure](http://msdn.microsoft.com/library/azure/hh180155.aspx).\n\nThe task file that is to be run as a Startup task (EnableLogOnAudit.cmd in the following example) needs to be included in your build package. If you are using Visual Studio, add the file to your cloud project, right-click the file name, click **Properties**, and then set **Copy to output Directory** to **Copy always**.\n\n    <Startup>\n        <Task commandLine=\"EnableLogOnAudit.cmd\" executionContext=\"elevated\" taskType=\"simple\" />\n    </Startup>\n\nContents of EnableLogOnAudit.cmd:\n\n    @echo off\n    auditpol.exe /set /category:\"Logon/Logoff\" /success:enable /failure:enable\n    Exit /B 0\n\n[Auditpol.exe](https://technet.microsoft.com/library/cc731451.aspx) used in the previous example is a command-line tool included in Windows Server operating system that allows you to manage audit policy settings.\n\nIn addition to generating Windows event logs, various Windows operating system components can be configured to generate logs that are important for security analysis and monitoring. For example, Internet Information Services (IIS) logs and http.err logs are automatically generated for web roles, and they can be configured for collection. These logs provide valuable information that can be used to identify unauthorized access or attacks against your web role. For more information, see [Configure Logging in IIS](http://technet.microsoft.com/library/hh831775.aspx) and [Advanced Logging for IIS â€“ Custom Logging](http://www.iis.net/learn/extensions/advanced-logging-module/advanced-logging-for-iis-custom-logging).\n\nTo change IIS logging in a web role, customers can add a startup task to the web role service definition file. The following example enables HTTP logging for a website named Contoso, and it specifies that IIS should log all requests for the Contoso website.\n\nThe task that updates the IIS configuration needs to be included within the service definition file of the web role. The following changes to the service definition file runs a startup task that configures IIS logging by running a script called ConfigureIISLogging.cmd.\n\n    <Startup>\n        <Task commandLine=\"ConfigureIISLogging.cmd\" executionContext=\"elevated\" taskType=\"simple\" />\n    </Startup>\n\nContents of ConfigureIISLogging:cmd\n\n    @echo off\n    appcmd.exe set config \"Contoso\" -section:system.webServer/httpLogging /dontLog:\"True\" /commit:apphost\n    appcmd.exe set config \"Contoso\" -section:system.webServer/httpLogging /selectiveLogging:\"LogAll\" /commit\n    Exit /B 0\n\n\n## <a name=\"log-collection\"></a>Log collection\nCollection of security events and logs from Cloud Services or virtual machines in Azure occurs through two primary methods:\n\n- Azure Diagnostics, collects events in a customerâ€™s Azure storage account\n- Windows Event Forwarding (WEF), a technology in computers running Windows\n\nSome key differences between these two technologies are included in the table below. Based on your requirements and these key differences, the appropriate method needs to be chosen to implement log collection.\n\n| Azure Diagnostics | Windows Event Forwarding |\n|-----|-----|\n|Supports Azure Virtual Machines and Azure Cloud Services | Supports domain-joined Azure Virtual Machines only |\n|Supports a variety of log formats, such as Windows event logs, [Event Tracing for Windows](https://msdn.microsoft.com/library/windows/desktop/bb968803.aspx) (ETW) traces, and IIS logs. For more information, see [Azure Diagnostics supported data sources](#diagnostics) |Supports Windows event logs only |\n|Pushes collected data to Azure Storage |Moves collected data to central collector servers |\n\n##  Security event data collection with Windows Event Forwarding\nFor domain-joined Azure Virtual Machines, you can configure WEF by using Group Policy settings in the same manner as for on-premises domain-joined computers. For more information, see [Hybrid Cloud](http://www.microsoft.com/server-cloud/solutions/hybrid-cloud.aspx).\n\nUsing this approach, an organization could purchase an IaaS subscription, connect it to their corporate network by using [ExpressRoute](http://azure.microsoft.com/services/expressroute/) or site-to-site VPN, and then join the virtual machines that you have in Azure to the corporate domain. Afterwards, you can configure WEF from the domain-joined machines.\n\nEvent forwarding is broken into two parts: the source and the collector. The source is the computer in which the security logs are generated. The collector is the centralized server that collects and consolidates the event logs. IT administrators can subscribe to events so that they can receive and store events that are forwarded from remote computers (the event source). For more information, see [Configure Computers to Forward and Collect Events](http://technet.microsoft.com/library/cc748890.aspx).\n\nCollected Windows events can be sent to on-premises analysis tools, such as a SIEM, for further analysis.\n\n## Security data collection with Azure Diagnostics\nAzure Diagnostics enables you to collect diagnostic data from a cloud service worker role or web role, or from virtual machines running in Azure. It is a predefined guest agent extension that needs to be enabled and configured for data collection. A customer's subscription can include pushing the data to Azure Storage.\n\nThe data is encrypted in-transit (by using HTTPS). The examples provided in this document are using Azure Diagnostics 1.2. We recommend that you upgrade to version 1.2 or higher for security data collection. For more information, see [Collect Logging Data by Using Azure Diagnostics](http://msdn.microsoft.com/library/gg433048.aspx).\n\nThe following diagram shows a high-level data flow for security data collection that uses Azure Diagnostics and further analysis and monitoring.\n\n![][1]\n\nAzure Diagnostics moves logs from customer Cloud Services applications and [Azure Virtual Machines](virtual-machines-about.md) to Azure Storage. Based on a log format, some data is stored in Azure tables and some in blobs. Data that is collected in [Azure Storage](storage-introduction.md) can be downloaded to on-premises SIEM systems by using Azure Storage client library for monitoring and analysis.\n\nAdditionally, HDInsight can be used for further analysis of the data in the cloud. Following are some examples of security data collection that use Azure Diagnostics.\n\n### Security data collection from Azure Virtual Machines by using Azure Diagnostics\n\nThe following examples use Azure Diagnostics 1.2 and Azure PowerShell cmdlets to enable security data collection from virtual machines. The data is collected from virtual machines on a scheduled interval (that is configurable) and pushed to Azure Storage within a customerâ€™s subscription.\nIn this section, we will walk through two log collection scenarios using Azure Diagnostics:\n\n1. Set up a new instance of a security log collection pipeline on a virtual machine.\n2. Update an existing security log collection pipeline with a new configuration on a virtual machine.\n\n#### Set up a new instance of a security log collection pipeline on a virtual machine\nIn this example, we set up a new instance of a security log collection pipeline that uses Azure Diagnostics, and we detect logon failure events (event IDs 4624 and 4625) from the virtual machines. You can implement the following steps from your development environment, or you can use a Remote Desktop session through Remote Desktop Protocol (RDP) to the node in the cloud.\n\n##### Step 1: Install the Azure PowerShell SDK\nThe Azure PowerShell SDK provides cmdlets to configure Azure Diagnostics on Azure Virtual Machines. The necessary cmdlets are available in Azure PowerShell version 0.8.7 or later. For more information, see [How to install and configure Azure PowerShell](powershell-install-configure.md).\n\n##### Step 2: Prepare the configuration file\nPrepare the configuration file based on the events you would like to collect. Following is an example of an Azure Diagnostics configuration file to collect Windows events from the **Security** channel, with filters added to collect only logon success and failure events. For more information, see [Azure Diagnostics 1.2 Configuration Schema](http://msdn.microsoft.com/library/azure/dn782207.aspx).\n\nThe storage account can be specified in the configuration file, or it can be specified as a parameter when you run the Azure PowerShell cmdlets to set up Azure Diagnostics.\n\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <PublicConfig xmlns=\"http://schemas.microsoft.com/ServiceHosting/2010/10/DiagnosticsConfiguration\">\n        <WadCfg>\n            <DiagnosticMonitorConfiguration overallQuotaInMB=\"10000\">\n                <WindowsEventLog scheduledTransferPeriod=\"PT1M\">\n                    <DataSource name=\"Security!*[System[(EventID=4624 or EventID=4625)]]\" />\n                </WindowsEventLog>\n            </DiagnosticMonitorConfiguration>\n        </WadCfg>\n    </PublicConfig>\n\nWhen you save the previous contents as an XML file, set the encoding to **UTF-8**. If you are using Notepad, you'll see the encoding option available in the \"Save As\" dialog box. The table below lists some key attributes to note in the configuration file.\n\n| Attribute | Description |\n|----- |-----|\n| overallQuotaInMB | The maximum amount of local disk space that can be consumed by Azure Diagnostics (value is configurable). |\n| scheduledTransferPeriod | The interval between scheduled transfers to Azure Storage, rounded up to the nearest minute. |\n| Name | In WindowsEventLog, this attibute is the XPath query that describes the Windows events to be collected. You can filter the data collection by adding a filter such as Event ID, Provider Name, or Channel. |\n\nAll Windows Event log data is moved to a table named **WADWindowsEventLogsTable**. Currently, Azure Diagnostics does not support renaming the table.\n\n##### <a name=\"step3\"></a> Step 3: Validate configuration XML file\nUse the following procedure to validate that there is no error in the configuration XML file, and that it is compatible with the Azure Diagnostic schema:\n\n1. To download the schema file, run the following command, and then save the file.\n\n    (Get-AzureServiceAvailableExtension  -ExtensionName 'PaaSDiagnostics' -ProviderNamespace 'Microsoft.Azure.Diagnostics').PublicConfigurationSchema | Out-File -Encoding utf8 -FilePath 'WadConfigSchema.xsd'\n\n2. After you download the schema file, you can validate the configuration XML file against the schema. To validate the file by using Visual Studio:\n  - Open the XML file in Visual Studio\n  - Press F4 to open **Properties**\n  - Click **Schema**, click **Add**, select the schema file that you downloaded (WadConfigSchema.XSD), and then click **OK**\n\n3.  On the **View** menu, click **Error List** to see if there are any validation errors.\n\n##### <a name=\"step4\"></a> Step 4: Configure Azure Diagnostics\n Use the following steps to enable Azure Diagnostics and start the data collection:\n\n 1. To open Azure PowerShell, type **Add-AzureAccount**, and press ENTER.\n 2. Sign in with your Azure account.\n 3. Run the following PowerShell script. Make sure to update the storage_name, key, config_path, service_name, and vm_name.\n\n ```PowerShell\n$storage_name =\"<Storage Name>\"\n$key = \"<Storage Key>\"\n$config_path=\"<Path Of WAD Config XML>\"\n$service_name=\"<Service Name. Usually it is same as VM Name>\"\n$vm_name=\"<VM Name>\"\n$storageContext = New-AzureStorageContext -StorageAccountName $storage_name -StorageAccountKey $key\n$VM1 = Get-AzureVM -ServiceName $service_name -Name $vm_name\n$VM2 = Set-AzureVMDiagnosticsExtension -DiagnosticsConfigurationPath $config_path -Version \"1.*\" -VM $VM1 -StorageContext $storageContext\n$VM3 = Update-AzureVM -ServiceName $service_name -Name $vm_name -VM $VM2.VM\n ```\n\n##### Step 5: Generate events\nFor demonstration purposes, we will create some logon events and verify that data is flowing to Azure Storage. As shown previously in Step 2, the XML file is configured to collect Event ID 4624 (Logon Success) and Event ID 4625 (Logon Failure) from the **Security** channel.\n\n To generate these events:\n\n1.  Open an RDP session to your virtual machine.\n2.  Enter incorrect credentials to generate some failed logon events (Event ID 4625).\n3.  After a few failed logon attempts, enter the correct credentials to generate a successful logon event (EventID 4624).\n\n##### Step 6: View data\nAbout five minutes after you complete the previous steps, data should start flowing to the customer storage account based on the configuration in the XML file. There are many tools available to view data from Azure Storage. For more information, see:\n\n- [Browsing Storage Resources with Server Explorer](http://msdn.microsoft.com/library/azure/ff683677.aspx)\n- [Azure Storage Explorer 6 Preview 3 (August 2014)](http://azurestorageexplorer.codeplex.com/)\n\nTo view your data:\n\n1.  In Visual Studio (2013, 2012 and 2010 with SP1), click **View**, and then click **Server Explorer**.\n2.  Navigate to the storage account.\n3.  Click **Tables** and then double-click the appropriate tables to view the security logs collected from the virtual machines.\n![][2]\n\n4.  Right-click the table named WADWindowsEventLogsTable, then click **View Data** to open the table view as shown here:\n\n![][3]\n\nIn the previous storage table, **PartitionKey**, **RowKey**, and **Timestamp** are system properties.\n\n- **PartitionKey** is a time stamp in seconds, and it is a unique identifier for the partition within the table.\n- **RowKey** is a unique identifier for an entity within a partition.\n\nTogether, **PartitionKey** and **RowKey** uniquely identify every entity within a table.\n\n- Timestamp is a date/time value that is maintained on the server to track when an entity was last modified.\n\n>[AZURE.NOTE] The maximum row size in an Azure Storage table is limited to 1 MB. A storage account can contain up to 200 TB of data from blobs, queues, and tables if the account was created after June 2012. Thus, your table size can grow up to 200 TB if blobs and queues do not take any storage space. Accounts created before June 2012 have a limit of 100 TB.\n\nStorage Explorer also gives you the option to edit table data. Double-click a particular row in the Table view to open the Edit Entity window as shown here:\n\n![][4]\n\n#### Update an existing security log collection pipeline with a new configuration on a virtual machine\nIn this section, we update an existing Azure Diagnostics security log collection pipeline on a virtual machine, and we detect Windows application event log errors.\n\n##### Step 1: Update configuration file to include events of interest\nThe Azure Diagnostics file created in the previous example needs to be updated to include Windows application event log error types.\n\n>[AZURE.NOTE] Any existing Azure Diagnostics configuration settings need to be merged with the new configuration file. The settings defined in the new file will overwrite the existing configurations.\n\nTo retrieve the existing configuration setting, you can use the **Get-AzureVMDiagnosticsExtension** cmdlet. The following is a sample Azure PowerShell script to retrieve the existing configuration:\n\n    $service_name=\"<VM Name>\"\n    $VM1 = Get-AzureVM -ServiceName $service_name\n    $config = Get-AzureVMDiagnosticsExtension -VM $VM1 | Select -Expand PublicConfiguration | % {$_.substring($_.IndexOf(':\"')+2,$_.LastIndexOf('\",')-$_.IndexOf(':\"')-2)}\n    [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String($config))\nUpdate the Azure Diagnostics configuration to collect Windows application event log errors and critical events as follows:\n\n    <?xml version=\"1.0\" encoding=\"utf-8\" ?>\n    <PublicConfig xmlns=\"http://schemas.microsoft.com/ServiceHosting/2010/10/DiagnosticsConfiguration\">\n    <WadCfg>\n        <DiagnosticMonitorConfiguration overallQuotaInMB=\"10000\">\n            <WindowsEventLog scheduledTransferPeriod=\"PT1M\">\n                <DataSource name=\"Application!*[System[(Level =2)]]\" />\n                <DataSource name=\"Security!*[System[(EventID=4624 or EventID=4625)]]\" />\n            </WindowsEventLog>\n        </DiagnosticMonitorConfiguration>\n    </WadCfg>\n    </PublicConfig>\n\nValidate the configuration file by using the same steps as shown earlier in [Step 3: Validate configuration XML file](#step3).\n\n##### Step 2: Update Azure Diagnostics to use new configuration file\nUse the **Set-AzureVMDiagnosticsExtension** and **Update-AzureVM** cmdlets to update the configuration as shown earlier in [Step 4: Configure Azure Diagnostics](#step4).\n\n##### Step 3: Verify configuration settings\nRun the following command to verify that the configuration settings have been updated:\n\n    $service_name=\"<VM Name>\"\n    $VM1 = Get-AzureVM -ServiceName $service_name\n    Get-AzureVMDiagnosticsExtension -VM $VM1\n\n##### Step 4: Generate events\nFor this example, run the following command to generate an application event log of the type **Error**:\n\n    eventcreate /t error /id 100 /l application /d \"Create event in application log for Demo Purpose\"\n\n![][5]\n\nOpen the Event viewer to verify that event is created.\n\n![][6]\n\n##### Step 5: View data\nOpen Server Explorer in Visual Studio to view the log data. You should see an **EventID 100** created on **ContosoDesktop** as shown here:\n\n![][7]\n\n## Security data collection from Azure Cloud Services by using Azure Diagnostics\n\nWe will now use Azure Diagnostics to explore the same two log collection scenarios from Azure Cloud Services as in the previous Virtual Machines (IaaS) section:\n\n1.  Set up a new instance of security log pipeline in a cloud service.\n2.  Update an existing log collection pipeline with a new configuration in a cloud service.\n\nThe step-by-step walkthrough in this section includes:\n\n1.  Build a cloud service.\n2.  Configure the cloud service for security log collection by using Azure Diagnostics.\n3.  Illustrate the generation and collection of security events on the Cloud Service:\n\n    - Add an administrator to a local group with an elevation of privilege\n    - New process creation\n4.  Update an existing log collection pipeline in a cloud service:\n\n    - Enable auditing of host firewall events (as an example of network security events) by using Auditpol\n    - Configure firewall audit data to be collected, and show the collected events in the customer storage account\n5.  Show Windows security event distribution and spike detection.\n6.  Configure the collection of IIS logs and verify the data.\n\nAll of the events and logs are collected into a customer storage account in Azure. The events can be viewed and exported by the customer to on-premises SIEM systems. They can also be aggregated and analyzed by using HDInsight.\n\n### Set up a new instance of a log collection pipeline on a cloud service\nIn this example, we set up a new instance of a security log collection pipeline that uses Azure Diagnostics, and we detect user addition to a local group, and new process creation events on a cloud service instance.\n\n#### Step 1: Create a cloud service (web role) and deploy\n\n1.  On your development computer, launch Visual Studio 2013.\n2.  Create a new cloud service project (our example uses ContosoWebRole).\n3.  Select the **ASP.NET** web role.\n4.  Select the **MVC** project.\n5.  In Solution Explorer, click **Roles**, then double-click the web role (WebRole1) to open the **Properties** window.\n6.  On the **Configuration** tab, clear the **Enable Diagnostics** check box to disable the version of Azure Diagnostics that ships with Visual Studio 2013.\n![][8]\n\n7.  Build your solution to verify that you have no errors.\n8.  Open the file WebRole1/Controllers/HomeController.cs.\n9.  Add the following method to enable the sample application to log HTTP status code 500 as a sample IIS log event (this will be used in the IIS example later):\n\n    ```\n    public ActionResult StatusCode500()\n        {\n            throw new InvalidOperationException(\"Response.StatusCode is 500\");\n        }\n    ```\n\n10.  Right-click the name of the cloud service project, and click **Publish**.\n\n#### Step 2: Prepare the configuration file\nWe will now prepare the Azure Diagnostics configuration file to add the events that can help detect the following situations:\n\n- New user addition to a local group\n- New process creation\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicConfig xmlns=\"http://schemas.microsoft.com/ServiceHosting/2010/10/DiagnosticsConfiguration\">\n    <WadCfg>\n        <DiagnosticMonitorConfiguration overallQuotaInMB=\"25000\">\n            <WindowsEventLog scheduledTransferPeriod=\"PT1M\">\n                <DataSource name=\"Security!*[System[(EventID=4732 or EventID=4733 or EventID=4688)]]\" />\n            </WindowsEventLog>\n        </DiagnosticMonitorConfiguration>\n    </WadCfg>\n</PublicConfig>\n```\n\n#### Step 3: Validate configuration XML file\nValidate the configuration file by using the same steps as shown earlier in [Step 3: Validate configuration XML file](#step3).\nâ€ƒ\n#### Step 4: Configure Azure Diagnostics\nRun the following Azure PowerShell script to enable Azure Diagnostics (make sure to update the storage_name, key, config_path, and service_name).\n\n    $storage_name = \"<storage account name>\"\n    $key = \" <storage key>\"\n    $config_path=\"<path to configuration XML file>\"\n    $service_name=\"<Cloud Service Name>\"\n    $storageContext = New-AzureStorageContext -StorageAccountName $storage_name -StorageAccountKey $key\n    Set-AzureServiceDiagnosticsExtension -StorageContext $storageContext -DiagnosticsConfigurationPath $config_path -ServiceName $service_name\n\nTo verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:\n\n    Get-AzureServiceDiagnosticsExtension -ServiceName <ServiceName>\n\n#### Step 5: Generate events\nTo generate events:\n\n1.  To start a Remote Desktop session to your cloud service instance, in Visual Studio, open Server Explorer, right-click the role instance, and click Connect using Remote Desktop.\n2.  Open an elevated command prompt and run the following commands to create a local administrator account on the virtual machine:\n\n\n    net user contosoadmin  <enterpassword> /add\n    net localgroup administrators contosoadmin  /add\n\n3.  Open Event Viewer, open the **Security** channel, and notice that an Event 4732 has been created, as shown here:\n\n![][9]\n\n#### Step 6: View data\nWait about five minutes to allow the Azure Diagnostics agent to push events to the storage table.\n\n![][10]\n\nTo validate the Process Creation event, open a Notepad. As shown here, a Process Creation event was logged in the Security channel.\n\n![][11]\n\nYou can now view the same event in your storage account as shown here:\n\n![][12]\n\n### Update an existing log collection pipeline in a cloud service with a new configuration\nIn this section, we update an existing Azure Diagnostics security log collection pipeline, and detect Windows Firewall Change Events in a Cloud Service instance.\n\nTo detect firewall changes, we will update the existing configuration to include firewall change events.\n\n#### Step 1: Get existing configuration\n>[AZURE.NOTE] The new configuration settings will overwrite the existing configuration. Thus, it is important that any existing Azure Diagnostics configuration settings be merged with the new configuration file.\n\nTo retrieve the existing configuration setting, you can use the **Get-AzureServiceDiagnosticsExtension** cmdlet:\n\n    Get-AzureServiceDiagnosticsExtension -ServiceName <ServiceName>\n\n#### Step 2: Update configuration XML to include firewall events\n\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <PublicConfig xmlns=\"http://schemas.microsoft.com/ServiceHosting/2010/10/DiagnosticsConfiguration\">\n    <WadCfg>\n        <DiagnosticMonitorConfiguration overallQuotaInMB=\"25000\">\n        <WindowsEventLog scheduledTransferPeriod=\"PT1M\">\n            <DataSource name=\"Security!*[System[(EventID=4732 or EventID=4733 or EventID=4688)]]\" />\n            <DataSource name=\"Security!*[System[(EventID &gt;= 4944 and EventID &lt;= 4958)]]\" />\n        </WindowsEventLog>\n        </DiagnosticMonitorConfiguration>\n    </WadCfg>\n    </PublicConfig>\n\nValidate the XML contents by using the same validation process as described earlier in [Step 3: Validate configuration XML file](#step3).\n\n#### Step 3: Update Azure Diagnostics to use new configuration\n\nRun the following Azure PowerShell script to update Azure Diagnostics to use the new configuration (make sure to update the storage_name, key, config_path, and service_name with your cloud service information).\n\n    Remove-AzureServiceDiagnosticsExtension -ServiceName <ServiceName> -Role <RoleName>\n    $storage_name = \"<storage account name>\"\n    $key = \" <storage key>\"\n    $config_path=\"<path to configuration XML file>\"\n    $service_name=\"<Cloud Service Name>\"\n    $storageContext = New-AzureStorageContext -StorageAccountName $storage_name -StorageAccountKey $key\n    Set-AzureServiceDiagnosticsExtension -StorageContext $storageContext -DiagnosticsConfigurationPath $config_path -ServiceName $service_name\n\nTo verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:\n\n    Get-AzureServiceDiagnosticsExtension -ServiceName <ServiceName>\n\n#### Step 4: Enable firewall events\n\n1.  Open a Remote Desktop session to your cloud service instance.\n2.  Open an elevated command prompt and run the following command:\n\n    ```\n    auditpol.exe /set /category:\"Policy Change\" /subcategory:\"MPSSVC rule-level Policy Change\" /success:enable /failure:enable\n    ```\n\n#### Step 5: Generate events\n\n1.  Open Windows Firewall, and click **Inbound Rules**.\n2.  Click **Add New Rule**, and then click **Port**.\n3.  In the **Local Ports** field, type **5000**, and then click **Next** three times.\n4.  In the **Name** field, type **Test5000**, and then click **Finish**.\n5.  Open Event Viewer, open the **Security** channel, and notice that an Event ID 4946 has been created as shown here:\n\n![][13]\n\n#### Step 6: View data\nWait about five minutes to allow the Azure Diagnostics agent to push the event data to the storage table.\n\n![][14]\n\n### Security event distribution and spike detection\nAfter the events are in the customerâ€™s storage account, applications can use the storage client libraries to access and perform event aggregation. For sample code to access table data, see [How to: Retrieve table data](storage-dotnet-how-to-use-tables.md).\n\nFollowing is an example of event aggregation. Any spikes in event distribution can be investigated further for anomalous activity.\n\n![][15]\n\n### IIS log collection and processing by using HDInsight\nIn this section, we collect IIS logs from your web role instance and move the logs to an Azure blob in the customerâ€™s storage account.\n\n#### Step 1: Update configuration file to include IIS log collection\n\n    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    <PublicConfig xmlns=\"http://schemas.microsoft.com/ServiceHosting/2010/10/DiagnosticsConfiguration\">\n    <WadCfg>\n        <DiagnosticMonitorConfiguration overallQuotaInMB=\"25000\">\n        <Directories scheduledTransferPeriod=\"PT5M\">\n        <IISLogs containerName=\"iislogs\" />\n        </Directories>\n        <WindowsEventLog scheduledTransferPeriod=\"PT1M\">\n            <DataSource name=\"Security!*[System[(EventID=4732 or EventID=4733 or EventID=4688)]]\" />\n            <DataSource name=\"Security!*[System[(EventID &gt;= 4944 and EventID &lt;= 4958)]]\" />\n        </WindowsEventLog>\n        </DiagnosticMonitorConfiguration>\n    </WadCfg>\n    </PublicConfig>\n\nIn the previous Azure Diagnostics configuration, **containerName** is the blob container name to which logs will be moved within customerâ€™s storage account.\n\nValidate the configuration file by using the same steps as shown earlier in [Step 3: Validate configuration XML file](#step3).\n\n\n#### Step 2: Update Azure Diagnostics to use a new configuration\nRun the following Azure PowerShell script to update Azure Diagnostics to use the new configuration (make sure to update the storage_name, key, config_path, and service_name with your cloud service information).\n\n    Remove-AzureServiceDiagnosticsExtension -ServiceName <ServiceName> -Role <RoleName>\n    $storage_name = \"<storage account name>\"\n    $key = \" <storage key>\"\n    $config_path=\"<path to configuration XML file>\"\n    $service_name=\"<Cloud Service Name>\"\n    $storageContext = New-AzureStorageContext -StorageAccountName $storage_name -StorageAccountKey $key\n    Set-AzureServiceDiagnosticsExtension -StorageContext $storageContext -DiagnosticsConfigurationPath $config_path -ServiceName $service_name\n\nTo verify that your service has the latest diagnostic configuration, run the following Azure PowerShell command:\n\n    Get-AzureServiceDiagnosticsExtension -ServiceName <ServiceName>\n\n#### Step 3: Generate IIS logs\n\n1.  Open a web browser and navigate to the cloud service web role (for example, http://contosowebrole.cloudapp.net/).\n2.  Navigate to the **About** and **Contact** pages to create some log events.\n3.  Navigate to a page that generates a status code 500 (for example, http://contosowebrole.cloudapp.net/Home/StatusCode500).\nYou should see an error such as the one that follows. Remember that we added code for **StatusCode500** in Step 1 of section titled Set up new instance of log collection pipeline on a cloud ServiceName.\n![][16]\n4.  Open a Remote Desktop session to your cloud service instance.\n5.  Open IIS Manager.\n6.  IIS Logging is enabled by default and it is set to hourly generate files that contain all fields in W3C format. Click **Browse**, and there will be at least one log file, as shown here:\n![][17]\n\n7.  Wait for about five minutes for the Azure Diagnostics agent to push the log file to the blob container. To validate the data, open **Server Explorer** > **Storage** > **Storage Account** > **Blobs**. As shown here, the blob **iislogs** is created:\n![][18]\n\n8.  Right-click and select **View Blob Container** to display the IIS log file stored in the blob:\n![][19]\n9.  After the IIS events are in the customerâ€™s storage account, applications that leverage HDInsight analysis can be used to perform event aggregation. The following line chart is an example of an event aggregation task that shows HTTP Status Code 500:\n![][20]\n\n## Security log collection recommendations\nWhen you are collecting security logs, we recommend that you:\n\n- Collect your own service application-specific audit log events.\n- Configure only the data that you need for analysis and monitoring. Capturing too much data can make it harder to troubleshoot and can impact your service or storage costs.\n- Merge existing Azure Diagnostics configuration settings with changes you make. The new configuration file overwrites the existing configuration settings.\n- Choose the **Scheduled Transfer Period** interval wisely. Shorter transfer times will increase data relevance, but that can increase storage costs and processing overhead.\n\n>[AZURE.NOTE] The other variable that will significantly impact the amount of data collected is the logging level. The following is an example of how to filter logs by logging level:\n\n    System!*[System[(Level =2)]]\n\nThe logging level is cumulative. If the filter is set to **Warning**, then **Error** and **Critical** events will also be collected.\n\n- Periodically clear the diagnostic data from Azure Storage if it is no longer needed.\n\n>[AZURE.NOTE] To learn more about diagnostic data see [Store and View Diagnostic Data in Azure Storage](https://msdn.microsoft.com/library/azure/hh411534.aspx).  The containers and tables that store diagnostic data are just like other containers and tables, you can delete blobs and entities from them in the same way you would for other data. You can delete the diagnostic data programmatically via one of the storage client libraries or visually via a [storage explorer client](http://blogs.msdn.com/b/windowsazurestorage/archive/2014/03/11/windows-azure-storage-explorers-2014.aspx).\n\n- It is a best practice to store service data and security log data in separate storage accounts. This isolation ensures that saving security log data does not impact the storage performance for production service data.\n- Choose the log retention duration based on your organizationâ€™s compliance policy and data analysis and monitoring requirements.\n\n## Exporting security logs to another system\nYou can download blob data by using the Azure Storage Client Library, and then export it to your on-premises system for processing. For sample code to manage blob data, see [How to use Blob Storage from .NET](storage-dotnet-how-to-use-blobs.md).\n\nSimilarly, you can download security data stored in Azure tables by using the Azure Storage Client Library. To learn more about accessing data that is stored in tables, see [How to use Table Storage from .NET](storage-dotnet-how-to-use-tables.md).\n\n## Azure Active Directory reports\nAzure Active Directory (Azure AD) includes a set of security, usage, and audit log reports that provide visibility into the integrity and security of your Azure AD tenant. For example, Azure AD has the capability to automatically analyze user activity and surface anomalous access, and then make it available through customer-visible reports.\n\nThese reports are available through the [Azure Management Portal](https://manage.windowsazure.com/) under **Active Directory** > **Directory**. Some of these reports are free, and others are offered as part of an Azure AD Premium edition. For more information about Azure AD reports, see [View your access and usage reports](http://msdn.microsoft.com/library/azure/dn283934.aspx).\n\n## Azure Operation Logs\nLogs for operations related to your Azure subscription resources are also available through the **Operation Logs** feature in the management portal.\n\nTo view the **Operation Logs**, open the [Azure Management Portal](https://manage.windowsazure.com/), click **Management Services**, and then click **Operation Logs**.\n\n## <a name=\"diagnostics\"></a> Azure Diagnostics supported data sources\n\n| Data Source | Description |\n|----- | ----- |\n| IIS Logs | Information about IIS websites |\n| Azure Diagnostic infrastructure logs | Information about Azure Diagnostics |\n| IIS Failed Request logs | Information about failed requests to an IIS website or application |\n| Windows Event logs | Information sent to the Windows event logging system |\n| Performance counters | Operating system and custom performance counters |\n| Crash dumps | Information about the state of the process in the event of an application crash |\n| Custom error logs | Logs created by your application or service |\n| .NET EventSource | Events generated by your code by using the .NET EventSource class |\n| Manifest-based ETW | Event Tracing for Windows events generated by any process |\n\n## Additional resources\nThe following resources provide general information about Microsoft Azure and related Microsoft services:\n\n- [Microsoft Azure Trust Center](http://azure.microsoft.com/support/trust-center/)\n\n    Information on how security and privacy are embedded into the development of Azure and how Azure meets a broad set of international and industry-specific compliance standards\n\n- [Microsoft Azure home page](http://www.microsoft.com/windowsazure/)\n\n    General information and links about Microsoft Azure\n\n- [Microsoft Azure Documentation Center](http://msdn.microsoft.com/windowsazure/default.aspx)\n\n    Guidance for Azure services and automation scripts\n\n- [Microsoft Security Response Center (MSRC)](http://www.microsoft.com/security/msrc/default.aspx)\n\n    The MSRC works with partners and security researchers around the world to help prevent security incidents and to advance Microsoft product security\n\n- [Microsoft Security Response Center email](mailto:secure@microsoft.com)\n\n    Email to report Microsoft security vulnerabilities, including Microsoft Azure\n\n<!--Image references-->\n[1]: ./media/azure-security-audit-log-management/sec-security-data-collection-flow.png\n[2]: ./media/azure-security-audit-log-management/sec-storage-table-security-log.PNG\n[3]: ./media/azure-security-audit-log-management/sec-wad-windows-event-logs-table.png\n[4]: ./media/azure-security-audit-log-management/sec-edit-entity.png\n[5]: ./media/azure-security-audit-log-management/sec-app-event-log-cmd.png\n[6]: ./media/azure-security-audit-log-management/sec-event-viewer.png\n[7]: ./media/azure-security-audit-log-management/sec-event-id100.png\n[8]: ./media/azure-security-audit-log-management/sec-diagnostics.png\n[9]: ./media/azure-security-audit-log-management/sec-event4732.png\n[10]: ./media/azure-security-audit-log-management/sec-step6.png\n[11]: ./media/azure-security-audit-log-management/sec-process-creation-event.png\n[12]: ./media/azure-security-audit-log-management/sec-process-creation-event-storage.png\n[13]: ./media/azure-security-audit-log-management/sec-event4946.png\n[14]: ./media/azure-security-audit-log-management/sec-event4946-storage.png\n[15]: ./media/azure-security-audit-log-management/sec-event-aggregation.png\n[16]: ./media/azure-security-audit-log-management/sec-status-code500.png\n[17]: ./media/azure-security-audit-log-management/sec-w3c-format.png\n[18]: ./media/azure-security-audit-log-management/sec-blob-iis-logs.png\n[19]: ./media/azure-security-audit-log-management/sec-view-blob-container.png\n[20]: ./media/azure-security-audit-log-management/sec-hdinsight-analysis.png\n\ntest\n"
}