{
  "nodes": [
    {
      "content": "Apache Storm topologies with Visual Studio and C#  | Microsoft Azure",
      "pos": [
        26,
        94
      ]
    },
    {
      "content": "Learn how to create Storm topologies in C# by creating a simple word count topology in Visual Studio using the HDInsight Tools for Visual Studio.",
      "pos": [
        112,
        257
      ]
    },
    {
      "content": "Develop C# topologies for Apache Storm on HDInsight using Hadoop tools for Visual Studio",
      "pos": [
        577,
        665
      ]
    },
    {
      "content": "Learn how to create a C# Storm topology by using the HDInsight tools for Visual Studio.",
      "pos": [
        667,
        754
      ]
    },
    {
      "content": "This tutorial walks through the process of creating a new Storm project in Visual Studio, testing it locally, and deploying it to an Apache Storm on HDInsight cluster.",
      "pos": [
        755,
        922
      ]
    },
    {
      "content": "You will also learn how to create hybrid topologies that use C# and Java components.",
      "pos": [
        924,
        1008
      ]
    },
    {
      "content": "Prerequisites",
      "pos": [
        1012,
        1025
      ]
    },
    {
      "content": "One of the following versions of Visual Studio",
      "pos": [
        1031,
        1077
      ]
    },
    {
      "pos": [
        1087,
        1178
      ],
      "content": "Visual Studio 2012 with <bpt id=\"p1\">[</bpt>Update 4<ept id=\"p1\">](http://www.microsoft.com/download/details.aspx?id=39305)</ept>"
    },
    {
      "pos": [
        1188,
        1360
      ],
      "content": "Visual Studio 2013 with <bpt id=\"p1\">[</bpt>Update 4<ept id=\"p1\">](http://www.microsoft.com/download/details.aspx?id=44921)</ept> or <bpt id=\"p2\">[</bpt>Visual Studio 2013 Community<ept id=\"p2\">](http://go.microsoft.com/fwlink/?LinkId=517284)</ept>"
    },
    {
      "pos": [
        1370,
        1470
      ],
      "content": "Visual Studio 2015 or <bpt id=\"p1\">[</bpt>Visual Studio 2015 Community<ept id=\"p1\">](https://go.microsoft.com/fwlink/?LinkId=532606)</ept>"
    },
    {
      "content": "Azure SDK 2.5.1 or later",
      "pos": [
        1476,
        1500
      ]
    },
    {
      "pos": [
        1506,
        1715
      ],
      "content": "HDInsight Tools for Visual Studio: See <bpt id=\"p1\">[</bpt>Get started using HDInsight Tools for Visual Studio<ept id=\"p1\">](hdinsight-hadoop-visual-studio-tools-get-started.md)</ept> to install and configure the HDInsight tools for Visual Studio."
    },
    {
      "pos": [
        1723,
        1812
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> HDInsight Tools for Visual Studio are not supported on Visual Studio Express"
    },
    {
      "pos": [
        1818,
        1972
      ],
      "content": "Apache Storm on HDInsight cluster: See <bpt id=\"p1\">[</bpt>Getting started with Apache Storm on HDInsight<ept id=\"p1\">](hdinsight-storm-getting-started.md)</ept> for steps to create a cluster."
    },
    {
      "pos": [
        1980,
        2096
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Currently, the HDInsight Tools for Visual Studio only support Storm on HDInsight versions 3.2 clusters."
    },
    {
      "content": "Templates",
      "pos": [
        2100,
        2109
      ]
    },
    {
      "content": "The HDInsight Tools for Visual Studio provide the following templates::",
      "pos": [
        2111,
        2182
      ]
    },
    {
      "content": "Project type",
      "pos": [
        2186,
        2198
      ]
    },
    {
      "content": "Demonstrates",
      "pos": [
        2201,
        2213
      ]
    },
    {
      "content": "Storm Application",
      "pos": [
        2251,
        2268
      ]
    },
    {
      "content": "An empty Storm topology project",
      "pos": [
        2271,
        2302
      ]
    },
    {
      "content": "Storm Azure SQL Writer Sample",
      "pos": [
        2307,
        2336
      ]
    },
    {
      "content": "How to write to Azure SQL Database",
      "pos": [
        2339,
        2373
      ]
    },
    {
      "content": "Storm DocumentDB Reader Sample",
      "pos": [
        2378,
        2408
      ]
    },
    {
      "content": "How to read from Azure DocumentDB",
      "pos": [
        2411,
        2444
      ]
    },
    {
      "content": "Storm DocumentDB Writer Sample",
      "pos": [
        2449,
        2479
      ]
    },
    {
      "content": "How to write to Azure DocumentDB",
      "pos": [
        2482,
        2514
      ]
    },
    {
      "content": "Storm EventHub Reader Sample",
      "pos": [
        2519,
        2547
      ]
    },
    {
      "content": "How to read from Azure Event Hubs",
      "pos": [
        2550,
        2583
      ]
    },
    {
      "content": "Storm EventHub Writer Sample",
      "pos": [
        2588,
        2616
      ]
    },
    {
      "content": "How to write to Azure Event Hubs",
      "pos": [
        2619,
        2651
      ]
    },
    {
      "content": "Storm HBase Reader Sample",
      "pos": [
        2656,
        2681
      ]
    },
    {
      "content": "How to read from HBase on HDInsight clusters",
      "pos": [
        2684,
        2728
      ]
    },
    {
      "content": "Storm HBase Writer Sample",
      "pos": [
        2733,
        2758
      ]
    },
    {
      "content": "How to write to HBase on HDInsight clusters",
      "pos": [
        2761,
        2804
      ]
    },
    {
      "content": "Storm Hybrid Sample",
      "pos": [
        2809,
        2828
      ]
    },
    {
      "content": "How to use a Java component",
      "pos": [
        2831,
        2858
      ]
    },
    {
      "content": "Storm Sample",
      "pos": [
        2863,
        2875
      ]
    },
    {
      "content": "A basic word count topology",
      "pos": [
        2878,
        2905
      ]
    },
    {
      "pos": [
        2911,
        3057
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The HBase reader and writer samples use the HBase REST API to communicate with an HBase on HDInsight cluster, not the HBase Java API."
    },
    {
      "content": "In the steps in this document, you will use the basic Storm Application project type to create a new topology.",
      "pos": [
        3059,
        3169
      ]
    },
    {
      "content": "Create a C# topology",
      "pos": [
        3173,
        3193
      ]
    },
    {
      "pos": [
        3199,
        3405
      ],
      "content": "If you have not already installed the latest version of the HDInsight Tools for Visual Studio, see <bpt id=\"p1\">[</bpt>Get started using HDInsight Tools for Visual Studio<ept id=\"p1\">](hdinsight-hadoop-visual-studio-tools-get-started.md)</ept>."
    },
    {
      "pos": [
        3411,
        3479
      ],
      "content": "Open Visual Studio, select <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> &gt; <bpt id=\"p2\">**</bpt>New<ept id=\"p2\">**</ept>, and then <bpt id=\"p3\">**</bpt>Project<ept id=\"p3\">**</ept>."
    },
    {
      "content": "From the <bpt id=\"p1\">**</bpt>New Project<ept id=\"p1\">**</ept> screen, expand <bpt id=\"p2\">**</bpt>Installed<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Templates<ept id=\"p3\">**</ept>, and select <bpt id=\"p4\">**</bpt>HDInsight<ept id=\"p4\">**</ept>.",
      "pos": [
        3485,
        3581
      ]
    },
    {
      "content": "From the list of templates, select <bpt id=\"p1\">**</bpt>Storm Application<ept id=\"p1\">**</ept>.",
      "pos": [
        3582,
        3639
      ]
    },
    {
      "content": "At the bottom of the screen, enter <bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept> as the name of the application.",
      "pos": [
        3640,
        3720
      ]
    },
    {
      "content": "image",
      "pos": [
        3728,
        3733
      ]
    },
    {
      "content": "After the project has been created, you should have the following files:",
      "pos": [
        3819,
        3891
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept>: This defines the topology for your project.",
      "pos": [
        3901,
        3960
      ]
    },
    {
      "content": "Note that a default topology that consists of one spout and one bolt is created by default.",
      "pos": [
        3961,
        4052
      ]
    },
    {
      "pos": [
        4062,
        4119
      ],
      "content": "<bpt id=\"p1\">**</bpt>Spout.cs<ept id=\"p1\">**</ept>: An example spout that emits random numbers."
    },
    {
      "pos": [
        4129,
        4209
      ],
      "content": "<bpt id=\"p1\">**</bpt>Bolt.cs<ept id=\"p1\">**</ept>: An example bolt that keeps a count of numbers emitted by the spout."
    },
    {
      "pos": [
        4215,
        4359
      ],
      "content": "As part of project creation, the latest <bpt id=\"p1\">[</bpt>SCP.NET packages<ept id=\"p1\">](https://www.nuget.org/packages/Microsoft.SCP.Net.SDK/)</ept> will be downloaded from NuGet."
    },
    {
      "content": "In the next sections, you will modify this project into a basic WordCount application.",
      "pos": [
        4361,
        4447
      ]
    },
    {
      "content": "Implement the spout",
      "pos": [
        4452,
        4471
      ]
    },
    {
      "content": "Open <bpt id=\"p1\">**</bpt>Spout.cs<ept id=\"p1\">**</ept>.",
      "pos": [
        4477,
        4495
      ]
    },
    {
      "content": "Spouts are used to read data in a topology from an external source.",
      "pos": [
        4496,
        4563
      ]
    },
    {
      "content": "The main components for a spout are:",
      "pos": [
        4564,
        4600
      ]
    },
    {
      "pos": [
        4610,
        4686
      ],
      "content": "<bpt id=\"p1\">**</bpt>NextTuple<ept id=\"p1\">**</ept>: Called by Storm when the spout is allowed to emit new tuples."
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Ack<ept id=\"p1\">**</ept> (transactional topology only): Handles acknowledgements initiated by other components in the topology for tuples sent from this spout.",
      "pos": [
        4696,
        4838
      ]
    },
    {
      "content": "Acknowledging a tuple lets the spout know that it was processed successfully by downstream components.",
      "pos": [
        4839,
        4941
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Fail<ept id=\"p1\">**</ept> (transactional topology only): Handles tuples that are fail-processing other components in the topology.",
      "pos": [
        4951,
        5064
      ]
    },
    {
      "content": "This provides the opportunity to re-emit the tuple so that it can be processed again.",
      "pos": [
        5065,
        5150
      ]
    },
    {
      "content": "Replace the contents of the <bpt id=\"p1\">**</bpt>Spout<ept id=\"p1\">**</ept> class with the following.",
      "pos": [
        5156,
        5219
      ]
    },
    {
      "content": "This creates a spout that randomly emits a sentence into the topology.",
      "pos": [
        5220,
        5290
      ]
    },
    {
      "content": "Take a moment to read through the comments to understand what this code does.",
      "pos": [
        7053,
        7130
      ]
    },
    {
      "content": "Implement the bolts",
      "pos": [
        7135,
        7154
      ]
    },
    {
      "pos": [
        7160,
        7214
      ],
      "content": "Delete the existing <bpt id=\"p1\">**</bpt>Bolt.cs<ept id=\"p1\">**</ept> file from the project."
    },
    {
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project and select <bpt id=\"p2\">**</bpt>Add<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>New item<ept id=\"p3\">**</ept>.",
      "pos": [
        7220,
        7304
      ]
    },
    {
      "content": "From the list, select <bpt id=\"p1\">**</bpt>Storm Bolt<ept id=\"p1\">**</ept>, and enter <bpt id=\"p2\">**</bpt>Splitter.cs<ept id=\"p2\">**</ept> as the name.",
      "pos": [
        7305,
        7381
      ]
    },
    {
      "content": "Repeat this to create a second bolt named <bpt id=\"p1\">**</bpt>Counter.cs<ept id=\"p1\">**</ept>.",
      "pos": [
        7382,
        7439
      ]
    },
    {
      "pos": [
        7449,
        7560
      ],
      "content": "<bpt id=\"p1\">**</bpt>Splitter.cs<ept id=\"p1\">**</ept>: Implements a bolt that splits sentences into individual words and emits a new stream of words."
    },
    {
      "pos": [
        7570,
        7686
      ],
      "content": "<bpt id=\"p1\">**</bpt>Counter.cs<ept id=\"p1\">**</ept>: Implements a bolt that counts each word and emits a new stream of words and the count for each word."
    },
    {
      "pos": [
        7694,
        7839
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> These bolts simply read and write to streams, but you can also use a bolt to communicate with sources such as a database or service."
    },
    {
      "content": "Open <bpt id=\"p1\">**</bpt>Splitter.cs<ept id=\"p1\">**</ept>.",
      "pos": [
        7845,
        7866
      ]
    },
    {
      "content": "Note that it has only one method by default: <bpt id=\"p1\">**</bpt>Execute<ept id=\"p1\">**</ept>.",
      "pos": [
        7867,
        7924
      ]
    },
    {
      "content": "This is called when the bolt receives a tuple for processing.",
      "pos": [
        7925,
        7986
      ]
    },
    {
      "content": "Here, you can read and process incoming tuples, and emit outbound tuples.",
      "pos": [
        7987,
        8060
      ]
    },
    {
      "pos": [
        8066,
        8137
      ],
      "content": "Replace the contents of the <bpt id=\"p1\">**</bpt>Splitter<ept id=\"p1\">**</ept> class with the following code:"
    },
    {
      "content": "Take a moment to read through the comments to understand what this code does.",
      "pos": [
        9625,
        9702
      ]
    },
    {
      "pos": [
        9708,
        9778
      ],
      "content": "Open <bpt id=\"p1\">**</bpt>Counter.cs<ept id=\"p1\">**</ept> and replace the class contents with the following:"
    },
    {
      "content": "Take a moment to read through the comments to understand what this code does.",
      "pos": [
        11714,
        11791
      ]
    },
    {
      "content": "Define the topology",
      "pos": [
        11796,
        11815
      ]
    },
    {
      "content": "Spouts and bolts are arranged in a graph, which defines how the data flows between components.",
      "pos": [
        11817,
        11911
      ]
    },
    {
      "content": "For this topology, the graph is as follows:",
      "pos": [
        11912,
        11955
      ]
    },
    {
      "content": "image of how components are arranged",
      "pos": [
        11959,
        11995
      ]
    },
    {
      "content": "Sentences are emitted from the spout, which are distributed to instances of the Splitter bolt.",
      "pos": [
        12084,
        12178
      ]
    },
    {
      "content": "The Splitter bolt breaks the sentences into words, which are distributed to the Counter bolt.",
      "pos": [
        12179,
        12272
      ]
    },
    {
      "content": "Because word count is held locally in the Counter instance, we want to make sure that specific words flow to the same Counter bolt instance, so we have only one instance keeping track of a specific word.",
      "pos": [
        12274,
        12477
      ]
    },
    {
      "content": "But for the Splitter bolt, it really doesn't matter which bolt receives which sentence, so we simply want to load balance sentences across those instances.",
      "pos": [
        12478,
        12633
      ]
    },
    {
      "content": "Open <bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept>.",
      "pos": [
        12635,
        12655
      ]
    },
    {
      "content": "The important method is <bpt id=\"p1\">**</bpt>ITopologyBuilder<ept id=\"p1\">**</ept>, which is used to define the topology that is submitted to Storm.",
      "pos": [
        12656,
        12766
      ]
    },
    {
      "content": "Replace the contents of <bpt id=\"p1\">**</bpt>ITopologyBuilder<ept id=\"p1\">**</ept> with the following code to implement the topology described previously:",
      "pos": [
        12767,
        12883
      ]
    },
    {
      "content": "Take a moment to read through the comments to understand what this code does.",
      "pos": [
        14800,
        14877
      ]
    },
    {
      "content": "Submit the topology",
      "pos": [
        14881,
        14900
      ]
    },
    {
      "pos": [
        14906,
        15001
      ],
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project, and select <bpt id=\"p2\">**</bpt>Submit to Storm on HDInsight<ept id=\"p2\">**</ept>."
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> If prompted, enter the login credentials for your Azure subscription.",
      "pos": [
        15009,
        15091
      ]
    },
    {
      "content": "If you have more than one subscription, log in to the one that contains your Storm on HDInsight cluster.",
      "pos": [
        15092,
        15196
      ]
    },
    {
      "content": "Select your Storm on HDInsight cluster from the <bpt id=\"p1\">**</bpt>Storm Cluster<ept id=\"p1\">**</ept> drop-down list, and then select <bpt id=\"p2\">**</bpt>Submit<ept id=\"p2\">**</ept>.",
      "pos": [
        15202,
        15311
      ]
    },
    {
      "content": "You can monitor if the submission is successful by using the <bpt id=\"p1\">**</bpt>Output<ept id=\"p1\">**</ept> window.",
      "pos": [
        15312,
        15391
      ]
    },
    {
      "content": "When the topology has been successfully submitted, the <bpt id=\"p1\">**</bpt>Storm Topologies<ept id=\"p1\">**</ept> for the cluster should appear.",
      "pos": [
        15397,
        15503
      ]
    },
    {
      "content": "Select the <bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept> topology from the list to view information about the running topology.",
      "pos": [
        15504,
        15599
      ]
    },
    {
      "pos": [
        15607,
        15803
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You can also view <bpt id=\"p1\">**</bpt>Storm Topologies<ept id=\"p1\">**</ept> from <bpt id=\"p2\">**</bpt>Server Explorer<ept id=\"p2\">**</ept>: Expand <bpt id=\"p3\">**</bpt>Azure<ept id=\"p3\">**</ept> &gt; <bpt id=\"p4\">**</bpt>HDInsight<ept id=\"p4\">**</ept>, right-click a Storm on HDInsight cluster, and then select <bpt id=\"p5\">**</bpt>View Storm Topologies<ept id=\"p5\">**</ept>."
    },
    {
      "content": "Use the links for the spouts or bolts to view information about these components.",
      "pos": [
        15809,
        15890
      ]
    },
    {
      "content": "A new window will be opened for each item selected.",
      "pos": [
        15891,
        15942
      ]
    },
    {
      "pos": [
        15948,
        16020
      ],
      "content": "From the <bpt id=\"p1\">**</bpt>Topology Summary<ept id=\"p1\">**</ept> view, click <bpt id=\"p2\">**</bpt>Kill<ept id=\"p2\">**</ept> to stop the topology."
    },
    {
      "pos": [
        16028,
        16128
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Storm topologies continue to run until they are deactivated, or the cluster is deleted."
    },
    {
      "content": "Transactional topology",
      "pos": [
        16132,
        16154
      ]
    },
    {
      "content": "The previous topology is non-transactional.",
      "pos": [
        16156,
        16199
      ]
    },
    {
      "content": "The components within the topology do not implement any functionality for replaying messages if processing fails by a component in the topology.",
      "pos": [
        16200,
        16344
      ]
    },
    {
      "content": "For an example transactional topology, create a new project and select <bpt id=\"p1\">**</bpt>Storm Sample<ept id=\"p1\">**</ept> as the project type.",
      "pos": [
        16345,
        16453
      ]
    },
    {
      "content": "Transactional topologies implement the following to support replay of data:",
      "pos": [
        16455,
        16530
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Metadata caching<ept id=\"p1\">**</ept>: The spout must store metadata about the data emitted so that the data can be retrieved and emitted again if a failure occurs.",
      "pos": [
        16536,
        16683
      ]
    },
    {
      "content": "Because the data emitted by the sample is small, the raw data for each tuple is stored in a dictionary for replay.",
      "pos": [
        16684,
        16798
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Ack<ept id=\"p1\">**</ept>: Each bolt in the topology can call <ph id=\"ph1\">`this.ctx.Ack(tuple)`</ph> to ack that it has successfully processed a tuple.",
      "pos": [
        16804,
        16920
      ]
    },
    {
      "content": "When all bolts have acked the tuple, the <ph id=\"ph1\">`Ack`</ph> method of the spout is invoked.",
      "pos": [
        16921,
        16999
      ]
    },
    {
      "content": "This allows the spout to remove cached data for replay because the data was completely processed.",
      "pos": [
        17000,
        17097
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Fail<ept id=\"p1\">**</ept>: Each bolt can call <ph id=\"ph1\">`this.ctx.Fail(tuple)`</ph> to indicate that processing has failed for a tuple.",
      "pos": [
        17103,
        17206
      ]
    },
    {
      "content": "The failure propagates to the <ph id=\"ph1\">`Fail`</ph> method of the spout, where the tuple can be replayed by using cached metadata.",
      "pos": [
        17207,
        17322
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Sequence ID<ept id=\"p1\">**</ept>: When emitting a tuple, a sequence ID can be specified.",
      "pos": [
        17328,
        17399
      ]
    },
    {
      "content": "This should be a value that identifies the tuple for replay (Ack and Fail) processing.",
      "pos": [
        17400,
        17486
      ]
    },
    {
      "content": "For example, the spout in the <bpt id=\"p1\">**</bpt>Storm Sample<ept id=\"p1\">**</ept> project uses the following when emitting data:",
      "pos": [
        17487,
        17580
      ]
    },
    {
      "content": "This emits a new tuple that contains a sentence to the default stream, with the sequence ID value contained in <bpt id=\"p1\">**</bpt>lastSeqId<ept id=\"p1\">**</ept>.",
      "pos": [
        17684,
        17809
      ]
    },
    {
      "content": "For this example, <bpt id=\"p1\">**</bpt>lastSeqId<ept id=\"p1\">**</ept> is simply incremented for every tuple emitted.",
      "pos": [
        17810,
        17888
      ]
    },
    {
      "pos": [
        17890,
        18023
      ],
      "content": "As demonstrated in the <bpt id=\"p1\">**</bpt>Storm Sample<ept id=\"p1\">**</ept> project, whether a component is transactional can be set at run time, based on configuration."
    },
    {
      "content": "Hybrid topology",
      "pos": [
        18027,
        18042
      ]
    },
    {
      "content": "HDInsight tools for Visual Studio can also be used to create hybrid topologies, where some components are C# and others are Java.",
      "pos": [
        18044,
        18173
      ]
    },
    {
      "content": "For an example hybrid topology, create a new project, and select <bpt id=\"p1\">**</bpt>Storm Hybrid Sample<ept id=\"p1\">**</ept>.",
      "pos": [
        18175,
        18264
      ]
    },
    {
      "content": "This creates a fully commented sample that contains several topologies that demonstrate the following:",
      "pos": [
        18265,
        18367
      ]
    },
    {
      "pos": [
        18373,
        18455
      ],
      "content": "<bpt id=\"p1\">**</bpt>Java spout<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>C# bolt<ept id=\"p2\">**</ept>: Defined in <bpt id=\"p3\">**</bpt>HybridTopology_javaSpout_csharpBolt<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        18465,
        18544
      ],
      "content": "A transactional version is defined in <bpt id=\"p1\">**</bpt>HybridTopologyTx_javaSpout_csharpBolt<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        18550,
        18632
      ],
      "content": "<bpt id=\"p1\">**</bpt>C# spout<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Java bolt<ept id=\"p2\">**</ept>: Defined in <bpt id=\"p3\">**</bpt>HybridTopology_csharpSpout_javaBolt<ept id=\"p3\">**</ept>"
    },
    {
      "pos": [
        18642,
        18721
      ],
      "content": "A transactional version is defined in <bpt id=\"p1\">**</bpt>HybridTopologyTx_csharpSpout_javaBolt<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        18733,
        18838
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> This version also demonstrates how to use Clojure code from a text file as a Java component."
    },
    {
      "pos": [
        18840,
        19026
      ],
      "content": "To switch between the topology that is used when the project is submitted, simply move the <ph id=\"ph1\">`[Active(true)]`</ph> statement to the topology you want to use before submitting it to the cluster."
    },
    {
      "pos": [
        19030,
        19150
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> All the Java files that are required are provided as part of this project in the <bpt id=\"p1\">**</bpt>JavaDependency<ept id=\"p1\">**</ept> folder."
    },
    {
      "content": "Consider the following when creating and submitting a hybrid topology:",
      "pos": [
        19152,
        19222
      ]
    },
    {
      "pos": [
        19228,
        19333
      ],
      "content": "<bpt id=\"p1\">**</bpt>JavaComponentConstructor<ept id=\"p1\">**</ept> must be used to create a new instance of the Java class for a spout or bolt."
    },
    {
      "pos": [
        19339,
        19496
      ],
      "content": "<bpt id=\"p1\">**</bpt>microsoft.scp.storm.multilang.CustomizedInteropJSONSerializer<ept id=\"p1\">**</ept> should be used to serialize data in to or out of Java components from Java objects to JSON."
    },
    {
      "content": "When submitting the topology to the server, you must use the <bpt id=\"p1\">**</bpt>Additional configurations<ept id=\"p1\">**</ept> option to specify the <bpt id=\"p2\">**</bpt>Java File paths<ept id=\"p2\">**</ept>.",
      "pos": [
        19502,
        19635
      ]
    },
    {
      "content": "The path specified should be the directory that contains the JAR files that contain your Java classes.",
      "pos": [
        19636,
        19738
      ]
    },
    {
      "content": "Azure Event Hubs",
      "pos": [
        19743,
        19759
      ]
    },
    {
      "content": "SCP.Net version 0.9.4.203 introduces a new class and method specifically for working with the Event Hub Spout (a Java spout that reads from Event Hub.) When creating a topology that uses this spout, use the following methods:",
      "pos": [
        19761,
        19986
      ]
    },
    {
      "pos": [
        19992,
        20096
      ],
      "content": "<bpt id=\"p1\">**</bpt>EventHubSpoutConfig<ept id=\"p1\">**</ept> class: creates an object that contains the configuration for the spout component"
    },
    {
      "pos": [
        20102,
        20197
      ],
      "content": "<bpt id=\"p1\">**</bpt>TopologyBuilder.SetEventHubSpout<ept id=\"p1\">**</ept> method: adds the Event Hub Spout component to the topology"
    },
    {
      "pos": [
        20201,
        20397
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> While these make it easier to work with the Event Hub Spout than other Java components, you must still use the CustomizedInteropJSONSerializer to serialize data produced by the spout."
    },
    {
      "content": "How to update SCP.NET",
      "pos": [
        20401,
        20422
      ]
    },
    {
      "content": "Recent releases of SCP.NET support package upgrade through NuGet.",
      "pos": [
        20424,
        20489
      ]
    },
    {
      "content": "When a new update is available, you will receive an upgrade notification.",
      "pos": [
        20490,
        20563
      ]
    },
    {
      "content": "To manually check for an upgrade, perform these steps:",
      "pos": [
        20564,
        20618
      ]
    },
    {
      "pos": [
        20623,
        20710
      ],
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project and select <bpt id=\"p2\">**</bpt>Manage NuGet Packages<ept id=\"p2\">**</ept>."
    },
    {
      "content": "From the package manager, select <bpt id=\"p1\">**</bpt>Updates<ept id=\"p1\">**</ept>.",
      "pos": [
        20715,
        20760
      ]
    },
    {
      "content": "If an update is available, it will be listed.",
      "pos": [
        20761,
        20806
      ]
    },
    {
      "content": "Click the <bpt id=\"p1\">**</bpt>Update<ept id=\"p1\">**</ept> button for the package to install it.",
      "pos": [
        20807,
        20865
      ]
    },
    {
      "pos": [
        20869,
        21069
      ],
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph> If your project was created with one of the earlier versions of SCP.NET that did not use NuGet for package updates, you must perform the following steps to update to the new version:"
    },
    {
      "pos": [
        21077,
        21164
      ],
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project and select <bpt id=\"p2\">**</bpt>Manage NuGet Packages<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        21170,
        21265
      ],
      "content": "Using the <bpt id=\"p1\">**</bpt>Search<ept id=\"p1\">**</ept> field, search for, and then add, <bpt id=\"p2\">**</bpt>Microsoft.SCP.Net.SDK<ept id=\"p2\">**</ept> to the project."
    },
    {
      "content": "Troubleshooting",
      "pos": [
        21269,
        21284
      ]
    },
    {
      "content": "Test a topology locally",
      "pos": [
        21289,
        21312
      ]
    },
    {
      "content": "Although it is easy to deploy a topology to a cluster, in some cases, you may need to test a topology locally.",
      "pos": [
        21314,
        21424
      ]
    },
    {
      "content": "Use the following steps to run and test the example topology in this tutorial locally in your development environment.",
      "pos": [
        21425,
        21543
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.WARNING]</ph> Local testing only works for basic, C# only topologies.",
      "pos": [
        21547,
        21618
      ]
    },
    {
      "content": "You should not use local testing for hybrid topologies or topologies that use multiple streams, as you will receive errors.",
      "pos": [
        21619,
        21742
      ]
    },
    {
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project, and select <bpt id=\"p2\">**</bpt>Properties<ept id=\"p2\">**</ept>.",
      "pos": [
        21748,
        21825
      ]
    },
    {
      "content": "In the project properties, change the <bpt id=\"p1\">**</bpt>Output type<ept id=\"p1\">**</ept> to <bpt id=\"p2\">**</bpt>Console Application<ept id=\"p2\">**</ept>.",
      "pos": [
        21826,
        21907
      ]
    },
    {
      "content": "output type",
      "pos": [
        21915,
        21926
      ]
    },
    {
      "pos": [
        22013,
        22135
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Remember to change the <bpt id=\"p1\">**</bpt>Output type<ept id=\"p1\">**</ept> back to <bpt id=\"p2\">**</bpt>Class Library<ept id=\"p2\">**</ept> before you deploy the topology to a cluster."
    },
    {
      "content": "In <bpt id=\"p1\">**</bpt>Solution Explorer<ept id=\"p1\">**</ept>, right-click the project, then select <bpt id=\"p2\">**</bpt>Add<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>New Item<ept id=\"p3\">**</ept>.",
      "pos": [
        22141,
        22227
      ]
    },
    {
      "content": "Select <bpt id=\"p1\">**</bpt>Class<ept id=\"p1\">**</ept> and enter <bpt id=\"p2\">**</bpt>LocalTest.cs<ept id=\"p2\">**</ept> as the class name.",
      "pos": [
        22228,
        22290
      ]
    },
    {
      "content": "Finally, click <bpt id=\"p1\">**</bpt>Add<ept id=\"p1\">**</ept>.",
      "pos": [
        22291,
        22314
      ]
    },
    {
      "pos": [
        22320,
        22395
      ],
      "content": "Open <bpt id=\"p1\">**</bpt>LocalTest.cs<ept id=\"p1\">**</ept> and add the following <bpt id=\"p2\">**</bpt>using<ept id=\"p2\">**</ept> statement at the top:"
    },
    {
      "pos": [
        22443,
        22504
      ],
      "content": "Use the following as the contents of the <bpt id=\"p1\">**</bpt>LocalTest<ept id=\"p1\">**</ept> class:"
    },
    {
      "content": "Take a moment to read through the code comments.",
      "pos": [
        25658,
        25706
      ]
    },
    {
      "content": "This code uses <bpt id=\"p1\">**</bpt>LocalContext<ept id=\"p1\">**</ept> to run the components in the development environment, and it persists the data stream between components to text files on the local drive.",
      "pos": [
        25707,
        25877
      ]
    },
    {
      "pos": [
        25883,
        25948
      ],
      "content": "Open <bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept> and add the following to the <bpt id=\"p2\">**</bpt>Main<ept id=\"p2\">**</ept> method:"
    },
    {
      "content": "Save the changes, then click <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> or select <bpt id=\"p2\">**</bpt>Debug<ept id=\"p2\">**</ept> &gt; <bpt id=\"p3\">**</bpt>Start Debugging<ept id=\"p3\">**</ept> to start the project.",
      "pos": [
        26576,
        26675
      ]
    },
    {
      "content": "A console window should appear, and log status as the tests progress.",
      "pos": [
        26676,
        26745
      ]
    },
    {
      "content": "When <bpt id=\"p1\">**</bpt>Tests finished<ept id=\"p1\">**</ept> appears, press any key to close the window.",
      "pos": [
        26746,
        26813
      ]
    },
    {
      "content": "Use <bpt id=\"p1\">**</bpt>Windows Explorer<ept id=\"p1\">**</ept> to locate the directory that contains your project, for example, <bpt id=\"p2\">**</bpt>C:\\Users\\&lt;your_user_name&gt;\\Documents\\Visual Studio 2013\\Projects\\WordCount\\WordCount<ept id=\"p2\">**</ept>.",
      "pos": [
        26819,
        26997
      ]
    },
    {
      "content": "In this directory, open <bpt id=\"p1\">**</bpt>Bin<ept id=\"p1\">**</ept>, and then click <bpt id=\"p2\">**</bpt>Debug<ept id=\"p2\">**</ept>.",
      "pos": [
        26998,
        27056
      ]
    },
    {
      "content": "You should see the text files that were produced when the tests ran: sentences.txt, counter.txt, and splitter.txt.",
      "pos": [
        27057,
        27171
      ]
    },
    {
      "content": "Open each text file and inspect the data.",
      "pos": [
        27172,
        27213
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> String data is persisted as an array of decimal values in these files.",
      "pos": [
        27221,
        27304
      ]
    },
    {
      "content": "For example, \\[[97,103,111]] in the <bpt id=\"p1\">**</bpt>splitter.txt<ept id=\"p1\">**</ept> file is the word 'and'.",
      "pos": [
        27305,
        27381
      ]
    },
    {
      "content": "Although testing a basic word count application locally is pretty trivial, the real value comes when you have a complex topology that communicates with external data sources or performs complex data analysis.",
      "pos": [
        27383,
        27591
      ]
    },
    {
      "content": "When you are working on such a project, you may need to set breakpoints and step through the code in your components to isolate issues.",
      "pos": [
        27592,
        27727
      ]
    },
    {
      "pos": [
        27731,
        27855
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Be sure to set the <bpt id=\"p1\">**</bpt>Project type<ept id=\"p1\">**</ept> back to <bpt id=\"p2\">**</bpt>Class Library<ept id=\"p2\">**</ept> before deploying to a Storm on HDInsight cluster."
    },
    {
      "content": "Log information",
      "pos": [
        27860,
        27875
      ]
    },
    {
      "content": "You can easily log information from your topology components by using <ph id=\"ph1\">`Context.Logger`</ph>.",
      "pos": [
        27877,
        27964
      ]
    },
    {
      "content": "For example, the following will create an informational log entry:",
      "pos": [
        27965,
        28031
      ]
    },
    {
      "content": "Logged information can be viewed from the <bpt id=\"p1\">**</bpt>Hadoop Service Log<ept id=\"p1\">**</ept>, which is found in <bpt id=\"p2\">**</bpt>Server Explorer<ept id=\"p2\">**</ept>.",
      "pos": [
        28084,
        28188
      ]
    },
    {
      "content": "Expand the entry for your Storm on HDInsight cluster, then expand <bpt id=\"p1\">**</bpt>Hadoop Service Log<ept id=\"p1\">**</ept>.",
      "pos": [
        28189,
        28278
      ]
    },
    {
      "content": "Finally, select the log file to view.",
      "pos": [
        28279,
        28316
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The logs are stored in the Azure Storage account that is used by your cluster.",
      "pos": [
        28320,
        28411
      ]
    },
    {
      "content": "If this is a different subscription than the one you are logged in to with Visual Studio, you need to log in to the subscription that contains the storage account to view this information.",
      "pos": [
        28412,
        28600
      ]
    },
    {
      "content": "View error information",
      "pos": [
        28605,
        28627
      ]
    },
    {
      "content": "To view errors that have occurred in a running topology, use the following steps:",
      "pos": [
        28629,
        28710
      ]
    },
    {
      "pos": [
        28716,
        28823
      ],
      "content": "From <bpt id=\"p1\">**</bpt>Server Explorer<ept id=\"p1\">**</ept>, right-click the Storm on HDInsight cluster, and select <bpt id=\"p2\">**</bpt>View Storm topologies<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        28829,
        28946
      ],
      "content": "For the <bpt id=\"p1\">**</bpt>Spout<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>Bolts<ept id=\"p2\">**</ept>, the <bpt id=\"p3\">**</bpt>Last Error<ept id=\"p3\">**</ept> column will have information on the last error that has occurred."
    },
    {
      "content": "Select the <bpt id=\"p1\">**</bpt>Spout Id<ept id=\"p1\">**</ept> or <bpt id=\"p2\">**</bpt>Bolt Id<ept id=\"p2\">**</ept> for the component that has an error listed.",
      "pos": [
        28952,
        29034
      ]
    },
    {
      "content": "On the details page that is displayed, additional error information will be listed in the <bpt id=\"p1\">**</bpt>Errors<ept id=\"p1\">**</ept> section at the bottom of the page.",
      "pos": [
        29035,
        29170
      ]
    },
    {
      "pos": [
        29176,
        29318
      ],
      "content": "To obtain more information, select a <bpt id=\"p1\">**</bpt>Port<ept id=\"p1\">**</ept> from the <bpt id=\"p2\">**</bpt>Executors<ept id=\"p2\">**</ept> section of the page to see the Storm worker log for the last few minutes."
    },
    {
      "content": "Next steps",
      "pos": [
        29322,
        29332
      ]
    },
    {
      "pos": [
        29334,
        29576
      ],
      "content": "Now that you have learned how to develop and deploy Storm topologies from the HDInsight tools for Visual Studio, learn how to <bpt id=\"p1\">[</bpt>Process events from Azure Event Hub with Storm on HDInsight<ept id=\"p1\">](hdinsight-storm-develop-csharp-event-hub-topology.md)</ept>."
    },
    {
      "pos": [
        29578,
        29731
      ],
      "content": "For an example of a C# topology that splits stream data into multiple streams, see <bpt id=\"p1\">[</bpt>C# Storm example<ept id=\"p1\">](https://github.com/Blackmist/csharp-storm-example)</ept>."
    },
    {
      "pos": [
        29733,
        29918
      ],
      "content": "To discover more information about creating C# topologies, visit <bpt id=\"p1\">[</bpt>SCP.NET GettingStarted.md<ept id=\"p1\">](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/SCPNet-GettingStarted.md)</ept>."
    },
    {
      "content": "For more ways to work with HDInsight and more Storm on HDinsight samples, see the following:",
      "pos": [
        29920,
        30012
      ]
    },
    {
      "content": "Apache Storm on HDInsight",
      "pos": [
        30016,
        30041
      ]
    },
    {
      "content": "Deploy and monitor topologies with Apache Storm on HDInsight",
      "pos": [
        30050,
        30110
      ]
    },
    {
      "content": "Example topologies for Storm on HDInsight",
      "pos": [
        30162,
        30203
      ]
    },
    {
      "content": "Apache Hadoop on HDInsight",
      "pos": [
        30245,
        30271
      ]
    },
    {
      "content": "Use Hive with Hadoop on HDInsight",
      "pos": [
        30280,
        30313
      ]
    },
    {
      "content": "Use Pig with Hadoop on HDInsight",
      "pos": [
        30344,
        30376
      ]
    },
    {
      "content": "Use MapReduce with Hadoop on HDInsight",
      "pos": [
        30406,
        30444
      ]
    },
    {
      "content": "Apache HBase on HDInsight",
      "pos": [
        30477,
        30502
      ]
    },
    {
      "content": "Getting started with HBase on HDInsight",
      "pos": [
        30511,
        30550
      ]
    },
    {
      "content": "test",
      "pos": [
        30588,
        30592
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"Apache Storm topologies with Visual Studio and C#  | Microsoft Azure\"\n   description=\"Learn how to create Storm topologies in C# by creating a simple word count topology in Visual Studio using the HDInsight Tools for Visual Studio.\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.devlang=\"java\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"big-data\"\n   ms.date=\"07/21/2015\"\n   ms.author=\"larryfr\"/>\n\n# Develop C# topologies for Apache Storm on HDInsight using Hadoop tools for Visual Studio\n\nLearn how to create a C# Storm topology by using the HDInsight tools for Visual Studio. This tutorial walks through the process of creating a new Storm project in Visual Studio, testing it locally, and deploying it to an Apache Storm on HDInsight cluster.\n\nYou will also learn how to create hybrid topologies that use C# and Java components.\n\n##Prerequisites\n\n-   One of the following versions of Visual Studio\n\n    -   Visual Studio 2012 with [Update 4](http://www.microsoft.com/download/details.aspx?id=39305)\n\n    -   Visual Studio 2013 with [Update 4](http://www.microsoft.com/download/details.aspx?id=44921) or [Visual Studio 2013 Community](http://go.microsoft.com/fwlink/?LinkId=517284)\n\n    -   Visual Studio 2015 or [Visual Studio 2015 Community](https://go.microsoft.com/fwlink/?LinkId=532606)\n\n-   Azure SDK 2.5.1 or later\n\n-   HDInsight Tools for Visual Studio: See [Get started using HDInsight Tools for Visual Studio](hdinsight-hadoop-visual-studio-tools-get-started.md) to install and configure the HDInsight tools for Visual Studio.\n\n    > [AZURE.NOTE] HDInsight Tools for Visual Studio are not supported on Visual Studio Express\n\n-   Apache Storm on HDInsight cluster: See [Getting started with Apache Storm on HDInsight](hdinsight-storm-getting-started.md) for steps to create a cluster.\n\n    > [AZURE.NOTE] Currently, the HDInsight Tools for Visual Studio only support Storm on HDInsight versions 3.2 clusters.\n\n##Templates\n\nThe HDInsight Tools for Visual Studio provide the following templates::\n\n| Project type | Demonstrates |\n| ------------ | ------------- |\n| Storm Application | An empty Storm topology project |\n| Storm Azure SQL Writer Sample | How to write to Azure SQL Database |\n| Storm DocumentDB Reader Sample | How to read from Azure DocumentDB |\n| Storm DocumentDB Writer Sample | How to write to Azure DocumentDB |\n| Storm EventHub Reader Sample | How to read from Azure Event Hubs |\n| Storm EventHub Writer Sample | How to write to Azure Event Hubs |\n| Storm HBase Reader Sample | How to read from HBase on HDInsight clusters |\n| Storm HBase Writer Sample | How to write to HBase on HDInsight clusters |\n| Storm Hybrid Sample | How to use a Java component |\n| Storm Sample | A basic word count topology |\n\n> [AZURE.NOTE] The HBase reader and writer samples use the HBase REST API to communicate with an HBase on HDInsight cluster, not the HBase Java API.\n\nIn the steps in this document, you will use the basic Storm Application project type to create a new topology.\n\n##Create a C# topology\n\n1.  If you have not already installed the latest version of the HDInsight Tools for Visual Studio, see [Get started using HDInsight Tools for Visual Studio](hdinsight-hadoop-visual-studio-tools-get-started.md).\n\n2.  Open Visual Studio, select **File** > **New**, and then **Project**.\n\n3.  From the **New Project** screen, expand **Installed** > **Templates**, and select **HDInsight**. From the list of templates, select **Storm Application**. At the bottom of the screen, enter **WordCount** as the name of the application.\n\n    ![image](./media/hdinsight-storm-develop-csharp-visual-studio-topology/new-project.png)\n\n4.  After the project has been created, you should have the following files:\n\n    -   **Program.cs**: This defines the topology for your project. Note that a default topology that consists of one spout and one bolt is created by default.\n\n    -   **Spout.cs**: An example spout that emits random numbers.\n\n    -   **Bolt.cs**: An example bolt that keeps a count of numbers emitted by the spout.\n\n    As part of project creation, the latest [SCP.NET packages](https://www.nuget.org/packages/Microsoft.SCP.Net.SDK/) will be downloaded from NuGet.\n\nIn the next sections, you will modify this project into a basic WordCount application.\n\n###Implement the spout\n\n1.  Open **Spout.cs**. Spouts are used to read data in a topology from an external source. The main components for a spout are:\n\n    -   **NextTuple**: Called by Storm when the spout is allowed to emit new tuples.\n\n    -   **Ack** (transactional topology only): Handles acknowledgements initiated by other components in the topology for tuples sent from this spout. Acknowledging a tuple lets the spout know that it was processed successfully by downstream components.\n\n    -   **Fail** (transactional topology only): Handles tuples that are fail-processing other components in the topology. This provides the opportunity to re-emit the tuple so that it can be processed again.\n\n2.  Replace the contents of the **Spout** class with the following. This creates a spout that randomly emits a sentence into the topology.\n\n    ```\n    private Context ctx;\n    private Random r = new Random();\n    string[] sentences = new string[] {\n        \"the cow jumped over the moon\",\n        \"an apple a day keeps the doctor away\",\n        \"four score and seven years ago\",\n        \"snow white and the seven dwarfs\",\n        \"i am at two with nature\"\n    };\n\n\n    public Spout(Context ctx)\n    {\n        // Set the instance context\n        this.ctx = ctx;\n\n\n        Context.Logger.Info(\"Generator constructor called\");\n\n\n        // Declare Output schema\n        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();\n        // The schema for the default output stream is\n        // a tuple that contains a string field\n        outputSchema.Add(\"default\", new List<Type>() { typeof(string) });\n        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(null, outputSchema));\n    }\n\n\n    // Get an instance of the spout\n    public static Spout Get(Context ctx, Dictionary<string, Object> parms)\n    {\n        return new Spout(ctx);\n    }\n\n\n    public void NextTuple(Dictionary<string, Object> parms)\n    {\n        Context.Logger.Info(\"NextTuple enter\");\n        // The sentence to be emitted\n        string sentence;\n\n\n        // Get a random sentence\n        sentence = sentences[r.Next(0, sentences.Length - 1)];\n        Context.Logger.Info(\"Emit: {0}\", sentence);\n        // Emit it\n        this.ctx.Emit(new Values(sentence));\n\n\n        Context.Logger.Info(\"NextTuple exit\");\n    }\n\n\n    public void Ack(long seqId, Dictionary<string, Object> parms)\n    {\n        // Only used for transactional topologies\n    }\n\n\n    public void Fail(long seqId, Dictionary<string, Object> parms)\n    {\n        // Only used for transactional topologies\n    }\n    ```\n\n    Take a moment to read through the comments to understand what this code does.\n\n###Implement the bolts\n\n1.  Delete the existing **Bolt.cs** file from the project.\n\n2.  In **Solution Explorer**, right-click the project and select **Add** > **New item**. From the list, select **Storm Bolt**, and enter **Splitter.cs** as the name. Repeat this to create a second bolt named **Counter.cs**.\n\n    -   **Splitter.cs**: Implements a bolt that splits sentences into individual words and emits a new stream of words.\n\n    -   **Counter.cs**: Implements a bolt that counts each word and emits a new stream of words and the count for each word.\n\n    > [AZURE.NOTE] These bolts simply read and write to streams, but you can also use a bolt to communicate with sources such as a database or service.\n\n3.  Open **Splitter.cs**. Note that it has only one method by default: **Execute**. This is called when the bolt receives a tuple for processing. Here, you can read and process incoming tuples, and emit outbound tuples.\n\n4.  Replace the contents of the **Splitter** class with the following code:\n\n    ```\n    private Context ctx;\n\n\n    // Constructor\n    public Splitter(Context ctx)\n    {\n        Context.Logger.Info(\"Splitter constructor called\");\n        this.ctx = ctx;\n\n\n        // Declare Input and Output schemas\n        Dictionary<string, List<Type>> inputSchema = new Dictionary<string, List<Type>>();\n        // Input contains a tuple with a string field (the sentence)\n        inputSchema.Add(\"default\", new List<Type>() { typeof(string) });\n        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();\n        // Outbound contains a tuple with a string field (the word)\n        outputSchema.Add(\"default\", new List<Type>() { typeof(string) });\n        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(inputSchema, outputSchema));\n    }\n\n\n    // Get a new instance of the bolt\n    public static Splitter Get(Context ctx, Dictionary<string, Object> parms)\n    {\n        return new Splitter(ctx);\n    }\n\n\n    // Called when a new tuple is available\n    public void Execute(SCPTuple tuple)\n    {\n        Context.Logger.Info(\"Execute enter\");\n\n\n        // Get the sentence from the tuple\n        string sentence = tuple.GetString(0);\n        // Split at space characters\n        foreach (string word in sentence.Split(' '))\n        {\n            Context.Logger.Info(\"Emit: {0}\", word);\n            //Emit each word\n            this.ctx.Emit(new Values(word));\n        }\n\n\n        Context.Logger.Info(\"Execute exit\");\n    }\n    ```\n\n    Take a moment to read through the comments to understand what this code does.\n\n5.  Open **Counter.cs** and replace the class contents with the following:\n\n    ```\n    private Context ctx;\n\n\n    // Dictionary for holding words and counts\n    private Dictionary<string, int> counts = new Dictionary<string, int>();\n\n\n    // Constructor\n    public Counter(Context ctx)\n    {\n        Context.Logger.Info(\"Counter constructor called\");\n        // Set instance context\n        this.ctx = ctx;\n\n\n        // Declare Input and Output schemas\n        Dictionary<string, List<Type>> inputSchema = new Dictionary<string, List<Type>>();\n        // A tuple containing a string field - the word\n        inputSchema.Add(\"default\", new List<Type>() { typeof(string) });\n\n\n        Dictionary<string, List<Type>> outputSchema = new Dictionary<string, List<Type>>();\n        // A tuple containing a string and integer field - the word and the word count\n        outputSchema.Add(\"default\", new List<Type>() { typeof(string), typeof(int) });\n        this.ctx.DeclareComponentSchema(new ComponentStreamSchema(inputSchema, outputSchema));\n    }\n\n\n    // Get a new instance\n    public static Counter Get(Context ctx, Dictionary<string, Object> parms)\n    {\n        return new Counter(ctx);\n    }\n\n\n    // Called when a new tuple is available\n    public void Execute(SCPTuple tuple)\n    {\n        Context.Logger.Info(\"Execute enter\");\n\n\n        // Get the word from the tuple\n        string word = tuple.GetString(0);\n        // Do we already have an entry for the word in the dictionary?\n        // If no, create one with a count of 0\n        int count = counts.ContainsKey(word) ? counts[word] : 0;\n        // Increment the count\n        count++;\n        // Update the count in the dictionary\n        counts[word] = count;\n\n\n        Context.Logger.Info(\"Emit: {0}, count: {1}\", word, count);\n        // Emit the word and count information\n        this.ctx.Emit(Constants.DEFAULT_STREAM_ID, new List<SCPTuple> { tuple }, new Values(word, count));\n\n\n        Context.Logger.Info(\"Execute exit\");\n    }\n    ```\n\n    Take a moment to read through the comments to understand what this code does.\n\n###Define the topology\n\nSpouts and bolts are arranged in a graph, which defines how the data flows between components. For this topology, the graph is as follows:\n\n![image of how components are arranged](./media/hdinsight-storm-develop-csharp-visual-studio-topology/wordcount-topology.png)\n\nSentences are emitted from the spout, which are distributed to instances of the Splitter bolt. The Splitter bolt breaks the sentences into words, which are distributed to the Counter bolt.\n\nBecause word count is held locally in the Counter instance, we want to make sure that specific words flow to the same Counter bolt instance, so we have only one instance keeping track of a specific word. But for the Splitter bolt, it really doesn't matter which bolt receives which sentence, so we simply want to load balance sentences across those instances.\n\nOpen **Program.cs**. The important method is **ITopologyBuilder**, which is used to define the topology that is submitted to Storm. Replace the contents of **ITopologyBuilder** with the following code to implement the topology described previously:\n\n```\n    // Create a new topology named 'WordCount'\n    TopologyBuilder topologyBuilder = new TopologyBuilder(\"WordCount\");\n\n    // Add the spout to the topology.\n    // Name the component 'sentences'\n    // Name the field that is emitted as 'sentence'\n    topologyBuilder.SetSpout(\n        \"sentences\",\n        Spout.Get,\n        new Dictionary<string, List<string>>()\n        {\n            {Constants.DEFAULT_STREAM_ID, new List<string>(){\"sentence\"}}\n        },\n        1);\n    // Add the splitter bolt to the topology.\n    // Name the component 'splitter'\n    // Name the field that is emitted 'word'\n    // Use suffleGrouping to distribute incoming tuples\n    //   from the 'sentences' spout across instances\n    //   of the splitter\n    topologyBuilder.SetBolt(\n        \"splitter\",\n        Splitter.Get,\n        new Dictionary<string, List<string>>()\n        {\n            {Constants.DEFAULT_STREAM_ID, new List<string>(){\"word\"}}\n        },\n        1).shuffleGrouping(\"sentences\");\n\n    // Add the counter bolt to the topology.\n    // Name the component 'counter'\n    // Name the fields that are emitted 'word' and 'count'\n    // Use fieldsGrouping to ensure that tuples are routed\n    //   to counter instances based on the contents of field\n    //   position 0 (the word). This could also have been\n    //   List<string>(){\"word\"}.\n    //   This ensures that the word 'jumped', for example, will always\n    //   go to the same instance\n    topologyBuilder.SetBolt(\n        \"counter\",\n        Counter.Get,\n        new Dictionary<string, List<string>>()\n        {\n            {Constants.DEFAULT_STREAM_ID, new List<string>(){\"word\", \"count\"}}\n        },\n        1).fieldsGrouping(\"splitter\", new List<int>() { 0 });\n\n    // Add topology config\n    topologyBuilder.SetTopologyConfig(new Dictionary<string, string>()\n    {\n        {\"topology.kryo.register\",\"[\\\"[B\\\"]\"}\n    });\n\n    return topologyBuilder;\n```\n\nTake a moment to read through the comments to understand what this code does.\n\n##Submit the topology\n\n1.  In **Solution Explorer**, right-click the project, and select **Submit to Storm on HDInsight**.\n\n    > [AZURE.NOTE] If prompted, enter the login credentials for your Azure subscription. If you have more than one subscription, log in to the one that contains your Storm on HDInsight cluster.\n\n2.  Select your Storm on HDInsight cluster from the **Storm Cluster** drop-down list, and then select **Submit**. You can monitor if the submission is successful by using the **Output** window.\n\n3.  When the topology has been successfully submitted, the **Storm Topologies** for the cluster should appear. Select the **WordCount** topology from the list to view information about the running topology.\n\n    > [AZURE.NOTE] You can also view **Storm Topologies** from **Server Explorer**: Expand **Azure** > **HDInsight**, right-click a Storm on HDInsight cluster, and then select **View Storm Topologies**.\n\n    Use the links for the spouts or bolts to view information about these components. A new window will be opened for each item selected.\n\n4.  From the **Topology Summary** view, click **Kill** to stop the topology.\n\n    > [AZURE.NOTE] Storm topologies continue to run until they are deactivated, or the cluster is deleted.\n\n##Transactional topology\n\nThe previous topology is non-transactional. The components within the topology do not implement any functionality for replaying messages if processing fails by a component in the topology. For an example transactional topology, create a new project and select **Storm Sample** as the project type.\n\nTransactional topologies implement the following to support replay of data:\n\n-   **Metadata caching**: The spout must store metadata about the data emitted so that the data can be retrieved and emitted again if a failure occurs. Because the data emitted by the sample is small, the raw data for each tuple is stored in a dictionary for replay.\n\n-   **Ack**: Each bolt in the topology can call `this.ctx.Ack(tuple)` to ack that it has successfully processed a tuple. When all bolts have acked the tuple, the `Ack` method of the spout is invoked. This allows the spout to remove cached data for replay because the data was completely processed.\n\n-   **Fail**: Each bolt can call `this.ctx.Fail(tuple)` to indicate that processing has failed for a tuple. The failure propagates to the `Fail` method of the spout, where the tuple can be replayed by using cached metadata.\n\n-   **Sequence ID**: When emitting a tuple, a sequence ID can be specified. This should be a value that identifies the tuple for replay (Ack and Fail) processing. For example, the spout in the **Storm Sample** project uses the following when emitting data:\n\n    ```\n    this.ctx.Emit(Constants.DEFAULT_STREAM_ID, new Values(sentence), lastSeqId);\n    ```\n\n    This emits a new tuple that contains a sentence to the default stream, with the sequence ID value contained in **lastSeqId**. For this example, **lastSeqId** is simply incremented for every tuple emitted.\n\nAs demonstrated in the **Storm Sample** project, whether a component is transactional can be set at run time, based on configuration.\n\n##Hybrid topology\n\nHDInsight tools for Visual Studio can also be used to create hybrid topologies, where some components are C# and others are Java.\n\nFor an example hybrid topology, create a new project, and select **Storm Hybrid Sample**. This creates a fully commented sample that contains several topologies that demonstrate the following:\n\n-   **Java spout** and **C# bolt**: Defined in **HybridTopology_javaSpout_csharpBolt**\n\n    -   A transactional version is defined in **HybridTopologyTx_javaSpout_csharpBolt**\n\n-   **C# spout** and **Java bolt**: Defined in **HybridTopology_csharpSpout_javaBolt**\n\n    -   A transactional version is defined in **HybridTopologyTx_csharpSpout_javaBolt**\n\n        > [AZURE.NOTE] This version also demonstrates how to use Clojure code from a text file as a Java component.\n\nTo switch between the topology that is used when the project is submitted, simply move the `[Active(true)]` statement to the topology you want to use before submitting it to the cluster.\n\n> [AZURE.NOTE] All the Java files that are required are provided as part of this project in the **JavaDependency** folder.\n\nConsider the following when creating and submitting a hybrid topology:\n\n-   **JavaComponentConstructor** must be used to create a new instance of the Java class for a spout or bolt.\n\n-   **microsoft.scp.storm.multilang.CustomizedInteropJSONSerializer** should be used to serialize data in to or out of Java components from Java objects to JSON.\n\n-   When submitting the topology to the server, you must use the **Additional configurations** option to specify the **Java File paths**. The path specified should be the directory that contains the JAR files that contain your Java classes.\n\n###Azure Event Hubs\n\nSCP.Net version 0.9.4.203 introduces a new class and method specifically for working with the Event Hub Spout (a Java spout that reads from Event Hub.) When creating a topology that uses this spout, use the following methods:\n\n-   **EventHubSpoutConfig** class: creates an object that contains the configuration for the spout component\n\n-   **TopologyBuilder.SetEventHubSpout** method: adds the Event Hub Spout component to the topology\n\n> [AZURE.NOTE] While these make it easier to work with the Event Hub Spout than other Java components, you must still use the CustomizedInteropJSONSerializer to serialize data produced by the spout.\n\n##How to update SCP.NET\n\nRecent releases of SCP.NET support package upgrade through NuGet. When a new update is available, you will receive an upgrade notification. To manually check for an upgrade, perform these steps:\n\n1. In **Solution Explorer**, right-click the project and select **Manage NuGet Packages**.\n\n2. From the package manager, select **Updates**. If an update is available, it will be listed. Click the **Update** button for the package to install it.\n\n> [AZURE.IMPORTANT] If your project was created with one of the earlier versions of SCP.NET that did not use NuGet for package updates, you must perform the following steps to update to the new version:\n>\n> 1. In **Solution Explorer**, right-click the project and select **Manage NuGet Packages**.\n> 2. Using the **Search** field, search for, and then add, **Microsoft.SCP.Net.SDK** to the project.\n\n##Troubleshooting\n\n###Test a topology locally\n\nAlthough it is easy to deploy a topology to a cluster, in some cases, you may need to test a topology locally. Use the following steps to run and test the example topology in this tutorial locally in your development environment.\n\n> [AZURE.WARNING] Local testing only works for basic, C# only topologies. You should not use local testing for hybrid topologies or topologies that use multiple streams, as you will receive errors.\n\n1.  In **Solution Explorer**, right-click the project, and select **Properties**. In the project properties, change the **Output type** to **Console Application**.\n\n    ![output type](./media/hdinsight-storm-develop-csharp-visual-studio-topology/outputtype.png)\n\n    > [AZURE.NOTE] Remember to change the **Output type** back to **Class Library** before you deploy the topology to a cluster.\n\n2.  In **Solution Explorer**, right-click the project, then select **Add** > **New Item**. Select **Class** and enter **LocalTest.cs** as the class name. Finally, click **Add**.\n\n3.  Open **LocalTest.cs** and add the following **using** statement at the top:\n\n    ```\n    using Microsoft.SCP;\n    ```\n\n4.  Use the following as the contents of the **LocalTest** class:\n\n    ```\n    // Drives the topology components\n    public void RunTestCase()\n    {\n        // An empty dictionary for use when creating components\n        Dictionary<string, Object> emptyDictionary = new Dictionary<string, object>();\n\n\n        #region Test the spout\n        {\n            Console.WriteLine(\"Starting spout\");\n            // LocalContext is a local-mode context that can be used to initialize\n            // components in the development environment.\n            LocalContext spoutCtx = LocalContext.Get();\n            // Get a new instance of the spout, using the local context\n            Spout sentences = Spout.Get(spoutCtx, emptyDictionary);\n\n\n            // Emit 10 tuples\n            for (int i = 0; i < 10; i++)\n            {\n                sentences.NextTuple(emptyDictionary);\n            }\n            // Use LocalContext to persist the data stream to file\n            spoutCtx.WriteMsgQueueToFile(\"sentences.txt\");\n            Console.WriteLine(\"Spout finished\");\n        }\n        #endregion\n\n\n        #region Test the splitter bolt\n        {\n            Console.WriteLine(\"Starting splitter bolt\");\n            // LocalContext is a local-mode context that can be used to initialize\n            // components in the development environment.\n            LocalContext splitterCtx = LocalContext.Get();\n            // Get a new instance of the bolt\n            Splitter splitter = Splitter.Get(splitterCtx, emptyDictionary);\n\n\n            // Set the data stream to the data created by the spout\n            splitterCtx.ReadFromFileToMsgQueue(\"sentences.txt\");\n            // Get a batch of tuples from the stream\n            List<SCPTuple> batch = splitterCtx.RecvFromMsgQueue();\n            // Process each tuple in the batch\n            foreach (SCPTuple tuple in batch)\n            {\n                splitter.Execute(tuple);\n            }\n            // Use LocalContext to persist the data stream to file\n            splitterCtx.WriteMsgQueueToFile(\"splitter.txt\");\n            Console.WriteLine(\"Splitter bolt finished\");\n        }\n        #endregion\n\n\n        #region Test the counter bolt\n        {\n            Console.WriteLine(\"Starting counter bolt\");\n            // LocalContext is a local-mode context that can be used to initialize\n            // components in the development environment.\n            LocalContext counterCtx = LocalContext.Get();\n            // Get a new instance of the bolt\n            Counter counter = Counter.Get(counterCtx, emptyDictionary);\n\n\n            // Set the data stream to the data created by splitter bolt\n            counterCtx.ReadFromFileToMsgQueue(\"splitter.txt\");\n            // Get a batch of tuples from the stream\n            List<SCPTuple> batch = counterCtx.RecvFromMsgQueue();\n            // Process each tuple in the batch\n            foreach (SCPTuple tuple in batch)\n            {\n                counter.Execute(tuple);\n            }\n            // Use LocalContext to persist the data stream to file\n            counterCtx.WriteMsgQueueToFile(\"counter.txt\");\n            Console.WriteLine(\"Counter bolt finished\");\n        }\n        #endregion\n    }\n    ```\n\n    Take a moment to read through the code comments. This code uses **LocalContext** to run the components in the development environment, and it persists the data stream between components to text files on the local drive.\n\n5.  Open **Program.cs** and add the following to the **Main** method:\n\n    ```\n    Console.WriteLine(\"Starting tests\");\n    System.Environment.SetEnvironmentVariable(\"microsoft.scp.logPrefix\", \"WordCount-LocalTest\");\n    // Initialize the runtime\n    SCPRuntime.Initialize();\n\n\n    //If we are not running under the local context, throw an error\n    if (Context.pluginType != SCPPluginType.SCP_NET_LOCAL)\n    {\n        throw new Exception(string.Format(\"unexpected pluginType: {0}\", Context.pluginType));\n    }\n    // Create test instance\n    LocalTest tests = new LocalTest();\n    // Run tests\n    tests.RunTestCase();\n    Console.WriteLine(\"Tests finished\");\n    Console.ReadKey();\n    ```\n\n6.  Save the changes, then click **F5** or select **Debug** > **Start Debugging** to start the project. A console window should appear, and log status as the tests progress. When **Tests finished** appears, press any key to close the window.\n\n7.  Use **Windows Explorer** to locate the directory that contains your project, for example, **C:\\Users\\<your_user_name>\\Documents\\Visual Studio 2013\\Projects\\WordCount\\WordCount**. In this directory, open **Bin**, and then click **Debug**. You should see the text files that were produced when the tests ran: sentences.txt, counter.txt, and splitter.txt. Open each text file and inspect the data.\n\n    > [AZURE.NOTE] String data is persisted as an array of decimal values in these files. For example, \\[[97,103,111]] in the **splitter.txt** file is the word 'and'.\n\nAlthough testing a basic word count application locally is pretty trivial, the real value comes when you have a complex topology that communicates with external data sources or performs complex data analysis. When you are working on such a project, you may need to set breakpoints and step through the code in your components to isolate issues.\n\n> [AZURE.NOTE] Be sure to set the **Project type** back to **Class Library** before deploying to a Storm on HDInsight cluster.\n\n###Log information\n\nYou can easily log information from your topology components by using `Context.Logger`. For example, the following will create an informational log entry:\n\n```\nContext.Logger.Info(\"Component started\");\n```\n\nLogged information can be viewed from the **Hadoop Service Log**, which is found in **Server Explorer**. Expand the entry for your Storm on HDInsight cluster, then expand **Hadoop Service Log**. Finally, select the log file to view.\n\n> [AZURE.NOTE] The logs are stored in the Azure Storage account that is used by your cluster. If this is a different subscription than the one you are logged in to with Visual Studio, you need to log in to the subscription that contains the storage account to view this information.\n\n###View error information\n\nTo view errors that have occurred in a running topology, use the following steps:\n\n1.  From **Server Explorer**, right-click the Storm on HDInsight cluster, and select **View Storm topologies**.\n\n2.  For the **Spout** and **Bolts**, the **Last Error** column will have information on the last error that has occurred.\n\n3.  Select the **Spout Id** or **Bolt Id** for the component that has an error listed. On the details page that is displayed, additional error information will be listed in the **Errors** section at the bottom of the page.\n\n4.  To obtain more information, select a **Port** from the **Executors** section of the page to see the Storm worker log for the last few minutes.\n\n##Next steps\n\nNow that you have learned how to develop and deploy Storm topologies from the HDInsight tools for Visual Studio, learn how to [Process events from Azure Event Hub with Storm on HDInsight](hdinsight-storm-develop-csharp-event-hub-topology.md).\n\nFor an example of a C# topology that splits stream data into multiple streams, see [C# Storm example](https://github.com/Blackmist/csharp-storm-example).\n\nTo discover more information about creating C# topologies, visit [SCP.NET GettingStarted.md](https://github.com/hdinsight/hdinsight-storm-examples/blob/master/SCPNet-GettingStarted.md).\n\nFor more ways to work with HDInsight and more Storm on HDinsight samples, see the following:\n\n**Apache Storm on HDInsight**\n\n-   [Deploy and monitor topologies with Apache Storm on HDInsight](hdinsight-storm-deploy-monitor-topology.md)\n\n-   [Example topologies for Storm on HDInsight](hdinsight-storm-example-topology.md)\n\n**Apache Hadoop on HDInsight**\n\n-   [Use Hive with Hadoop on HDInsight](hdinsight-use-hive.md)\n\n-   [Use Pig with Hadoop on HDInsight](hdinsight-use-pig.md)\n\n-   [Use MapReduce with Hadoop on HDInsight](hdinsight-use-mapreduce.md)\n\n**Apache HBase on HDInsight**\n\n-   [Getting started with HBase on HDInsight](../hdinsight-hbase-get-started.md)\n\ntest\n"
}