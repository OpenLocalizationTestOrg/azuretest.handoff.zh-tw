<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Feature Engineering and Selection in Azure Machine Learning | Microsoft Azure</source>
          <target state="new">Feature Engineering and Selection in Azure Machine Learning | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Explains the purposes of feature selection and feature engineering and provides examples of their role in the data enhancement process of machine learning.</source>
          <target state="new">Explains the purposes of feature selection and feature engineering and provides examples of their role in the data enhancement process of machine learning.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Feature engineering and selection in Azure Machine Learning</source>
          <target state="new">Feature engineering and selection in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This topic explains the purposes of feature engineering and feature selection in the data enhancement process of machine learning.</source>
          <target state="new">This topic explains the purposes of feature engineering and feature selection in the data enhancement process of machine learning.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>It illustrates what these processes involve using examples provided by Azure Machine Learning Studio.</source>
          <target state="new">It illustrates what these processes involve using examples provided by Azure Machine Learning Studio.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The training data used in machine learning can often be enhanced by the selection or extraction of features from the raw data collected.</source>
          <target state="new">The training data used in machine learning can often be enhanced by the selection or extraction of features from the raw data collected.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>A  example of an engineered feature in the context of learning how to classify the images of handwritten characters is a bit density map constructed from the raw bit distribution data.</source>
          <target state="new">A  example of an engineered feature in the context of learning how to classify the images of handwritten characters is a bit density map constructed from the raw bit distribution data.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This map can help locate the edges of the characters more efficiently than the raw distribution.</source>
          <target state="new">This map can help locate the edges of the characters more efficiently than the raw distribution.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</source>
          <target state="new">Engineered and selected features increase the efficiency of the training process which attempts to extract the key information contained in the data.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</source>
          <target state="new">They also improve the power of these models to classify the input data accurately and to predict outcomes of interest more robustly.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Feature engineering and selection can also combine to make the learning more computationally tractable.</source>
          <target state="new">Feature engineering and selection can also combine to make the learning more computationally tractable.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</source>
          <target state="new">It does so by enhancing and then reducing the number of features needed to calibrate or train a model.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</source>
          <target state="new">Mathematically speaking, the features selected to train the model are a minimal set of independent variables that explain the patterns in the data and then predict outcomes successfully.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The engineering and selection of features is one part of a larger process, which typically consists of four steps:</source>
          <target state="new">The engineering and selection of features is one part of a larger process, which typically consists of four steps:</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>data collection</source>
          <target state="new">data collection</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>data enhancement</source>
          <target state="new">data enhancement</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>model construction</source>
          <target state="new">model construction</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>post-processing</source>
          <target state="new">post-processing</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Engineering and selection are the <bpt id="p1">**</bpt>data enhancement<ept id="p1">**</ept> step of machine learning.</source>
          <target state="new">Engineering and selection are the <bpt id="p1">**</bpt>data enhancement<ept id="p1">**</ept> step of machine learning.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Three aspects of this process may be distinguished for our purposes:</source>
          <target state="new">Three aspects of this process may be distinguished for our purposes:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>data pre-processing<ept id="p1">**</ept>: This process tries to insure that the collected data is clean and consistent.</source>
          <target state="new"><bpt id="p1">**</bpt>data pre-processing<ept id="p1">**</ept>: This process tries to insure that the collected data is clean and consistent.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>It includes tasks such as integrating multiple datasets, handling missing data, handling inconsistent data, and converting data types.</source>
          <target state="new">It includes tasks such as integrating multiple datasets, handling missing data, handling inconsistent data, and converting data types.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>feature engineering<ept id="p1">**</ept>: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</source>
          <target state="new"><bpt id="p1">**</bpt>feature engineering<ept id="p1">**</ept>: This process attempts to create additional relevant features from the existing raw features in the data, and to increase predictive power to the learning algorithm.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>feature selection<ept id="p1">**</ept>: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</source>
          <target state="new"><bpt id="p1">**</bpt>feature selection<ept id="p1">**</ept>: This process selects the key subset of original data features in an attempt to reduce the dimensionality of the training problem.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This topic only covers the feature engineering and feature selection aspects of the data enhancement process.</source>
          <target state="new">This topic only covers the feature engineering and feature selection aspects of the data enhancement process.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>For additional information on the data pre-processing step, see the <bpt id="p1">[</bpt>Pre-processing Data in Azure ML Studio<ept id="p1">](http://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/)</ept> video.</source>
          <target state="new">For additional information on the data pre-processing step, see the <bpt id="p1">[</bpt>Pre-processing Data in Azure ML Studio<ept id="p1">](http://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/)</ept> video.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Creating Features from Your Data - Feature Engineering</source>
          <target state="new">Creating Features from Your Data - Feature Engineering</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</source>
          <target state="new">The training data consists of a matrix composed of examples (records or observations stored in rows), each of which has a set of features (variables or fields stored in columns).</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The features specified in the experimental design are expected to characterize the patterns in the data.</source>
          <target state="new">The features specified in the experimental design are expected to characterize the patterns in the data.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Although many of the raw data fields can be directly included in the selected feature set used to train a model, it is often the case that additional (engineered) features need to be constructed from the features in the raw data to generate an enhanced training dataset.</source>
          <target state="new">Although many of the raw data fields can be directly included in the selected feature set used to train a model, it is often the case that additional (engineered) features need to be constructed from the features in the raw data to generate an enhanced training dataset.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>What kind of features should be created to enhance the dataset when training a model?</source>
          <target state="new">What kind of features should be created to enhance the dataset when training a model?</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Engineered features that enhance the training provide information that better differentiates the patterns in the data.</source>
          <target state="new">Engineered features that enhance the training provide information that better differentiates the patterns in the data.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>We expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set.</source>
          <target state="new">We expect the new features to provide additional information that is not clearly captured or easily apparent in the original or existing feature set.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>But this process is something of an art.</source>
          <target state="new">But this process is something of an art.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Sound and productive decisions often require some domain expertise.</source>
          <target state="new">Sound and productive decisions often require some domain expertise.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>When starting with Azure Machine Learning, it is easiest to grasp this process concretely using samples provided in the Studio.</source>
          <target state="new">When starting with Azure Machine Learning, it is easiest to grasp this process concretely using samples provided in the Studio.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Two examples are presented here:</source>
          <target state="new">Two examples are presented here:</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>A regression example <bpt id="p1">[</bpt>Prediction of the number of bike rentals<ept id="p1">](../machine-learning-sample-prediction-of-number-of-bike-rentals.md)</ept> in a supervised experiment where the target values are known</source>
          <target state="new">A regression example <bpt id="p1">[</bpt>Prediction of the number of bike rentals<ept id="p1">](../machine-learning-sample-prediction-of-number-of-bike-rentals.md)</ept> in a supervised experiment where the target values are known</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>A text mining classification example using [Feature Hashing][feature-hashing]</source>
          <target state="new">A text mining classification example using [Feature Hashing][feature-hashing]</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Example 1: Adding Temporal Features for Regression Model</source>
          <target state="new">Example 1: Adding Temporal Features for Regression Model</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio to demonstrate how to engineer features for a regression task.</source>
          <target state="new">Let's use the experiment "Demand forecasting of bikes" in Azure Machine Learning Studio to demonstrate how to engineer features for a regression task.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month/day/hour.</source>
          <target state="new">The objective of this experiment is to predict the demand for the bikes, that is, the number of bike rentals within a specific month/day/hour.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The dataset "Bike Rental UCI dataset" is used as the raw input data.</source>
          <target state="new">The dataset "Bike Rental UCI dataset" is used as the raw input data.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>This dataset is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</source>
          <target state="new">This dataset is based on real data from the Capital Bikeshare company that maintains a bike rental network in Washington DC in the United States.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The dataset represents the number of bike rentals within a specific hour of a day in the years 2011 and year 2012 and contains 17379 rows and 17 columns.</source>
          <target state="new">The dataset represents the number of bike rentals within a specific hour of a day in the years 2011 and year 2012 and contains 17379 rows and 17 columns.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The raw feature set contains weather conditions (temperature/humidity/wind speed) and the type of the day (holiday/weekday).</source>
          <target state="new">The raw feature set contains weather conditions (temperature/humidity/wind speed) and the type of the day (holiday/weekday).</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The field to predict is "cnt", a count which represents the bike rentals within a specific hour and which ranges ranges from 1 to 977.</source>
          <target state="new">The field to predict is "cnt", a count which represents the bike rentals within a specific hour and which ranges ranges from 1 to 977.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>With the goal of constructing effective features in the training data, four regression models are built using the same algorithm but with four different training datasets.</source>
          <target state="new">With the goal of constructing effective features in the training data, four regression models are built using the same algorithm but with four different training datasets.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The four datasets represent the same raw input data, but with an increasing number of features set.</source>
          <target state="new">The four datasets represent the same raw input data, but with an increasing number of features set.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>These features are grouped into four categories:</source>
          <target state="new">These features are grouped into four categories:</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>A = weather + holiday + weekday + weekend features for the predicted day</source>
          <target state="new">A = weather + holiday + weekday + weekend features for the predicted day</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>B = number of bikes that were rented in each of the previous 12 hours</source>
          <target state="new">B = number of bikes that were rented in each of the previous 12 hours</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>C = number of bikes that were rented in each of the previous 12 days at the same hour</source>
          <target state="new">C = number of bikes that were rented in each of the previous 12 days at the same hour</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</source>
          <target state="new">D = number of bikes that were rented in each of the previous 12 weeks at the same hour and the same day</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Besides feature set A, which already exist in the original raw data, the other three sets of features are created through the feature engineering process.</source>
          <target state="new">Besides feature set A, which already exist in the original raw data, the other three sets of features are created through the feature engineering process.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Feature set B captures very recent demand for the bikes.</source>
          <target state="new">Feature set B captures very recent demand for the bikes.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Feature set C captures the demand for bikes at a particular hour.</source>
          <target state="new">Feature set C captures the demand for bikes at a particular hour.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Feature set D captures demand for bikes at particular hour and particular day of the week.</source>
          <target state="new">Feature set D captures demand for bikes at particular hour and particular day of the week.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>The four training datasets each includes feature set A, A+B, A+B+C, and A+B+C+D, respectively.</source>
          <target state="new">The four training datasets each includes feature set A, A+B, A+B+C, and A+B+C+D, respectively.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>In the Azure Machine Learning experiment, these four training datasets are formed via four branches from the pre-processed input dataset.</source>
          <target state="new">In the Azure Machine Learning experiment, these four training datasets are formed via four branches from the pre-processed input dataset.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Except the left most branch, each of these branches contains an [Execute R Script][execute-r-script] module, in which a set of derived features (feature set B, C, and D) are respectively constructed and appended to the imported dataset.</source>
          <target state="new">Except the left most branch, each of these branches contains an [Execute R Script][execute-r-script] module, in which a set of derived features (feature set B, C, and D) are respectively constructed and appended to the imported dataset.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>The following figure demonstrates the R script used to create feature set B in the second left branch.</source>
          <target state="new">The following figure demonstrates the R script used to create feature set B in the second left branch.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>create features</source>
          <target state="new">create features</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The comparison of the performance results of the four models are summarized in the following table.</source>
          <target state="new">The comparison of the performance results of the four models are summarized in the following table.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The best results are shown by features A+B+C.</source>
          <target state="new">The best results are shown by features A+B+C.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Note that the error rate decreases when additional feature set are included in the training data.</source>
          <target state="new">Note that the error rate decreases when additional feature set are included in the training data.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>It verifies our presumption that the feature set B, C provide additional relevant information for the regression task.</source>
          <target state="new">It verifies our presumption that the feature set B, C provide additional relevant information for the regression task.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>But adding the D feature does not seem to provide any additional reduction in the error rate.</source>
          <target state="new">But adding the D feature does not seem to provide any additional reduction in the error rate.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>result comparison</source>
          <target state="new">result comparison</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="example2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Example 2: Creating Features in Text Mining</source>
          <target state="new"><ph id="ph1">&lt;a name="example2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Example 2: Creating Features in Text Mining</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</source>
          <target state="new">Feature engineering is widely applied in tasks related to text mining, such as document classification and sentiment analysis.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>For example, when we want to classify documents into several categories, a typical assumption is that the word/phrases included in one doc category are less likely to occur in another doc category.</source>
          <target state="new">For example, when we want to classify documents into several categories, a typical assumption is that the word/phrases included in one doc category are less likely to occur in another doc category.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>In another words, the frequency of the words/phrases distribution is able to characterize different document categories.</source>
          <target state="new">In another words, the frequency of the words/phrases distribution is able to characterize different document categories.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>In text mining applications, because individual pieces of text-contents usually serve as the input data, the feature engineering process is needed to create the features involving word/phrase frequencies.</source>
          <target state="new">In text mining applications, because individual pieces of text-contents usually serve as the input data, the feature engineering process is needed to create the features involving word/phrase frequencies.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>To achieve this task, a technique called <bpt id="p1">**</bpt>feature hashing<ept id="p1">**</ept> is applied to efficiently turn arbitrary text features into indices.</source>
          <target state="new">To achieve this task, a technique called <bpt id="p1">**</bpt>feature hashing<ept id="p1">**</ept> is applied to efficiently turn arbitrary text features into indices.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Instead of associating each text feature (words/phrases) to a particular index, this method functions by applying a hash function to the features and using their hash values as indices directly.</source>
          <target state="new">Instead of associating each text feature (words/phrases) to a particular index, this method functions by applying a hash function to the features and using their hash values as indices directly.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>In Azure Machine Learning, there is a [Feature Hashing][feature-hashing] module that creates these word/phrase features conveniently.</source>
          <target state="new">In Azure Machine Learning, there is a [Feature Hashing][feature-hashing] module that creates these word/phrase features conveniently.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Following figure shows an example of using this module.</source>
          <target state="new">Following figure shows an example of using this module.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>The input dataset contains two columns: the book rating ranging from 1 to 5, and the actual review content.</source>
          <target state="new">The input dataset contains two columns: the book rating ranging from 1 to 5, and the actual review content.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>The goal of this [Feature Hashing][feature-hashing] module is to retrieve a bunch of new features that show the occurrence frequency of the corresponding word(s)/phrase(s) within the particular book review.</source>
          <target state="new">The goal of this [Feature Hashing][feature-hashing] module is to retrieve a bunch of new features that show the occurrence frequency of the corresponding word(s)/phrase(s) within the particular book review.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>To use this module, we need to complete the following steps:</source>
          <target state="new">To use this module, we need to complete the following steps:</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>First, select the column that contains the input text ("Col2" in this example).</source>
          <target state="new">First, select the column that contains the input text ("Col2" in this example).</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Second, set the "Hashing bitsize" to 8, which means 2^8=256 features will be created.</source>
          <target state="new">Second, set the "Hashing bitsize" to 8, which means 2^8=256 features will be created.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>The word/phase in all the text will be hashed to 256 indices.</source>
          <target state="new">The word/phase in all the text will be hashed to 256 indices.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>The parameter "Hashing bitsize" ranges from 1 to 31.</source>
          <target state="new">The parameter "Hashing bitsize" ranges from 1 to 31.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>The word(s)/phrase(s) are less likely to be hashed into the same index if setting it to be a larger number.</source>
          <target state="new">The word(s)/phrase(s) are less likely to be hashed into the same index if setting it to be a larger number.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Third, set the parameter "N-grams" to 2.</source>
          <target state="new">Third, set the parameter "N-grams" to 2.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>This gets the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</source>
          <target state="new">This gets the occurrence frequency of unigrams (a feature for every single word) and bigrams (a feature for every pair of adjacent words) from the input text.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The parameter "N-grams" ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</source>
          <target state="new">The parameter "N-grams" ranges from 0 to 10, which indicates the maximum number of sequential words to be included in a feature.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>"Feature Hashing" module</source>
          <target state="new">"Feature Hashing" module</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>The following figure shows what the these new feature look like.</source>
          <target state="new">The following figure shows what the these new feature look like.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>"Feature Hashing" example</source>
          <target state="new">"Feature Hashing" example</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Filtering Features from Your Data - Feature Selection</source>
          <target state="new">Filtering Features from Your Data - Feature Selection</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</source>
          <target state="new">Feature selection is a process that is commonly applied for the construction of training datasets for predictive modeling tasks such as classification or regression tasks.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</source>
          <target state="new">The goal is to select a subset of the features from the original dataset that reduce its dimensions by using a minimal set of features to represent the maximum amount of variance in the data.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>This subset of features are, then, the only features to be included to train the model.</source>
          <target state="new">This subset of features are, then, the only features to be included to train the model.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Feature selection serves two main purposes.</source>
          <target state="new">Feature selection serves two main purposes.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</source>
          <target state="new">First, feature selection often increases classification accuracy by eliminating irrelevant, redundant, or highly correlated features.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Second, it decreases the number of features which makes model training process more efficient.</source>
          <target state="new">Second, it decreases the number of features which makes model training process more efficient.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>This is particularly important for learners that are expensive to train such as support vector machines.</source>
          <target state="new">This is particularly important for learners that are expensive to train such as support vector machines.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</source>
          <target state="new">Although feature selection does seek to reduce the number of features in the dataset used to train the model, it is not usually referred to by the term "dimensionality reduction".</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Feature selection methods extract a subset of original features in the data without changing them.</source>
          <target state="new">Feature selection methods extract a subset of original features in the data without changing them.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</source>
          <target state="new">Dimensionality reduction methods employ engineered features that can transform the original features and thus modify them.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</source>
          <target state="new">Examples of dimensionality reduction methods include Principal Component Analysis, canonical correlation analysis, and Singular Value Decomposition.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</source>
          <target state="new">Among others, one widely applied category of feature selection methods in a supervised context is called "filter based feature selection".</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</source>
          <target state="new">By evaluating the correlation between each feature and the target attribute, these methods apply a statistical measure to assign a score to each feature.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</source>
          <target state="new">The features are then ranked by the score, which may be used to help set the threshold for keeping or eliminating a specific feature.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</source>
          <target state="new">Examples of the statistical measures used in these methods include Person correlation, mutual information, and the Chi squared test.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>In Azure Machine Learning Studio, there are modules provided for feature selection.</source>
          <target state="new">In Azure Machine Learning Studio, there are modules provided for feature selection.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>As shown in the following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</source>
          <target state="new">As shown in the following figure, these modules include [Filter-Based Feature Selection][filter-based-feature-selection] and [Fisher Linear Discriminant Analysis][fisher-linear-discriminant-analysis].</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Feature selection example</source>
          <target state="new">Feature selection example</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Consider, for example, the use of the [Filter-Based Feature Selection][filter-based-feature-selection] module.</source>
          <target state="new">Consider, for example, the use of the [Filter-Based Feature Selection][filter-based-feature-selection] module.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>For the purpose of convenience, we continue to use the text mining example outlined above.</source>
          <target state="new">For the purpose of convenience, we continue to use the text mining example outlined above.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Assume that we want to build a regression model after a set of 256 features are created through the [Feature Hashing][feature-hashing] module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</source>
          <target state="new">Assume that we want to build a regression model after a set of 256 features are created through the [Feature Hashing][feature-hashing] module, and that the response variable is the "Col1" and represents a book review ratings ranging from 1 to 5.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</source>
          <target state="new">By setting "Feature scoring method" to be "Pearson Correlation", the "Target column" to be "Col1", and the "Number of desired features" to 50.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Then the module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with the target attribute "Col1".</source>
          <target state="new">Then the module [Filter-Based Feature Selection][filter-based-feature-selection] will produce a dataset containing 50 features together with the target attribute "Col1".</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>The following figure shows the flow of this experiment and the input parameters we just described.</source>
          <target state="new">The following figure shows the flow of this experiment and the input parameters we just described.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Feature selection example</source>
          <target state="new">Feature selection example</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>The following figure shows the resulting datasets.</source>
          <target state="new">The following figure shows the resulting datasets.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</source>
          <target state="new">Each feature is scored based on the Pearson Correlation between itself and the target attribute "Col1".</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>The features with top scores are kept.</source>
          <target state="new">The features with top scores are kept.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Feature selection example</source>
          <target state="new">Feature selection example</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>The corresponding scores of the selected features are shown in the following figure.</source>
          <target state="new">The corresponding scores of the selected features are shown in the following figure.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Feature selection example</source>
          <target state="new">Feature selection example</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</source>
          <target state="new">By applying this [Filter-Based Feature Selection][filter-based-feature-selection] module, 50 out of 256 features are selected because they have the most correlated features with the target variable "Col1", based on the scoring method "Pearson Correlation".</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Conclusion</source>
          <target state="new">Conclusion</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Feature engineering and feature selection are two commonly performed steps to prepare the training data when building a machine learning model.</source>
          <target state="new">Feature engineering and feature selection are two commonly performed steps to prepare the training data when building a machine learning model.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Normally feature engineering is applied first to generate additional features, and then the feature selection step is performed to eliminate irrelevant, redundant, or highly correlated features.</source>
          <target state="new">Normally feature engineering is applied first to generate additional features, and then the feature selection step is performed to eliminate irrelevant, redundant, or highly correlated features.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Note that it is not always necessarily to perform feature engineering or feature selection.</source>
          <target state="new">Note that it is not always necessarily to perform feature engineering or feature selection.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</source>
          <target state="new">Whether it is needed or not depends on the data we have or collect, the algorithm we pick, and the objective of the experiment.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">29ec8669cceac36ca4a8f09dc2b1b72c6d8b7939</xliffext:olfilehash>
  </header>
</xliff>