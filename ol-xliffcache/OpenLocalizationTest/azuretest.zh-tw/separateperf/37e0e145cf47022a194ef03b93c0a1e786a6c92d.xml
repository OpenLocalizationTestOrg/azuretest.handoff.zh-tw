{
  "nodes": [
    {
      "content": "Use C# with Hive and Pig on Hadoop in HDInsight | Microsoft Azure",
      "pos": [
        27,
        92
      ]
    },
    {
      "content": "Learn how to use C# user-defined functions (UDF) with Hive and Pig streaming in Azure HDInsight.",
      "pos": [
        111,
        207
      ]
    },
    {
      "content": "Use C# user-defined functions with Hive and Pig streaming on Hadoop in HDInsight",
      "pos": [
        541,
        621
      ]
    },
    {
      "content": "Hive and Pig are great for working with data in Azure HDInsight, but sometimes you need a more general-purpose language.",
      "pos": [
        623,
        743
      ]
    },
    {
      "content": "Both Hive and Pig allow you to call external code through user-defined functions (UDFs) or streaming.",
      "pos": [
        744,
        845
      ]
    },
    {
      "content": "In this document, learn how to use C# with Hive and Pig.",
      "pos": [
        847,
        903
      ]
    },
    {
      "content": "Prerequisites",
      "pos": [
        907,
        920
      ]
    },
    {
      "content": "Windows 7, Windows 8, or Windows 8.1.",
      "pos": [
        924,
        961
      ]
    },
    {
      "content": "Visual Studio with the following versions:",
      "pos": [
        965,
        1007
      ]
    },
    {
      "pos": [
        1015,
        1136
      ],
      "content": "Visual Studio 2012 Professional/Premium/Ultimate with <bpt id=\"p1\">[</bpt>Update 4<ept id=\"p1\">](http://www.microsoft.com/download/details.aspx?id=39305)</ept>"
    },
    {
      "pos": [
        1144,
        1276
      ],
      "content": "Visual Studio 2013 Community/Professional/Premium/Ultimate with <bpt id=\"p1\">[</bpt>Update 4<ept id=\"p1\">](https://www.microsoft.com/download/details.aspx?id=44921)</ept>"
    },
    {
      "content": "Visual Studio 2015 Preview",
      "pos": [
        1284,
        1310
      ]
    },
    {
      "pos": [
        1314,
        1443
      ],
      "content": "Hadoop on HDInsight cluster - see <bpt id=\"p1\">[</bpt>Provision an HDInsight cluster<ept id=\"p1\">](hdinsight-provision-clusters.md)</ept> for steps to create a cluster"
    },
    {
      "content": "Hadoop Tools for Visual Studio.",
      "pos": [
        1447,
        1478
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Get started using HDInsight Hadoop Tools for Visual Studio<ept id=\"p1\">](hdinsight-hadoop-visual-studio-tools-get-started.md)</ept> for steps on installing and configuring the tools.",
      "pos": [
        1479,
        1647
      ]
    },
    {
      "content": ".NET on HDInsight",
      "pos": [
        1651,
        1668
      ]
    },
    {
      "content": "The .NET common language runtime (CLR) and frameworks are installed by default on Windows-based HDInsight clusters.",
      "pos": [
        1670,
        1785
      ]
    },
    {
      "content": "This allows you to use C# applications with Hive and Pig streaming (data is passed between Hive/Pig and the C# application via stdout/stdin).",
      "pos": [
        1786,
        1927
      ]
    },
    {
      "content": "Currently there is no support for running .NET Framework applications on Linux-based HDInsight clusters.",
      "pos": [
        1929,
        2033
      ]
    },
    {
      "content": ".NET and streaming",
      "pos": [
        2037,
        2055
      ]
    },
    {
      "content": "Streaming involves Hive and Pig passing data to an external application over stdout, and receiving the results over stdin.",
      "pos": [
        2057,
        2179
      ]
    },
    {
      "content": "For C# applications, this is most easily accomplished via <ph id=\"ph1\">`Console.ReadLine()`</ph> and <ph id=\"ph2\">`Console.WriteLine()`</ph>.",
      "pos": [
        2180,
        2285
      ]
    },
    {
      "pos": [
        2287,
        2423
      ],
      "content": "Since Hive and Pig need to invoke the application at run time, the <bpt id=\"p1\">**</bpt>Console Application<ept id=\"p1\">**</ept> template should be used for your C# projects."
    },
    {
      "content": "Hive and C&amp;#35;",
      "pos": [
        2427,
        2442
      ]
    },
    {
      "content": "Create the C# project",
      "pos": [
        2447,
        2468
      ]
    },
    {
      "content": "Open Visual Studio and create a new solution.",
      "pos": [
        2473,
        2518
      ]
    },
    {
      "content": "For the project type, select <bpt id=\"p1\">**</bpt>Console Application<ept id=\"p1\">**</ept>, and name the new project <bpt id=\"p2\">**</bpt>HiveCSharp<ept id=\"p2\">**</ept>.",
      "pos": [
        2519,
        2613
      ]
    },
    {
      "pos": [
        2618,
        2676
      ],
      "content": "Replace the contents of <bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept> with the following:"
    },
    {
      "content": "Build the project.",
      "pos": [
        4598,
        4616
      ]
    },
    {
      "content": "Upload to storage",
      "pos": [
        4621,
        4638
      ]
    },
    {
      "pos": [
        4643,
        4686
      ],
      "content": "In Visual Studio, open <bpt id=\"p1\">**</bpt>Server Explorer<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4691,
        4739
      ],
      "content": "Expand <bpt id=\"p1\">**</bpt>Azure<ept id=\"p1\">**</ept>, and then expand <bpt id=\"p2\">**</bpt>HDInsight<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        4744,
        4827
      ],
      "content": "If prompted, enter your Azure subscription credentials, and then click <bpt id=\"p1\">**</bpt>Sign In<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4832,
        4950
      ],
      "content": "Expand the HDInsight cluster that you wish to deploy this application to, and then expand <bpt id=\"p1\">**</bpt>Default Storage Account<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Server Explorer showing the storage account for the cluster",
      "pos": [
        4958,
        5017
      ]
    },
    {
      "content": "Double-click <bpt id=\"p1\">**</bpt>Default Container<ept id=\"p1\">**</ept> for the cluster.",
      "pos": [
        5088,
        5139
      ]
    },
    {
      "content": "This will open a new window that displays the contents of the default container.",
      "pos": [
        5140,
        5220
      ]
    },
    {
      "content": "Click the upload icon, and then browse to the <bpt id=\"p1\">**</bpt>bin\\debug<ept id=\"p1\">**</ept> folder for the <bpt id=\"p2\">**</bpt>HiveCSharp<ept id=\"p2\">**</ept> project.",
      "pos": [
        5225,
        5323
      ]
    },
    {
      "content": "Finally, select the <bpt id=\"p1\">**</bpt>HiveCSharp.exe<ept id=\"p1\">**</ept> file and click <bpt id=\"p2\">**</bpt>Ok<ept id=\"p2\">**</ept>.",
      "pos": [
        5324,
        5385
      ]
    },
    {
      "content": "upload icon",
      "pos": [
        5393,
        5404
      ]
    },
    {
      "content": "Once the upload has finished, you will be able to use the application from a Hive query.",
      "pos": [
        5474,
        5562
      ]
    },
    {
      "content": "Hive query",
      "pos": [
        5567,
        5577
      ]
    },
    {
      "pos": [
        5582,
        5625
      ],
      "content": "In Visual Studio, open <bpt id=\"p1\">**</bpt>Server Explorer<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        5630,
        5678
      ],
      "content": "Expand <bpt id=\"p1\">**</bpt>Azure<ept id=\"p1\">**</ept>, and then expand <bpt id=\"p2\">**</bpt>HDInsight<ept id=\"p2\">**</ept>."
    },
    {
      "pos": [
        5683,
        5799
      ],
      "content": "Right-click the cluster that you deployed the <bpt id=\"p1\">**</bpt>HiveCSharp<ept id=\"p1\">**</ept> application to, and then select <bpt id=\"p2\">**</bpt>Write a Hive Query<ept id=\"p2\">**</ept>."
    },
    {
      "content": "Use the following for the Hive query:",
      "pos": [
        5804,
        5841
      ]
    },
    {
      "content": "This selects the <ph id=\"ph1\">`clientid`</ph>, <ph id=\"ph2\">`devicemake`</ph>, and <ph id=\"ph3\">`devicemodel`</ph> fields from <ph id=\"ph4\">`hivesampletable`</ph>, and passes the fields to the HiveCSharp.exe application.",
      "pos": [
        6113,
        6261
      ]
    },
    {
      "content": "The query expects the application to return three fields, which are stored as <ph id=\"ph1\">`clientid`</ph>, <ph id=\"ph2\">`phoneLabel`</ph>, and <ph id=\"ph3\">`phoneHash`</ph>.",
      "pos": [
        6262,
        6382
      ]
    },
    {
      "content": "The query also expects to find HiveCSharp.exe in the root of the default storage container (<ph id=\"ph1\">`add file wasb:///HiveCSharp.exe`</ph>).",
      "pos": [
        6383,
        6510
      ]
    },
    {
      "content": "Click <bpt id=\"p1\">**</bpt>Submit<ept id=\"p1\">**</ept> to submit the job to the HDInsight cluster.",
      "pos": [
        6515,
        6575
      ]
    },
    {
      "content": "The <bpt id=\"p1\">**</bpt>Hive Job Summary<ept id=\"p1\">**</ept> window will open.",
      "pos": [
        6576,
        6618
      ]
    },
    {
      "content": "Click <bpt id=\"p1\">**</bpt>Refresh<ept id=\"p1\">**</ept> to refresh the summary until <bpt id=\"p2\">**</bpt>Job Status<ept id=\"p2\">**</ept> changes to <bpt id=\"p3\">**</bpt>Completed<ept id=\"p3\">**</ept>.",
      "pos": [
        6623,
        6710
      ]
    },
    {
      "content": "To view the job output, click <bpt id=\"p1\">**</bpt>Job Output<ept id=\"p1\">**</ept>.",
      "pos": [
        6711,
        6756
      ]
    },
    {
      "content": "Pig and C&amp;#35;",
      "pos": [
        6760,
        6774
      ]
    },
    {
      "content": "Create the C# project",
      "pos": [
        6779,
        6800
      ]
    },
    {
      "content": "Open Visual Studio and create a new solution.",
      "pos": [
        6805,
        6850
      ]
    },
    {
      "content": "For the project type, select <bpt id=\"p1\">**</bpt>Console Application<ept id=\"p1\">**</ept>, and name the new project <bpt id=\"p2\">**</bpt>PigUDF<ept id=\"p2\">**</ept>.",
      "pos": [
        6851,
        6941
      ]
    },
    {
      "pos": [
        6946,
        7013
      ],
      "content": "Replace the contents of the <bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept> file with the following:"
    },
    {
      "pos": [
        8058,
        8168
      ],
      "content": "This application will parse the lines sent from Pig, and reformat lines that begin with <ph id=\"ph1\">`java.lang.Exception`</ph>."
    },
    {
      "pos": [
        8173,
        8221
      ],
      "content": "Save <bpt id=\"p1\">**</bpt>Program.cs<ept id=\"p1\">**</ept>, and then build the project."
    },
    {
      "content": "Upload the application",
      "pos": [
        8226,
        8248
      ]
    },
    {
      "content": "Pig streaming expects the application to be local on the cluster file system.",
      "pos": [
        8253,
        8330
      ]
    },
    {
      "content": "Enable Remote Desktop for the HDInsight cluster, and then connect to it by following the instructions at <bpt id=\"p1\">[</bpt>Connect to HDInsight clusters using RDP<ept id=\"p1\">](hdinsight-administer-use-management-portal.md#rdp)</ept>.",
      "pos": [
        8331,
        8529
      ]
    },
    {
      "pos": [
        8534,
        8709
      ],
      "content": "Once connected, copy <bpt id=\"p1\">**</bpt>PigUDF.exe<ept id=\"p1\">**</ept> from the <bpt id=\"p2\">**</bpt>bin/debug<ept id=\"p2\">**</ept> directory for the PigUDF project on your local machine, and paste it to the <bpt id=\"p3\">**</bpt>%PIG_HOME%<ept id=\"p3\">**</ept> directory on the cluster."
    },
    {
      "content": "Use the application from Pig Latin",
      "pos": [
        8714,
        8748
      ]
    },
    {
      "pos": [
        8753,
        8873
      ],
      "content": "From the Remote Desktop session, start the Hadoop command line by using the <bpt id=\"p1\">**</bpt>Hadoop Command Line<ept id=\"p1\">**</ept> icon on the desktop."
    },
    {
      "content": "Use the following to start the Pig command line:",
      "pos": [
        8878,
        8926
      ]
    },
    {
      "pos": [
        8971,
        9016
      ],
      "content": "You will be presented with a <ph id=\"ph1\">`grunt&gt;`</ph> prompt."
    },
    {
      "content": "Enter the following to run a simple Pig job by using the .NET Framework application:",
      "pos": [
        9021,
        9105
      ]
    },
    {
      "content": "The <ph id=\"ph1\">`DEFINE`</ph> statement creates an alias of <ph id=\"ph2\">`streamer`</ph> for the pigudf.exe applications, and <ph id=\"ph3\">`SHIP`</ph> distributes it across the nodes in the cluster.",
      "pos": [
        9394,
        9539
      ]
    },
    {
      "content": "Later, <ph id=\"ph1\">`streamer`</ph> is used with the <ph id=\"ph2\">`STREAM`</ph> operator to process the single lines contained in LOG and return the data as a series of columns.",
      "pos": [
        9540,
        9681
      ]
    },
    {
      "pos": [
        9685,
        9853
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The application name that is used for streaming must be surrounded by the \\` (backtick) character when aliased, and ' (single quote) when used with <ph id=\"ph2\">`SHIP`</ph>."
    },
    {
      "content": "After entering the last line, the job should start.",
      "pos": [
        9858,
        9909
      ]
    },
    {
      "content": "Eventually it will return output similar to the following:",
      "pos": [
        9910,
        9968
      ]
    },
    {
      "content": "Summary",
      "pos": [
        10395,
        10402
      ]
    },
    {
      "content": "In this document, you have learned how to use a .NET Framework application from Hive and Pig on HDInsight.",
      "pos": [
        10404,
        10510
      ]
    },
    {
      "content": "If you would like to learn how to use Python with Hive and Pig, see <bpt id=\"p1\">[</bpt>Use Python with Hive and Pig in HDInsight<ept id=\"p1\">](hdinsight-python.md)</ept>.",
      "pos": [
        10511,
        10644
      ]
    },
    {
      "content": "For other ways to use Pig and Hive, and to learn about using MapReduce, see the following:",
      "pos": [
        10646,
        10736
      ]
    },
    {
      "content": "Use Hive with HDInsight",
      "pos": [
        10741,
        10764
      ]
    },
    {
      "content": "Use Pig with HDInsight",
      "pos": [
        10793,
        10815
      ]
    },
    {
      "content": "Use MapReduce with HDInsight",
      "pos": [
        10843,
        10871
      ]
    },
    {
      "content": "test",
      "pos": [
        10902,
        10906
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Use C# with Hive and Pig on Hadoop in HDInsight | Microsoft Azure\"\n    description=\"Learn how to use C# user-defined functions (UDF) with Hive and Pig streaming in Azure HDInsight.\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"Blackmist\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.workload=\"big-data\"\n    ms.tgt_pltfrm=\"na\"\n    ms.devlang=\"dotnet\"\n    ms.topic=\"article\"\n    ms.date=\"07/06/2015\"\n    ms.author=\"larryfr\"/>\n\n\n#Use C# user-defined functions with Hive and Pig streaming on Hadoop in HDInsight\n\nHive and Pig are great for working with data in Azure HDInsight, but sometimes you need a more general-purpose language. Both Hive and Pig allow you to call external code through user-defined functions (UDFs) or streaming.\n\nIn this document, learn how to use C# with Hive and Pig.\n\n##Prerequisites\n\n* Windows 7, Windows 8, or Windows 8.1.\n\n* Visual Studio with the following versions:\n\n    * Visual Studio 2012 Professional/Premium/Ultimate with [Update 4](http://www.microsoft.com/download/details.aspx?id=39305)\n\n    * Visual Studio 2013 Community/Professional/Premium/Ultimate with [Update 4](https://www.microsoft.com/download/details.aspx?id=44921)\n\n    * Visual Studio 2015 Preview\n\n* Hadoop on HDInsight cluster - see [Provision an HDInsight cluster](hdinsight-provision-clusters.md) for steps to create a cluster\n\n* Hadoop Tools for Visual Studio. See [Get started using HDInsight Hadoop Tools for Visual Studio](hdinsight-hadoop-visual-studio-tools-get-started.md) for steps on installing and configuring the tools.\n\n##.NET on HDInsight\n\nThe .NET common language runtime (CLR) and frameworks are installed by default on Windows-based HDInsight clusters. This allows you to use C# applications with Hive and Pig streaming (data is passed between Hive/Pig and the C# application via stdout/stdin).\n\nCurrently there is no support for running .NET Framework applications on Linux-based HDInsight clusters.\n\n##.NET and streaming\n\nStreaming involves Hive and Pig passing data to an external application over stdout, and receiving the results over stdin. For C# applications, this is most easily accomplished via `Console.ReadLine()` and `Console.WriteLine()`.\n\nSince Hive and Pig need to invoke the application at run time, the **Console Application** template should be used for your C# projects.\n\n##Hive and C&#35;\n\n###Create the C# project\n\n1. Open Visual Studio and create a new solution. For the project type, select **Console Application**, and name the new project **HiveCSharp**.\n\n2. Replace the contents of **Program.cs** with the following:\n\n        using System;\n        using System.Security.Cryptography;\n        using System.Text;\n        using System.Threading.Tasks;\n\n        namespace HiveCSharp\n        {\n            class Program\n            {\n                static void Main(string[] args)\n                {\n                    string line;\n                    // Read stdin in a loop\n                    while ((line = Console.ReadLine()) != null)\n                    {\n                        // Parse the string, trimming line feeds\n                        // and splitting fields at tabs\n                        line = line.TrimEnd('\\n');\n                        string[] field = line.Split('\\t');\n                        string phoneLabel = field[1] + ' ' + field[2];\n                        // Emit new data to stdout, delimited by tabs\n                        Console.WriteLine(\"{0}\\t{1}\\t{2}\", field[0], phoneLabel, GetMD5Hash(phoneLabel));\n                    }\n                }\n                /// <summary>\n                /// Returns an MD5 hash for the given string\n                /// </summary>\n                /// <param name=\"input\">string value</param>\n                /// <returns>an MD5 hash</returns>\n                static string GetMD5Hash(string input)\n                {\n                    // Step 1, calculate MD5 hash from input\n                    MD5 md5 = System.Security.Cryptography.MD5.Create();\n                    byte[] inputBytes = System.Text.Encoding.ASCII.GetBytes(input);\n                    byte[] hash = md5.ComputeHash(inputBytes);\n\n                    // Step 2, convert byte array to hex string\n                    StringBuilder sb = new StringBuilder();\n                    for (int i = 0; i < hash.Length; i++)\n                    {\n                        sb.Append(hash[i].ToString(\"x2\"));\n                    }\n                    return sb.ToString();\n                }\n            }\n        }\n\n3. Build the project.\n\n###Upload to storage\n\n1. In Visual Studio, open **Server Explorer**.\n\n3. Expand **Azure**, and then expand **HDInsight**.\n\n4. If prompted, enter your Azure subscription credentials, and then click **Sign In**.\n\n5. Expand the HDInsight cluster that you wish to deploy this application to, and then expand **Default Storage Account**.\n\n    ![Server Explorer showing the storage account for the cluster](./media/hdinsight-hadoop-hive-pig-udf-dotnet-csharp/storage.png)\n\n6. Double-click **Default Container** for the cluster. This will open a new window that displays the contents of the default container.\n\n7. Click the upload icon, and then browse to the **bin\\debug** folder for the **HiveCSharp** project. Finally, select the **HiveCSharp.exe** file and click **Ok**.\n\n    ![upload icon](./media/hdinsight-hadoop-hive-pig-udf-dotnet-csharp/upload.png)\n\n8. Once the upload has finished, you will be able to use the application from a Hive query.\n\n###Hive query\n\n1. In Visual Studio, open **Server Explorer**.\n\n2. Expand **Azure**, and then expand **HDInsight**.\n\n5. Right-click the cluster that you deployed the **HiveCSharp** application to, and then select **Write a Hive Query**.\n\n6. Use the following for the Hive query:\n\n        add file wasb:///HiveCSharp.exe;\n\n        SELECT TRANSFORM (clientid, devicemake, devicemodel)\n        USING 'HiveCSharp.exe' AS\n        (clientid string, phoneLabel string, phoneHash string)\n        FROM hivesampletable\n        ORDER BY clientid LIMIT 50;\n\n    This selects the `clientid`, `devicemake`, and `devicemodel` fields from `hivesampletable`, and passes the fields to the HiveCSharp.exe application. The query expects the application to return three fields, which are stored as `clientid`, `phoneLabel`, and `phoneHash`. The query also expects to find HiveCSharp.exe in the root of the default storage container (`add file wasb:///HiveCSharp.exe`).\n\n5. Click **Submit** to submit the job to the HDInsight cluster. The **Hive Job Summary** window will open.\n\n6. Click **Refresh** to refresh the summary until **Job Status** changes to **Completed**. To view the job output, click **Job Output**.\n\n##Pig and C&#35;\n\n###Create the C# project\n\n1. Open Visual Studio and create a new solution. For the project type, select **Console Application**, and name the new project **PigUDF**.\n\n2. Replace the contents of the **Program.cs** file with the following:\n\n        using System;\n\n        namespace PigUDF\n        {\n            class Program\n            {\n                static void Main(string[] args)\n                {\n                    string line;\n                    // Read stdin in a loop\n                    while ((line = Console.ReadLine()) != null)\n                    {\n                        // Fix formatting on lines that begin with an exception\n                        if(line.StartsWith(\"java.lang.Exception\"))\n                        {\n                            // Trim the error info off the beginning and add a note to the end of the line\n                            line = line.Remove(0, 21) + \" - java.lang.Exception\";\n                        }\n                        // Split the fields apart at tab characters\n                        string[] field = line.Split('\\t');\n                        // Put fields back together for writing\n                        Console.WriteLine(String.Join(\"\\t\",field));\n                    }\n                }\n            }\n        }\n\n    This application will parse the lines sent from Pig, and reformat lines that begin with `java.lang.Exception`.\n\n3. Save **Program.cs**, and then build the project.\n\n###Upload the application\n\n1. Pig streaming expects the application to be local on the cluster file system. Enable Remote Desktop for the HDInsight cluster, and then connect to it by following the instructions at [Connect to HDInsight clusters using RDP](hdinsight-administer-use-management-portal.md#rdp).\n\n2. Once connected, copy **PigUDF.exe** from the **bin/debug** directory for the PigUDF project on your local machine, and paste it to the **%PIG_HOME%** directory on the cluster.\n\n###Use the application from Pig Latin\n\n1. From the Remote Desktop session, start the Hadoop command line by using the **Hadoop Command Line** icon on the desktop.\n\n2. Use the following to start the Pig command line:\n\n        cd %PIG_HOME%\n        bin\\pig\n\n    You will be presented with a `grunt>` prompt.\n\n3. Enter the following to run a simple Pig job by using the .NET Framework application:\n\n        DEFINE streamer `pigudf.exe` SHIP('pigudf.exe');\n        LOGS = LOAD 'wasb:///example/data/sample.log' as (LINE:chararray);\n        LOG = FILTER LOGS by LINE is not null;\n        DETAILS = STREAM LOG through streamer as (col1, col2, col3, col4, col5);\n        DUMP DETAILS;\n\n    The `DEFINE` statement creates an alias of `streamer` for the pigudf.exe applications, and `SHIP` distributes it across the nodes in the cluster. Later, `streamer` is used with the `STREAM` operator to process the single lines contained in LOG and return the data as a series of columns.\n\n> [AZURE.NOTE] The application name that is used for streaming must be surrounded by the \\` (backtick) character when aliased, and ' (single quote) when used with `SHIP`.\n\n3. After entering the last line, the job should start. Eventually it will return output similar to the following:\n\n        (2012-02-03 20:11:56 SampleClass5 [WARN] problem finding id 1358451042 - java.lang.Exception)\n        (2012-02-03 20:11:56 SampleClass5 [DEBUG] detail for id 1976092771)\n        (2012-02-03 20:11:56 SampleClass5 [TRACE] verbose detail for id 1317358561)\n        (2012-02-03 20:11:56 SampleClass5 [TRACE] verbose detail for id 1737534798)\n        (2012-02-03 20:11:56 SampleClass7 [DEBUG] detail for id 1475865947)\n\n##Summary\n\nIn this document, you have learned how to use a .NET Framework application from Hive and Pig on HDInsight. If you would like to learn how to use Python with Hive and Pig, see [Use Python with Hive and Pig in HDInsight](hdinsight-python.md).\n\nFor other ways to use Pig and Hive, and to learn about using MapReduce, see the following:\n\n* [Use Hive with HDInsight](hdinsight-use-hive.md)\n\n* [Use Pig with HDInsight](hdinsight-use-pig.md)\n\n* [Use MapReduce with HDInsight](hdinsight-use-mapreduce.md)\n\ntest\n"
}