{
  "nodes": [
    {
      "content": "Use Script Action to install Solr on Hadoop cluster | Microsoft Azure",
      "pos": [
        28,
        97
      ]
    },
    {
      "content": "Learn how to customize HDInsight cluster with Solr.",
      "pos": [
        117,
        168
      ]
    },
    {
      "content": "You'll use a Script Action configuration option to use a script to install Solr.",
      "pos": [
        169,
        249
      ]
    },
    {
      "content": "Install and use Solr on HDInsight Hadoop clusters",
      "pos": [
        591,
        640
      ]
    },
    {
      "content": "In this topic, you will learn how to install Solr on Azure HDInsight by using Script Action.",
      "pos": [
        643,
        735
      ]
    },
    {
      "content": "Solr is a powerful search platform and provides enterprise-level search capabilities on data managed by Hadoop.",
      "pos": [
        736,
        847
      ]
    },
    {
      "content": "Once you have installed Solr on HDInsight cluster, you'll also learn how to search data by using Solr.",
      "pos": [
        848,
        950
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The steps in this document require a Linux-based HDInsight cluster.",
      "pos": [
        954,
        1034
      ]
    },
    {
      "content": "For information on using Solr with a Windows-based cluster, see <bpt id=\"p1\">[</bpt>Install and use R on HDinsight Hadoop clusters (Windows)<ept id=\"p1\">](hdinsight-hadoop-solr-install.md)</ept>",
      "pos": [
        1035,
        1191
      ]
    },
    {
      "content": "The sample script used in this topic creates a Solr cluster with a specific configuration.",
      "pos": [
        1193,
        1283
      ]
    },
    {
      "content": "If you want to configure the Solr cluster with different collections, shards, schemas, replicas, etc., you must modify the script and Solr binaries accordingly.",
      "pos": [
        1284,
        1444
      ]
    },
    {
      "pos": [
        1449,
        1483
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"whatis\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>What is Solr?"
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Apache Solr<ept id=\"p1\">](http://lucene.apache.org/solr/features.html)</ept> is an enterprise search platform that enables powerful full-text search on data.",
      "pos": [
        1485,
        1624
      ]
    },
    {
      "content": "While Hadoop enables storing and managing vast amounts of data, Apache Solr provides the search capabilities to quickly retrieve the data.",
      "pos": [
        1625,
        1763
      ]
    },
    {
      "content": "This topic provides instructions on how to customize an HDInsight cluster to install Solr.",
      "pos": [
        1764,
        1854
      ]
    },
    {
      "content": "What the script does",
      "pos": [
        1862,
        1882
      ]
    },
    {
      "content": "This script makes the following changes to the HDInsight cluster:",
      "pos": [
        1884,
        1949
      ]
    },
    {
      "pos": [
        1953,
        1995
      ],
      "content": "Installs Solr into <ph id=\"ph1\">`/usr/hdp/current/solr`</ph>"
    },
    {
      "pos": [
        1998,
        2068
      ],
      "content": "Creates a new user, <bpt id=\"p1\">__</bpt>solrusr<ept id=\"p1\">__</ept>, which is used to run the Solr service"
    },
    {
      "pos": [
        2071,
        2128
      ],
      "content": "Sets <bpt id=\"p1\">__</bpt>solruser<ept id=\"p1\">__</ept> as the owner of <ph id=\"ph1\">`/usr/hdp/current/solr`</ph>"
    },
    {
      "content": "Adds an <bpt id=\"p1\">[</bpt>Upstart<ept id=\"p1\">](http://upstart.ubuntu.com/)</ept> configuration that will start Solr if a cluster node restarts.",
      "pos": [
        2131,
        2239
      ]
    },
    {
      "content": "Solr is also automatically started on the cluster nodes after installation",
      "pos": [
        2240,
        2314
      ]
    },
    {
      "pos": [
        2319,
        2374
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"install\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Install Solr using Script Actions"
    },
    {
      "content": "A sample script to install Solr on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id=\"p1\">[</bpt>https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh<ept id=\"p1\">](https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh)</ept>.",
      "pos": [
        2376,
        2675
      ]
    },
    {
      "content": "This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.",
      "pos": [
        2676,
        2800
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script.",
      "pos": [
        2805,
        2916
      ]
    },
    {
      "content": "For more information on using these methods, see <bpt id=\"p1\">[</bpt>Customize HDInsight clusters with Script Actions<ept id=\"p1\">](hdinsight-hadoop-customize-cluster-linux.md)</ept>.",
      "pos": [
        2917,
        3062
      ]
    },
    {
      "pos": [
        3067,
        3241
      ],
      "content": "Start provisioning a cluster by using the steps in <bpt id=\"p1\">[</bpt>Provision Linux-based HDInsight clusters<ept id=\"p1\">](hdinsight-provision-linux-clusters.md#portal)</ept>, but do not complete provisioning."
    },
    {
      "pos": [
        3246,
        3348
      ],
      "content": "On the <bpt id=\"p1\">**</bpt>Optional Configuration<ept id=\"p1\">**</ept> blade, select <bpt id=\"p2\">**</bpt>Script Actions<ept id=\"p2\">**</ept>, and provide the information below:"
    },
    {
      "pos": [
        3356,
        3410
      ],
      "content": "<bpt id=\"p1\">__</bpt>NAME<ept id=\"p1\">__</ept>: Enter a friendly name for the script action."
    },
    {
      "pos": [
        3417,
        3526
      ],
      "content": "<bpt id=\"p1\">__</bpt>SCRIPT URI<ept id=\"p1\">__</ept>: https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh"
    },
    {
      "pos": [
        3533,
        3560
      ],
      "content": "<bpt id=\"p1\">__</bpt>HEAD<ept id=\"p1\">__</ept>: Check this option"
    },
    {
      "pos": [
        3567,
        3596
      ],
      "content": "<bpt id=\"p1\">__</bpt>WORKER<ept id=\"p1\">__</ept>: Check this option"
    },
    {
      "pos": [
        3603,
        3668
      ],
      "content": "<bpt id=\"p1\">__</bpt>ZOOKEEPER<ept id=\"p1\">__</ept>: Check this option to install on the Zookeeper node"
    },
    {
      "pos": [
        3675,
        3713
      ],
      "content": "<bpt id=\"p1\">__</bpt>PARAMETERS<ept id=\"p1\">__</ept>: Leave this field blank"
    },
    {
      "content": "At the bottom of the <bpt id=\"p1\">**</bpt>Script Actions<ept id=\"p1\">**</ept>, use the <bpt id=\"p2\">**</bpt>Select<ept id=\"p2\">**</ept> button to save the configuration.",
      "pos": [
        3718,
        3811
      ]
    },
    {
      "content": "Finally, use the <bpt id=\"p1\">**</bpt>Select<ept id=\"p1\">**</ept> button at the bottom of the <bpt id=\"p2\">**</bpt>Optional Configuration<ept id=\"p2\">**</ept> blade to save the optional configuration information.",
      "pos": [
        3812,
        3948
      ]
    },
    {
      "pos": [
        3953,
        4091
      ],
      "content": "Continue provisining the cluster as described in <bpt id=\"p1\">[</bpt>Provision Linux-based HDInsight clusters<ept id=\"p1\">](hdinsight-provision-linux-clusters.md#portal)</ept>."
    },
    {
      "pos": [
        4096,
        4149
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"usesolr\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>How do I use Solr in HDInsight?"
    },
    {
      "content": "Indexing data",
      "pos": [
        4154,
        4167
      ]
    },
    {
      "content": "You must start with indexing Solr with some data files.",
      "pos": [
        4169,
        4224
      ]
    },
    {
      "content": "You can then use Solr to run search queries on the indexed data.",
      "pos": [
        4225,
        4289
      ]
    },
    {
      "content": "Use the following steps to add some example data to Solr, and then query it:",
      "pos": [
        4290,
        4366
      ]
    },
    {
      "content": "Connect to the HDInsight cluster using SSH:",
      "pos": [
        4371,
        4414
      ]
    },
    {
      "content": "For more information on using SSH with HDInsight, see the following:",
      "pos": [
        4485,
        4553
      ]
    },
    {
      "content": "Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X",
      "pos": [
        4566,
        4636
      ]
    },
    {
      "content": "Use SSH with Linux-based Hadoop on HDInsight from Windows",
      "pos": [
        4690,
        4747
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph> Steps later in this document make use of an SSL tunnel to connect to the Solr web UI.",
      "pos": [
        4803,
        4906
      ]
    },
    {
      "content": "In order to use these steps, you must establish an SSL tunnel and then configure your browser to use it.",
      "pos": [
        4907,
        5011
      ]
    },
    {
      "pos": [
        5025,
        5198
      ],
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's<ept id=\"p1\">](hdinsight-linux-ambari-ssh-tunnel.md)</ept>"
    },
    {
      "content": "Use the following commands to have Solr index sample data:",
      "pos": [
        5203,
        5261
      ]
    },
    {
      "content": "You'll see the following output on the console:",
      "pos": [
        5370,
        5417
      ]
    },
    {
      "content": "The post.jar utility indexes Solr with two sample documents, <bpt id=\"p1\">**</bpt>solr.xml<ept id=\"p1\">**</ept> and <bpt id=\"p2\">**</bpt>monitor.xml<ept id=\"p2\">**</ept>.",
      "pos": [
        5621,
        5715
      ]
    },
    {
      "content": "These will be stored in <bpt id=\"p1\">__</bpt>collection1<ept id=\"p1\">__</ept> within Solr.",
      "pos": [
        5716,
        5768
      ]
    },
    {
      "content": "Use the following to query the REST API exposed by Solr:",
      "pos": [
        5777,
        5833
      ]
    },
    {
      "content": "This issues a query against <bpt id=\"p1\">__</bpt>collection1<ept id=\"p1\">__</ept> for any documents matching <bpt id=\"p2\">__</bpt>\\*:\\*<ept id=\"p2\">__</ept> (encoded as \\*%3A\\* in the query string,) and that the response should be returned as JSON.",
      "pos": [
        5937,
        6109
      ]
    },
    {
      "content": "The response should appear similar to the following:",
      "pos": [
        6110,
        6162
      ]
    },
    {
      "content": "Using the Solr dashboard",
      "pos": [
        8350,
        8374
      ]
    },
    {
      "content": "The Solr dashbaord is a web UI that allows you to work with Solr through your web browser.",
      "pos": [
        8376,
        8466
      ]
    },
    {
      "content": "The Solr dashboard is not exposed directly on the Internet from your HDInsight cluster, but must be accessed using an SSH tunnel.",
      "pos": [
        8467,
        8596
      ]
    },
    {
      "content": "For more information on using an SSH tunnel, see <bpt id=\"p1\">[</bpt>Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's<ept id=\"p1\">](hdinsight-linux-ambari-ssh-tunnel.md)</ept>",
      "pos": [
        8597,
        8793
      ]
    },
    {
      "content": "Once you have established an SSH tunnel, use the following steps to use the Solr dashboard:",
      "pos": [
        8799,
        8890
      ]
    },
    {
      "content": "In your browser, connect to <bpt id=\"p1\">__</bpt>http://headnode0:8983/solr/#/<ept id=\"p1\">__</ept>.",
      "pos": [
        8895,
        8957
      ]
    },
    {
      "content": "This traffic should be routed through the SSH tunnel to headnode0 for your HDInsight cluster.",
      "pos": [
        8958,
        9051
      ]
    },
    {
      "content": "You should see a page similar to the following:",
      "pos": [
        9052,
        9099
      ]
    },
    {
      "content": "Image of Solr dashboard",
      "pos": [
        9107,
        9130
      ]
    },
    {
      "content": "From the left pane, use the <bpt id=\"p1\">**</bpt>Core Selector<ept id=\"p1\">**</ept> drop-down to select <bpt id=\"p2\">**</bpt>collection1<ept id=\"p2\">**</ept>.",
      "pos": [
        9199,
        9281
      ]
    },
    {
      "content": "Several entries should them appear below <bpt id=\"p1\">__</bpt>collection1<ept id=\"p1\">__</ept>.",
      "pos": [
        9282,
        9339
      ]
    },
    {
      "content": "From the entries below <bpt id=\"p1\">__</bpt>collection1<ept id=\"p1\">__</ept>, select <bpt id=\"p2\">__</bpt>Query<ept id=\"p2\">__</ept>.",
      "pos": [
        9344,
        9401
      ]
    },
    {
      "content": "Use the following values to populate the search page:",
      "pos": [
        9402,
        9455
      ]
    },
    {
      "content": "In the <bpt id=\"p1\">**</bpt>q<ept id=\"p1\">**</ept> text box, enter <bpt id=\"p2\">**</bpt>\\*:<ept id=\"p2\">**</ept>\\*.",
      "pos": [
        9463,
        9502
      ]
    },
    {
      "content": "This will return all the documents that are indexed in Solr.",
      "pos": [
        9503,
        9563
      ]
    },
    {
      "content": "If you want to search for a specific string within the documents, you can enter that string here.",
      "pos": [
        9564,
        9661
      ]
    },
    {
      "content": "In the <bpt id=\"p1\">**</bpt>wt<ept id=\"p1\">**</ept> text box, select the output format.",
      "pos": [
        9673,
        9722
      ]
    },
    {
      "content": "Default is <bpt id=\"p1\">**</bpt>json<ept id=\"p1\">**</ept>.",
      "pos": [
        9723,
        9743
      ]
    },
    {
      "pos": [
        9754,
        9832
      ],
      "content": "Finally, select the <bpt id=\"p1\">**</bpt>Execute Query<ept id=\"p1\">**</ept> button at the bottom of the search pate."
    },
    {
      "content": "Use Script Action to customize a cluster",
      "pos": [
        9840,
        9880
      ]
    },
    {
      "content": "The output returns the two docs that we used for indexing Solr.",
      "pos": [
        9965,
        10028
      ]
    },
    {
      "content": "The output resembles the following:",
      "pos": [
        10029,
        10064
      ]
    },
    {
      "content": "Starting and stopping Solr",
      "pos": [
        12248,
        12274
      ]
    },
    {
      "content": "If you need to manually stop or start Solar, use the following commands:",
      "pos": [
        12276,
        12348
      ]
    },
    {
      "content": "Backup indexed data",
      "pos": [
        12401,
        12420
      ]
    },
    {
      "content": "As a good practice, you should back up the indexed data from the Solr cluster nodes onto Azure Blob storage.",
      "pos": [
        12422,
        12530
      ]
    },
    {
      "content": "Perform the following steps to do so:",
      "pos": [
        12531,
        12568
      ]
    },
    {
      "content": "Connect to the cluster using SSH, then use the following command to create a snapshot of the indexed data:",
      "pos": [
        12573,
        12679
      ]
    },
    {
      "content": "You should see a response like this:",
      "pos": [
        12753,
        12789
      ]
    },
    {
      "content": "Next, change directories to <bpt id=\"p1\">__</bpt>/usr/hdp/current/solr/example/solr<ept id=\"p1\">__</ept>.",
      "pos": [
        13051,
        13118
      ]
    },
    {
      "content": "There will be a subdirectory here for each collection.",
      "pos": [
        13119,
        13173
      ]
    },
    {
      "content": "Each collection directory contains a <bpt id=\"p1\">__</bpt>data<ept id=\"p1\">__</ept> directory, which is where the snapshot for that collection is located.",
      "pos": [
        13174,
        13290
      ]
    },
    {
      "pos": [
        13296,
        13554
      ],
      "content": "For example, if you used the steps earlier to index the sample documents, the <bpt id=\"p1\">__</bpt>/usr/hdp/current/solr/example/solr/collection1/data<ept id=\"p1\">__</ept> directory should now contain a directory named <bpt id=\"p2\">__</bpt>snapshot.###########<ept id=\"p2\">__</ept> where the #'s are the date and time of the snapshot."
    },
    {
      "content": "Create a compressed archive of the snapshot folder using a command similar to the following:",
      "pos": [
        13563,
        13655
      ]
    },
    {
      "pos": [
        13737,
        13886
      ],
      "content": "This will create a new archive named <bpt id=\"p1\">__</bpt>snapshot.20150806185338855.tgz<ept id=\"p1\">__</ept>, which contains the contents of the <bpt id=\"p2\">__</bpt>snapshot.20150806185338855<ept id=\"p2\">__</ept> directory."
    },
    {
      "content": "You can then store the archive to the cluster's primary storage using the following command:",
      "pos": [
        13895,
        13987
      ]
    },
    {
      "content": "hadoop fs -copyFromLocal snapshot.20150806185338855.tgz /example/data",
      "pos": [
        13993,
        14062
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> You may want to create a dedicated directory for storing Solr snapshots.",
      "pos": [
        14074,
        14159
      ]
    },
    {
      "content": "For example, <ph id=\"ph1\">`hadoop fs -mkdir /solrbackup`</ph>.",
      "pos": [
        14160,
        14204
      ]
    },
    {
      "pos": [
        14206,
        14409
      ],
      "content": "For more information on working with Solr backup and restores, see <bpt id=\"p1\">[</bpt>Making and restoring backups of SolrCores<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/solr/Making+and+Restoring+Backups+of+SolrCores)</ept>."
    },
    {
      "content": "See also",
      "pos": [
        14415,
        14423
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install and use Hue on HDInsight clusters<ept id=\"p1\">](hdinsight-hadoop-hue-linux.md)</ept>.",
      "pos": [
        14429,
        14504
      ]
    },
    {
      "content": "Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.",
      "pos": [
        14505,
        14648
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install and use Spark on HDInsight clusters<ept id=\"p1\">][hdinsight-install-spark]</ept>.",
      "pos": [
        14652,
        14723
      ]
    },
    {
      "content": "Use cluster customization to install Spark on HDInsight Hadoop clusters.",
      "pos": [
        14724,
        14796
      ]
    },
    {
      "content": "Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.",
      "pos": [
        14797,
        14945
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install R on HDInsight clusters<ept id=\"p1\">][hdinsight-install-r]</ept>.",
      "pos": [
        14949,
        15004
      ]
    },
    {
      "content": "Use cluster customization to install R on HDInsight Hadoop clusters.",
      "pos": [
        15005,
        15073
      ]
    },
    {
      "content": "R is an open-source language and environment for statistical computing.",
      "pos": [
        15074,
        15145
      ]
    },
    {
      "content": "It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.",
      "pos": [
        15146,
        15302
      ]
    },
    {
      "content": "It also provides extensive graphical capabilities.",
      "pos": [
        15303,
        15353
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install Giraph on HDInsight clusters<ept id=\"p1\">](hdinsight-hadoop-giraph-install-linux.md)</ept>.",
      "pos": [
        15357,
        15438
      ]
    },
    {
      "content": "Use cluster customization to install Giraph on HDInsight Hadoop clusters.",
      "pos": [
        15439,
        15512
      ]
    },
    {
      "content": "Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.",
      "pos": [
        15513,
        15613
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Install Hue on HDInsight clusters<ept id=\"p1\">](hdinsight-hadoop-hue-linux.md)</ept>.",
      "pos": [
        15617,
        15684
      ]
    },
    {
      "content": "Use cluster customization to install Hue on HDInsight Hadoop clusters.",
      "pos": [
        15685,
        15755
      ]
    },
    {
      "content": "Hue is a set of Web applications used to interact with a Hadoop cluster.",
      "pos": [
        15756,
        15828
      ]
    },
    {
      "content": "test",
      "pos": [
        16099,
        16103
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Use Script Action to install Solr on Hadoop cluster | Microsoft Azure\" \n    description=\"Learn how to customize HDInsight cluster with Solr. You'll use a Script Action configuration option to use a script to install Solr.\" \n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    authors=\"Blackmist\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.workload=\"big-data\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"08/20/2015\" \n    ms.author=\"larryfr\"/>\n\n# Install and use Solr on HDInsight Hadoop clusters\n\n\nIn this topic, you will learn how to install Solr on Azure HDInsight by using Script Action. Solr is a powerful search platform and provides enterprise-level search capabilities on data managed by Hadoop. Once you have installed Solr on HDInsight cluster, you'll also learn how to search data by using Solr.\n\n> [AZURE.NOTE] The steps in this document require a Linux-based HDInsight cluster. For information on using Solr with a Windows-based cluster, see [Install and use R on HDinsight Hadoop clusters (Windows)](hdinsight-hadoop-solr-install.md)\n\nThe sample script used in this topic creates a Solr cluster with a specific configuration. If you want to configure the Solr cluster with different collections, shards, schemas, replicas, etc., you must modify the script and Solr binaries accordingly.\n\n## <a name=\"whatis\"></a>What is Solr?\n\n[Apache Solr](http://lucene.apache.org/solr/features.html) is an enterprise search platform that enables powerful full-text search on data. While Hadoop enables storing and managing vast amounts of data, Apache Solr provides the search capabilities to quickly retrieve the data. This topic provides instructions on how to customize an HDInsight cluster to install Solr.   \n\n## What the script does\n\nThis script makes the following changes to the HDInsight cluster:\n\n* Installs Solr into `/usr/hdp/current/solr`\n* Creates a new user, __solrusr__, which is used to run the Solr service\n* Sets __solruser__ as the owner of `/usr/hdp/current/solr`\n* Adds an [Upstart](http://upstart.ubuntu.com/) configuration that will start Solr if a cluster node restarts. Solr is also automatically started on the cluster nodes after installation\n\n## <a name=\"install\"></a>Install Solr using Script Actions\n\nA sample script to install Solr on an HDInsight cluster is available from a read-only Azure storage blob at [https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh). This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal. \n\n> [AZURE.NOTE] You can also use Azure PowerShell or the HDInsight .NET SDK to create a cluster using this script. For more information on using these methods, see [Customize HDInsight clusters with Script Actions](hdinsight-hadoop-customize-cluster-linux.md).\n\n1. Start provisioning a cluster by using the steps in [Provision Linux-based HDInsight clusters](hdinsight-provision-linux-clusters.md#portal), but do not complete provisioning.\n\n2. On the **Optional Configuration** blade, select **Script Actions**, and provide the information below:\n\n    * __NAME__: Enter a friendly name for the script action.\n    * __SCRIPT URI__: https://hdiconfigactions.blob.core.windows.net/linuxsolrconfigactionv01/solr-installer-v01.sh\n    * __HEAD__: Check this option\n    * __WORKER__: Check this option\n    * __ZOOKEEPER__: Check this option to install on the Zookeeper node\n    * __PARAMETERS__: Leave this field blank\n\n3. At the bottom of the **Script Actions**, use the **Select** button to save the configuration. Finally, use the **Select** button at the bottom of the **Optional Configuration** blade to save the optional configuration information.\n\n4. Continue provisining the cluster as described in [Provision Linux-based HDInsight clusters](hdinsight-provision-linux-clusters.md#portal).\n\n## <a name=\"usesolr\"></a>How do I use Solr in HDInsight?\n\n###Indexing data\n\nYou must start with indexing Solr with some data files. You can then use Solr to run search queries on the indexed data. Use the following steps to add some example data to Solr, and then query it:\n\n1. Connect to the HDInsight cluster using SSH:\n\n        ssh USERNAME@CLUSTERNAME-ssh.azurehdinsight.net\n        \n    For more information on using SSH with HDInsight, see the following:\n    \n    * [Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X](hdinsight-hadoop-linux-use-ssh-unix.md)\n    \n    * [Use SSH with Linux-based Hadoop on HDInsight from Windows](hdinsight-hadoop-linux-use-ssh-windows.md)\n    \n    > [AZURE.IMPORTANT] Steps later in this document make use of an SSL tunnel to connect to the Solr web UI. In order to use these steps, you must establish an SSL tunnel and then configure your browser to use it.\n    > \n    > For more information, see [Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's](hdinsight-linux-ambari-ssh-tunnel.md)\n\n2. Use the following commands to have Solr index sample data: \n\n        cd /usr/hdp/current/solr/example/exampledocs\n        java -jar post.jar solr.xml monitor.xml\n\n    You'll see the following output on the console:\n\n        POSTing file solr.xml\n        POSTing file monitor.xml\n        2 files indexed.\n        COMMITting Solr index changes to http://localhost:8983/solr/update..\n        Time spent: 0:00:01.624\n\n    The post.jar utility indexes Solr with two sample documents, **solr.xml** and **monitor.xml**. These will be stored in __collection1__ within Solr.\n    \n3. Use the following to query the REST API exposed by Solr:\n\n        curl \"http://localhost:8983/solr/collection1/select?q=*%3A*&wt=json&indent=true\"\n        \n    This issues a query against __collection1__ for any documents matching __\\*:\\*__ (encoded as \\*%3A\\* in the query string,) and that the response should be returned as JSON. The response should appear similar to the following:\n    \n            \"response\": {\n                \"numFound\": 2,\n                \"start\": 0,\n                \"maxScore\": 1,\n                \"docs\": [\n                  {\n                    \"id\": \"SOLR1000\",\n                    \"name\": \"Solr, the Enterprise Search Server\",\n                    \"manu\": \"Apache Software Foundation\",\n                    \"cat\": [\n                      \"software\",\n                      \"search\"\n                    ],\n                    \"features\": [\n                      \"Advanced Full-Text Search Capabilities using Lucene\",\n                      \"Optimized for High Volume Web Traffic\",\n                      \"Standards Based Open Interfaces - XML and HTTP\",\n                      \"Comprehensive HTML Administration Interfaces\",\n                      \"Scalability - Efficient Replication to other Solr Search Servers\",\n                      \"Flexible and Adaptable with XML configuration and Schema\",\n                      \"Good unicode support: héllo (hello with an accent over the e)\"\n                    ],\n                    \"price\": 0,\n                    \"price_c\": \"0,USD\",\n                    \"popularity\": 10,\n                    \"inStock\": true,\n                    \"incubationdate_dt\": \"2006-01-17T00:00:00Z\",\n                    \"_version_\": 1486960636996878300\n                  },\n                  {\n                    \"id\": \"3007WFP\",\n                    \"name\": \"Dell Widescreen UltraSharp 3007WFP\",\n                    \"manu\": \"Dell, Inc.\",\n                    \"manu_id_s\": \"dell\",\n                    \"cat\": [\n                      \"electronics and computer1\"\n                    ],\n                    \"features\": [\n                      \"30\\\" TFT active matrix LCD, 2560 x 1600, .25mm dot pitch, 700:1 contrast\"\n                    ],\n                    \"includes\": \"USB cable\",\n                    \"weight\": 401.6,\n                    \"price\": 2199,\n                    \"price_c\": \"2199,USD\",\n                    \"popularity\": 6,\n                    \"inStock\": true,\n                    \"store\": \"43.17614,-90.57341\",\n                    \"_version_\": 1486960637584081000\n                  }\n                ]\n              }\n\n###Using the Solr dashboard\n\nThe Solr dashbaord is a web UI that allows you to work with Solr through your web browser. The Solr dashboard is not exposed directly on the Internet from your HDInsight cluster, but must be accessed using an SSH tunnel. For more information on using an SSH tunnel, see [Use SSH Tunneling to access Ambari web UI, ResourceManager, JobHistory, NameNode, Oozie, and other web UI's](hdinsight-linux-ambari-ssh-tunnel.md)\n    \nOnce you have established an SSH tunnel, use the following steps to use the Solr dashboard:\n\n1. In your browser, connect to __http://headnode0:8983/solr/#/__. This traffic should be routed through the SSH tunnel to headnode0 for your HDInsight cluster. You should see a page similar to the following:\n\n    ![Image of Solr dashboard](./media/hdinsight-hadoop-solr-install-linux/solrdashboard.png)\n\n2. From the left pane, use the **Core Selector** drop-down to select **collection1**. Several entries should them appear below __collection1__.\n\n3. From the entries below __collection1__, select __Query__. Use the following values to populate the search page:\n\n    * In the **q** text box, enter **\\*:**\\*. This will return all the documents that are indexed in Solr. If you want to search for a specific string within the documents, you can enter that string here.\n    \n    * In the **wt** text box, select the output format. Default is **json**. \n    \n    Finally, select the **Execute Query** button at the bottom of the search pate.\n\n    ![Use Script Action to customize a cluster](./media/hdinsight-hadoop-solr-install-linux/hdi-solr-dashboard-query.png)\n    \n    The output returns the two docs that we used for indexing Solr. The output resembles the following:\n\n            \"response\": {\n                \"numFound\": 2,\n                \"start\": 0,\n                \"maxScore\": 1,\n                \"docs\": [\n                  {\n                    \"id\": \"SOLR1000\",\n                    \"name\": \"Solr, the Enterprise Search Server\",\n                    \"manu\": \"Apache Software Foundation\",\n                    \"cat\": [\n                      \"software\",\n                      \"search\"\n                    ],\n                    \"features\": [\n                      \"Advanced Full-Text Search Capabilities using Lucene\",\n                      \"Optimized for High Volume Web Traffic\",\n                      \"Standards Based Open Interfaces - XML and HTTP\",\n                      \"Comprehensive HTML Administration Interfaces\",\n                      \"Scalability - Efficient Replication to other Solr Search Servers\",\n                      \"Flexible and Adaptable with XML configuration and Schema\",\n                      \"Good unicode support: héllo (hello with an accent over the e)\"\n                    ],\n                    \"price\": 0,\n                    \"price_c\": \"0,USD\",\n                    \"popularity\": 10,\n                    \"inStock\": true,\n                    \"incubationdate_dt\": \"2006-01-17T00:00:00Z\",\n                    \"_version_\": 1486960636996878300\n                  },\n                  {\n                    \"id\": \"3007WFP\",\n                    \"name\": \"Dell Widescreen UltraSharp 3007WFP\",\n                    \"manu\": \"Dell, Inc.\",\n                    \"manu_id_s\": \"dell\",\n                    \"cat\": [\n                      \"electronics and computer1\"\n                    ],\n                    \"features\": [\n                      \"30\\\" TFT active matrix LCD, 2560 x 1600, .25mm dot pitch, 700:1 contrast\"\n                    ],\n                    \"includes\": \"USB cable\",\n                    \"weight\": 401.6,\n                    \"price\": 2199,\n                    \"price_c\": \"2199,USD\",\n                    \"popularity\": 6,\n                    \"inStock\": true,\n                    \"store\": \"43.17614,-90.57341\",\n                    \"_version_\": 1486960637584081000\n                  }\n                ]\n              }\n\n###Starting and stopping Solr\n\nIf you need to manually stop or start Solar, use the following commands:\n\n    sudo stop solr\n\n    sudo start solr\n    \n   \n##Backup indexed data\n\nAs a good practice, you should back up the indexed data from the Solr cluster nodes onto Azure Blob storage. Perform the following steps to do so:\n\n1. Connect to the cluster using SSH, then use the following command to create a snapshot of the indexed data:\n\n        curl http://headnode0:8983/solr/replication?command=backup\n\n    You should see a response like this:\n\n        <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        <response>\n          <lst name=\"responseHeader\">\n            <int name=\"status\">0</int>\n            <int name=\"QTime\">9</int>\n          </lst>\n          <str name=\"status\">OK</str>\n        </response>\n\n2. Next, change directories to __/usr/hdp/current/solr/example/solr__. There will be a subdirectory here for each collection. Each collection directory contains a __data__ directory, which is where the snapshot for that collection is located.\n\n    For example, if you used the steps earlier to index the sample documents, the __/usr/hdp/current/solr/example/solr/collection1/data__ directory should now contain a directory named __snapshot.###########__ where the #'s are the date and time of the snapshot.\n    \n3. Create a compressed archive of the snapshot folder using a command similar to the following:\n\n        tar -zcf snapshot.20150806185338855.tgz snapshot.20150806185338855\n\n    This will create a new archive named __snapshot.20150806185338855.tgz__, which contains the contents of the __snapshot.20150806185338855__ directory.\n    \n3. You can then store the archive to the cluster's primary storage using the following command:\n\n    hadoop fs -copyFromLocal snapshot.20150806185338855.tgz /example/data\n    \n    > [AZURE.NOTE] You may want to create a dedicated directory for storing Solr snapshots. For example, `hadoop fs -mkdir /solrbackup`.\n\nFor more information on working with Solr backup and restores, see [Making and restoring backups of SolrCores](https://cwiki.apache.org/confluence/display/solr/Making+and+Restoring+Backups+of+SolrCores).\n\n\n## See also##\n\n- [Install and use Hue on HDInsight clusters](hdinsight-hadoop-hue-linux.md). Hue is a web UI that makes it easy to create, run and save Pig and Hive jobs, as well as browse the default storage for your HDInsight cluster.\n\n- [Install and use Spark on HDInsight clusters][hdinsight-install-spark]. Use cluster customization to install Spark on HDInsight Hadoop clusters. Spark is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.\n\n- [Install R on HDInsight clusters][hdinsight-install-r]. Use cluster customization to install R on HDInsight Hadoop clusters. R is an open-source language and environment for statistical computing. It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming. It also provides extensive graphical capabilities.\n\n- [Install Giraph on HDInsight clusters](hdinsight-hadoop-giraph-install-linux.md). Use cluster customization to install Giraph on HDInsight Hadoop clusters. Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.\n\n- [Install Hue on HDInsight clusters](hdinsight-hadoop-hue-linux.md). Use cluster customization to install Hue on HDInsight Hadoop clusters. Hue is a set of Web applications used to interact with a Hadoop cluster.\n\n\n\n\n\n\n[hdinsight-provision]: hdinsight-provision-clusters-linux.md\n[hdinsight-install-r]: hdinsight-hadoop-r-scripts-linux.md\n[hdinsight-install-spark]: hdinsight-hadoop-spark-install-linux.md\n[hdinsight-cluster-customize]: hdinsight-hadoop-customize-cluster-linux.md\n \ntest\n"
}