{
  "nodes": [
    {
      "content": "Step 2: Upload data into a Machine Learning experiment | Microsoft Azure",
      "pos": [
        28,
        100
      ]
    },
    {
      "content": "Step 2 of the Develop a predictive solution walkthrough: Upload stored public data into Azure Machine Learning Studio.",
      "pos": [
        120,
        238
      ]
    },
    {
      "content": "Walkthrough Step 2: Upload existing data into an Azure Machine Learning experiment",
      "pos": [
        566,
        648
      ]
    },
    {
      "pos": [
        650,
        803
      ],
      "content": "This is the second step of the walkthrough, <bpt id=\"p1\">[</bpt>Developing a Predictive Solution with Azure ML<ept id=\"p1\">](machine-learning-walkthrough-develop-predictive-solution.md)</ept>"
    },
    {
      "content": "Create a Machine Learning workspace",
      "pos": [
        811,
        846
      ]
    },
    {
      "content": "Upload existing data",
      "pos": [
        909,
        929
      ]
    },
    {
      "content": "Create a new experiment",
      "pos": [
        937,
        960
      ]
    },
    {
      "content": "Train and evaluate the models",
      "pos": [
        1024,
        1053
      ]
    },
    {
      "content": "Publish the web service",
      "pos": [
        1121,
        1144
      ]
    },
    {
      "content": "Access the web service",
      "pos": [
        1206,
        1228
      ]
    },
    {
      "content": "To develop a predictive model for credit risk, we'll use the \"UCI Statlog (German Credit Data) Data Set\" from the UCI Machine Learning repository.",
      "pos": [
        1297,
        1443
      ]
    },
    {
      "content": "You can find it here:",
      "pos": [
        1444,
        1465
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a href=\"http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)\"&gt;</ph>http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)<ph id=\"ph2\">&lt;/a&gt;</ph>",
      "pos": [
        1468,
        1617
      ]
    },
    {
      "content": "We'll use the file named <bpt id=\"p1\">**</bpt>german.data<ept id=\"p1\">**</ept>.",
      "pos": [
        1619,
        1660
      ]
    },
    {
      "content": "Download this file to your local hard drive.",
      "pos": [
        1661,
        1705
      ]
    },
    {
      "content": "This dataset contains rows of 20 variables for 1000 past applicants for credit.",
      "pos": [
        1709,
        1788
      ]
    },
    {
      "content": "These 20 variables represent the dataset's feature vector, which provides identifying characteristics for each credit applicant.",
      "pos": [
        1789,
        1917
      ]
    },
    {
      "content": "An additional column in each row represents the applicant's credit risk, with 700 applicants identified as a low credit risk and 300 as a high risk.",
      "pos": [
        1918,
        2066
      ]
    },
    {
      "content": "The UCI website provides a description of the attributes of the feature vector, which include financial information, credit history, employment status, and personal information.",
      "pos": [
        2071,
        2248
      ]
    },
    {
      "content": "For each applicant, a binary rating has been given indicating whether they are a low or high credit risk.",
      "pos": [
        2249,
        2354
      ]
    },
    {
      "content": "We'll use this data to train a predictive analytics model.",
      "pos": [
        2358,
        2416
      ]
    },
    {
      "content": "When we're done, our model should be able to accept information for new individuals and predict whether they are a low or high credit risk.",
      "pos": [
        2417,
        2556
      ]
    },
    {
      "content": "Here's one interesting twist.",
      "pos": [
        2560,
        2589
      ]
    },
    {
      "content": "The description of the dataset explains that misclassifying a person as a low credit risk when they are actually a high credit risk is 5 times more costly to the financial institution than misclassifying a low credit risk as high.",
      "pos": [
        2590,
        2820
      ]
    },
    {
      "content": "One simple way to take this into account in our experiment is by duplicating (5 times) those entries that represent someone with a high credit risk.",
      "pos": [
        2821,
        2969
      ]
    },
    {
      "content": "Then, if the model misclassifies a high credit risk as low, it will do that misclassification 5 times, once for each duplicate.",
      "pos": [
        2970,
        3097
      ]
    },
    {
      "content": "This will increase the cost of this error in the training results.",
      "pos": [
        3098,
        3164
      ]
    },
    {
      "content": "Convert the dataset format",
      "pos": [
        3170,
        3196
      ]
    },
    {
      "content": "The original dataset uses a blank-separated format.",
      "pos": [
        3197,
        3248
      ]
    },
    {
      "content": "Machine Learning Studio works better with a comma-separated value (CSV) file, so we'll convert the dataset by replacing spaces with commas.",
      "pos": [
        3249,
        3388
      ]
    },
    {
      "content": "We can do this by using the following Windows PowerShell command:",
      "pos": [
        3392,
        3457
      ]
    },
    {
      "content": "We can also do this by using the Unix sed command:",
      "pos": [
        3526,
        3576
      ]
    },
    {
      "content": "Upload the dataset to Machine Learning Studio",
      "pos": [
        3628,
        3673
      ]
    },
    {
      "content": "Once the data has been converted to CSV format, we need to upload it into Machine Learning Studio.",
      "pos": [
        3675,
        3773
      ]
    },
    {
      "pos": [
        3781,
        3991
      ],
      "content": "Sign in to Machine Learning Studio (<bpt id=\"p1\">[</bpt>https://studio.azureml.net<ept id=\"p1\">](https://studio.azureml.net)</ept>) by using the Microsoft account you specified as the owner of the workspace, and click the <bpt id=\"p2\">**</bpt>Studio<ept id=\"p2\">**</ept> tab at the top."
    },
    {
      "pos": [
        3996,
        4039
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>+NEW<ept id=\"p1\">**</ept> at the bottom of the window."
    },
    {
      "pos": [
        4044,
        4063
      ],
      "content": "Select <bpt id=\"p1\">**</bpt>DATASET<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4068,
        4095
      ],
      "content": "Select <bpt id=\"p1\">**</bpt>FROM LOCAL FILE<ept id=\"p1\">**</ept>."
    },
    {
      "pos": [
        4100,
        4202
      ],
      "content": "In the <bpt id=\"p1\">**</bpt>Upload a new dataset<ept id=\"p1\">**</ept> dialog, click <bpt id=\"p2\">**</bpt>Browse<ept id=\"p2\">**</ept> and find the <bpt id=\"p3\">**</bpt>german.csv<ept id=\"p3\">**</ept> file you created."
    },
    {
      "content": "Enter a name for the dataset.",
      "pos": [
        4207,
        4236
      ]
    },
    {
      "content": "For this example, we'll call it \"UCI German Credit Card Data\".",
      "pos": [
        4237,
        4299
      ]
    },
    {
      "pos": [
        4304,
        4372
      ],
      "content": "For data type, select <bpt id=\"p1\">**</bpt>Generic CSV File With no header (.nh.csv)<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Add a description if youâ€™d like.",
      "pos": [
        4377,
        4409
      ]
    },
    {
      "pos": [
        4414,
        4427
      ],
      "content": "Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Upload the dataset",
      "pos": [
        4433,
        4451
      ]
    },
    {
      "content": "This uploads the data into a dataset module that we can use in an experiment.",
      "pos": [
        4461,
        4538
      ]
    },
    {
      "pos": [
        4540,
        4719
      ],
      "content": "For more information about importing various types of data into an experiment, see <bpt id=\"p1\">[</bpt>Import your training data into Azure Machine Learning Studio<ept id=\"p1\">](machine-learning-import-data.md)</ept>."
    },
    {
      "pos": [
        4723,
        4811
      ],
      "content": "Next: <bpt id=\"p1\">[</bpt>Create a new experiment<ept id=\"p1\">](machine-learning-walkthrough-3-create-new-experiment.md)</ept>"
    },
    {
      "content": "test",
      "pos": [
        4885,
        4889
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Step 2: Upload data into a Machine Learning experiment | Microsoft Azure\" \n    description=\"Step 2 of the Develop a predictive solution walkthrough: Upload stored public data into Azure Machine Learning Studio.\" \n    services=\"machine-learning\" \n    documentationCenter=\"\" \n    authors=\"garyericson\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"/>\n\n<tags \n    ms.service=\"machine-learning\" \n    ms.workload=\"tbd\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"07/10/2015\" \n    ms.author=\"garye\"/>\n\n\n# Walkthrough Step 2: Upload existing data into an Azure Machine Learning experiment\n\nThis is the second step of the walkthrough, [Developing a Predictive Solution with Azure ML](machine-learning-walkthrough-develop-predictive-solution.md)\n\n\n1.  [Create a Machine Learning workspace](machine-learning-walkthrough-1-create-ml-workspace.md)\n2.  **Upload existing data**\n3.  [Create a new experiment](machine-learning-walkthrough-3-create-new-experiment.md)\n4.  [Train and evaluate the models](machine-learning-walkthrough-4-train-and-evaluate-models.md)\n5.  [Publish the web service](machine-learning-walkthrough-5-publish-web-service.md)\n6.  [Access the web service](machine-learning-walkthrough-6-access-web-service.md)\n\n----------\n\nTo develop a predictive model for credit risk, we'll use the \"UCI Statlog (German Credit Data) Data Set\" from the UCI Machine Learning repository. You can find it here:  \n<a href=\"http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)\">http://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)</a>\n\nWe'll use the file named **german.data**. Download this file to your local hard drive.  \n\nThis dataset contains rows of 20 variables for 1000 past applicants for credit. These 20 variables represent the dataset's feature vector, which provides identifying characteristics for each credit applicant. An additional column in each row represents the applicant's credit risk, with 700 applicants identified as a low credit risk and 300 as a high risk.   \n\nThe UCI website provides a description of the attributes of the feature vector, which include financial information, credit history, employment status, and personal information. For each applicant, a binary rating has been given indicating whether they are a low or high credit risk.  \n\nWe'll use this data to train a predictive analytics model. When we're done, our model should be able to accept information for new individuals and predict whether they are a low or high credit risk.  \n\nHere's one interesting twist. The description of the dataset explains that misclassifying a person as a low credit risk when they are actually a high credit risk is 5 times more costly to the financial institution than misclassifying a low credit risk as high. One simple way to take this into account in our experiment is by duplicating (5 times) those entries that represent someone with a high credit risk. Then, if the model misclassifies a high credit risk as low, it will do that misclassification 5 times, once for each duplicate. This will increase the cost of this error in the training results.  \n\n##Convert the dataset format\nThe original dataset uses a blank-separated format. Machine Learning Studio works better with a comma-separated value (CSV) file, so we'll convert the dataset by replacing spaces with commas.  \n\nWe can do this by using the following Windows PowerShell command:   \n\n    cat german.data | %{$_ -replace \" \",\",\"} | sc german.csv  \n\nWe can also do this by using the Unix sed command:  \n\n    sed 's/ /,/g' german.data > german.csv  \n\n##Upload the dataset to Machine Learning Studio\n\nOnce the data has been converted to CSV format, we need to upload it into Machine Learning Studio.  \n\n1.  Sign in to Machine Learning Studio ([https://studio.azureml.net](https://studio.azureml.net)) by using the Microsoft account you specified as the owner of the workspace, and click the **Studio** tab at the top.\n2.  Click **+NEW** at the bottom of the window.\n3.  Select **DATASET**.\n4.  Select **FROM LOCAL FILE**.\n5.  In the **Upload a new dataset** dialog, click **Browse** and find the **german.csv** file you created.\n6.  Enter a name for the dataset. For this example, we'll call it \"UCI German Credit Card Data\".\n7.  For data type, select **Generic CSV File With no header (.nh.csv)**.\n8.  Add a description if youâ€™d like.\n9.  Click **OK**.  \n\n![Upload the dataset][1]  \n\n \nThis uploads the data into a dataset module that we can use in an experiment.\n\nFor more information about importing various types of data into an experiment, see [Import your training data into Azure Machine Learning Studio](machine-learning-import-data.md).\n\n**Next: [Create a new experiment](machine-learning-walkthrough-3-create-new-experiment.md)**\n\n[1]: ./media/machine-learning-walkthrough-2-upload-data/upload1.png\n \ntest\n"
}