<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Serialize data with the Microsoft Avro Library | Microsoft Azure</source>
          <target state="new">Serialize data with the Microsoft Avro Library | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how Azure HDInsight uses Avro to serialize big data.</source>
          <target state="new">Learn how Azure HDInsight uses Avro to serialize big data.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Serialize data in Hadoop with the Microsoft Avro Library</source>
          <target state="new">Serialize data in Hadoop with the Microsoft Avro Library</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This topic shows how to use the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library<ph id="ph2">&lt;/a&gt;</ph> to serialize objects and other data structures into streams in order to persist them to memory, a database, or a file, and also how to deserialize them to recover the original objects.</source>
          <target state="new">This topic shows how to use the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library<ph id="ph2">&lt;/a&gt;</ph> to serialize objects and other data structures into streams in order to persist them to memory, a database, or a file, and also how to deserialize them to recover the original objects.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="apacheAvro"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Apache Avro</source>
          <target state="new"><ph id="ph1">&lt;a name="apacheAvro"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Apache Avro</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library<ph id="ph2">&lt;/a&gt;</ph> implements the Apache Avro data serialization system for the Microsoft.NET environment.</source>
          <target state="new">The <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library<ph id="ph2">&lt;/a&gt;</ph> implements the Apache Avro data serialization system for the Microsoft.NET environment.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Apache Avro provides a compact binary data interchange format for serialization.</source>
          <target state="new">Apache Avro provides a compact binary data interchange format for serialization.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>It uses <ph id="ph1">&lt;a href="http://www.json.org" target="_blank"&gt;</ph>JSON<ph id="ph2">&lt;/a&gt;</ph> to define a language-agnostic schema that underwrites language interoperability.</source>
          <target state="new">It uses <ph id="ph1">&lt;a href="http://www.json.org" target="_blank"&gt;</ph>JSON<ph id="ph2">&lt;/a&gt;</ph> to define a language-agnostic schema that underwrites language interoperability.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Data serialized in one language can be read in another.</source>
          <target state="new">Data serialized in one language can be read in another.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Currently C, C++, C#, Java, PHP, Python, and Ruby are supported.</source>
          <target state="new">Currently C, C++, C#, Java, PHP, Python, and Ruby are supported.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Detailed information on the format can be found in the <ph id="ph1">&lt;a href="http://avro.apache.org/docs/current/spec.html" target="_blank"&gt;</ph>Apache Avro Specification<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">Detailed information on the format can be found in the <ph id="ph1">&lt;a href="http://avro.apache.org/docs/current/spec.html" target="_blank"&gt;</ph>Apache Avro Specification<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Note that the current version of the Microsoft Avro Library does not support the remote procedure calls (RPCs) part of this specification.</source>
          <target state="new">Note that the current version of the Microsoft Avro Library does not support the remote procedure calls (RPCs) part of this specification.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The serialized representation of an object in the Avro system consists of two parts: schema and actual value.</source>
          <target state="new">The serialized representation of an object in the Avro system consists of two parts: schema and actual value.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The Avro schema describes the language-independent data model of the serialized data with JSON.</source>
          <target state="new">The Avro schema describes the language-independent data model of the serialized data with JSON.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>It is present side-by-side with a binary representation of data.</source>
          <target state="new">It is present side-by-side with a binary representation of data.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Having the schema separate from the binary representation permits each object to be written with no per-value overheads, making serialization fast and the representation small.</source>
          <target state="new">Having the schema separate from the binary representation permits each object to be written with no per-value overheads, making serialization fast and the representation small.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hadoopScenario"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>The Hadoop scenario</source>
          <target state="new"><ph id="ph1">&lt;a name="hadoopScenario"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>The Hadoop scenario</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The Apache Avro serialization format is widely used in Azure HDInsight and other Apache Hadoop environments.</source>
          <target state="new">The Apache Avro serialization format is widely used in Azure HDInsight and other Apache Hadoop environments.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Avro provides a convenient way to represent complex data structures within a Hadoop MapReduce job.</source>
          <target state="new">Avro provides a convenient way to represent complex data structures within a Hadoop MapReduce job.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The format of Avro files (Avro object container file) has been designed to support the distributed MapReduce programming model.</source>
          <target state="new">The format of Avro files (Avro object container file) has been designed to support the distributed MapReduce programming model.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The key feature that enables the distribution is that the files are “splittable” in the sense that one can seek any point in a file and start reading from a particular block.</source>
          <target state="new">The key feature that enables the distribution is that the files are “splittable” in the sense that one can seek any point in a file and start reading from a particular block.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="serializationMAL"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Serialization in the Microsoft Avro Library</source>
          <target state="new"><ph id="ph1">&lt;a name="serializationMAL"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Serialization in the Microsoft Avro Library</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The .NET Library for Avro supports two ways of serializing objects:</source>
          <target state="new">The .NET Library for Avro supports two ways of serializing objects:</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>reflection<ept id="p1">**</ept> - The JSON schema for the types is automatically built from the data contract attributes of the .NET types to be serialized.</source>
          <target state="new"><bpt id="p1">**</bpt>reflection<ept id="p1">**</ept> - The JSON schema for the types is automatically built from the data contract attributes of the .NET types to be serialized.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>generic record<ept id="p1">**</ept> - A JSON schema is explicitly specified in a record represented by the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AvroRecord<ept id="p3">**</ept><ept id="p2">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> class when no .NET types are present to describe the schema for the data to be serialized.</source>
          <target state="new"><bpt id="p1">**</bpt>generic record<ept id="p1">**</ept> - A JSON schema is explicitly specified in a record represented by the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AvroRecord<ept id="p3">**</ept><ept id="p2">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> class when no .NET types are present to describe the schema for the data to be serialized.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>When the data schema is known to both the writer and reader of the stream, the data can be sent without its schema.</source>
          <target state="new">When the data schema is known to both the writer and reader of the stream, the data can be sent without its schema.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>In cases when an Avro object container file is used, the schema is stored within the file.</source>
          <target state="new">In cases when an Avro object container file is used, the schema is stored within the file.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Other parameters, such as the codec used for data compression, can be specified.</source>
          <target state="new">Other parameters, such as the codec used for data compression, can be specified.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>These scenarios are outlined in more detail and illustrated in the code examples below.</source>
          <target state="new">These scenarios are outlined in more detail and illustrated in the code examples below.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="prerequisites"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Microsoft Avro Library prerequisites</source>
          <target state="new"><ph id="ph1">&lt;a name="prerequisites"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Microsoft Avro Library prerequisites</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="http://www.microsoft.com/download/details.aspx?id=17851" target="_blank"&gt;</ph>Microsoft .NET Framework 4<ph id="ph2">&lt;/a&gt;</ph></source>
          <target state="new"><ph id="ph1">&lt;a href="http://www.microsoft.com/download/details.aspx?id=17851" target="_blank"&gt;</ph>Microsoft .NET Framework 4<ph id="ph2">&lt;/a&gt;</ph></target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="http://james.newtonking.com/json" target="_blank"&gt;</ph>Newtonsoft Json.NET<ph id="ph2">&lt;/a&gt;</ph> (6.0.4 or later)</source>
          <target state="new"><ph id="ph1">&lt;a href="http://james.newtonking.com/json" target="_blank"&gt;</ph>Newtonsoft Json.NET<ph id="ph2">&lt;/a&gt;</ph> (6.0.4 or later)</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Note that the Newtonsoft.Json.dll dependency is downloaded automatically with the installation of the Microsoft Avro Library.</source>
          <target state="new">Note that the Newtonsoft.Json.dll dependency is downloaded automatically with the installation of the Microsoft Avro Library.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>The procedure for this is provided in the following section.</source>
          <target state="new">The procedure for this is provided in the following section.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="installation"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Microsoft Avro Library installation</source>
          <target state="new"><ph id="ph1">&lt;a name="installation"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Microsoft Avro Library installation</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>The Microsoft Avro Library is distributed as a NuGet package that can be installed from Visual Studio via the following procedure:</source>
          <target state="new">The Microsoft Avro Library is distributed as a NuGet package that can be installed from Visual Studio via the following procedure:</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Select the <bpt id="p1">**</bpt>Project<ept id="p1">**</ept> tab -&gt; <bpt id="p2">**</bpt>Manage NuGet Packages...<ept id="p2">**</ept></source>
          <target state="new">Select the <bpt id="p1">**</bpt>Project<ept id="p1">**</ept> tab -&gt; <bpt id="p2">**</bpt>Manage NuGet Packages...<ept id="p2">**</ept></target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Search for "Microsoft.Hadoop.Avro" in the <bpt id="p1">**</bpt>Search Online<ept id="p1">**</ept> box.</source>
          <target state="new">Search for "Microsoft.Hadoop.Avro" in the <bpt id="p1">**</bpt>Search Online<ept id="p1">**</ept> box.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Click the <bpt id="p1">**</bpt>Install<ept id="p1">**</ept> button next to <bpt id="p2">**</bpt>Microsoft Azure HDInsight Avro Library<ept id="p2">**</ept>.</source>
          <target state="new">Click the <bpt id="p1">**</bpt>Install<ept id="p1">**</ept> button next to <bpt id="p2">**</bpt>Microsoft Azure HDInsight Avro Library<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Note that the Newtonsoft.Json.dll (&gt;=6.0.4) dependency is also downloaded automatically with the Microsoft Avro Library.</source>
          <target state="new">Note that the Newtonsoft.Json.dll (&gt;=6.0.4) dependency is also downloaded automatically with the Microsoft Avro Library.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>You may want to visit the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library home page<ph id="ph2">&lt;/a&gt;</ph> to read the current release notes.</source>
          <target state="new">You may want to visit the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library home page<ph id="ph2">&lt;/a&gt;</ph> to read the current release notes.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="sourceCode"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Microsoft Avro Library source code</source>
          <target state="new"><ph id="ph1">&lt;a name="sourceCode"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Microsoft Avro Library source code</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The Microsoft Avro Library source code is available at the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library home page<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">The Microsoft Avro Library source code is available at the <ph id="ph1">&lt;a href="https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library" target="_blank"&gt;</ph>Microsoft Avro Library home page<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="compiling"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Compiling the schema by using the Microsoft Avro Library</source>
          <target state="new"><ph id="ph1">&lt;a name="compiling"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Compiling the schema by using the Microsoft Avro Library</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The Microsoft Avro Library contains a code generation utility that allows creating C# types automatically based on the previously defined JSON schema.</source>
          <target state="new">The Microsoft Avro Library contains a code generation utility that allows creating C# types automatically based on the previously defined JSON schema.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The code generation utility is not distributed as a binary executable, but can be easily built via the following procedure:</source>
          <target state="new">The code generation utility is not distributed as a binary executable, but can be easily built via the following procedure:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Download the .zip file with the latest version of HDInsight SDK source code from <ph id="ph1">&lt;a href="http://hadoopsdk.codeplex.com/SourceControl/latest" target="_blank"&gt;</ph>Microsoft .NET SDK For Hadoop<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">Download the .zip file with the latest version of HDInsight SDK source code from <ph id="ph1">&lt;a href="http://hadoopsdk.codeplex.com/SourceControl/latest" target="_blank"&gt;</ph>Microsoft .NET SDK For Hadoop<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>(Click the <bpt id="p1">**</bpt>Download<ept id="p1">**</ept> icon.)</source>
          <target state="new">(Click the <bpt id="p1">**</bpt>Download<ept id="p1">**</ept> icon.)</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Extract the HDInsight SDK to a directory on the machine with .NET Framework 4 installed and connected to the Internet for downloading necessary dependency NuGet packages.</source>
          <target state="new">Extract the HDInsight SDK to a directory on the machine with .NET Framework 4 installed and connected to the Internet for downloading necessary dependency NuGet packages.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Below we will assume that the source code is extracted to C:\SDK.</source>
          <target state="new">Below we will assume that the source code is extracted to C:\SDK.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Go to the folder C:\SDK\src\Microsoft.Hadoop.Avro.Tools and run build.bat.</source>
          <target state="new">Go to the folder C:\SDK\src\Microsoft.Hadoop.Avro.Tools and run build.bat.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>(The file will call MSBuild from the 32-bit distribution of the .NET Framework.</source>
          <target state="new">(The file will call MSBuild from the 32-bit distribution of the .NET Framework.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>If you would like to use the 64-bit version, edit build.bat, following the comments inside the file.) Ensure that the build is successful.</source>
          <target state="new">If you would like to use the 64-bit version, edit build.bat, following the comments inside the file.) Ensure that the build is successful.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>(On some systems, MSBuild may produce warnings.</source>
          <target state="new">(On some systems, MSBuild may produce warnings.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>These warnings do not affect the utility as long as there are no build errors.)</source>
          <target state="new">These warnings do not affect the utility as long as there are no build errors.)</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>The compiled utility is located in C:\SDK\Bin\Unsigned\Release\Microsoft.Hadoop.Avro.Tools.</source>
          <target state="new">The compiled utility is located in C:\SDK\Bin\Unsigned\Release\Microsoft.Hadoop.Avro.Tools.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>To get familiar with the command-line syntax, execute the following command from the folder where the code generation utility is located: <ph id="ph1">`Microsoft.Hadoop.Avro.Tools help /c:codegen`</ph></source>
          <target state="new">To get familiar with the command-line syntax, execute the following command from the folder where the code generation utility is located: <ph id="ph1">`Microsoft.Hadoop.Avro.Tools help /c:codegen`</ph></target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>To test the utility, you can generate C# classes from the sample JSON schema file provided with the source code.</source>
          <target state="new">To test the utility, you can generate C# classes from the sample JSON schema file provided with the source code.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Execute the following command:</source>
          <target state="new">Execute the following command:</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>This is supposed to produce two C# files in the current directory: SensorData.cs and Location.cs.</source>
          <target state="new">This is supposed to produce two C# files in the current directory: SensorData.cs and Location.cs.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>To understand the logic that the code generation utility is using while converting the JSON schema to C# types, see the file GenerationVerification.feature located in C:\SDK\src\Microsoft.Hadoop.Avro.Tools\Doc.</source>
          <target state="new">To understand the logic that the code generation utility is using while converting the JSON schema to C# types, see the file GenerationVerification.feature located in C:\SDK\src\Microsoft.Hadoop.Avro.Tools\Doc.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Please note that namespaces are extracted from the JSON schema, using the logic described in the file mentioned in the previous paragraph.</source>
          <target state="new">Please note that namespaces are extracted from the JSON schema, using the logic described in the file mentioned in the previous paragraph.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Namespaces extracted from the schema take precedence over whatever is provided with the /n parameter in the utility command line.</source>
          <target state="new">Namespaces extracted from the schema take precedence over whatever is provided with the /n parameter in the utility command line.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>If you want to override the namespaces contained within the schema, use the /nf parameter.</source>
          <target state="new">If you want to override the namespaces contained within the schema, use the /nf parameter.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>For example, to change all namespaces from the SampleJSONSchema.avsc to my.own.nspace, execute the following command:</source>
          <target state="new">For example, to change all namespaces from the SampleJSONSchema.avsc to my.own.nspace, execute the following command:</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="samples"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Guide to the samples for the Microsoft Avro Library</source>
          <target state="new"><ph id="ph1">&lt;a name="samples"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Guide to the samples for the Microsoft Avro Library</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Six examples provided in this topic illustrate different scenarios supported by the Microsoft Avro Library.</source>
          <target state="new">Six examples provided in this topic illustrate different scenarios supported by the Microsoft Avro Library.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>The Microsoft Avro Library is designed to work with any stream.</source>
          <target state="new">The Microsoft Avro Library is designed to work with any stream.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>In these examples, data is manipulated via memory streams rather than file streams or databases for simplicity and consistency.</source>
          <target state="new">In these examples, data is manipulated via memory streams rather than file streams or databases for simplicity and consistency.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The approach taken in a production environment will depend on the exact scenario requirements, data source and volume, performance constraints, and other factors.</source>
          <target state="new">The approach taken in a production environment will depend on the exact scenario requirements, data source and volume, performance constraints, and other factors.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>The first two examples show how to serialize and deserialize data into memory stream buffers by using reflection and generic records.</source>
          <target state="new">The first two examples show how to serialize and deserialize data into memory stream buffers by using reflection and generic records.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>The schema in these two cases is assumed to be shared between the readers and writers out-of-band.</source>
          <target state="new">The schema in these two cases is assumed to be shared between the readers and writers out-of-band.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>The third and fourth examples show how to serialize and deserialize data by using the Avro object container files.</source>
          <target state="new">The third and fourth examples show how to serialize and deserialize data by using the Avro object container files.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>When data is stored in an Avro container file, its schema is always stored with it because the schema must be shared for deserialization.</source>
          <target state="new">When data is stored in an Avro container file, its schema is always stored with it because the schema must be shared for deserialization.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>The sample containing the first four examples can be downloaded from the <ph id="ph1">&lt;a href="http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-86055923" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</source>
          <target state="new">The sample containing the first four examples can be downloaded from the <ph id="ph1">&lt;a href="http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-86055923" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>The fifth example shows how to how to use a custom compression codec for Avro object container files.</source>
          <target state="new">The fifth example shows how to how to use a custom compression codec for Avro object container files.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>A sample containing the code for this example can be downloaded from the <ph id="ph1">&lt;a href="http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-67159111" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</source>
          <target state="new">A sample containing the code for this example can be downloaded from the <ph id="ph1">&lt;a href="http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-67159111" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The sixth sample shows how to use Avro serialization to upload data to Azure Blob storage and then analyze it by using Hive with an HDInsight (Hadoop) cluster.</source>
          <target state="new">The sixth sample shows how to use Avro serialization to upload data to Azure Blob storage and then analyze it by using Hive with an HDInsight (Hadoop) cluster.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>It can be downloaded from the <ph id="ph1">&lt;a href="https://code.msdn.microsoft.com/windowsazure/Using-Avro-to-upload-data-ae81b1e3" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</source>
          <target state="new">It can be downloaded from the <ph id="ph1">&lt;a href="https://code.msdn.microsoft.com/windowsazure/Using-Avro-to-upload-data-ae81b1e3" target="_blank"&gt;</ph>Azure code samples<ph id="ph2">&lt;/a&gt;</ph> site.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Here are links to the six samples discussed in the topic:</source>
          <target state="new">Here are links to the six samples discussed in the topic:</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario1"&gt;</ph><bpt id="p1">**</bpt>Serialization with reflection<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema for types to be serialized is automatically built from the data contract attributes.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario1"&gt;</ph><bpt id="p1">**</bpt>Serialization with reflection<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema for types to be serialized is automatically built from the data contract attributes.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario2"&gt;</ph><bpt id="p1">**</bpt>Serialization with generic record<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is explicitly specified in a record when no .NET type is available for reflection.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario2"&gt;</ph><bpt id="p1">**</bpt>Serialization with generic record<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is explicitly specified in a record when no .NET type is available for reflection.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario3"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with reflection<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is automatically built and shared together with the serialized data via an Avro object container file.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario3"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with reflection<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is automatically built and shared together with the serialized data via an Avro object container file.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario4"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with generic record<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is explicitly specified before the serialization and shared together with the data via an Avro object container file.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario4"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with generic record<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The JSON schema is explicitly specified before the serialization and shared together with the data via an Avro object container file.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario5"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with a custom compression codec<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The example shows how to create an Avro object container file with a customized .NET implementation of the Deflate data compression codec.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario5"&gt;</ph><bpt id="p1">**</bpt>Serialization using object container files with a custom compression codec<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The example shows how to create an Avro object container file with a customized .NET implementation of the Deflate data compression codec.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="#Scenario6"&gt;</ph><bpt id="p1">**</bpt>Using Avro to upload data for the Microsoft Azure HDInsight service<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The example illustrates how Avro serialization interacts with the HDInsight service.</source>
          <target state="new"><ph id="ph1">&lt;a href="#Scenario6"&gt;</ph><bpt id="p1">**</bpt>Using Avro to upload data for the Microsoft Azure HDInsight service<ept id="p1">**</ept><ph id="ph2">&lt;/a&gt;</ph> - The example illustrates how Avro serialization interacts with the HDInsight service.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>An active Azure subscription and access to an Azure HDInsight cluster are required to run this example.</source>
          <target state="new">An active Azure subscription and access to an Azure HDInsight cluster are required to run this example.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario1"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 1: Serialization with reflection</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario1"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 1: Serialization with reflection</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The JSON schema for the types can be automatically built by the Microsoft Avro Library via reflection from the data contract attributes of the C# objects to be serialized.</source>
          <target state="new">The JSON schema for the types can be automatically built by the Microsoft Avro Library via reflection from the data contract attributes of the C# objects to be serialized.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>The Microsoft Avro Library creates an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAvroSeralizer<ph id="ph1">&lt;T&gt;</ph><ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/dn627341.aspx)</ept> to identify the fields to be serialized.</source>
          <target state="new">The Microsoft Avro Library creates an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>IAvroSeralizer<ph id="ph1">&lt;T&gt;</ph><ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/dn627341.aspx)</ept> to identify the fields to be serialized.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>In this example, objects (a <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> class with a member <bpt id="p2">**</bpt>Location<ept id="p2">**</ept> struct) are serialized to a memory stream, and this stream is in turn deserialized.</source>
          <target state="new">In this example, objects (a <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> class with a member <bpt id="p2">**</bpt>Location<ept id="p2">**</ept> struct) are serialized to a memory stream, and this stream is in turn deserialized.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>The result is then compared to the initial instance to confirm that the <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> object recovered is identical to the original.</source>
          <target state="new">The result is then compared to the initial instance to confirm that the <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> object recovered is identical to the original.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>The schema in this example is assumed to be shared between the readers and writers, so the Avro object container format is not required.</source>
          <target state="new">The schema in this example is assumed to be shared between the readers and writers, so the Avro object container format is not required.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>For an example of how to serialize and deserialize data into memory buffers by using reflection with the object container format when the schema must be shared with the data, see <ph id="ph1">&lt;a href="#Scenario3"&gt;</ph>Serialization using object container files with reflection<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">For an example of how to serialize and deserialize data into memory buffers by using reflection with the object container format when the schema must be shared with the data, see <ph id="ph1">&lt;a href="#Scenario3"&gt;</ph>Serialization using object container files with reflection<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 2: Serialization with a generic record</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario2"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 2: Serialization with a generic record</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>A JSON schema can be explicitly specified in a generic record when reflection cannot be used because the data cannot be represented via .NET classes with a data contract.</source>
          <target state="new">A JSON schema can be explicitly specified in a generic record when reflection cannot be used because the data cannot be represented via .NET classes with a data contract.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>This method is generally slower than using reflection.</source>
          <target state="new">This method is generally slower than using reflection.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>In such cases, the schema for the data may also be dynamic, i.e., not be known at compile time.</source>
          <target state="new">In such cases, the schema for the data may also be dynamic, i.e., not be known at compile time.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Data represented as comma-separated values (CSV) files whose schema is unknown until it is transformed to the Avro format at run time is an example of this sort of dynamic scenario.</source>
          <target state="new">Data represented as comma-separated values (CSV) files whose schema is unknown until it is transformed to the Avro format at run time is an example of this sort of dynamic scenario.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>This example shows how to create and use an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AvroRecord<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> to explicitly specify a JSON schema, how to populate it with the data, and then how to serialize and deserialize it.</source>
          <target state="new">This example shows how to create and use an <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AvroRecord<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> to explicitly specify a JSON schema, how to populate it with the data, and then how to serialize and deserialize it.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>The result is then compared to the initial instance to confirm that the record recovered is identical to the original.</source>
          <target state="new">The result is then compared to the initial instance to confirm that the record recovered is identical to the original.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>The schema in this example is assumed to be shared between the readers and writers, so the Avro object container format is not required.</source>
          <target state="new">The schema in this example is assumed to be shared between the readers and writers, so the Avro object container format is not required.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>For an example of how to serialize and deserialize data into memory buffers by using a generic record with the object container format when the schema must be included with the serialized data, see the <ph id="ph1">&lt;a href="#Scenario4"&gt;</ph>Serialization using object container files with generic record<ph id="ph2">&lt;/a&gt;</ph> example.</source>
          <target state="new">For an example of how to serialize and deserialize data into memory buffers by using a generic record with the object container format when the schema must be included with the serialized data, see the <ph id="ph1">&lt;a href="#Scenario4"&gt;</ph>Serialization using object container files with generic record<ph id="ph2">&lt;/a&gt;</ph> example.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario3"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 3: Serialization using object container files and serialization with reflection</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario3"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 3: Serialization using object container files and serialization with reflection</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>This example is similar to the scenario in the <ph id="ph1">&lt;a href="#Scenario1"&gt;</ph> first example<ph id="ph2">&lt;/a&gt;</ph>, where the schema is implicitly specified with reflection.</source>
          <target state="new">This example is similar to the scenario in the <ph id="ph1">&lt;a href="#Scenario1"&gt;</ph> first example<ph id="ph2">&lt;/a&gt;</ph>, where the schema is implicitly specified with reflection.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>The difference is that here, the schema is not assumed to be known to the reader that deserializes it.</source>
          <target state="new">The difference is that here, the schema is not assumed to be known to the reader that deserializes it.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> objects to be serialized and their implicitly specified schema are stored in an Avro object container file represented by the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AvroContainer<ept id="p3">**</ept><ept id="p2">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> class.</source>
          <target state="new">The <bpt id="p1">**</bpt>SensorData<ept id="p1">**</ept> objects to be serialized and their implicitly specified schema are stored in an Avro object container file represented by the <bpt id="p2">[</bpt><bpt id="p3">**</bpt>AvroContainer<ept id="p3">**</ept><ept id="p2">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> class.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>The data is serialized in this example with <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SequentialWriter<ph id="ph1">&lt;SensorData&gt;</ph><ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/dn627340.aspx)</ept> and deserialized with <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SequentialReader<ph id="ph2">&lt;SensorData&gt;</ph><ept id="p4">**</ept><ept id="p3">](http://msdn.microsoft.com/library/dn627340.aspx)</ept>.</source>
          <target state="new">The data is serialized in this example with <bpt id="p1">[</bpt><bpt id="p2">**</bpt>SequentialWriter<ph id="ph1">&lt;SensorData&gt;</ph><ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/dn627340.aspx)</ept> and deserialized with <bpt id="p3">[</bpt><bpt id="p4">**</bpt>SequentialReader<ph id="ph2">&lt;SensorData&gt;</ph><ept id="p4">**</ept><ept id="p3">](http://msdn.microsoft.com/library/dn627340.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>The result then is compared to the initial instances to ensure identity.</source>
          <target state="new">The result then is compared to the initial instances to ensure identity.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>The data in the object container file is compressed via the default <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-100]</ept> compression codec from .NET Framework 4.</source>
          <target state="new">The data in the object container file is compressed via the default <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-100]</ept> compression codec from .NET Framework 4.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>See the <ph id="ph1">&lt;a href="#Scenario5"&gt;</ph> fifth example<ph id="ph2">&lt;/a&gt;</ph> in this topic to learn how to use a more recent and superior version of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-110]</ept> compression codec available in .NET Framework 4.5.</source>
          <target state="new">See the <ph id="ph1">&lt;a href="#Scenario5"&gt;</ph> fifth example<ph id="ph2">&lt;/a&gt;</ph> in this topic to learn how to use a more recent and superior version of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-110]</ept> compression codec available in .NET Framework 4.5.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario4"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 4: Serialization using object container files and serialization with generic record</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario4"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 4: Serialization using object container files and serialization with generic record</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>This example is similar to the scenario in the <ph id="ph1">&lt;a href="#Scenario2"&gt;</ph> second example<ph id="ph2">&lt;/a&gt;</ph>, where the schema is explicitly specified with JSON.</source>
          <target state="new">This example is similar to the scenario in the <ph id="ph1">&lt;a href="#Scenario2"&gt;</ph> second example<ph id="ph2">&lt;/a&gt;</ph>, where the schema is explicitly specified with JSON.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>The difference is that here, the schema is not assumed to be known to the reader that deserializes it.</source>
          <target state="new">The difference is that here, the schema is not assumed to be known to the reader that deserializes it.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>The test data set is collected into a list of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AvroRecord<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> objects via an explicitly defined JSON schema and then stored in an object container file represented by the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AvroContainer<ept id="p4">**</ept><ept id="p3">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> class.</source>
          <target state="new">The test data set is collected into a list of <bpt id="p1">[</bpt><bpt id="p2">**</bpt>AvroRecord<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> objects via an explicitly defined JSON schema and then stored in an object container file represented by the <bpt id="p3">[</bpt><bpt id="p4">**</bpt>AvroContainer<ept id="p4">**</ept><ept id="p3">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> class.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>This container file creates a writer that is used to serialize the data, uncompressed, to a memory stream that is then saved to a file.</source>
          <target state="new">This container file creates a writer that is used to serialize the data, uncompressed, to a memory stream that is then saved to a file.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Codec.Null<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.codec.null.aspx)</ept> parameter used for creating the reader specifies that this data will not be compressed.</source>
          <target state="new">The <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Codec.Null<ept id="p2">**</ept><ept id="p1">](http://msdn.microsoft.com/library/microsoft.hadoop.avro.container.codec.null.aspx)</ept> parameter used for creating the reader specifies that this data will not be compressed.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>The data is then read from the file and deserialized into a collection of objects.</source>
          <target state="new">The data is then read from the file and deserialized into a collection of objects.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>This collection is compared to the initial list of Avro records to confirm that they are identical.</source>
          <target state="new">This collection is compared to the initial list of Avro records to confirm that they are identical.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario5"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 5: Serialization using object container files with a custom compression codec</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario5"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 5: Serialization using object container files with a custom compression codec</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>The fifth example shows how to how to use a custom compression codec for Avro object container files.</source>
          <target state="new">The fifth example shows how to how to use a custom compression codec for Avro object container files.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>A sample containing the code for this example can be downloaded from the <bpt id="p1">[</bpt>Azure code samples<ept id="p1">](http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-67159111)</ept> site.</source>
          <target state="new">A sample containing the code for this example can be downloaded from the <bpt id="p1">[</bpt>Azure code samples<ept id="p1">](http://code.msdn.microsoft.com/windowsazure/Serialize-data-with-the-67159111)</ept> site.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt>Avro Specification<ept id="p1">](http://avro.apache.org/docs/current/spec.html#Required+Codecs)</ept> allows usage of an optional compression codec (in addition to <bpt id="p2">**</bpt>Null<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Deflate<ept id="p3">**</ept> defaults).</source>
          <target state="new">The <bpt id="p1">[</bpt>Avro Specification<ept id="p1">](http://avro.apache.org/docs/current/spec.html#Required+Codecs)</ept> allows usage of an optional compression codec (in addition to <bpt id="p2">**</bpt>Null<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Deflate<ept id="p3">**</ept> defaults).</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>This example is not implementing a completely new codec such as Snappy (mentioned as a supported optional codec in the <bpt id="p1">[</bpt>Avro Specification<ept id="p1">](http://avro.apache.org/docs/current/spec.html#snappy)</ept>).</source>
          <target state="new">This example is not implementing a completely new codec such as Snappy (mentioned as a supported optional codec in the <bpt id="p1">[</bpt>Avro Specification<ept id="p1">](http://avro.apache.org/docs/current/spec.html#snappy)</ept>).</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>It shows how to use the .NET Framework 4.5 implementation of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-110]</ept> codec, which provides a better compression algorithm based on the <bpt id="p3">[</bpt>zlib<ept id="p3">](http://zlib.net/)</ept> compression library than the default .NET Framework 4 version.</source>
          <target state="new">It shows how to use the .NET Framework 4.5 implementation of the <bpt id="p1">[</bpt><bpt id="p2">**</bpt>Deflate<ept id="p2">**</ept><ept id="p1">][deflate-110]</ept> codec, which provides a better compression algorithm based on the <bpt id="p3">[</bpt>zlib<ept id="p3">](http://zlib.net/)</ept> compression library than the default .NET Framework 4 version.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="Scenario6"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 6: Using Avro to upload data for the Microsoft Azure HDInsight service</source>
          <target state="new"><ph id="ph1">&lt;a name="Scenario6"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Sample 6: Using Avro to upload data for the Microsoft Azure HDInsight service</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>The sixth example illustrates some programming techniques related to interacting with the Azure HDInsight service.</source>
          <target state="new">The sixth example illustrates some programming techniques related to interacting with the Azure HDInsight service.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>A sample containing the code for this example can be downloaded from the <bpt id="p1">[</bpt>Azure code samples<ept id="p1">](https://code.msdn.microsoft.com/windowsazure/Using-Avro-to-upload-data-ae81b1e3)</ept> site.</source>
          <target state="new">A sample containing the code for this example can be downloaded from the <bpt id="p1">[</bpt>Azure code samples<ept id="p1">](https://code.msdn.microsoft.com/windowsazure/Using-Avro-to-upload-data-ae81b1e3)</ept> site.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>The sample does the following:</source>
          <target state="new">The sample does the following:</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Connects to an existing HDInsight service cluster.</source>
          <target state="new">Connects to an existing HDInsight service cluster.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Serializes several CSV files and uploads the result to Azure Blob storage.</source>
          <target state="new">Serializes several CSV files and uploads the result to Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>(The CSV files are distributed together with the sample and represent an extract from AMEX Stock historical data distributed by <bpt id="p1">[</bpt>Infochimps<ept id="p1">](http://www.infochimps.com/)</ept> for the period 1970-2010.</source>
          <target state="new">(The CSV files are distributed together with the sample and represent an extract from AMEX Stock historical data distributed by <bpt id="p1">[</bpt>Infochimps<ept id="p1">](http://www.infochimps.com/)</ept> for the period 1970-2010.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>The sample reads CSV file data, converts the records to instances of the <bpt id="p1">**</bpt>Stock<ept id="p1">**</ept> class, and then serializes them by using reflection.</source>
          <target state="new">The sample reads CSV file data, converts the records to instances of the <bpt id="p1">**</bpt>Stock<ept id="p1">**</ept> class, and then serializes them by using reflection.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Stock type definition is created from a JSON schema via the Microsoft Avro Library code generation utility.</source>
          <target state="new">Stock type definition is created from a JSON schema via the Microsoft Avro Library code generation utility.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Creates a new external table called <bpt id="p1">**</bpt>Stocks<ept id="p1">**</ept> in Hive, and links it to the data uploaded in the previous step.</source>
          <target state="new">Creates a new external table called <bpt id="p1">**</bpt>Stocks<ept id="p1">**</ept> in Hive, and links it to the data uploaded in the previous step.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Executes a query by using Hive over the <bpt id="p1">**</bpt>Stocks<ept id="p1">**</ept> table.</source>
          <target state="new">Executes a query by using Hive over the <bpt id="p1">**</bpt>Stocks<ept id="p1">**</ept> table.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>In addition, the sample performs a clean-up procedure before and after performing major operations.</source>
          <target state="new">In addition, the sample performs a clean-up procedure before and after performing major operations.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>During the clean-up, all of the related Azure Blob data and folders are removed, and the Hive table is dropped.</source>
          <target state="new">During the clean-up, all of the related Azure Blob data and folders are removed, and the Hive table is dropped.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>You can also invoke the clean-up procedure from the sample command line.</source>
          <target state="new">You can also invoke the clean-up procedure from the sample command line.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>The sample has the following prerequisites:</source>
          <target state="new">The sample has the following prerequisites:</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>An active Microsoft Azure subscription and its subscription ID.</source>
          <target state="new">An active Microsoft Azure subscription and its subscription ID.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>A management certificate for the subscription with the corresponding private key.</source>
          <target state="new">A management certificate for the subscription with the corresponding private key.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>The certificate should be installed in the current user private storage on the machine used to run the sample.</source>
          <target state="new">The certificate should be installed in the current user private storage on the machine used to run the sample.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>An active HDInsight cluster.</source>
          <target state="new">An active HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>An Azure Storage account linked to the HDInsight cluster from the previous prerequisite, together with the corresponding primary or secondary access key.</source>
          <target state="new">An Azure Storage account linked to the HDInsight cluster from the previous prerequisite, together with the corresponding primary or secondary access key.</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>All of the information from the prerequisites should be entered to the sample configuration file before the sample is run.</source>
          <target state="new">All of the information from the prerequisites should be entered to the sample configuration file before the sample is run.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>There are two possible ways to do it:</source>
          <target state="new">There are two possible ways to do it:</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Edit the app.config file in the sample root directory and then build the sample</source>
          <target state="new">Edit the app.config file in the sample root directory and then build the sample</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>First build the sample, and then edit AvroHDISample.exe.config in the build directory</source>
          <target state="new">First build the sample, and then edit AvroHDISample.exe.config in the build directory</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>In both cases all edits should be done in the <bpt id="p1">**</bpt><ph id="ph1">&lt;appSettings&gt;</ph><ept id="p1">**</ept> settings section.</source>
          <target state="new">In both cases all edits should be done in the <bpt id="p1">**</bpt><ph id="ph1">&lt;appSettings&gt;</ph><ept id="p1">**</ept> settings section.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Please follow the comments in the file.</source>
          <target state="new">Please follow the comments in the file.</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>The sample is run from the command line by executing the following command (where the .zip file with the sample was assumed to be extracted to C:\AvroHDISample; if otherwise, use the relevant file path):</source>
          <target state="new">The sample is run from the command line by executing the following command (where the .zip file with the sample was assumed to be extracted to C:\AvroHDISample; if otherwise, use the relevant file path):</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>To clean up the cluster, run the following command:</source>
          <target state="new">To clean up the cluster, run the following command:</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4b91edf52a54b700e13ddd3d6f3ee83f4f9e7aa9</xliffext:olfilehash>
  </header>
</xliff>