{
  "nodes": [
    {
      "content": "Event Hubs Overview",
      "pos": [
        27,
        46
      ]
    },
    {
      "content": "Introduction and overview of Azure Event Hubs.",
      "pos": [
        64,
        110
      ]
    },
    {
      "content": "Azure Event Hubs overview",
      "pos": [
        394,
        419
      ]
    },
    {
      "content": "Many modern solutions intend to provide adaptive customer experiences or to improve products through continuous feedback and automated telemetry.",
      "pos": [
        421,
        566
      ]
    },
    {
      "content": "Such solutions are faced with the challenge of how to securely and reliably process very large amounts of information from many concurrent publishers.",
      "pos": [
        567,
        717
      ]
    },
    {
      "content": "Microsoft Azure Event Hubs is a managed platform service that provides a foundation for large-scale data intake in a broad variety of scenarios.",
      "pos": [
        718,
        862
      ]
    },
    {
      "content": "Examples of such scenarios are behavior tracking in mobile apps, traffic information from web farms, in-game event capture in console games, or telemetry data collected from industrial machines or connected vehicles.",
      "pos": [
        863,
        1079
      ]
    },
    {
      "content": "The common role that Event Hubs plays in solution architectures is that it acts as the \"front door\" for an event pipeline, often called an <bpt id=\"p1\">*</bpt>event ingestor<ept id=\"p1\">*</ept>.",
      "pos": [
        1080,
        1236
      ]
    },
    {
      "content": "An event ingestor is a component or service that sits between event producers and event consumers to decouple the production of an event stream from the consumption of those events.",
      "pos": [
        1237,
        1418
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        1422,
        1432
      ]
    },
    {
      "content": "Azure Event Hubs is an event processing service that provides event and telemetry ingress to the cloud at massive scale, with low latency and high reliability.",
      "pos": [
        1477,
        1636
      ]
    },
    {
      "content": "This service, used with other downstream services, is particularly useful in application instrumentation, user experience or workflow processing, and Internet of Things (IoT) scenarios.",
      "pos": [
        1637,
        1822
      ]
    },
    {
      "content": "Event Hubs provides a message stream handling capability and though an Event Hub is an entity similar to queues and topics, it has characteristics that are very different from traditional enterprise messaging.",
      "pos": [
        1823,
        2032
      ]
    },
    {
      "content": "Enterprise messaging scenarios commonly require a number of sophisticated capabilities such as sequencing, dead-lettering, transaction support, and strong delivery assurances, while the dominant concern for event intake is high throughput and processing flexibility for event streams.",
      "pos": [
        2033,
        2317
      ]
    },
    {
      "content": "Therefore, Azure Event Hubs capabilities differ from Service Bus topics in that they are strongly biased towards high throughput and event processing scenarios.",
      "pos": [
        2318,
        2478
      ]
    },
    {
      "content": "As such, Event Hubs do not implement some of the messaging capabilities that are available for topics.",
      "pos": [
        2479,
        2581
      ]
    },
    {
      "content": "If you need those capabilities, topics remain the optimal choice.",
      "pos": [
        2582,
        2647
      ]
    },
    {
      "content": "An Event Hub is created at the namespace level in Service Bus, similar to queues and topics.",
      "pos": [
        2649,
        2741
      ]
    },
    {
      "content": "Event Hubs uses AMQP and HTTP as its primary API interfaces.",
      "pos": [
        2742,
        2802
      ]
    },
    {
      "content": "The following diagram shows the relationship between Event Hubs and Service Bus.",
      "pos": [
        2803,
        2883
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        2887,
        2897
      ]
    },
    {
      "content": "Conceptual overview",
      "pos": [
        2945,
        2964
      ]
    },
    {
      "content": "Event Hubs provides message streaming through a partitioned consumer pattern.",
      "pos": [
        2966,
        3043
      ]
    },
    {
      "content": "Queues and topics use a <bpt id=\"p1\">[</bpt>Competing Consumer<ept id=\"p1\">](https://msdn.microsoft.com/library/dn568101.aspx)</ept> model in which each consumer attempts to read from the same queue or resource.",
      "pos": [
        3044,
        3217
      ]
    },
    {
      "content": "This competition for resources ultimately results in complexity and scale limits for stream processing applications.",
      "pos": [
        3218,
        3334
      ]
    },
    {
      "content": "Event Hubs uses a partitioned consumer pattern in which each consumer only reads a specific subset, or partition, of the message stream.",
      "pos": [
        3335,
        3471
      ]
    },
    {
      "content": "This pattern enables horizontal scale for event processing and provides other stream-focused features that are unavailable in queues and topics.",
      "pos": [
        3472,
        3616
      ]
    },
    {
      "content": "Partitions",
      "pos": [
        3622,
        3632
      ]
    },
    {
      "content": "A partition is an ordered sequence of events that is held in an Event Hub.",
      "pos": [
        3634,
        3708
      ]
    },
    {
      "content": "As newer events arrive, they are added to the end of this sequence.",
      "pos": [
        3709,
        3776
      ]
    },
    {
      "content": "A partition can be thought of as a \"commit log.\"",
      "pos": [
        3777,
        3825
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        3829,
        3839
      ]
    },
    {
      "content": "Partitions retain data for a configured retention time that is set at the Event Hub level.",
      "pos": [
        3884,
        3974
      ]
    },
    {
      "content": "This setting applies across all partitions in the Event Hub.",
      "pos": [
        3975,
        4035
      ]
    },
    {
      "content": "Events expire on a time basis; you cannot explicitly delete them.",
      "pos": [
        4036,
        4101
      ]
    },
    {
      "content": "An Event Hub contains multiple partitions.",
      "pos": [
        4102,
        4144
      ]
    },
    {
      "content": "Each partition is independent and contains its own sequence of data.",
      "pos": [
        4145,
        4213
      ]
    },
    {
      "content": "As a result, partitions often grow at different rates.",
      "pos": [
        4214,
        4268
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        4272,
        4282
      ]
    },
    {
      "content": "The number of partitions is specified at the Event Hub creation time and must be between 8 and 32.",
      "pos": [
        4327,
        4425
      ]
    },
    {
      "content": "Partitions are a data organization mechanism and are more related to the degree of downstream parallelism required in consuming applications than to Event Hubs throughput.",
      "pos": [
        4426,
        4597
      ]
    },
    {
      "content": "This makes the choice of the number of partitions in an Event Hub directly related to the number of concurrent readers you expect to have.",
      "pos": [
        4598,
        4736
      ]
    },
    {
      "content": "After Event Hub creation, the partition count is not changeable; you should consider this number in terms of long-term expected scale.",
      "pos": [
        4737,
        4871
      ]
    },
    {
      "content": "You can increase the 32 partition limit by contacting the Azure Service Bus team.",
      "pos": [
        4872,
        4953
      ]
    },
    {
      "content": "While partitions are identifiable and can be sent to directly, it is generally best to avoid sending data to specific partitions.",
      "pos": [
        4955,
        5084
      ]
    },
    {
      "content": "Instead, you can use higher level constructs introduced in the <bpt id=\"p1\">[</bpt>Event publisher<ept id=\"p1\">](#Event-publisher)</ept> and <bpt id=\"p2\">[</bpt>Publisher Policy<ept id=\"p2\">](#Capacity-and-security)</ept> sections.",
      "pos": [
        5085,
        5240
      ]
    },
    {
      "content": "In the context of Event Hubs, messages are referred to as <bpt id=\"p1\">*</bpt>event data<ept id=\"p1\">*</ept>.",
      "pos": [
        5242,
        5313
      ]
    },
    {
      "content": "Event data contains the body of the event, a user defined property bag, and various metadata about the event such as its offset in the partition and its number in the stream sequence.",
      "pos": [
        5314,
        5497
      ]
    },
    {
      "content": "Partitions are filled with a sequence of event data.",
      "pos": [
        5498,
        5550
      ]
    },
    {
      "content": "Event publisher",
      "pos": [
        5555,
        5570
      ]
    },
    {
      "content": "Any entity that sends events or data to an Event Hub is an <bpt id=\"p1\">*</bpt>event publisher<ept id=\"p1\">*</ept>.",
      "pos": [
        5572,
        5649
      ]
    },
    {
      "content": "Event publishers can publish events using either HTTPS or AMQP 1.0.",
      "pos": [
        5650,
        5717
      ]
    },
    {
      "content": "Event publishers use a Shared Access Signature (SAS) token to identify themselves to an Event Hub, and can have a unique identity, or use a common SAS token, depending on the requirements of the scenario.",
      "pos": [
        5718,
        5922
      ]
    },
    {
      "pos": [
        5924,
        6081
      ],
      "content": "For more information about working with SAS, see <bpt id=\"p1\">[</bpt>Shared Access Signature Authentication with Service Bus<ept id=\"p1\">](https://msdn.microsoft.com/library/dn170477.aspx)</ept>."
    },
    {
      "content": "Common publisher tasks",
      "pos": [
        6087,
        6109
      ]
    },
    {
      "content": "This section describes common tasks for event publishers.",
      "pos": [
        6111,
        6168
      ]
    },
    {
      "content": "Acquiring a SAS token",
      "pos": [
        6175,
        6196
      ]
    },
    {
      "content": "Shared Access Signature (SAS) is the authentication mechanism for Event Hubs.",
      "pos": [
        6198,
        6275
      ]
    },
    {
      "content": "Service Bus provides SAS policies at the namespace and Event Hub level.",
      "pos": [
        6276,
        6347
      ]
    },
    {
      "content": "A SAS token is generated from a SAS key and is an SHA hash of a URL, encoded in a specific format.",
      "pos": [
        6348,
        6446
      ]
    },
    {
      "content": "Using the name of the key (policy) and the token, Service Bus can regenerate the hash and thus authenticate the sender.",
      "pos": [
        6447,
        6566
      ]
    },
    {
      "content": "Normally, SAS tokens for event publishers are created with only <bpt id=\"p1\">**</bpt>send<ept id=\"p1\">**</ept> privileges on a specific Event Hub.",
      "pos": [
        6567,
        6675
      ]
    },
    {
      "content": "This SAS token URL mechanism is the basis for publisher identification introduced in the publisher policy.",
      "pos": [
        6676,
        6782
      ]
    },
    {
      "content": "For more information about working with SAS, see <bpt id=\"p1\">[</bpt>Shared Access Signature Authentication with Service Bus<ept id=\"p1\">](https://msdn.microsoft.com/library/dn170477.aspx)</ept>.",
      "pos": [
        6783,
        6940
      ]
    },
    {
      "content": "Publishing an event",
      "pos": [
        6947,
        6966
      ]
    },
    {
      "content": "You can publish an event via AMQP 1.0 or HTTPS.",
      "pos": [
        6968,
        7015
      ]
    },
    {
      "content": "Service Bus provides an <bpt id=\"p1\">[</bpt>EventHubClient<ept id=\"p1\">](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventhubclient.aspx)</ept> class for publishing events to an Event Hub from .NET clients.",
      "pos": [
        7016,
        7206
      ]
    },
    {
      "content": "For other runtimes and platforms, you can use any AMQP 1.0 client, such as <bpt id=\"p1\">[</bpt>Apache Qpid<ept id=\"p1\">](http://qpid.apache.org/)</ept>.",
      "pos": [
        7207,
        7321
      ]
    },
    {
      "content": "You can publish events individually, or batched.",
      "pos": [
        7322,
        7370
      ]
    },
    {
      "content": "A single publication (event data instance) has a limit of 256KB, regardless of whether it is a single event or a batch.",
      "pos": [
        7371,
        7490
      ]
    },
    {
      "content": "Publishing events larger than this results in an error.",
      "pos": [
        7491,
        7546
      ]
    },
    {
      "content": "It is a best practice for publishers to be unaware of partitions within the Event Hub and to only specify a <bpt id=\"p1\">*</bpt>partition key<ept id=\"p1\">*</ept> (introduced in the next section), or their identity via their SAS token.",
      "pos": [
        7547,
        7743
      ]
    },
    {
      "content": "The choice to use AMQP or HTTPS is specific to the usage scenario.",
      "pos": [
        7745,
        7811
      ]
    },
    {
      "content": "AMQP requires the establishment of a persistent bidirectional socket in addition to transport level security (TLS) or SSL/TLS.",
      "pos": [
        7812,
        7938
      ]
    },
    {
      "content": "This can be a costly operation in terms of network traffic, but only happens at the beginning of an AMQP session.",
      "pos": [
        7939,
        8052
      ]
    },
    {
      "content": "HTTPS has a lower initial overhead, but requires additional SSL overhead for every request.",
      "pos": [
        8053,
        8144
      ]
    },
    {
      "content": "For publishers who frequently publish events, AMQP offers significant performance, latency, and throughput savings.",
      "pos": [
        8145,
        8260
      ]
    },
    {
      "content": "Partition key",
      "pos": [
        8266,
        8279
      ]
    },
    {
      "content": "A partition key is a value that is used to map incoming event data into specific partitions for the purposes of data organization.",
      "pos": [
        8281,
        8411
      ]
    },
    {
      "content": "The partition key is a sender-supplied value passed into an Event Hub.",
      "pos": [
        8412,
        8482
      ]
    },
    {
      "content": "It is processed through a static hashing function, the result of which creates the partition assignment.",
      "pos": [
        8483,
        8587
      ]
    },
    {
      "content": "If you don't specify a partition key when publishing an event, a round robin assignment is used.",
      "pos": [
        8588,
        8684
      ]
    },
    {
      "content": "When using partition keys, the event publisher is only aware of its partition key, not the partition to which the events are published.",
      "pos": [
        8685,
        8820
      ]
    },
    {
      "content": "This decoupling of key and partition insulates the sender from needing to know too much about the downstream processing and storage of events.",
      "pos": [
        8821,
        8963
      ]
    },
    {
      "content": "Partition keys are important for organizing data for downstream processing, but are fundamentally unrelated to partitions themselves.",
      "pos": [
        8964,
        9097
      ]
    },
    {
      "content": "A per-device or user unique identity makes a good partition key, but other attributes such as geography can also be used to group related events into a single partition.",
      "pos": [
        9098,
        9267
      ]
    },
    {
      "content": "The following image shows event senders using partition keys to pin to partitions.",
      "pos": [
        9268,
        9350
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        9354,
        9364
      ]
    },
    {
      "content": "Azure Event Hubs ensures that any and all events sharing the same partition key value are delivered in order, and to the same partition.",
      "pos": [
        9409,
        9545
      ]
    },
    {
      "content": "Importantly, if partition keys are used with publisher policies, described in the next section, then the identity of the publisher and the value of the partition key must match.",
      "pos": [
        9546,
        9723
      ]
    },
    {
      "content": "Otherwise, an error occurs.",
      "pos": [
        9724,
        9751
      ]
    },
    {
      "content": "Event consumer",
      "pos": [
        9757,
        9771
      ]
    },
    {
      "content": "Any entity that reads event data from an Event Hub is an event consumer.",
      "pos": [
        9773,
        9845
      ]
    },
    {
      "content": "All event consumers read the event stream through partitions in a consumer group.",
      "pos": [
        9846,
        9927
      ]
    },
    {
      "content": "Each partition should have only one active reader at a time.",
      "pos": [
        9928,
        9988
      ]
    },
    {
      "content": "All Event Hubs consumers connect via the AMQP 1.0 session, in which events are delivered as they become available.",
      "pos": [
        9989,
        10103
      ]
    },
    {
      "content": "The client does not need to poll for data availability.",
      "pos": [
        10104,
        10159
      ]
    },
    {
      "content": "Consumer groups",
      "pos": [
        10166,
        10181
      ]
    },
    {
      "content": "The publish/subscribe mechanism of Event Hubs is enabled through consumer groups.",
      "pos": [
        10183,
        10264
      ]
    },
    {
      "content": "A consumer group is a view (state, position, or offset) of an entire Event Hub.",
      "pos": [
        10265,
        10344
      ]
    },
    {
      "content": "Consumer groups enable multiple consuming applications to each have a separate view of the event stream, and to read the stream independently at their own pace and with their own offsets.",
      "pos": [
        10345,
        10532
      ]
    },
    {
      "content": "In a stream processing architecture, each downstream application equates to a consumer group.",
      "pos": [
        10533,
        10626
      ]
    },
    {
      "content": "If you want to write event data to long-term storage, then that storage writer application is a consumer group.",
      "pos": [
        10627,
        10738
      ]
    },
    {
      "content": "Complex event processing is performed by another, separate consumer group.",
      "pos": [
        10739,
        10813
      ]
    },
    {
      "content": "You can only access partitions through a consumer group.",
      "pos": [
        10814,
        10870
      ]
    },
    {
      "content": "There is always a default consumer group in an Event Hub, and you can create up to 20 consumer groups for a Standard tier Event Hub.",
      "pos": [
        10871,
        11003
      ]
    },
    {
      "content": "The following are examples of the consumer group URI convention:",
      "pos": [
        11005,
        11069
      ]
    },
    {
      "content": "The following image shows the event consumers within consumer groups.",
      "pos": [
        11234,
        11303
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        11307,
        11317
      ]
    },
    {
      "content": "Stream offsets",
      "pos": [
        11367,
        11381
      ]
    },
    {
      "content": "An offset is the position of an event within a partition.",
      "pos": [
        11383,
        11440
      ]
    },
    {
      "content": "You can think of an offset as a client-side cursor.",
      "pos": [
        11441,
        11492
      ]
    },
    {
      "content": "The offset is a byte numbering of the event.",
      "pos": [
        11493,
        11537
      ]
    },
    {
      "content": "This enables an event consumer (reader) to specify a point in the event stream from which they want to begin reading events.",
      "pos": [
        11538,
        11662
      ]
    },
    {
      "content": "You can specify the offset as a timestamp or as an offset value.",
      "pos": [
        11663,
        11727
      ]
    },
    {
      "content": "Consumers are responsible for storing their own offset values outside of the Event Hubs service.",
      "pos": [
        11728,
        11824
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        11828,
        11838
      ]
    },
    {
      "content": "Within a partition, each event includes an offset.",
      "pos": [
        11883,
        11933
      ]
    },
    {
      "content": "This offset is used by consumers to show the location in the event sequence for a given partition.",
      "pos": [
        11934,
        12032
      ]
    },
    {
      "content": "Offsets can be passed to the Event Hub as either a number or as a timestamp value when a reader connects.",
      "pos": [
        12033,
        12138
      ]
    },
    {
      "content": "Checkpointing",
      "pos": [
        12145,
        12158
      ]
    },
    {
      "content": "<bpt id=\"p1\">*</bpt>Checkpointing<ept id=\"p1\">*</ept> is a process by which readers mark or commit their position within a partition event sequence.",
      "pos": [
        12160,
        12270
      ]
    },
    {
      "content": "Checkpointing is the responsibility of the consumer and occurs on a per-partition basis within a consumer group.",
      "pos": [
        12271,
        12383
      ]
    },
    {
      "content": "This means that for each consumer group, each partition reader must keep track of its current position in the event stream, and can inform the service when it considers the data stream complete.",
      "pos": [
        12384,
        12578
      ]
    },
    {
      "content": "If a reader disconnects from a partition, when it reconnects it begins reading at the checkpoint that was previously submitted by the last reader of that partition in that consumer group.",
      "pos": [
        12579,
        12766
      ]
    },
    {
      "content": "When the reader connects, it passes this offset to the Event Hub to specify the location at which to start reading.",
      "pos": [
        12767,
        12882
      ]
    },
    {
      "content": "In this way, you can use checkpointing to both mark events as \"complete\" by downstream applications, and to provide resiliency in the event of a failover between readers running on different machines.",
      "pos": [
        12883,
        13083
      ]
    },
    {
      "content": "Because event data is retained for the retention interval specified at the time the Event Hub is created, it is possible to return to older data by specifying a lower offset from this checkpointing process.",
      "pos": [
        13084,
        13290
      ]
    },
    {
      "content": "Through this mechanism, checkpointing enables both failover resiliency and controlled event stream replay.",
      "pos": [
        13291,
        13397
      ]
    },
    {
      "content": "Common consumer tasks",
      "pos": [
        13404,
        13425
      ]
    },
    {
      "content": "This section describes common tasks for Event Hubs event consumers or readers.",
      "pos": [
        13427,
        13505
      ]
    },
    {
      "content": "All Event Hubs consumers connect via AMQP 1.0.",
      "pos": [
        13506,
        13552
      ]
    },
    {
      "content": "AMQP 1.0 is a session and state-aware bidirectional communication channel.",
      "pos": [
        13553,
        13627
      ]
    },
    {
      "content": "Each partition has an AMQP 1.0 link session that facilitates the transport of events segregated by partition.",
      "pos": [
        13628,
        13737
      ]
    },
    {
      "content": "Connecting to a partition",
      "pos": [
        13745,
        13770
      ]
    },
    {
      "content": "In order to consume events from an Event Hub, a consumer must connect to a partition.",
      "pos": [
        13772,
        13857
      ]
    },
    {
      "content": "As mentioned previously, you always access partitions through a consumer group.",
      "pos": [
        13858,
        13937
      ]
    },
    {
      "content": "As part of the partitioned consumer model, only a single reader should be active on a partition at any one time within a consumer group.",
      "pos": [
        13938,
        14074
      ]
    },
    {
      "content": "It is common practice when connecting directly to partitions to use a leasing mechanism in order to coordinate reader connections to specific partitions.",
      "pos": [
        14075,
        14228
      ]
    },
    {
      "content": "This way, it is possible for every partition in a consumer group to have only one active reader.",
      "pos": [
        14229,
        14325
      ]
    },
    {
      "content": "Managing the position in the sequence for a reader is an important task that is achieved through checkpointing.",
      "pos": [
        14326,
        14437
      ]
    },
    {
      "content": "This functionality is simplified by using the <bpt id=\"p1\">[</bpt>EventProcessorHost<ept id=\"p1\">](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventprocessorhost.aspx)</ept> class for .NET clients.",
      "pos": [
        14438,
        14619
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>EventProcessorHost<ept id=\"p1\">](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventprocessorhost.aspx)</ept> is an intelligent consumer agent and is described in the next section.",
      "pos": [
        14620,
        14802
      ]
    },
    {
      "content": "Reading events",
      "pos": [
        14810,
        14824
      ]
    },
    {
      "content": "After an AMQP 1.0 session and link is opened for a specific partition, events are delivered to the AMQP 1.0 client by the Event Hubs service.",
      "pos": [
        14826,
        14967
      ]
    },
    {
      "content": "This delivery mechanism enables higher throughput and lower latency than pull-based mechanisms such as HTTP GET.",
      "pos": [
        14968,
        15080
      ]
    },
    {
      "content": "As events are sent to the client, each event data instance contains important metadata such as the offset and sequence number that are used to facilitate checkpointing on the event sequence.",
      "pos": [
        15081,
        15271
      ]
    },
    {
      "content": "Event Hubs",
      "pos": [
        15275,
        15285
      ]
    },
    {
      "content": "It is the user's responsibility to manage this offset in a way that best enables managing progress in processing the stream.",
      "pos": [
        15330,
        15454
      ]
    },
    {
      "content": "Capacity and security",
      "pos": [
        15459,
        15480
      ]
    },
    {
      "content": "Event Hubs is a highly scalable parallel architecture for stream ingress.",
      "pos": [
        15482,
        15555
      ]
    },
    {
      "content": "As such, there are several key aspects to consider when sizing and scaling a solution based on Event Hubs.",
      "pos": [
        15556,
        15662
      ]
    },
    {
      "content": "The first of these capacity controls is <bpt id=\"p1\">*</bpt>throughput units<ept id=\"p1\">*</ept>, described in the following section.",
      "pos": [
        15663,
        15758
      ]
    },
    {
      "content": "Throughput units",
      "pos": [
        15764,
        15780
      ]
    },
    {
      "content": "The throughput capacity of Event Hubs is controlled by throughput units.",
      "pos": [
        15782,
        15854
      ]
    },
    {
      "content": "Throughput units are pre-purchased units of capacity.",
      "pos": [
        15855,
        15908
      ]
    },
    {
      "content": "A single throughput unit includes the following:",
      "pos": [
        15909,
        15957
      ]
    },
    {
      "content": "Ingress: Up to 1MB per second or 1000 events per second.",
      "pos": [
        15961,
        16017
      ]
    },
    {
      "content": "Egress: Up to 2MB per second.",
      "pos": [
        16021,
        16050
      ]
    },
    {
      "content": "Ingress is throttled to the amount of capacity provided by the number of throughput units purchased.",
      "pos": [
        16052,
        16152
      ]
    },
    {
      "content": "Sending data above this amount results in a \"quota exceeded\" exception.",
      "pos": [
        16153,
        16224
      ]
    },
    {
      "content": "This amount is either 1 MB per second or 1000 events per second, whichever comes first.",
      "pos": [
        16225,
        16312
      ]
    },
    {
      "content": "Egress does not produce throttling exceptions, but is limited to the amount of data transfer provided for by the purchased throughput units: 2 MB per second per throughput unit.",
      "pos": [
        16313,
        16490
      ]
    },
    {
      "content": "If you receive publishing rate exceptions or are expecting to see higher egress be sure to check how many throughput units you have purchased for the namespace in which the Event Hub was created.",
      "pos": [
        16491,
        16686
      ]
    },
    {
      "content": "To obtain more throughput units, you can adjust the setting on the <bpt id=\"p1\">**</bpt>Namespaces<ept id=\"p1\">**</ept> page on the <bpt id=\"p2\">**</bpt>Configure<ept id=\"p2\">**</ept> tab in the Azure management portal.",
      "pos": [
        16687,
        16830
      ]
    },
    {
      "content": "You can also change this setting using the Azure APIs.",
      "pos": [
        16831,
        16885
      ]
    },
    {
      "content": "While partitions are a data organization concept, throughput units are purely a capacity concept.",
      "pos": [
        16887,
        16984
      ]
    },
    {
      "content": "Throughput units are billed per hour and are pre-purchased.",
      "pos": [
        16985,
        17044
      ]
    },
    {
      "content": "Once purchased, throughput units are billed for a minimum of one hour.",
      "pos": [
        17045,
        17115
      ]
    },
    {
      "content": "Up to 20 throughput units can be purchased for a Service Bus namespace, and there is an Azure account limit of 20 throughput units.",
      "pos": [
        17116,
        17247
      ]
    },
    {
      "content": "These throughput units are shared across all Event Hubs in a given namespace.",
      "pos": [
        17248,
        17325
      ]
    },
    {
      "content": "Throughput units are provisioned on a best effort basis and may not always be available for immediate purchase.",
      "pos": [
        17327,
        17438
      ]
    },
    {
      "content": "If you require a specific capacity, it is recommended that you purchase those throughput units ahead of time.",
      "pos": [
        17439,
        17548
      ]
    },
    {
      "content": "If you require more than 20 throughput units, you can contact Microsoft Azure Service Bus support to purchase more throughput units on a commitment basis in blocks of 20, up to the first 100 throughput units.",
      "pos": [
        17549,
        17757
      ]
    },
    {
      "content": "Beyond that, you can also purchase blocks of 100 throughput units.",
      "pos": [
        17758,
        17824
      ]
    },
    {
      "content": "It is recommended that you carefully balance throughput units and partitions in order to achieve optimal scale with Event Hubs.",
      "pos": [
        17826,
        17953
      ]
    },
    {
      "content": "A single partition has a maximum scale of one throughput unit.",
      "pos": [
        17954,
        18016
      ]
    },
    {
      "content": "The number of throughput units should be less than or equal to the number of partitions in an Event Hub.",
      "pos": [
        18017,
        18121
      ]
    },
    {
      "pos": [
        18123,
        18238
      ],
      "content": "For detailed pricing information, see <bpt id=\"p1\">[</bpt>Event Hubs Pricing<ept id=\"p1\">](http://azure.microsoft.com/pricing/details/event-hubs/)</ept>."
    },
    {
      "content": "Publisher policy",
      "pos": [
        18244,
        18260
      ]
    },
    {
      "content": "Event Hubs enables granular control over event producers through <bpt id=\"p1\">*</bpt>publisher policies<ept id=\"p1\">*</ept>.",
      "pos": [
        18262,
        18348
      ]
    },
    {
      "content": "Publisher policies are a set of run-time features designed to facilitate large numbers of independent event producers.",
      "pos": [
        18349,
        18467
      ]
    },
    {
      "content": "With publisher policies, each publisher uses its own unique identifier when publishing events to an Event Hub, using the following mechanism:",
      "pos": [
        18468,
        18609
      ]
    },
    {
      "content": "You don't have to create publisher names ahead of time, but they must match the SAS token used when publishing an event, in order to ensure independent publisher identities.",
      "pos": [
        18704,
        18877
      ]
    },
    {
      "content": "For more information about SAS, see <bpt id=\"p1\">[</bpt>Shared Access Signature Authentication with Service Bus<ept id=\"p1\">](https://msdn.microsoft.com/library/dn170477.aspx)</ept>.",
      "pos": [
        18878,
        19022
      ]
    },
    {
      "content": "When using publisher policies, the <bpt id=\"p1\">**</bpt>PartitionKey<ept id=\"p1\">**</ept> value is set to the publisher name.",
      "pos": [
        19023,
        19110
      ]
    },
    {
      "content": "In order to work properly, these values must match.",
      "pos": [
        19111,
        19162
      ]
    },
    {
      "content": "Summary",
      "pos": [
        19167,
        19174
      ]
    },
    {
      "content": "Azure Event Hubs provides a hyper-scale event and telemetry processing service that can be used for common application and user workflow monitoring at any scale.",
      "pos": [
        19176,
        19337
      ]
    },
    {
      "content": "With the ability to provide publish-subscribe capabilities with low latency and at massive scale, Event Hubs serve as the \"on ramp\" for Big Data.",
      "pos": [
        19338,
        19483
      ]
    },
    {
      "content": "With publisher-based identity and revocation lists, these capabilities are extended into common Internet of Things scenarios.",
      "pos": [
        19484,
        19609
      ]
    },
    {
      "content": "For more information about developing Event Hubs applications.",
      "pos": [
        19610,
        19672
      ]
    },
    {
      "content": "see the <bpt id=\"p1\">[</bpt>Event Hubs Programming Guide<ept id=\"p1\">](https://msdn.microsoft.com/library/dn789972.aspx)</ept>.",
      "pos": [
        19673,
        19762
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        19767,
        19777
      ]
    },
    {
      "content": "Now that you've learned about Event Hubs concepts, you can move on to the following scenarios:",
      "pos": [
        19779,
        19873
      ]
    },
    {
      "pos": [
        19877,
        19919
      ],
      "content": "Get started with an <bpt id=\"p1\">[</bpt><ept id=\"p1\">Event Hubs tutorial]</ept>."
    },
    {
      "pos": [
        19922,
        19975
      ],
      "content": "A complete <bpt id=\"p1\">[</bpt><ept id=\"p1\">sample application that uses Event Hubs]</ept>."
    },
    {
      "pos": [
        19978,
        20033
      ],
      "content": "A <bpt id=\"p1\">[</bpt><ept id=\"p1\">queued messaging solution]</ept> using Service Bus queues."
    },
    {
      "content": "test",
      "pos": [
        20326,
        20330
      ]
    }
  ],
  "content": "<properties \n   pageTitle=\"Event Hubs Overview\"\n   description=\"Introduction and overview of Azure Event Hubs.\"\n   services=\"event-hubs\"\n   documentationCenter=\"na\"\n   authors=\"sethmanheim\"\n   manager=\"timlt\"\n   editor=\"\" />\n<tags \n   ms.service=\"event-hubs\"\n   ms.devlang=\"na\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"na\"\n   ms.workload=\"tbd\"\n   ms.date=\"06/09/2015\"\n   ms.author=\"sethm\" />\n\n# Azure Event Hubs overview\n\nMany modern solutions intend to provide adaptive customer experiences or to improve products through continuous feedback and automated telemetry. Such solutions are faced with the challenge of how to securely and reliably process very large amounts of information from many concurrent publishers. Microsoft Azure Event Hubs is a managed platform service that provides a foundation for large-scale data intake in a broad variety of scenarios. Examples of such scenarios are behavior tracking in mobile apps, traffic information from web farms, in-game event capture in console games, or telemetry data collected from industrial machines or connected vehicles. The common role that Event Hubs plays in solution architectures is that it acts as the \"front door\" for an event pipeline, often called an *event ingestor*. An event ingestor is a component or service that sits between event producers and event consumers to decouple the production of an event stream from the consumption of those events.\n\n![Event Hubs](./media/event-hubs-overview/IC759856.png)\n\nAzure Event Hubs is an event processing service that provides event and telemetry ingress to the cloud at massive scale, with low latency and high reliability. This service, used with other downstream services, is particularly useful in application instrumentation, user experience or workflow processing, and Internet of Things (IoT) scenarios. Event Hubs provides a message stream handling capability and though an Event Hub is an entity similar to queues and topics, it has characteristics that are very different from traditional enterprise messaging. Enterprise messaging scenarios commonly require a number of sophisticated capabilities such as sequencing, dead-lettering, transaction support, and strong delivery assurances, while the dominant concern for event intake is high throughput and processing flexibility for event streams. Therefore, Azure Event Hubs capabilities differ from Service Bus topics in that they are strongly biased towards high throughput and event processing scenarios. As such, Event Hubs do not implement some of the messaging capabilities that are available for topics. If you need those capabilities, topics remain the optimal choice.\n\nAn Event Hub is created at the namespace level in Service Bus, similar to queues and topics. Event Hubs uses AMQP and HTTP as its primary API interfaces. The following diagram shows the relationship between Event Hubs and Service Bus.\n\n![Event Hubs](./media/event-hubs-overview/IC741188.png)\n\n## Conceptual overview\n\nEvent Hubs provides message streaming through a partitioned consumer pattern. Queues and topics use a [Competing Consumer](https://msdn.microsoft.com/library/dn568101.aspx) model in which each consumer attempts to read from the same queue or resource. This competition for resources ultimately results in complexity and scale limits for stream processing applications. Event Hubs uses a partitioned consumer pattern in which each consumer only reads a specific subset, or partition, of the message stream. This pattern enables horizontal scale for event processing and provides other stream-focused features that are unavailable in queues and topics.\n\n### Partitions\n\nA partition is an ordered sequence of events that is held in an Event Hub. As newer events arrive, they are added to the end of this sequence. A partition can be thought of as a \"commit log.\"\n\n![Event Hubs](./media/event-hubs-overview/IC759857.png)\n\nPartitions retain data for a configured retention time that is set at the Event Hub level. This setting applies across all partitions in the Event Hub. Events expire on a time basis; you cannot explicitly delete them. An Event Hub contains multiple partitions. Each partition is independent and contains its own sequence of data. As a result, partitions often grow at different rates.\n\n![Event Hubs](./media/event-hubs-overview/IC759858.png)\n\nThe number of partitions is specified at the Event Hub creation time and must be between 8 and 32. Partitions are a data organization mechanism and are more related to the degree of downstream parallelism required in consuming applications than to Event Hubs throughput. This makes the choice of the number of partitions in an Event Hub directly related to the number of concurrent readers you expect to have. After Event Hub creation, the partition count is not changeable; you should consider this number in terms of long-term expected scale. You can increase the 32 partition limit by contacting the Azure Service Bus team.\n\nWhile partitions are identifiable and can be sent to directly, it is generally best to avoid sending data to specific partitions. Instead, you can use higher level constructs introduced in the [Event publisher](#Event-publisher) and [Publisher Policy](#Capacity-and-security) sections.\n\nIn the context of Event Hubs, messages are referred to as *event data*. Event data contains the body of the event, a user defined property bag, and various metadata about the event such as its offset in the partition and its number in the stream sequence. Partitions are filled with a sequence of event data.\n\n## Event publisher\n\nAny entity that sends events or data to an Event Hub is an *event publisher*. Event publishers can publish events using either HTTPS or AMQP 1.0. Event publishers use a Shared Access Signature (SAS) token to identify themselves to an Event Hub, and can have a unique identity, or use a common SAS token, depending on the requirements of the scenario.\n\nFor more information about working with SAS, see [Shared Access Signature Authentication with Service Bus](https://msdn.microsoft.com/library/dn170477.aspx).\n\n### Common publisher tasks\n\nThis section describes common tasks for event publishers.\n\n#### Acquiring a SAS token\n\nShared Access Signature (SAS) is the authentication mechanism for Event Hubs. Service Bus provides SAS policies at the namespace and Event Hub level. A SAS token is generated from a SAS key and is an SHA hash of a URL, encoded in a specific format. Using the name of the key (policy) and the token, Service Bus can regenerate the hash and thus authenticate the sender. Normally, SAS tokens for event publishers are created with only **send** privileges on a specific Event Hub. This SAS token URL mechanism is the basis for publisher identification introduced in the publisher policy. For more information about working with SAS, see [Shared Access Signature Authentication with Service Bus](https://msdn.microsoft.com/library/dn170477.aspx).\n\n#### Publishing an event\n\nYou can publish an event via AMQP 1.0 or HTTPS. Service Bus provides an [EventHubClient](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventhubclient.aspx) class for publishing events to an Event Hub from .NET clients. For other runtimes and platforms, you can use any AMQP 1.0 client, such as [Apache Qpid](http://qpid.apache.org/). You can publish events individually, or batched. A single publication (event data instance) has a limit of 256KB, regardless of whether it is a single event or a batch. Publishing events larger than this results in an error. It is a best practice for publishers to be unaware of partitions within the Event Hub and to only specify a *partition key* (introduced in the next section), or their identity via their SAS token.\n\nThe choice to use AMQP or HTTPS is specific to the usage scenario. AMQP requires the establishment of a persistent bidirectional socket in addition to transport level security (TLS) or SSL/TLS. This can be a costly operation in terms of network traffic, but only happens at the beginning of an AMQP session. HTTPS has a lower initial overhead, but requires additional SSL overhead for every request. For publishers who frequently publish events, AMQP offers significant performance, latency, and throughput savings.\n\n### Partition key\n\nA partition key is a value that is used to map incoming event data into specific partitions for the purposes of data organization. The partition key is a sender-supplied value passed into an Event Hub. It is processed through a static hashing function, the result of which creates the partition assignment. If you don't specify a partition key when publishing an event, a round robin assignment is used. When using partition keys, the event publisher is only aware of its partition key, not the partition to which the events are published. This decoupling of key and partition insulates the sender from needing to know too much about the downstream processing and storage of events. Partition keys are important for organizing data for downstream processing, but are fundamentally unrelated to partitions themselves. A per-device or user unique identity makes a good partition key, but other attributes such as geography can also be used to group related events into a single partition. The following image shows event senders using partition keys to pin to partitions.\n\n![Event Hubs](./media/event-hubs-overview/IC759859.png)\n\nAzure Event Hubs ensures that any and all events sharing the same partition key value are delivered in order, and to the same partition. Importantly, if partition keys are used with publisher policies, described in the next section, then the identity of the publisher and the value of the partition key must match. Otherwise, an error occurs.\n\n### Event consumer\n\nAny entity that reads event data from an Event Hub is an event consumer. All event consumers read the event stream through partitions in a consumer group. Each partition should have only one active reader at a time. All Event Hubs consumers connect via the AMQP 1.0 session, in which events are delivered as they become available. The client does not need to poll for data availability.\n\n#### Consumer groups\n\nThe publish/subscribe mechanism of Event Hubs is enabled through consumer groups. A consumer group is a view (state, position, or offset) of an entire Event Hub. Consumer groups enable multiple consuming applications to each have a separate view of the event stream, and to read the stream independently at their own pace and with their own offsets. In a stream processing architecture, each downstream application equates to a consumer group. If you want to write event data to long-term storage, then that storage writer application is a consumer group. Complex event processing is performed by another, separate consumer group. You can only access partitions through a consumer group. There is always a default consumer group in an Event Hub, and you can create up to 20 consumer groups for a Standard tier Event Hub.\n\nThe following are examples of the consumer group URI convention:\n\n    //<my namespace>.servicebus.windows.net/<event hub name>/<Consumer Group #1>\n    //<my namespace>.servicebus.windows.net/<event hub name>/<Consumer Group #2>\n\nThe following image shows the event consumers within consumer groups.\n\n![Event Hubs](./media/event-hubs-overview/IC759860.png)\n\n#### Stream offsets\n\nAn offset is the position of an event within a partition. You can think of an offset as a client-side cursor. The offset is a byte numbering of the event. This enables an event consumer (reader) to specify a point in the event stream from which they want to begin reading events. You can specify the offset as a timestamp or as an offset value. Consumers are responsible for storing their own offset values outside of the Event Hubs service.\n\n![Event Hubs](./media/event-hubs-overview/IC759861.png)\n\nWithin a partition, each event includes an offset. This offset is used by consumers to show the location in the event sequence for a given partition. Offsets can be passed to the Event Hub as either a number or as a timestamp value when a reader connects.\n\n#### Checkpointing\n\n*Checkpointing* is a process by which readers mark or commit their position within a partition event sequence. Checkpointing is the responsibility of the consumer and occurs on a per-partition basis within a consumer group. This means that for each consumer group, each partition reader must keep track of its current position in the event stream, and can inform the service when it considers the data stream complete. If a reader disconnects from a partition, when it reconnects it begins reading at the checkpoint that was previously submitted by the last reader of that partition in that consumer group. When the reader connects, it passes this offset to the Event Hub to specify the location at which to start reading. In this way, you can use checkpointing to both mark events as \"complete\" by downstream applications, and to provide resiliency in the event of a failover between readers running on different machines. Because event data is retained for the retention interval specified at the time the Event Hub is created, it is possible to return to older data by specifying a lower offset from this checkpointing process. Through this mechanism, checkpointing enables both failover resiliency and controlled event stream replay.\n\n#### Common consumer tasks\n\nThis section describes common tasks for Event Hubs event consumers or readers. All Event Hubs consumers connect via AMQP 1.0. AMQP 1.0 is a session and state-aware bidirectional communication channel. Each partition has an AMQP 1.0 link session that facilitates the transport of events segregated by partition.\n\n##### Connecting to a partition\n\nIn order to consume events from an Event Hub, a consumer must connect to a partition. As mentioned previously, you always access partitions through a consumer group. As part of the partitioned consumer model, only a single reader should be active on a partition at any one time within a consumer group. It is common practice when connecting directly to partitions to use a leasing mechanism in order to coordinate reader connections to specific partitions. This way, it is possible for every partition in a consumer group to have only one active reader. Managing the position in the sequence for a reader is an important task that is achieved through checkpointing. This functionality is simplified by using the [EventProcessorHost](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventprocessorhost.aspx) class for .NET clients. [EventProcessorHost](https://msdn.microsoft.com/library/microsoft.servicebus.messaging.eventprocessorhost.aspx) is an intelligent consumer agent and is described in the next section.\n\n##### Reading events\n\nAfter an AMQP 1.0 session and link is opened for a specific partition, events are delivered to the AMQP 1.0 client by the Event Hubs service. This delivery mechanism enables higher throughput and lower latency than pull-based mechanisms such as HTTP GET. As events are sent to the client, each event data instance contains important metadata such as the offset and sequence number that are used to facilitate checkpointing on the event sequence.\n\n![Event Hubs](./media/event-hubs-overview/IC759862.png)\n\nIt is the user's responsibility to manage this offset in a way that best enables managing progress in processing the stream.\n\n## Capacity and security\n\nEvent Hubs is a highly scalable parallel architecture for stream ingress. As such, there are several key aspects to consider when sizing and scaling a solution based on Event Hubs. The first of these capacity controls is *throughput units*, described in the following section.\n\n### Throughput units\n\nThe throughput capacity of Event Hubs is controlled by throughput units. Throughput units are pre-purchased units of capacity. A single throughput unit includes the following:\n\n- Ingress: Up to 1MB per second or 1000 events per second.\n\n- Egress: Up to 2MB per second.\n\nIngress is throttled to the amount of capacity provided by the number of throughput units purchased. Sending data above this amount results in a \"quota exceeded\" exception. This amount is either 1 MB per second or 1000 events per second, whichever comes first. Egress does not produce throttling exceptions, but is limited to the amount of data transfer provided for by the purchased throughput units: 2 MB per second per throughput unit. If you receive publishing rate exceptions or are expecting to see higher egress be sure to check how many throughput units you have purchased for the namespace in which the Event Hub was created. To obtain more throughput units, you can adjust the setting on the **Namespaces** page on the **Configure** tab in the Azure management portal. You can also change this setting using the Azure APIs.\n\nWhile partitions are a data organization concept, throughput units are purely a capacity concept. Throughput units are billed per hour and are pre-purchased. Once purchased, throughput units are billed for a minimum of one hour. Up to 20 throughput units can be purchased for a Service Bus namespace, and there is an Azure account limit of 20 throughput units. These throughput units are shared across all Event Hubs in a given namespace.\n\nThroughput units are provisioned on a best effort basis and may not always be available for immediate purchase. If you require a specific capacity, it is recommended that you purchase those throughput units ahead of time. If you require more than 20 throughput units, you can contact Microsoft Azure Service Bus support to purchase more throughput units on a commitment basis in blocks of 20, up to the first 100 throughput units. Beyond that, you can also purchase blocks of 100 throughput units.\n\nIt is recommended that you carefully balance throughput units and partitions in order to achieve optimal scale with Event Hubs. A single partition has a maximum scale of one throughput unit. The number of throughput units should be less than or equal to the number of partitions in an Event Hub.\n\nFor detailed pricing information, see [Event Hubs Pricing](http://azure.microsoft.com/pricing/details/event-hubs/).\n\n### Publisher policy\n\nEvent Hubs enables granular control over event producers through *publisher policies*. Publisher policies are a set of run-time features designed to facilitate large numbers of independent event producers. With publisher policies, each publisher uses its own unique identifier when publishing events to an Event Hub, using the following mechanism:\n\n    //<my namespace>.servicebus.windows.net/<event hub name>/publishers/<my publisher name>\n\nYou don't have to create publisher names ahead of time, but they must match the SAS token used when publishing an event, in order to ensure independent publisher identities. For more information about SAS, see [Shared Access Signature Authentication with Service Bus](https://msdn.microsoft.com/library/dn170477.aspx). When using publisher policies, the **PartitionKey** value is set to the publisher name. In order to work properly, these values must match.\n\n## Summary\n\nAzure Event Hubs provides a hyper-scale event and telemetry processing service that can be used for common application and user workflow monitoring at any scale. With the ability to provide publish-subscribe capabilities with low latency and at massive scale, Event Hubs serve as the \"on ramp\" for Big Data. With publisher-based identity and revocation lists, these capabilities are extended into common Internet of Things scenarios. For more information about developing Event Hubs applications. see the [Event Hubs Programming Guide](https://msdn.microsoft.com/library/dn789972.aspx).\n\n## Next steps\n\nNow that you've learned about Event Hubs concepts, you can move on to the following scenarios:\n\n- Get started with an [Event Hubs tutorial].\n- A complete [sample application that uses Event Hubs].\n- A [queued messaging solution] using Service Bus queues.\n\n[Event Hubs tutorial]: service-bus-event-hubs-csharp-ephcs-getstarted.md\n[sample application that uses Event Hubs]: https://code.msdn.microsoft.com/windowsazure/Service-Bus-Event-Hub-286fd097\n[queued messaging solution]: ../cloud-services-dotnet-multi-tier-app-using-service-bus-queues.md\n \ntest\n"
}