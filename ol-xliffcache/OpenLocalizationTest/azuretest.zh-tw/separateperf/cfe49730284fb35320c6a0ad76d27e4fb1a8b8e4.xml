{
  "nodes": [
    {
      "content": "Access datasets with Machine Learning Python client library | Microsoft Azure",
      "pos": [
        28,
        105
      ]
    },
    {
      "content": "Install and use the Python client library to access and manage Azure Machine Learning data securely from a local Python environment.",
      "pos": [
        125,
        257
      ]
    },
    {
      "content": "Access datasets with Python using the Azure Machine Learning Python client library",
      "pos": [
        606,
        688
      ]
    },
    {
      "content": "The preview of Microsoft Azure Machine Learning Python client library can enable secure access to your Azure Machine Learning datasets from a local Python environment and enables the creation and management of datasets in workspace.",
      "pos": [
        691,
        923
      ]
    },
    {
      "content": "This topic provides instructions on how to:",
      "pos": [
        925,
        968
      ]
    },
    {
      "content": "install the Machine Learning Python client library",
      "pos": [
        972,
        1022
      ]
    },
    {
      "content": "access and upload datasets, including instructions on how to get authorization to access Azure Machine Learning datasets from your local Python environment",
      "pos": [
        1026,
        1181
      ]
    },
    {
      "content": "access intermediate datasets from experiments",
      "pos": [
        1185,
        1230
      ]
    },
    {
      "content": "use the Python client library to enumerate datasets, access metadata, read the contents of a dataset, create new datasets and update existing datasets",
      "pos": [
        1234,
        1384
      ]
    },
    {
      "pos": [
        1484,
        1525
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"prerequisites\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Prerequisites"
    },
    {
      "content": "The Python client library has been tested under the following environments:",
      "pos": [
        1527,
        1602
      ]
    },
    {
      "content": "Windows, Mac and Linux",
      "pos": [
        1607,
        1629
      ]
    },
    {
      "content": "Python 2.7, 3.3 and 3.4",
      "pos": [
        1633,
        1656
      ]
    },
    {
      "content": "It has a dependency on the following packages:",
      "pos": [
        1658,
        1704
      ]
    },
    {
      "content": "requests",
      "pos": [
        1709,
        1717
      ]
    },
    {
      "content": "python-dateutil",
      "pos": [
        1721,
        1736
      ]
    },
    {
      "content": "pandas",
      "pos": [
        1740,
        1746
      ]
    },
    {
      "content": "We recommend using a Python distribution such as <bpt id=\"p1\">[</bpt>Anaconda<ept id=\"p1\">](http://continuum.io/downloads#all)</ept> or <bpt id=\"p2\">[</bpt>Canopy<ept id=\"p2\">](https://store.enthought.com/downloads/)</ept>, which come with Python, IPython and the three packages  listed above installed.",
      "pos": [
        1748,
        1975
      ]
    },
    {
      "content": "Although IPython is not strictly required, it is a great environment for manipulating and visualizing data interactively.",
      "pos": [
        1976,
        2097
      ]
    },
    {
      "pos": [
        2103,
        2193
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"installation\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>How to install the Azure Machine Learning Python client library"
    },
    {
      "content": "The Azure Machine Learning Python client library must also be installed to complete the tasks outlined in this topic.",
      "pos": [
        2195,
        2312
      ]
    },
    {
      "content": "It is available from the <bpt id=\"p1\">[</bpt>Python Package Index<ept id=\"p1\">](https://pypi.python.org/pypi/azureml)</ept>.",
      "pos": [
        2313,
        2399
      ]
    },
    {
      "content": "To install it in your Python environment, run the following command from your local Python environment:",
      "pos": [
        2400,
        2503
      ]
    },
    {
      "pos": [
        2530,
        2672
      ],
      "content": "Alternatively, you can download and install from the sources on <bpt id=\"p1\">[</bpt>github<ept id=\"p1\">](https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python)</ept>."
    },
    {
      "content": "If you have git installed on your machine, you can use pip to install directly from the git repository:",
      "pos": [
        2703,
        2806
      ]
    },
    {
      "pos": [
        2904,
        2975
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"datasetAccess\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Use Studio Code snippets to access datasets"
    },
    {
      "content": "The Python client library gives you programmatic access to your existing datasets from experiments that have been run.",
      "pos": [
        2977,
        3095
      ]
    },
    {
      "content": "From the Studio web interface, you can generate code snippets that include all the necessary information to download and deserialize datasets as Pandas DataFrame objects on your location machine.",
      "pos": [
        3097,
        3292
      ]
    },
    {
      "pos": [
        3298,
        3345
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"security\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Security for data access"
    },
    {
      "content": "The code snippets provided by Studio for use with the Python client library includes your workspace id and authorization token.",
      "pos": [
        3347,
        3474
      ]
    },
    {
      "content": "These provide full access to your workspace and must be protect, like a password.",
      "pos": [
        3475,
        3556
      ]
    },
    {
      "content": "For security reasons, the code snippet functionality is only available to users that have their role set as <bpt id=\"p1\">**</bpt>Owner<ept id=\"p1\">**</ept> for the workspace.",
      "pos": [
        3558,
        3694
      ]
    },
    {
      "content": "Your role is displayed in Azure Machine Learning Studio on the <bpt id=\"p1\">**</bpt>USERS<ept id=\"p1\">**</ept> page under <bpt id=\"p2\">**</bpt>Settings<ept id=\"p2\">**</ept>.",
      "pos": [
        3695,
        3792
      ]
    },
    {
      "content": "![Security][security]",
      "pos": [
        3794,
        3815
      ]
    },
    {
      "pos": [
        3817,
        3979
      ],
      "content": "If your role is not set as <bpt id=\"p1\">**</bpt>Owner<ept id=\"p1\">**</ept>, you can either request to be re-invited as an owner, or ask the owner of the workspace to provide you with the code snippet."
    },
    {
      "content": "To obtain the authorization token, you can do one of the following:",
      "pos": [
        3981,
        4048
      ]
    },
    {
      "content": "Ask for a token from an owner.",
      "pos": [
        4053,
        4083
      ]
    },
    {
      "content": "Owners can access their authorization tokens from the Settings page of their workspace in Studio.",
      "pos": [
        4084,
        4181
      ]
    },
    {
      "content": "Select <bpt id=\"p1\">**</bpt>Settings<ept id=\"p1\">**</ept> from the left pane and click on <bpt id=\"p2\">**</bpt>AUTHORIZATION TOKENS<ept id=\"p2\">**</ept> to see the primary and secondary tokens.",
      "pos": [
        4182,
        4299
      ]
    },
    {
      "content": "Although either the primary or the secondary authorization tokens can be used in the code snippet, it is recommended that owners only share the secondary authorization tokens.",
      "pos": [
        4301,
        4476
      ]
    },
    {
      "content": "Ask to be promoted to role of owner.",
      "pos": [
        4522,
        4558
      ]
    },
    {
      "content": "To do this, a current owner of the workspace needs to first remove you from the workspace then re-invite you to it as an owner.",
      "pos": [
        4560,
        4687
      ]
    },
    {
      "content": "Once developers have obtained the workspace id and authorization token, they will be able to access the workspace using the code  snippet regardless of their role.",
      "pos": [
        4689,
        4852
      ]
    },
    {
      "content": "Authorization tokens are managed on the <bpt id=\"p1\">**</bpt>AUTHORIZATION TOKENS<ept id=\"p1\">**</ept> page under <bpt id=\"p2\">**</bpt>SETTINGS<ept id=\"p2\">**</ept>.",
      "pos": [
        4854,
        4943
      ]
    },
    {
      "content": "You can regenerate them, but this procedure will revoke access to the previous token.",
      "pos": [
        4944,
        5029
      ]
    },
    {
      "pos": [
        5035,
        5114
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"accessingDatasets\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Access datasets from a local Python application"
    },
    {
      "pos": [
        5119,
        5203
      ],
      "content": "In Machine Learning Studio, click on <bpt id=\"p1\">**</bpt>DATASETS<ept id=\"p1\">**</ept> in the navigation bar on the left."
    },
    {
      "content": "Select the dataset you would like to access.",
      "pos": [
        5208,
        5252
      ]
    },
    {
      "content": "You can select any of the datasets from the <bpt id=\"p1\">**</bpt>MY DATASETS<ept id=\"p1\">**</ept> list or from the <bpt id=\"p2\">**</bpt>SAMPLES<ept id=\"p2\">**</ept> list.",
      "pos": [
        5253,
        5347
      ]
    },
    {
      "content": "From the bottom toolbar, click on <bpt id=\"p1\">**</bpt>Generate Data Access Code<ept id=\"p1\">**</ept>.",
      "pos": [
        5352,
        5416
      ]
    },
    {
      "content": "Note that this button will be disabled if the data is in a format incompatible with the Python client library.",
      "pos": [
        5417,
        5527
      ]
    },
    {
      "content": "![Datasets][datasets]",
      "pos": [
        5533,
        5554
      ]
    },
    {
      "content": "Select the code snippet from the window that appears and copy it to your clipboard.",
      "pos": [
        5559,
        5642
      ]
    },
    {
      "content": "![Access Code][dataset-access-code]",
      "pos": [
        5648,
        5683
      ]
    },
    {
      "content": "Paste the code into the notebook of you local Python application.",
      "pos": [
        5688,
        5753
      ]
    },
    {
      "content": "![Notebook][ipython-dataset]",
      "pos": [
        5759,
        5787
      ]
    },
    {
      "pos": [
        5793,
        5899
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"accessingIntermediateDatasets\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Access intermediate datasets from Machine Learning experiments"
    },
    {
      "content": "After an experiment is run in the Machine Learning Studio, it is possible to access the intermediate datasets from the output nodes of modules.",
      "pos": [
        5901,
        6044
      ]
    },
    {
      "content": "Intermediate datasets are data that has been created and used for intermediate steps when a model tool has been run.",
      "pos": [
        6045,
        6161
      ]
    },
    {
      "content": "Intermediate datasets can be accessed as long as the data format is compatible with the Python client library.",
      "pos": [
        6163,
        6273
      ]
    },
    {
      "pos": [
        6275,
        6372
      ],
      "content": "The following formats are supported (constants for these are in the <ph id=\"ph1\">`azureml.DataTypeIds`</ph> class):"
    },
    {
      "content": "PlainText",
      "pos": [
        6377,
        6386
      ]
    },
    {
      "content": "GenericCSV",
      "pos": [
        6390,
        6400
      ]
    },
    {
      "content": "GenericTSV",
      "pos": [
        6404,
        6414
      ]
    },
    {
      "content": "GenericCSVNoHeader",
      "pos": [
        6418,
        6436
      ]
    },
    {
      "content": "GenericTSVNoHeader",
      "pos": [
        6440,
        6458
      ]
    },
    {
      "content": "You can determine the format by hovering over a module output node.",
      "pos": [
        6460,
        6527
      ]
    },
    {
      "content": "It is displayed along with the node name, in a tooltip.",
      "pos": [
        6528,
        6583
      ]
    },
    {
      "pos": [
        6585,
        6729
      ],
      "content": "Some of the modules, such as the <bpt id=\"p1\">[</bpt>Split<ept id=\"p1\">][split]</ept> module, output to a format named <ph id=\"ph1\">`Dataset`</ph>, which is not supported by the Python client library."
    },
    {
      "content": "![Dataset Format][dataset-format]",
      "pos": [
        6731,
        6764
      ]
    },
    {
      "pos": [
        6766,
        6889
      ],
      "content": "You'll need to use a conversion module, such as <bpt id=\"p1\">[</bpt>Convert to CSV<ept id=\"p1\">][convert-to-csv]</ept>, to get an output into a supported format."
    },
    {
      "content": "![GenericCSV Format][csv-format]",
      "pos": [
        6891,
        6923
      ]
    },
    {
      "content": "The following steps show an example that creates an experiment, runs it and accesses the intermediate dataset.",
      "pos": [
        6925,
        7035
      ]
    },
    {
      "content": "Create a new experiment.",
      "pos": [
        7040,
        7064
      ]
    },
    {
      "pos": [
        7069,
        7140
      ],
      "content": "Insert an <bpt id=\"p1\">**</bpt>Adult Census Income Binary Classification dataset<ept id=\"p1\">**</ept> module."
    },
    {
      "pos": [
        7145,
        7228
      ],
      "content": "Insert a <bpt id=\"p1\">[</bpt>Split<ept id=\"p1\">][split]</ept> module, and connect its input to the dataset module output."
    },
    {
      "pos": [
        7233,
        7348
      ],
      "content": "Insert a <bpt id=\"p1\">[</bpt>Convert to CSV<ept id=\"p1\">][convert-to-csv]</ept> module and connect its input to one of the <bpt id=\"p2\">[</bpt>Split<ept id=\"p2\">][split]</ept> module outputs."
    },
    {
      "content": "Save the experiment, run it, and wait for it to finish running.",
      "pos": [
        7353,
        7416
      ]
    },
    {
      "pos": [
        7421,
        7493
      ],
      "content": "Click on the output node on the <bpt id=\"p1\">[</bpt>Convert to CSV<ept id=\"p1\">][convert-to-csv]</ept> module."
    },
    {
      "pos": [
        7498,
        7563
      ],
      "content": "A context menu will appear, select <bpt id=\"p1\">**</bpt>Generate Data Access Code<ept id=\"p1\">**</ept>."
    },
    {
      "content": "![Context Menu][experiment]",
      "pos": [
        7569,
        7596
      ]
    },
    {
      "content": "A window will appear.",
      "pos": [
        7601,
        7622
      ]
    },
    {
      "content": "Select the code snippet and copy it to your clipboard.",
      "pos": [
        7623,
        7677
      ]
    },
    {
      "content": "![Access Code][intermediate-dataset-access-code]",
      "pos": [
        7683,
        7731
      ]
    },
    {
      "content": "Paste the code in your notebook.",
      "pos": [
        7736,
        7768
      ]
    },
    {
      "content": "![Notebook][ipython-intermediate-dataset]",
      "pos": [
        7774,
        7815
      ]
    },
    {
      "content": "You can visualize the data using matplotlib.",
      "pos": [
        7821,
        7865
      ]
    },
    {
      "content": "This displays in a histogram for the age column:",
      "pos": [
        7866,
        7914
      ]
    },
    {
      "content": "![Histogram][ipython-histogram]",
      "pos": [
        7920,
        7951
      ]
    },
    {
      "pos": [
        7956,
        8072
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"clientApis\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Use the Machine Learning Python client library to access, read, create, and manage datasets"
    },
    {
      "content": "Workspace",
      "pos": [
        8078,
        8087
      ]
    },
    {
      "content": "The workspace is the entry point for the Python client library.",
      "pos": [
        8089,
        8152
      ]
    },
    {
      "content": "Provide the <ph id=\"ph1\">`Workspace`</ph> class with your workspace id and authorization token to create an instance:",
      "pos": [
        8153,
        8252
      ]
    },
    {
      "content": "Enumerate datasets",
      "pos": [
        8403,
        8421
      ]
    },
    {
      "content": "To enumerate all datasets in a given workspace:",
      "pos": [
        8423,
        8470
      ]
    },
    {
      "content": "To enumerate just the user-created datasets:",
      "pos": [
        8523,
        8567
      ]
    },
    {
      "content": "To enumerate just the example datasets:",
      "pos": [
        8625,
        8664
      ]
    },
    {
      "content": "You can access a dataset by name (which is case-sensitive):",
      "pos": [
        8725,
        8784
      ]
    },
    {
      "content": "Or you can access it by index:",
      "pos": [
        8827,
        8857
      ]
    },
    {
      "content": "Metadata",
      "pos": [
        8889,
        8897
      ]
    },
    {
      "content": "Datasets have metadata, in addition to content.",
      "pos": [
        8899,
        8946
      ]
    },
    {
      "content": "(Intermediate datasets are an exception to this rule and do not have any metadata.)",
      "pos": [
        8947,
        9030
      ]
    },
    {
      "content": "Some metadata values are assigned by the user at creation time:",
      "pos": [
        9032,
        9095
      ]
    },
    {
      "content": "Others are values assigned by Azure ML:",
      "pos": [
        9194,
        9233
      ]
    },
    {
      "pos": [
        9299,
        9364
      ],
      "content": "See the <ph id=\"ph1\">`SourceDataset`</ph> class for more on the available metadata."
    },
    {
      "content": "Read contents",
      "pos": [
        9371,
        9384
      ]
    },
    {
      "content": "The code snippets provided by Machine Learning Studio automatically download and deserialize the dataset to a Pandas DataFrame object.",
      "pos": [
        9386,
        9520
      ]
    },
    {
      "content": "This is done with the <ph id=\"ph1\">`to_dataframe`</ph> method:",
      "pos": [
        9521,
        9565
      ]
    },
    {
      "content": "If you prefer to download the raw data, and perform the deserialization yourself, that is an option.",
      "pos": [
        9598,
        9698
      ]
    },
    {
      "content": "At the moment, this is the only option for formats such as 'ARFF', which the Python client library cannot deserialize.",
      "pos": [
        9699,
        9817
      ]
    },
    {
      "content": "To read the contents as text:",
      "pos": [
        9819,
        9848
      ]
    },
    {
      "content": "To read the contents as binary:",
      "pos": [
        9885,
        9916
      ]
    },
    {
      "content": "You can also just open a stream to the contents:",
      "pos": [
        9957,
        10005
      ]
    },
    {
      "content": "Create a new dataset",
      "pos": [
        10085,
        10105
      ]
    },
    {
      "content": "The Python client library allow you to upload datasets from your Python program.",
      "pos": [
        10107,
        10187
      ]
    },
    {
      "content": "These datasets will be available for use in your workspace.",
      "pos": [
        10188,
        10247
      ]
    },
    {
      "content": "If you have your data in a Pandas DataFrame, use the following code:",
      "pos": [
        10249,
        10317
      ]
    },
    {
      "content": "If your data is already serialized, you can use:",
      "pos": [
        10547,
        10595
      ]
    },
    {
      "pos": [
        10826,
        10979
      ],
      "content": "The Python client library are able to serialize a Pandas DataFrame to the following formats (constants for these are in the <ph id=\"ph1\">`azureml.DataTypeIds`</ph> class):"
    },
    {
      "content": "PlainText",
      "pos": [
        10984,
        10993
      ]
    },
    {
      "content": "GenericCSV",
      "pos": [
        10997,
        11007
      ]
    },
    {
      "content": "GenericTSV",
      "pos": [
        11011,
        11021
      ]
    },
    {
      "content": "GenericCSVNoHeader",
      "pos": [
        11025,
        11043
      ]
    },
    {
      "content": "GenericTSVNoHeader",
      "pos": [
        11047,
        11065
      ]
    },
    {
      "content": "Update an existing dataset",
      "pos": [
        11072,
        11098
      ]
    },
    {
      "content": "If you try to upload a new dataset with a name that matches an existing dataset, you'll get a conflict error.",
      "pos": [
        11100,
        11209
      ]
    },
    {
      "content": "To update an existing dataset, you first need to get a reference to the existing dataset:",
      "pos": [
        11211,
        11300
      ]
    },
    {
      "pos": [
        11506,
        11601
      ],
      "content": "Then use <ph id=\"ph1\">`update_from_dataframe`</ph> to serialize and replace the contents of the dataset on Azure:"
    },
    {
      "pos": [
        11850,
        11965
      ],
      "content": "If you want to serialize the data to a different format, specify a value for the optional <ph id=\"ph1\">`data_type_id`</ph> parameter."
    },
    {
      "pos": [
        12321,
        12416
      ],
      "content": "You can optionally set a new description by specifying a value for the <ph id=\"ph1\">`description`</ph> parameter."
    },
    {
      "content": "You can optionally set a new name by specifying a value for the <ph id=\"ph1\">`name`</ph> parameter.",
      "pos": [
        12733,
        12814
      ]
    },
    {
      "content": "From now on, you'll retrieve the dataset using the new name only.",
      "pos": [
        12815,
        12880
      ]
    },
    {
      "content": "The following code updates the data, name and description.",
      "pos": [
        12881,
        12939
      ]
    },
    {
      "content": "The <ph id=\"ph1\">`data_type_id`</ph>, <ph id=\"ph2\">`name`</ph> and <ph id=\"ph3\">`description`</ph> parameters are all optional, and default to their previous value.",
      "pos": [
        13492,
        13602
      ]
    },
    {
      "content": "The <ph id=\"ph1\">`dataframe`</ph> parameter is always required.",
      "pos": [
        13603,
        13648
      ]
    },
    {
      "content": "If your data is already serialized, use <ph id=\"ph1\">`update_from_raw_data`</ph> instead of <ph id=\"ph2\">`update_from_dataframe`</ph>.",
      "pos": [
        13650,
        13748
      ]
    },
    {
      "content": "It works similarly, you just pass in <ph id=\"ph1\">`raw_data`</ph> instead of  <ph id=\"ph2\">`dataframe`</ph>.",
      "pos": [
        13749,
        13821
      ]
    },
    {
      "content": "test",
      "pos": [
        14899,
        14903
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Access datasets with Machine Learning Python client library | Microsoft Azure\" \n    description=\"Install and use the Python client library to access and manage Azure Machine Learning data securely from a local Python environment.\" \n    services=\"machine-learning\" \n    documentationCenter=\"python\" \n    authors=\"bradsev\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"/>\n\n<tags \n    ms.service=\"machine-learning\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"07/14/2015\" \n    ms.author=\"huvalo;bradsev\" />\n\n\n#Access datasets with Python using the Azure Machine Learning Python client library \n\nThe preview of Microsoft Azure Machine Learning Python client library can enable secure access to your Azure Machine Learning datasets from a local Python environment and enables the creation and management of datasets in workspace.\n\nThis topic provides instructions on how to:\n\n* install the Machine Learning Python client library \n* access and upload datasets, including instructions on how to get authorization to access Azure Machine Learning datasets from your local Python environment\n*  access intermediate datasets from experiments\n*  use the Python client library to enumerate datasets, access metadata, read the contents of a dataset, create new datasets and update existing datasets\n\n[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]\n\n \n##<a name=\"prerequisites\"></a>Prerequisites\n\nThe Python client library has been tested under the following environments:\n\n - Windows, Mac and Linux\n - Python 2.7, 3.3 and 3.4\n\nIt has a dependency on the following packages:\n\n - requests\n - python-dateutil\n - pandas\n\nWe recommend using a Python distribution such as [Anaconda](http://continuum.io/downloads#all) or [Canopy](https://store.enthought.com/downloads/), which come with Python, IPython and the three packages  listed above installed. Although IPython is not strictly required, it is a great environment for manipulating and visualizing data interactively.\n\n\n###<a name=\"installation\"></a>How to install the Azure Machine Learning Python client library\n\nThe Azure Machine Learning Python client library must also be installed to complete the tasks outlined in this topic. It is available from the [Python Package Index](https://pypi.python.org/pypi/azureml). To install it in your Python environment, run the following command from your local Python environment:\n\n    pip install azureml\n\nAlternatively, you can download and install from the sources on [github](https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python).\n\n    python setup.py install\n\nIf you have git installed on your machine, you can use pip to install directly from the git repository:\n\n    pip install git+https://github.com/Azure/Azure-MachineLearning-ClientLibrary-Python.git\n\n\n##<a name=\"datasetAccess\"></a>Use Studio Code snippets to access datasets\n\nThe Python client library gives you programmatic access to your existing datasets from experiments that have been run.\n\nFrom the Studio web interface, you can generate code snippets that include all the necessary information to download and deserialize datasets as Pandas DataFrame objects on your location machine.\n\n### <a name=\"security\"></a>Security for data access\n\nThe code snippets provided by Studio for use with the Python client library includes your workspace id and authorization token. These provide full access to your workspace and must be protect, like a password.\n\nFor security reasons, the code snippet functionality is only available to users that have their role set as **Owner** for the workspace. Your role is displayed in Azure Machine Learning Studio on the **USERS** page under **Settings**.\n\n![Security][security]\n\nIf your role is not set as **Owner**, you can either request to be re-invited as an owner, or ask the owner of the workspace to provide you with the code snippet.\n\nTo obtain the authorization token, you can do one of the following:\n\n1. Ask for a token from an owner. Owners can access their authorization tokens from the Settings page of their workspace in Studio. Select **Settings** from the left pane and click on **AUTHORIZATION TOKENS** to see the primary and secondary tokens.  Although either the primary or the secondary authorization tokens can be used in the code snippet, it is recommended that owners only share the secondary authorization tokens.\n\n    ![](http://i.imgur.com/h33GoZX.jpg)\n\n2. Ask to be promoted to role of owner.  To do this, a current owner of the workspace needs to first remove you from the workspace then re-invite you to it as an owner.\n\nOnce developers have obtained the workspace id and authorization token, they will be able to access the workspace using the code  snippet regardless of their role.\n\nAuthorization tokens are managed on the **AUTHORIZATION TOKENS** page under **SETTINGS**. You can regenerate them, but this procedure will revoke access to the previous token.\n\n### <a name=\"accessingDatasets\"></a>Access datasets from a local Python application\n\n1. In Machine Learning Studio, click on **DATASETS** in the navigation bar on the left.\n\n2. Select the dataset you would like to access. You can select any of the datasets from the **MY DATASETS** list or from the **SAMPLES** list.\n\n3. From the bottom toolbar, click on **Generate Data Access Code**. Note that this button will be disabled if the data is in a format incompatible with the Python client library.\n\n    ![Datasets][datasets]\n\n4. Select the code snippet from the window that appears and copy it to your clipboard.\n\n    ![Access Code][dataset-access-code]\n\n5. Paste the code into the notebook of you local Python application.\n\n    ![Notebook][ipython-dataset]\n\n### <a name=\"accessingIntermediateDatasets\"></a>Access intermediate datasets from Machine Learning experiments\n\nAfter an experiment is run in the Machine Learning Studio, it is possible to access the intermediate datasets from the output nodes of modules. Intermediate datasets are data that has been created and used for intermediate steps when a model tool has been run.\n\nIntermediate datasets can be accessed as long as the data format is compatible with the Python client library.\n\nThe following formats are supported (constants for these are in the `azureml.DataTypeIds` class):\n\n - PlainText\n - GenericCSV\n - GenericTSV\n - GenericCSVNoHeader\n - GenericTSVNoHeader\n\nYou can determine the format by hovering over a module output node. It is displayed along with the node name, in a tooltip.\n\nSome of the modules, such as the [Split][split] module, output to a format named `Dataset`, which is not supported by the Python client library.\n\n![Dataset Format][dataset-format]\n\nYou'll need to use a conversion module, such as [Convert to CSV][convert-to-csv], to get an output into a supported format.\n\n![GenericCSV Format][csv-format]\n\nThe following steps show an example that creates an experiment, runs it and accesses the intermediate dataset.\n\n1. Create a new experiment.\n\n2. Insert an **Adult Census Income Binary Classification dataset** module.\n\n3. Insert a [Split][split] module, and connect its input to the dataset module output.\n\n4. Insert a [Convert to CSV][convert-to-csv] module and connect its input to one of the [Split][split] module outputs.\n\n5. Save the experiment, run it, and wait for it to finish running.\n\n6. Click on the output node on the [Convert to CSV][convert-to-csv] module.\n\n7. A context menu will appear, select **Generate Data Access Code**.\n\n    ![Context Menu][experiment]\n\n8. A window will appear. Select the code snippet and copy it to your clipboard.\n\n    ![Access Code][intermediate-dataset-access-code]\n\n9. Paste the code in your notebook.\n\n    ![Notebook][ipython-intermediate-dataset]\n\n10. You can visualize the data using matplotlib. This displays in a histogram for the age column:\n\n    ![Histogram][ipython-histogram]\n\n\n##<a name=\"clientApis\"></a>Use the Machine Learning Python client library to access, read, create, and manage datasets\n\n### Workspace\n\nThe workspace is the entry point for the Python client library. Provide the `Workspace` class with your workspace id and authorization token to create an instance:\n\n    ws = Workspace(workspace_id='4c29e1adeba2e5a7cbeb0e4f4adfb4df',\n                   authorization_token='f4f3ade2c6aefdb1afb043cd8bcf3daf')\n\n\n### Enumerate datasets\n\nTo enumerate all datasets in a given workspace:\n\n    for ds in ws.datasets:\n        print(ds.name)\n\nTo enumerate just the user-created datasets:\n\n    for ds in ws.user_datasets:\n        print(ds.name)\n\nTo enumerate just the example datasets:\n\n    for ds in ws.example_datasets:\n        print(ds.name)\n\nYou can access a dataset by name (which is case-sensitive):\n\n    ds = ws.datasets['my dataset name']\n\nOr you can access it by index:\n\n    ds = ws.datasets[0]\n\n\n### Metadata\n\nDatasets have metadata, in addition to content. (Intermediate datasets are an exception to this rule and do not have any metadata.)\n\nSome metadata values are assigned by the user at creation time:\n\n    print(ds.name)\n    print(ds.description)\n    print(ds.family_id)\n    print(ds.data_type_id)\n\nOthers are values assigned by Azure ML:\n\n    print(ds.id)\n    print(ds.created_date)\n    print(ds.size)\n\nSee the `SourceDataset` class for more on the available metadata.\n\n\n### Read contents\n\nThe code snippets provided by Machine Learning Studio automatically download and deserialize the dataset to a Pandas DataFrame object. This is done with the `to_dataframe` method:\n\n    frame = ds.to_dataframe()\n\nIf you prefer to download the raw data, and perform the deserialization yourself, that is an option. At the moment, this is the only option for formats such as 'ARFF', which the Python client library cannot deserialize.\n\nTo read the contents as text:\n\n    text_data = ds.read_as_text()\n\nTo read the contents as binary:\n\n    binary_data = ds.read_as_binary()\n\nYou can also just open a stream to the contents:\n\n    with ds.open() as file:\n        binary_data_chunk = file.read(1000)\n\n\n### Create a new dataset\n\nThe Python client library allow you to upload datasets from your Python program. These datasets will be available for use in your workspace.\n\nIf you have your data in a Pandas DataFrame, use the following code:\n\n    from azureml import DataTypeIds\n\n    dataset = ws.datasets.add_from_dataframe(\n        dataframe=frame,\n        data_type_id=DataTypeIds.GenericCSV,\n        name='my new dataset',\n        description='my description'\n    )\n\nIf your data is already serialized, you can use:\n\n    from azureml import DataTypeIds\n\n    dataset = ws.datasets.add_from_raw_data(\n        raw_data=raw_data,\n        data_type_id=DataTypeIds.GenericCSV,\n        name='my new dataset',\n        description='my description'\n    )\n\nThe Python client library are able to serialize a Pandas DataFrame to the following formats (constants for these are in the `azureml.DataTypeIds` class):\n\n - PlainText\n - GenericCSV\n - GenericTSV\n - GenericCSVNoHeader\n - GenericTSVNoHeader\n\n\n### Update an existing dataset\n\nIf you try to upload a new dataset with a name that matches an existing dataset, you'll get a conflict error.\n\nTo update an existing dataset, you first need to get a reference to the existing dataset:\n\n    dataset = ws.datasets['existing dataset']\n\n    print(dataset.data_type_id) # 'GenericCSV'\n    print(dataset.name)         # 'existing dataset'\n    print(dataset.description)  # 'data up to jan 2015'\n\nThen use `update_from_dataframe` to serialize and replace the contents of the dataset on Azure:\n\n    dataset = ws.datasets['existing dataset']\n\n    dataset.update_from_dataframe(frame2)\n\n    print(dataset.data_type_id) # 'GenericCSV'\n    print(dataset.name)         # 'existing dataset'\n    print(dataset.description)  # 'data up to jan 2015'\n\nIf you want to serialize the data to a different format, specify a value for the optional `data_type_id` parameter.\n\n    from azureml import DataTypeIds\n\n    dataset = ws.datasets['existing dataset']\n\n    dataset.update_from_dataframe(\n        dataframe=frame2,\n        data_type_id=DataTypeIds.GenericTSV,\n    )\n\n    print(dataset.data_type_id) # 'GenericTSV'\n    print(dataset.name)         # 'existing dataset'\n    print(dataset.description)  # 'data up to jan 2015'\n\nYou can optionally set a new description by specifying a value for the `description` parameter.\n\n    dataset = ws.datasets['existing dataset']\n\n    dataset.update_from_dataframe(\n        dataframe=frame2,\n        description='data up to feb 2015',\n    )\n\n    print(dataset.data_type_id) # 'GenericCSV'\n    print(dataset.name)         # 'existing dataset'\n    print(dataset.description)  # 'data up to feb 2015'\n\nYou can optionally set a new name by specifying a value for the `name` parameter. From now on, you'll retrieve the dataset using the new name only. The following code updates the data, name and description.\n\n    dataset = ws.datasets['existing dataset']\n\n    dataset.update_from_dataframe(\n        dataframe=frame2,\n        name='existing dataset v2',\n        description='data up to feb 2015',\n    )\n\n    print(dataset.data_type_id)                    # 'GenericCSV'\n    print(dataset.name)                            # 'existing dataset v2'\n    print(dataset.description)                     # 'data up to feb 2015'\n\n    print(ws.datasets['existing dataset v2'].name) # 'existing dataset v2'\n    print(ws.datasets['existing dataset'].name)    # IndexError\n\nThe `data_type_id`, `name` and `description` parameters are all optional, and default to their previous value. The `dataframe` parameter is always required.\n\nIf your data is already serialized, use `update_from_raw_data` instead of `update_from_dataframe`. It works similarly, you just pass in `raw_data` instead of  `dataframe`.\n\n\n\n<!-- Images -->\n[security]:./media/machine-learning-python-data-access/security.png\n[dataset-format]:./media/machine-learning-python-data-access/dataset-format.png\n[csv-format]:./media/machine-learning-python-data-access/csv-format.png\n[datasets]:./media/machine-learning-python-data-access/datasets.png\n[dataset-access-code]:./media/machine-learning-python-data-access/dataset-access-code.png\n[ipython-dataset]:./media/machine-learning-python-data-access/ipython-dataset.png\n[experiment]:./media/machine-learning-python-data-access/experiment.png\n[intermediate-dataset-access-code]:./media/machine-learning-python-data-access/intermediate-dataset-access-code.png\n[ipython-intermediate-dataset]:./media/machine-learning-python-data-access/ipython-intermediate-dataset.png\n[ipython-histogram]:./media/machine-learning-python-data-access/ipython-histogram.png\n\n\n<!-- Module References -->\n[convert-to-csv]: https://msdn.microsoft.com/library/azure/faa6ba63-383c-4086-ba58-7abf26b85814/\n[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/\n \ntest\n"
}