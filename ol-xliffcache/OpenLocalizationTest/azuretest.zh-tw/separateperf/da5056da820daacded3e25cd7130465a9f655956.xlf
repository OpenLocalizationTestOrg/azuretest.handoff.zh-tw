<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Develop Java MapReduce programs for Hadoop | Microsoft Azure</source>
          <target state="new">Develop Java MapReduce programs for Hadoop | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to develop Java MapReduce programs on HDInsight emulator, how to deploy them to HDInsight.</source>
          <target state="new">Learn how to develop Java MapReduce programs on HDInsight emulator, how to deploy them to HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Develop Java MapReduce programs for Hadoop in HDInsight</source>
          <target state="new">Develop Java MapReduce programs for Hadoop in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This tutorial walks you through an end-to-end scenario for developing a word-counting Hadoop MapReduce job in Java by using Apache Maven.</source>
          <target state="new">This tutorial walks you through an end-to-end scenario for developing a word-counting Hadoop MapReduce job in Java by using Apache Maven.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The tutorial also shows how to test the application on the HDInsight Emulator for Azure and then deploy and run it on an Windows-based HDInsight cluster.</source>
          <target state="new">The tutorial also shows how to test the application on the HDInsight Emulator for Azure and then deploy and run it on an Windows-based HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="prerequisites"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</source>
          <target state="new"><ph id="ph1">&lt;a name="prerequisites"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Before you begin this tutorial, you must have completed the following:</source>
          <target state="new">Before you begin this tutorial, you must have completed the following:</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Install the HDInsight Emulator.</source>
          <target state="new">Install the HDInsight Emulator.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Get started using HDInsight Emulator<ept id="p1">][hdinsight-emulator]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Get started using HDInsight Emulator<ept id="p1">][hdinsight-emulator]</ept>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Make sure all the required services are running.</source>
          <target state="new">Make sure all the required services are running.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>On the computer that has HDInsight Emulator installed, launch the Hadoop Command line from the Desktop shortcut, navigate to <bpt id="p1">**</bpt>C:\hdp<ept id="p1">**</ept>, and run the command <bpt id="p2">**</bpt>start_local_hdp_services.cmd<ept id="p2">**</ept>.</source>
          <target state="new">On the computer that has HDInsight Emulator installed, launch the Hadoop Command line from the Desktop shortcut, navigate to <bpt id="p1">**</bpt>C:\hdp<ept id="p1">**</ept>, and run the command <bpt id="p2">**</bpt>start_local_hdp_services.cmd<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Install Azure PowerShell on the emulator computer.</source>
          <target state="new">Install Azure PowerShell on the emulator computer.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">][powershell-install-configure]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">][powershell-install-configure]</ept>.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Install Java platform JDK 7 or higher on the emulator computer.</source>
          <target state="new">Install Java platform JDK 7 or higher on the emulator computer.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>This is already available on the emulator computer.</source>
          <target state="new">This is already available on the emulator computer.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Install and configure <bpt id="p1">[</bpt>Apache Maven<ept id="p1">](http://maven.apache.org/)</ept>.</source>
          <target state="new">Install and configure <bpt id="p1">[</bpt>Apache Maven<ept id="p1">](http://maven.apache.org/)</ept>.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Obtain an Azure subscription.</source>
          <target state="new">Obtain an Azure subscription.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Purchase Options<ept id="p1">][azure-purchase-options]</ept>, <bpt id="p2">[</bpt>Member Offers<ept id="p2">][azure-member-offers]</ept>, or <bpt id="p3">[</bpt>Free Trial<ept id="p3">][azure-free-trial]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Purchase Options<ept id="p1">][azure-purchase-options]</ept>, <bpt id="p2">[</bpt>Member Offers<ept id="p2">][azure-member-offers]</ept>, or <bpt id="p3">[</bpt>Free Trial<ept id="p3">][azure-free-trial]</ept>.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="develop"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Use Apache Maven to create a MapReduce program in Java</source>
          <target state="new"><ph id="ph1">&lt;a name="develop"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Use Apache Maven to create a MapReduce program in Java</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Create a word-counting MapReduce application.</source>
          <target state="new">Create a word-counting MapReduce application.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>It is a simple application that counts the occurrences of each word in a given input set.</source>
          <target state="new">It is a simple application that counts the occurrences of each word in a given input set.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>In this section, we will performing the following tasks:</source>
          <target state="new">In this section, we will performing the following tasks:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Create a project by using Apache Maven</source>
          <target state="new">Create a project by using Apache Maven</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Update the Project Object Model (POM)</source>
          <target state="new">Update the Project Object Model (POM)</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Create the word-counting MapReduce application</source>
          <target state="new">Create the word-counting MapReduce application</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Build and package the application</source>
          <target state="new">Build and package the application</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>To create a project by using Maven</source>
          <target state="new">To create a project by using Maven</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Create a directory *<bpt id="p1">*</bpt>C:\Tutorials\WordCountJava\*<ept id="p1">*</ept>.</source>
          <target state="new">Create a directory *<bpt id="p1">*</bpt>C:\Tutorials\WordCountJava\*<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>From the command line in your development environment, change directories to the location you created.</source>
          <target state="new">From the command line in your development environment, change directories to the location you created.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p1">__</bpt>mvn<ept id="p1">__</ept> command, which is installed with Maven, to generate the scaffolding for the project.</source>
          <target state="new">Use the <bpt id="p1">__</bpt>mvn<ept id="p1">__</ept> command, which is installed with Maven, to generate the scaffolding for the project.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>This will create a new directory in the current directory, with the name specified by the <bpt id="p1">__</bpt>artifactID<ept id="p1">__</ept> parameter (<bpt id="p2">**</bpt>wordcountjava<ept id="p2">**</ept> in this example.) This directory will contain the following items:</source>
          <target state="new">This will create a new directory in the current directory, with the name specified by the <bpt id="p1">__</bpt>artifactID<ept id="p1">__</ept> parameter (<bpt id="p2">**</bpt>wordcountjava<ept id="p2">**</ept> in this example.) This directory will contain the following items:</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> - The <bpt id="p2">[</bpt>Project Object Model (POM)<ept id="p2">](http://maven.apache.org/guides/introduction/introduction-to-the-pom.html)</ept> that contains information and configuration details used to build the project.</source>
          <target state="new"><bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> - The <bpt id="p2">[</bpt>Project Object Model (POM)<ept id="p2">](http://maven.apache.org/guides/introduction/introduction-to-the-pom.html)</ept> that contains information and configuration details used to build the project.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">__</bpt>src<ept id="p1">__</ept> - The directory that contains the <bpt id="p2">__</bpt>main\java\org\apache\hadoop\examples<ept id="p2">__</ept> directory, where you will author the application.</source>
          <target state="new"><bpt id="p1">__</bpt>src<ept id="p1">__</ept> - The directory that contains the <bpt id="p2">__</bpt>main\java\org\apache\hadoop\examples<ept id="p2">__</ept> directory, where you will author the application.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Delete the <bpt id="p1">__</bpt>src\test\java\org\apache\hadoop\examples\apptest.java<ept id="p1">__</ept> file, as it will not be used in this example.</source>
          <target state="new">Delete the <bpt id="p1">__</bpt>src\test\java\org\apache\hadoop\examples\apptest.java<ept id="p1">__</ept> file, as it will not be used in this example.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>To update the POM</source>
          <target state="new">To update the POM</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Edit the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file and add the following inside the <ph id="ph1">`&lt;dependencies&gt;`</ph> section:</source>
          <target state="new">Edit the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file and add the following inside the <ph id="ph1">`&lt;dependencies&gt;`</ph> section:</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>This tells Maven that the project requires the libraries (listed within &lt;artifactId\&gt;) with a specific version (listed within &lt;version\&gt;).</source>
          <target state="new">This tells Maven that the project requires the libraries (listed within &lt;artifactId\&gt;) with a specific version (listed within &lt;version\&gt;).</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>At compile time, this will be downloaded from the default Maven repository.</source>
          <target state="new">At compile time, this will be downloaded from the default Maven repository.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>You can use the <bpt id="p1">[</bpt>Maven repository search<ept id="p1">](http://search.maven.org/#artifactdetails%7Corg.apache.hadoop%7Chadoop-mapreduce-examples%7C2.5.1%7Cjar)</ept> to view more.</source>
          <target state="new">You can use the <bpt id="p1">[</bpt>Maven repository search<ept id="p1">](http://search.maven.org/#artifactdetails%7Corg.apache.hadoop%7Chadoop-mapreduce-examples%7C2.5.1%7Cjar)</ept> to view more.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Add the following to the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file.</source>
          <target state="new">Add the following to the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>This must be inside the <ph id="ph1">`&lt;project&gt;...&lt;/project&gt;`</ph> tags in the file; for example, between <ph id="ph2">`&lt;/dependencies&gt;`</ph> and <ph id="ph3">`&lt;/project&gt;`</ph>.</source>
          <target state="new">This must be inside the <ph id="ph1">`&lt;project&gt;...&lt;/project&gt;`</ph> tags in the file; for example, between <ph id="ph2">`&lt;/dependencies&gt;`</ph> and <ph id="ph3">`&lt;/project&gt;`</ph>.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>This configures the <bpt id="p1">[</bpt>Maven Shade Plugin<ept id="p1">](http://maven.apache.org/plugins/maven-shade-plugin/)</ept>, which is used to prevent license duplication in the JAR file that is built by Maven.</source>
          <target state="new">This configures the <bpt id="p1">[</bpt>Maven Shade Plugin<ept id="p1">](http://maven.apache.org/plugins/maven-shade-plugin/)</ept>, which is used to prevent license duplication in the JAR file that is built by Maven.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The reason this is used is that the duplicate license files cause an error at run time on the HDInsight cluster.</source>
          <target state="new">The reason this is used is that the duplicate license files cause an error at run time on the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Using the Maven Shade Plugin with the <ph id="ph1">`ApacheLicenseResourceTransformer`</ph> implementation prevents this error.</source>
          <target state="new">Using the Maven Shade Plugin with the <ph id="ph1">`ApacheLicenseResourceTransformer`</ph> implementation prevents this error.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The Maven Shade Plugin will also produce an uberjar (sometimes called a fatjar), which contains all the dependencies required by the application.</source>
          <target state="new">The Maven Shade Plugin will also produce an uberjar (sometimes called a fatjar), which contains all the dependencies required by the application.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Save the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file.</source>
          <target state="new">Save the <bpt id="p1">__</bpt>pom.xml<ept id="p1">__</ept> file.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>To create the word-counting application</source>
          <target state="new">To create the word-counting application</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Go to the <bpt id="p1">__</bpt>wordcountjava\src\main\java\org\apache\hadoop\examples<ept id="p1">__</ept> directory and rename the <bpt id="p2">__</bpt>app.java<ept id="p2">__</ept> file to <bpt id="p3">__</bpt>WordCount.java<ept id="p3">__</ept>.</source>
          <target state="new">Go to the <bpt id="p1">__</bpt>wordcountjava\src\main\java\org\apache\hadoop\examples<ept id="p1">__</ept> directory and rename the <bpt id="p2">__</bpt>app.java<ept id="p2">__</ept> file to <bpt id="p3">__</bpt>WordCount.java<ept id="p3">__</ept>.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Open Notepad.</source>
          <target state="new">Open Notepad.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Copy and paste the following program into Notepad:</source>
          <target state="new">Copy and paste the following program into Notepad:</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Notice the package name is <bpt id="p1">**</bpt>org.apache.hadoop.examples<ept id="p1">**</ept> and the class name is <bpt id="p2">**</bpt>WordCount<ept id="p2">**</ept>.</source>
          <target state="new">Notice the package name is <bpt id="p1">**</bpt>org.apache.hadoop.examples<ept id="p1">**</ept> and the class name is <bpt id="p2">**</bpt>WordCount<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>You will use these names when you submit the MapReduce job.</source>
          <target state="new">You will use these names when you submit the MapReduce job.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Save the file.</source>
          <target state="new">Save the file.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>To build and package the application</source>
          <target state="new">To build and package the application</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Open a command prompt and change directories to the <bpt id="p1">__</bpt>wordcountjava<ept id="p1">__</ept> directory.</source>
          <target state="new">Open a command prompt and change directories to the <bpt id="p1">__</bpt>wordcountjava<ept id="p1">__</ept> directory.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Use the following command to build a JAR file containing the application:</source>
          <target state="new">Use the following command to build a JAR file containing the application:</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>This will clean any previous build artifacts, download any dependencies that have not already been installed, and then build and package the application.</source>
          <target state="new">This will clean any previous build artifacts, download any dependencies that have not already been installed, and then build and package the application.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Once the command finishes, the <bpt id="p1">__</bpt>wordcountjava\target<ept id="p1">__</ept> directory will contain a file named <bpt id="p2">__</bpt>wordcountjava-1.0-SNAPSHOT.jar<ept id="p2">__</ept>.</source>
          <target state="new">Once the command finishes, the <bpt id="p1">__</bpt>wordcountjava\target<ept id="p1">__</ept> directory will contain a file named <bpt id="p2">__</bpt>wordcountjava-1.0-SNAPSHOT.jar<ept id="p2">__</ept>.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The <bpt id="p1">__</bpt>wordcountjava-1.0-SNAPSHOT.jar<ept id="p1">__</ept> file is an uberjar.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The <bpt id="p1">__</bpt>wordcountjava-1.0-SNAPSHOT.jar<ept id="p1">__</ept> file is an uberjar.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="test"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Test the program on the emulator</source>
          <target state="new"><ph id="ph1">&lt;a name="test"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Test the program on the emulator</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Testing the MapReduce job on the HDInsight Emulator includes the following procedures:</source>
          <target state="new">Testing the MapReduce job on the HDInsight Emulator includes the following procedures:</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Upload the data files to the Hadoop Distributed File System (HDFS) on the emulator</source>
          <target state="new">Upload the data files to the Hadoop Distributed File System (HDFS) on the emulator</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Create a local user group</source>
          <target state="new">Create a local user group</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Run a word-counting MapReduce job</source>
          <target state="new">Run a word-counting MapReduce job</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Retrieve the job results</source>
          <target state="new">Retrieve the job results</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>By default, the HDInsight Emulator uses HDFS as the file system.</source>
          <target state="new">By default, the HDInsight Emulator uses HDFS as the file system.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Optionally, you can configure the HDInsight Emulator to use Azure Blob storage.</source>
          <target state="new">Optionally, you can configure the HDInsight Emulator to use Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>For details, see <bpt id="p1">[</bpt>Get started with HDInsight Emulator<ept id="p1">][hdinsight-emulator-wasb]</ept>.</source>
          <target state="new">For details, see <bpt id="p1">[</bpt>Get started with HDInsight Emulator<ept id="p1">][hdinsight-emulator-wasb]</ept>.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will use the HDFS <bpt id="p1">**</bpt>copyFromLocal<ept id="p1">**</ept> command to upload the data files to HDFS.</source>
          <target state="new">In this tutorial, you will use the HDFS <bpt id="p1">**</bpt>copyFromLocal<ept id="p1">**</ept> command to upload the data files to HDFS.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The next section shows you how to upload files to Azure Blob storage by using Azure PowerShell.</source>
          <target state="new">The next section shows you how to upload files to Azure Blob storage by using Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>For other methods for uploading files to Azure Blob storage, see <bpt id="p1">[</bpt>Upload data to HDInsight<ept id="p1">][hdinsight-upload-data]</ept>.</source>
          <target state="new">For other methods for uploading files to Azure Blob storage, see <bpt id="p1">[</bpt>Upload data to HDInsight<ept id="p1">][hdinsight-upload-data]</ept>.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>This tutorial uses the following HDFS folder structure:</source>
          <target state="new">This tutorial uses the following HDFS folder structure:</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Folder</source>
          <target state="new">Folder</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Note</source>
          <target state="new">Note</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>/WordCount</source>
          <target state="new">/WordCount</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>The root folder for the word-counting project.</source>
          <target state="new">The root folder for the word-counting project.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>/WordCount/Apps</source>
          <target state="new">/WordCount/Apps</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The folder for the mapper and reducer executables.</source>
          <target state="new">The folder for the mapper and reducer executables.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>/WordCount/Input</source>
          <target state="new">/WordCount/Input</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>The MapReduce source file folder.</source>
          <target state="new">The MapReduce source file folder.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>/WordCount/Output</source>
          <target state="new">/WordCount/Output</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>The MapReduce output file folder.</source>
          <target state="new">The MapReduce output file folder.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>/WordCount/MRStatusOutput</source>
          <target state="new">/WordCount/MRStatusOutput</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>The job output folder.</source>
          <target state="new">The job output folder.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>This tutorial uses the .txt files located in the %hadoop_home% directory as the data files.</source>
          <target state="new">This tutorial uses the .txt files located in the %hadoop_home% directory as the data files.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The Hadoop HDFS commands are case sensitive.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The Hadoop HDFS commands are case sensitive.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>To copy the data files to the emulator HDFS</source>
          <target state="new">To copy the data files to the emulator HDFS</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Open the Hadoop command line from your desktop.</source>
          <target state="new">Open the Hadoop command line from your desktop.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The Hadoop command line is installed by the emulator installer.</source>
          <target state="new">The Hadoop command line is installed by the emulator installer.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>From the Hadoop command-line window, run the following command to make a directory for the input files:</source>
          <target state="new">From the Hadoop command-line window, run the following command to make a directory for the input files:</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>The path used here is the relative path.</source>
          <target state="new">The path used here is the relative path.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>It is equivalent to the following:</source>
          <target state="new">It is equivalent to the following:</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Run the following command to copy some text files to the input folder on HDFS:</source>
          <target state="new">Run the following command to copy some text files to the input folder on HDFS:</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>The MapReduce job will count the words in these files.</source>
          <target state="new">The MapReduce job will count the words in these files.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Run the following command to list and verify the uploaded files:</source>
          <target state="new">Run the following command to list and verify the uploaded files:</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>To create a local user group</source>
          <target state="new">To create a local user group</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>To successfully run the MapReduce job on the cluster, you must create a user group called hdfs.</source>
          <target state="new">To successfully run the MapReduce job on the cluster, you must create a user group called hdfs.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>To this group, you must also add a user called hadoop and the local user with which you log on to the emulator.</source>
          <target state="new">To this group, you must also add a user called hadoop and the local user with which you log on to the emulator.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Use the following commands from an elevated command prompt:</source>
          <target state="new">Use the following commands from an elevated command prompt:</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>To run the MapReduce job by using the Hadoop command line</source>
          <target state="new">To run the MapReduce job by using the Hadoop command line</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Open the Hadoop command line from your desktop.</source>
          <target state="new">Open the Hadoop command line from your desktop.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Run the following command to delete the /WordCount/Output folder structure from HDFS.</source>
          <target state="new">Run the following command to delete the /WordCount/Output folder structure from HDFS.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>/WordCount/Output is the output folder of the word-counting MapReduce job.</source>
          <target state="new">/WordCount/Output is the output folder of the word-counting MapReduce job.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>The MapReduce job will fail if the folder already exists.</source>
          <target state="new">The MapReduce job will fail if the folder already exists.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>This step is necessary if this is the second time you're running the job.</source>
          <target state="new">This step is necessary if this is the second time you're running the job.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Run the following command:</source>
          <target state="new">Run the following command:</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>If the job finishes successfully, you should get an output similar to the following screenshot:</source>
          <target state="new">If the job finishes successfully, you should get an output similar to the following screenshot:</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>HDI.EMulator.WordCount.Run</source>
          <target state="new">HDI.EMulator.WordCount.Run</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>From the screenshot, you can see both map and reduce finished 100%.</source>
          <target state="new">From the screenshot, you can see both map and reduce finished 100%.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>It also lists the job ID.</source>
          <target state="new">It also lists the job ID.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>The same report can be retrieved by opening the <bpt id="p1">**</bpt>Hadoop MapReduce status<ept id="p1">**</ept> shortcut from your desktop, and looking for the same job ID.</source>
          <target state="new">The same report can be retrieved by opening the <bpt id="p1">**</bpt>Hadoop MapReduce status<ept id="p1">**</ept> shortcut from your desktop, and looking for the same job ID.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>The other option for running a MapReduce job is using Azure PowerShell.</source>
          <target state="new">The other option for running a MapReduce job is using Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Get started with the HDInsight Emulator<ept id="p1">][hdinsight-emulator]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Get started with the HDInsight Emulator<ept id="p1">][hdinsight-emulator]</ept>.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>To display the output from HDFS</source>
          <target state="new">To display the output from HDFS</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>Open the Hadoop command line.</source>
          <target state="new">Open the Hadoop command line.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Run the following commands to display the output:</source>
          <target state="new">Run the following commands to display the output:</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>You can append "|more" at the end of the command to get the page view.</source>
          <target state="new">You can append "|more" at the end of the command to get the page view.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Or use the <bpt id="p1">**</bpt>findstr<ept id="p1">**</ept> command to find a string pattern:</source>
          <target state="new">Or use the <bpt id="p1">**</bpt>findstr<ept id="p1">**</ept> command to find a string pattern:</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>You have now developed a word-counting MapReduce job and tested it successfully on the emulator.</source>
          <target state="new">You have now developed a word-counting MapReduce job and tested it successfully on the emulator.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>The next step is to deploy and run it on Azure HDInsight.</source>
          <target state="new">The next step is to deploy and run it on Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="upload"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Upload data and application to Azure Blob storage</source>
          <target state="new"><ph id="ph1">&lt;a id="upload"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Upload data and application to Azure Blob storage</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Azure HDInsight uses Azure Blob storage for data storage.</source>
          <target state="new">Azure HDInsight uses Azure Blob storage for data storage.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>When an HDInsight cluster is provisioned, an Azure Blob storage container is used to store the system files.</source>
          <target state="new">When an HDInsight cluster is provisioned, an Azure Blob storage container is used to store the system files.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>You can use either this default container or a different container (either on the same Azure Storage account or on a different Storage account located in the same datacenter as the cluster) for storing the data files.</source>
          <target state="new">You can use either this default container or a different container (either on the same Azure Storage account or on a different Storage account located in the same datacenter as the cluster) for storing the data files.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will create a container on a separate Storage account for the data files and the MapReduce application.</source>
          <target state="new">In this tutorial, you will create a container on a separate Storage account for the data files and the MapReduce application.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>The data files are the text files in the <bpt id="p1">**</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\share\doc\hadoop\common<ept id="p1">**</ept> directory on your emulator workstation.</source>
          <target state="new">The data files are the text files in the <bpt id="p1">**</bpt>C:\hdp\hadoop-2.4.0.2.1.3.0-1981\share\doc\hadoop\common<ept id="p1">**</ept> directory on your emulator workstation.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>To create a Blob storage account and a container</source>
          <target state="new">To create a Blob storage account and a container</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Open Azure PowerShell.</source>
          <target state="new">Open Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Set the variables, and then run the commands:</source>
          <target state="new">Set the variables, and then run the commands:</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$subscripionName<ept id="p1">**</ept> variable is associated with your Azure subscription.</source>
          <target state="new">The <bpt id="p1">**</bpt>$subscripionName<ept id="p1">**</ept> variable is associated with your Azure subscription.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>You must name <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept>.</source>
          <target state="new">You must name <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>For the naming restrictions, see <bpt id="p1">[</bpt>Naming and Referencing Containers, Blobs, and Metadata<ept id="p1">](http://msdn.microsoft.com/library/windowsazure/dd135715.aspx)</ept>.</source>
          <target state="new">For the naming restrictions, see <bpt id="p1">[</bpt>Naming and Referencing Containers, Blobs, and Metadata<ept id="p1">](http://msdn.microsoft.com/library/windowsazure/dd135715.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Run the following commands to create a Storage account and a Blob storage container on the account:</source>
          <target state="new">Run the following commands to create a Storage account and a Blob storage container on the account:</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Run the following commands to verify the Storage account and the container:</source>
          <target state="new">Run the following commands to verify the Storage account and the container:</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>To upload the data files</source>
          <target state="new">To upload the data files</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Open Azure PowerShell.</source>
          <target state="new">Open Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Set the first three variables, and then run the commands:</source>
          <target state="new">Set the first three variables, and then run the commands:</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the same as you defined in the last procedure.</source>
          <target state="new">The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the same as you defined in the last procedure.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Notice the source file folder is <bpt id="p1">**</bpt>c:\Hadoop\hadoop-1.1.0-SNAPSHOT<ept id="p1">**</ept>, and the destination folder is <bpt id="p2">**</bpt>WordCount/Input<ept id="p2">**</ept>.</source>
          <target state="new">Notice the source file folder is <bpt id="p1">**</bpt>c:\Hadoop\hadoop-1.1.0-SNAPSHOT<ept id="p1">**</ept>, and the destination folder is <bpt id="p2">**</bpt>WordCount/Input<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>Run the following commands to get a list of the .txt files in the source file folder:</source>
          <target state="new">Run the following commands to get a list of the .txt files in the source file folder:</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Run the following commands to create a storage context object:</source>
          <target state="new">Run the following commands to create a storage context object:</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>Run the following commands to copy the files:</source>
          <target state="new">Run the following commands to copy the files:</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Run the following commands to list the uploaded files:</source>
          <target state="new">Run the following commands to list the uploaded files:</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>You should see about the uploaded text data files.</source>
          <target state="new">You should see about the uploaded text data files.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>To upload the word-counting application</source>
          <target state="new">To upload the word-counting application</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>Open Azure PowerShell.</source>
          <target state="new">Open Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Set the first three variables, and then run the commands:</source>
          <target state="new">Set the first three variables, and then run the commands:</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the same as you defined in the last procedure, which means you will upload both the data file and the application to the same container on the same Storage account.</source>
          <target state="new">The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the same as you defined in the last procedure, which means you will upload both the data file and the application to the same container on the same Storage account.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Notice the destination folder is <bpt id="p1">**</bpt>WordCount/jars<ept id="p1">**</ept>.</source>
          <target state="new">Notice the destination folder is <bpt id="p1">**</bpt>WordCount/jars<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>Run the following commands to create a storage context object:</source>
          <target state="new">Run the following commands to create a storage context object:</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Run the following command to copy the applications:</source>
          <target state="new">Run the following command to copy the applications:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Run the following commands to list the uploaded files:</source>
          <target state="new">Run the following commands to list the uploaded files:</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>You should see the JAR file listed there.</source>
          <target state="new">You should see the JAR file listed there.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="run"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Run the MapReduce job on Azure HDInsight</source>
          <target state="new"><ph id="ph1">&lt;a name="run"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Run the MapReduce job on Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>In this section, you will create an Azure PowerShell script that performs the following tasks:</source>
          <target state="new">In this section, you will create an Azure PowerShell script that performs the following tasks:</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>Provisions an HDInsight cluster</source>
          <target state="new">Provisions an HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Create a Storage account that will be used as the default HDInsight cluster file system</source>
          <target state="new">Create a Storage account that will be used as the default HDInsight cluster file system</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Create a Blob storage container</source>
          <target state="new">Create a Blob storage container</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Create an HDInsight cluster</source>
          <target state="new">Create an HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Submits the MapReduce job</source>
          <target state="new">Submits the MapReduce job</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Create a MapReduce job definition</source>
          <target state="new">Create a MapReduce job definition</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Submit a MapReduce job</source>
          <target state="new">Submit a MapReduce job</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Wait for the job to finish</source>
          <target state="new">Wait for the job to finish</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Display standard error</source>
          <target state="new">Display standard error</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Display standard output</source>
          <target state="new">Display standard output</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Deletes the cluster</source>
          <target state="new">Deletes the cluster</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>Delete the HDInsight cluster</source>
          <target state="new">Delete the HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>Delete the Storage account used as the default HDInsight cluster file system</source>
          <target state="new">Delete the Storage account used as the default HDInsight cluster file system</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>To run the Azure PowerShell script</source>
          <target state="new">To run the Azure PowerShell script</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>Open Notepad.</source>
          <target state="new">Open Notepad.</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Copy and paste the following code:</source>
          <target state="new">Copy and paste the following code:</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>Set the first six variables in the script.</source>
          <target state="new">Set the first six variables in the script.</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$stringPrefix<ept id="p1">**</ept> variable is used to prefix the specified string to the HDInsight cluster name, the Storage account name, and the Blob storage container name.</source>
          <target state="new">The <bpt id="p1">**</bpt>$stringPrefix<ept id="p1">**</ept> variable is used to prefix the specified string to the HDInsight cluster name, the Storage account name, and the Blob storage container name.</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Because the names for these must be 3 to 24 characters, make sure the string you specify and the names this script uses, together, do not exceed the character limit for the name.</source>
          <target state="new">Because the names for these must be 3 to 24 characters, make sure the string you specify and the names this script uses, together, do not exceed the character limit for the name.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>You must use all lowercase for <bpt id="p1">**</bpt>$stringPrefix<ept id="p1">**</ept>.</source>
          <target state="new">You must use all lowercase for <bpt id="p1">**</bpt>$stringPrefix<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the Storage account and container that are used for storing the data files and the application.</source>
          <target state="new">The <bpt id="p1">**</bpt>$storageAccountName\_Data<ept id="p1">**</ept> and <bpt id="p2">**</bpt>$containerName\_Data<ept id="p2">**</ept> variables are the Storage account and container that are used for storing the data files and the application.</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>$location<ept id="p1">**</ept> variable must match the data Storage account location.</source>
          <target state="new">The <bpt id="p1">**</bpt>$location<ept id="p1">**</ept> variable must match the data Storage account location.</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>Review the rest of the variables.</source>
          <target state="new">Review the rest of the variables.</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Save the script file.</source>
          <target state="new">Save the script file.</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>Open Azure PowerShell.</source>
          <target state="new">Open Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>Run the following command to set the execution policy to RemoteSigned:</source>
          <target state="new">Run the following command to set the execution policy to RemoteSigned:</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>When prompted, enter the user name and password for the HDInsight cluster.</source>
          <target state="new">When prompted, enter the user name and password for the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>Because you will delete the cluster at the end of the script and you will not need the user name and password anymore, the user name and password can be any strings.</source>
          <target state="new">Because you will delete the cluster at the end of the script and you will not need the user name and password anymore, the user name and password can be any strings.</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>If you don't want to get prompted for the credentials, see <bpt id="p1">[</bpt>Working with Passwords, Secure Strings and Credentials in Windows PowerShell<ept id="p1">][powershell-PSCredential]</ept>.</source>
          <target state="new">If you don't want to get prompted for the credentials, see <bpt id="p1">[</bpt>Working with Passwords, Secure Strings and Credentials in Windows PowerShell<ept id="p1">][powershell-PSCredential]</ept>.</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="retrieve"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Retrieve the MapReduce job output</source>
          <target state="new"><ph id="ph1">&lt;a name="retrieve"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Retrieve the MapReduce job output</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>This section shows you how to download and display the output.</source>
          <target state="new">This section shows you how to download and display the output.</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>For the information on displaying the results in Excel, see <bpt id="p1">[</bpt>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver<ept id="p1">][hdinsight-ODBC]</ept> and <bpt id="p2">[</bpt>Connect Excel to HDInsight with Power Query<ept id="p2">][hdinsight-power-query]</ept>.</source>
          <target state="new">For the information on displaying the results in Excel, see <bpt id="p1">[</bpt>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver<ept id="p1">][hdinsight-ODBC]</ept> and <bpt id="p2">[</bpt>Connect Excel to HDInsight with Power Query<ept id="p2">][hdinsight-power-query]</ept>.</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>To retrieve the output</source>
          <target state="new">To retrieve the output</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>Open the Azure PowerShell window.</source>
          <target state="new">Open the Azure PowerShell window.</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>Change the directory to <bpt id="p1">**</bpt>C:\Tutorials\WordCountJava<ept id="p1">**</ept>.</source>
          <target state="new">Change the directory to <bpt id="p1">**</bpt>C:\Tutorials\WordCountJava<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source>The default Azure PowerShell folder is <bpt id="p1">**</bpt>C:\Windows\System32\WindowsPowerShell\v1.0<ept id="p1">**</ept>.</source>
          <target state="new">The default Azure PowerShell folder is <bpt id="p1">**</bpt>C:\Windows\System32\WindowsPowerShell\v1.0<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>The cmdlets you will run will download the output file to the current folder.</source>
          <target state="new">The cmdlets you will run will download the output file to the current folder.</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>You don't have permissions to download the files to the system folders.</source>
          <target state="new">You don't have permissions to download the files to the system folders.</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source>Run the following commands to set the values:</source>
          <target state="new">Run the following commands to set the values:</target>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>Run the following commands to create an Azure storage context object:</source>
          <target state="new">Run the following commands to create an Azure storage context object:</target>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source>Run the following commands to download and display the output:</source>
          <target state="new">Run the following commands to download and display the output:</target>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source>After the job is completed, you have the option to export the data to SQL Server or Azure SQL Database by using <bpt id="p1">[</bpt>Sqoop<ept id="p1">][hdinsight-use-sqoop]</ept>, or to export the data to Excel.</source>
          <target state="new">After the job is completed, you have the option to export the data to SQL Server or Azure SQL Database by using <bpt id="p1">[</bpt>Sqoop<ept id="p1">][hdinsight-use-sqoop]</ept>, or to export the data to Excel.</target>
        </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve">
          <source>In this tutorial, you have learned how to develop a Java MapReduce job, how to test the application on the HDInsight Emulator, and how to write an Azure PowerShell script to provision an HDInsight cluster and run a MapReduce job on the cluster.</source>
          <target state="new">In this tutorial, you have learned how to develop a Java MapReduce job, how to test the application on the HDInsight Emulator, and how to write an Azure PowerShell script to provision an HDInsight cluster and run a MapReduce job on the cluster.</target>
        </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve">
          <source>To learn more, see the following articles:</source>
          <target state="new">To learn more, see the following articles:</target>
        </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve">
          <source>Develop C# Hadoop streaming MapReduce programs for HDInsight</source>
          <target state="new">Develop C# Hadoop streaming MapReduce programs for HDInsight</target>
        </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>Get started with Azure HDInsight</source>
          <target state="new">Get started with Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve">
          <source>Get started with the HDInsight Emulator</source>
          <target state="new">Get started with the HDInsight Emulator</target>
        </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve">
          <source>Use Azure Blob storage with HDInsight</source>
          <target state="new">Use Azure Blob storage with HDInsight</target>
        </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve">
          <source>Administer HDInsight using Azure PowerShell</source>
          <target state="new">Administer HDInsight using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve">
          <source>Upload data to HDInsight</source>
          <target state="new">Upload data to HDInsight</target>
        </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve">
          <source>Connect Excel to HDInsight with Power Query</source>
          <target state="new">Connect Excel to HDInsight with Power Query</target>
        </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve">
          <source>Connect Excel to HDInsight with the Microsoft Hive ODBC Driver</source>
          <target state="new">Connect Excel to HDInsight with the Microsoft Hive ODBC Driver</target>
        </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">da5056da820daacded3e25cd7130465a9f655956</xliffext:olfilehash>
  </header>
</xliff>