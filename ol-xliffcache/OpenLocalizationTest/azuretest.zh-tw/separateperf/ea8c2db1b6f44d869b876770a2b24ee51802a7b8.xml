{
  "nodes": [
    {
      "content": "Typical workflow for Azure Search development | Microsoft Azure",
      "pos": [
        27,
        90
      ]
    },
    {
      "content": "A workflow or roadmap for building prototype and production applications that integrate with Azure Search.",
      "pos": [
        109,
        215
      ]
    },
    {
      "content": "Typical workflow for Azure Search development",
      "pos": [
        523,
        568
      ]
    },
    {
      "content": "This article is a roadmap for including Azure Search as a component that provides the search experience in your custom application.",
      "pos": [
        570,
        701
      ]
    },
    {
      "content": "Depending on whether you are testing the waters or ready to dive right in, youâ€™ll want some preliminary guidance on how to integrate Azure Search into your custom development project.",
      "pos": [
        702,
        885
      ]
    },
    {
      "content": "In the following sections, we break out a typical workflow for an initial prototype that will help you evaluate how well Azure Search meets the search requirements of your application.",
      "pos": [
        887,
        1071
      ]
    },
    {
      "content": "Part two of this article covers important design decisions that factor into a more serious application development effort.",
      "pos": [
        1072,
        1194
      ]
    },
    {
      "content": "Before you start prototyping, we recommend that you ramp up with one of our Getting Started tutorials or this <bpt id=\"p1\">[</bpt>one-hour deep dive presentation video<ept id=\"p1\">](http://azure.microsoft.com/documentation/videos/tech-ed-europe-2014-azure-search-deep-dive/)</ept>.",
      "pos": [
        1196,
        1439
      ]
    },
    {
      "content": "Get Started tutorials are offered in these languages: <bpt id=\"p1\">[</bpt>.NET<ept id=\"p1\">](search-get-started-dotnet.md)</ept>, <bpt id=\"p2\">[</bpt>Java<ept id=\"p2\">](search-get-started-java.md)</ept>, <bpt id=\"p3\">[</bpt>Node.JS<ept id=\"p3\">](search-get-started-nodejs.md)</ept>.",
      "pos": [
        1440,
        1608
      ]
    },
    {
      "content": "Prototype development",
      "pos": [
        1613,
        1634
      ]
    },
    {
      "content": "The quickest path to a successful prototype typically includes the steps in this section.",
      "pos": [
        1636,
        1725
      ]
    },
    {
      "content": "Steps include provisioning a service, define a schema for your index, load the index with documents, and query the index.",
      "pos": [
        1726,
        1847
      ]
    },
    {
      "content": "For applications with volatile data (for example, if the common case includes rapid changes to inventory or content), your prototype should include a component for updating documents as well.",
      "pos": [
        1849,
        2040
      ]
    },
    {
      "content": "![][1]",
      "pos": [
        2045,
        2051
      ]
    },
    {
      "content": "Step 1: Provision the service",
      "pos": [
        2057,
        2086
      ]
    },
    {
      "content": "Azure Search is a fully-managed online service available through an Azure subscription.",
      "pos": [
        2088,
        2175
      ]
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>Once you sign up for Azure<ept id=\"p1\">](http://azure.microsoft.com/pricing/free-trial/)</ept>, adding the Search service is quick.",
      "pos": [
        2176,
        2289
      ]
    },
    {
      "content": "Visit <bpt id=\"p1\">[</bpt>Create a Search service in the portal<ept id=\"p1\">](search-create-service-portal.md)</ept> for instructions on how to add a Search service to your subscription.",
      "pos": [
        2290,
        2438
      ]
    },
    {
      "content": "There are two pricing tiers to choose from.",
      "pos": [
        2440,
        2483
      ]
    },
    {
      "content": "We recommend the shared (free) service for prototyping, with the caveat that you will need to work with a small subset of your data.",
      "pos": [
        2484,
        2616
      ]
    },
    {
      "content": "The shared service is free to existing subscribers (through trial or regular memberships) and is fast to set up, but it constrains the number of indexes and documents you can use to 3 indexes, up to 10,000 documents per index, or 50 MB of storage total, whichever comes first.",
      "pos": [
        2617,
        2893
      ]
    },
    {
      "content": "Step 2: Create the index",
      "pos": [
        2899,
        2923
      ]
    },
    {
      "content": "After you create the service, you are ready to create an index, starting with its schema definition.",
      "pos": [
        2925,
        3025
      ]
    },
    {
      "content": "The fastest and easiest way to create an index is through the Azure portal.",
      "pos": [
        3027,
        3102
      ]
    },
    {
      "content": "At a minimum, each document must have a unique key and at least one field that contains searchable data.",
      "pos": [
        3103,
        3207
      ]
    },
    {
      "content": "To get started, see <bpt id=\"p1\">[</bpt>Create an index in the portal<ept id=\"p1\">](search-create-index-portal.md)</ept>.",
      "pos": [
        3208,
        3291
      ]
    },
    {
      "pos": [
        3295,
        3336
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Inside an Azure Search Index"
    },
    {
      "content": "An <bpt id=\"p1\">*</bpt>index<ept id=\"p1\">*</ept> is organized, persisted data that serves as the <bpt id=\"p2\">*</bpt>search corpus<ept id=\"p2\">*</ept> for all subsequent search operations.",
      "pos": [
        3341,
        3453
      ]
    },
    {
      "content": "Your search corpus is stored in the cloud as part of your Search service subscription, which enables search operations to execute quickly and consistently.",
      "pos": [
        3454,
        3609
      ]
    },
    {
      "content": "In search terminology, an item in your search corpus is called a <bpt id=\"p1\">*</bpt>document<ept id=\"p1\">*</ept>, and the sum total of all documents is the <bpt id=\"p2\">*</bpt>documents collection<ept id=\"p2\">*</ept>.",
      "pos": [
        3610,
        3752
      ]
    },
    {
      "pos": [
        3756,
        3935
      ],
      "content": "An <bpt id=\"p1\">*</bpt>index schema<ept id=\"p1\">*</ept> defines all of the fields within a document by name, data type, and attributes that specify whether the field is searchable, filterable, facetable, and so forth."
    },
    {
      "content": "Besides document structure, an index schema also specifies scoring profiles that provide criteria for boosting a search score, and configuration settings that enable auto-complete queries (suggesters) and CORS for cross-domain query requests.",
      "pos": [
        3940,
        4182
      ]
    },
    {
      "content": "<bpt id=\"p1\">*</bpt>For prototypes, we recommend that you start out simply by specifying just the fields in a document<ept id=\"p1\">*</ept>, and then add other features incrementally (see Step 5 for a list of additional functionality to add later).",
      "pos": [
        4183,
        4392
      ]
    },
    {
      "content": "Applied to a real-world example, consider an e-commerce application.",
      "pos": [
        4399,
        4467
      ]
    },
    {
      "content": "The search index would contain all of the products or services that are searchable in your application (anything that comes back in a search results).",
      "pos": [
        4468,
        4618
      ]
    },
    {
      "content": "There would be one document for each SKU.",
      "pos": [
        4619,
        4660
      ]
    },
    {
      "content": "Each document would include the product name, brand, sizes, price, colors, and even references to images or other resource files that you want returned within search results.",
      "pos": [
        4661,
        4835
      ]
    },
    {
      "content": "Step 3: Load documents",
      "pos": [
        4841,
        4863
      ]
    },
    {
      "content": "After saving the index in Azure Search, the next step is to populate the index with documents.",
      "pos": [
        4865,
        4959
      ]
    },
    {
      "content": "In this step, data is uploaded, analyzed, tokenized, and stored in data structures (such as inverted indexes) that are designed for search workloads.",
      "pos": [
        4960,
        5109
      ]
    },
    {
      "content": "Data that you upload to an index must conform to the schema you defined in the previous step.",
      "pos": [
        5111,
        5204
      ]
    },
    {
      "content": "Document data is represented as a set of key/value pairs for each field, in JSON format.",
      "pos": [
        5205,
        5293
      ]
    },
    {
      "content": "If your schema specifies an ID (key) field, a name field, a number field, and a URL field (which you might do if external images are part of your search results), then all the documents you feed into the index must have values (or null) for each field.",
      "pos": [
        5294,
        5546
      ]
    },
    {
      "content": "There are several ways to load documents, but right now, all of them require an API.",
      "pos": [
        5548,
        5632
      ]
    },
    {
      "content": "For most prototypes, this step might be the most time consuming due to a coding requirement.",
      "pos": [
        5633,
        5725
      ]
    },
    {
      "content": "Options are described later in this article.",
      "pos": [
        5726,
        5770
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Remember that the shared service limits you to 10,000 documents per index.",
      "pos": [
        5774,
        5861
      ]
    },
    {
      "content": "Be sure to reduce your dataset so that it stays under the limits.",
      "pos": [
        5862,
        5927
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Limits and constraints<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798934.aspx)</ept> for more information.",
      "pos": [
        5928,
        6028
      ]
    },
    {
      "content": "How to load data into an index",
      "pos": [
        6035,
        6065
      ]
    },
    {
      "content": "One approach is to use an indexer.",
      "pos": [
        6067,
        6101
      ]
    },
    {
      "content": "For Azure DocumentDB or SQL Server relational data sources in Azure (specifically Azure SQL Database, or SQL Server in an Azure VM), you can use <bpt id=\"p1\">[</bpt>indexers<ept id=\"p1\">](https://msdn.microsoft.com/library/dn946891.aspx)</ept> to retrieve documents from a supported data source.",
      "pos": [
        6102,
        6359
      ]
    },
    {
      "content": "Code samples that use indexers for loading documents can be found in any of these getting started tutorials: <bpt id=\"p1\">[</bpt>.NET<ept id=\"p1\">](search-get-started-dotnet.md)</ept>, <bpt id=\"p2\">[</bpt>Java<ept id=\"p2\">](search-get-started-java.md)</ept>, <bpt id=\"p3\">[</bpt>Node.JS<ept id=\"p3\">](search-get-started-nodejs.md)</ept>.",
      "pos": [
        6360,
        6583
      ]
    },
    {
      "content": "A second option is to write a simple program using either the REST API or the .NET library that loads the documents:",
      "pos": [
        6585,
        6701
      ]
    },
    {
      "content": "Add, update, or delete documents (REST API)",
      "pos": [
        6706,
        6749
      ]
    },
    {
      "content": "DocumentOperationsExtensions Class",
      "pos": [
        6804,
        6838
      ]
    },
    {
      "pos": [
        6934,
        7089
      ],
      "content": "A third option that works for very small datasets is to use <bpt id=\"p1\">[</bpt>Fiddler<ept id=\"p1\">](search-fiddler.md)</ept> or <bpt id=\"p2\">[</bpt>Chrome Postman<ept id=\"p2\">](search-chrome-postman.md)</ept> to upload documents."
    },
    {
      "pos": [
        7091,
        7483
      ],
      "content": "A fourth option, perhaps the easiest one, is to borrow code from either the <bpt id=\"p1\">[</bpt>Adventure Works C# REST API Example<ept id=\"p1\">](https://azuresearchadventureworksdemo.codeplex.com/)</ept> that loads documents from an embedded database (.mdf) in the solution, or <bpt id=\"p2\">[</bpt>Scoring Profiles C# REST API Example<ept id=\"p2\">](https://azuresearchscoringprofiles.codeplex.com/)</ept> that loads data from JSON data files included in the solution."
    },
    {
      "pos": [
        7487,
        7701
      ],
      "content": "<ph id=\"ph1\">[AZURE.TIP]</ph> You could modify and run the <bpt id=\"p1\">[</bpt>scoring profiles sample<ept id=\"p1\">](https://azuresearchscoringprofiles.codeplex.com/)</ept>, replacing the data JSON files and schema.json file with data that is valid for your application."
    },
    {
      "content": "Step 4: Query documents",
      "pos": [
        7707,
        7730
      ]
    },
    {
      "content": "Once documents are loaded into the index, you can write your first query.",
      "pos": [
        7732,
        7805
      ]
    },
    {
      "pos": [
        7807,
        8091
      ],
      "content": "The fastest way to get initial search results back from your Search service is to use <bpt id=\"p1\">[</bpt>Fiddler<ept id=\"p1\">](search-fiddler.md)</ept> or <bpt id=\"p2\">[</bpt>Chrome Postman<ept id=\"p2\">](search-chrome-postman.md)</ept> to view a response, but realistically, you will want to write some simple UI code to view the results in a readable format."
    },
    {
      "content": "APIs for search operations include:",
      "pos": [
        8093,
        8128
      ]
    },
    {
      "content": "Search Documents operation",
      "pos": [
        8133,
        8159
      ]
    },
    {
      "content": "SearchIndexClient Class",
      "pos": [
        8214,
        8237
      ]
    },
    {
      "content": "Queries in Azure Search can be very simple.",
      "pos": [
        8322,
        8365
      ]
    },
    {
      "content": "Including <ph id=\"ph1\">`search=*`</ph> on the URI will return the first 50 items in your search corpus; specifying <ph id=\"ph2\">`search=&lt;some phrase&gt;`</ph> will perform a full-text search on the phrase, returning up to 50 documents, assuming there are at least 50 documents that contain a match on the term input.",
      "pos": [
        8366,
        8643
      ]
    },
    {
      "content": "50 documents is the default.",
      "pos": [
        8645,
        8673
      ]
    },
    {
      "content": "You can change the number of items returned using the <ph id=\"ph1\">`$Count`</ph> query parameter.",
      "pos": [
        8674,
        8753
      ]
    },
    {
      "content": "This parameter is documented in <bpt id=\"p1\">[</bpt>Search Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798927.aspx)</ept>.",
      "pos": [
        8754,
        8855
      ]
    },
    {
      "pos": [
        8859,
        9152
      ],
      "content": "<ph id=\"ph1\">[AZURE.TIP]</ph> The most comprehensive list of query examples can be found in <bpt id=\"p1\">[</bpt>Search Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798927.aspx)</ept>, but you might also want to review the <bpt id=\"p2\">[</bpt>syntax reference<ept id=\"p2\">](https://msdn.microsoft.com/library/dn798920.aspx)</ept> to review the list of supported operators."
    },
    {
      "content": "Step 5: Explore more features",
      "pos": [
        9158,
        9187
      ]
    },
    {
      "content": "Now that you have a service and index, you can experiment with features to further evolve the search experience.",
      "pos": [
        9189,
        9301
      ]
    },
    {
      "content": "A short list of features to investigate are listed next.",
      "pos": [
        9302,
        9358
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Search pages<ept id=\"p1\">**</ept> often include document counts in a result set, or use pagination to subdivide results into more manageable numbers.",
      "pos": [
        9360,
        9492
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Pagination<ept id=\"p1\">](search-pagination-page-layout.md)</ept> for details.",
      "pos": [
        9493,
        9556
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>searchMode=all<ept id=\"p1\">**</ept> is a query parameter that changes how Azure Search evaluates the NOT operator.",
      "pos": [
        9558,
        9655
      ]
    },
    {
      "content": "By default, queries that include NOT (-) expand rather than narrow the results.",
      "pos": [
        9656,
        9735
      ]
    },
    {
      "content": "You can set this parameter to change how the operator is evaluated.",
      "pos": [
        9736,
        9803
      ]
    },
    {
      "content": "Itâ€™s documented in <bpt id=\"p1\">[</bpt>Search Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798927.aspx)</ept> or <bpt id=\"p2\">[</bpt>SearchMode Enumeration<ept id=\"p2\">](https://msdn.microsoft.com/library/microsoft.azure.search.models.searchmode.aspx)</ept>.",
      "pos": [
        9804,
        10002
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Scoring profiles<ept id=\"p1\">**</ept> are used to boost search scores, causing items that meet predefined criteria to appear higher in the search results.",
      "pos": [
        10004,
        10141
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Get started with scoring profiles<ept id=\"p1\">](search-get-started-scoring-profiles.md)</ept> to step through this feature.",
      "pos": [
        10142,
        10251
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Filters<ept id=\"p1\">**</ept> are used to narrow search results by providing additional criteria on the selection.",
      "pos": [
        10253,
        10349
      ]
    },
    {
      "content": "Filter expressions are placed within the query.",
      "pos": [
        10350,
        10397
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Search Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798927.aspx)</ept> for details.",
      "pos": [
        10398,
        10483
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Faceted navigation<ept id=\"p1\">**</ept> is used for self-directed filtering.",
      "pos": [
        10485,
        10544
      ]
    },
    {
      "content": "Azure Search builds and returns the structure, and your code renders the faceted navigation structure in a search results page.",
      "pos": [
        10545,
        10672
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Faceted Navigation<ept id=\"p1\">](search-faceted-navigation.md)</ept> for details.",
      "pos": [
        10673,
        10740
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Suggesters<ept id=\"p1\">**</ept> refers to type-ahead or auto-complete queries that return suggested search terms as the user types in the first characters of a search phrase.",
      "pos": [
        10742,
        10899
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Suggestions operation<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798936.aspx)</ept> or <bpt id=\"p2\">[</bpt>Suggesters Class<ept id=\"p2\">](https://msdn.microsoft.com/library/microsoft.azure.search.models.suggester.aspx)</ept> for more information.",
      "pos": [
        10900,
        11102
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Language analyzers<ept id=\"p1\">**</ept> provide the linguistic rules used during text analysis.",
      "pos": [
        11104,
        11182
      ]
    },
    {
      "content": "The default language analyzer for Azure Search is Lucene English, but you can use different, or even multiple, analyzers by specifying them in your index.",
      "pos": [
        11183,
        11337
      ]
    },
    {
      "content": "Lucene analyzers are available in all APIs.",
      "pos": [
        11338,
        11381
      ]
    },
    {
      "content": "Microsoft natural language processors are only available in <bpt id=\"p1\">[</bpt>2015-02-28-Preview REST API<ept id=\"p1\">](search-api-2015-02-28-preview.md)</ept>.",
      "pos": [
        11382,
        11506
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Language Support<ept id=\"p1\">](https://msdn.microsoft.com/library/dn879793.aspx)</ept> for more information.",
      "pos": [
        11507,
        11601
      ]
    },
    {
      "content": "Step 6: Update indexes and documents",
      "pos": [
        11607,
        11643
      ]
    },
    {
      "content": "Some of the features that you want to evaluate might require an update to your index, which often has the downstream effect of requiring updates to your documents.",
      "pos": [
        11645,
        11808
      ]
    },
    {
      "content": "If you need to update an index or documents, for example to add suggesters or specify language analyzers on fields that youâ€™ve added for that purpose, see the following links for instructions:",
      "pos": [
        11810,
        12002
      ]
    },
    {
      "content": "Update Index operation (REST API)",
      "pos": [
        12007,
        12040
      ]
    },
    {
      "content": "Update Indexer operation (REST API)",
      "pos": [
        12095,
        12130
      ]
    },
    {
      "content": "Add, update or delete documents operation (REST API)",
      "pos": [
        12185,
        12237
      ]
    },
    {
      "content": "Index Class (.NET library)",
      "pos": [
        12292,
        12318
      ]
    },
    {
      "content": "Documents Class (.NET library)",
      "pos": [
        12400,
        12430
      ]
    },
    {
      "content": "Once you have built a prototype that establishes proof-of-concept, you can take what youâ€™ve learned to the next level by designing a development project that can support production workloads.",
      "pos": [
        12513,
        12704
      ]
    },
    {
      "content": "Application development",
      "pos": [
        12709,
        12732
      ]
    },
    {
      "content": "Advancing to the next phase now requires decisions about which APIs to use, how to manage documents and upload frequency, and whether to include external resources in your search results.",
      "pos": [
        12734,
        12921
      ]
    },
    {
      "content": "Your solution design will still need to include all of the steps described for prototypes, but instead of prioritizing the most expedient path, you will want to consider which approaches are the most compatible with your overall solution.",
      "pos": [
        12923,
        13161
      ]
    },
    {
      "content": "Choose an API",
      "pos": [
        13167,
        13180
      ]
    },
    {
      "content": "Azure Search provides two programming models: the .NET library for managed code, and a REST API for programming languages like Java, JavaScript, or another language that does not target the Microsoft .NET Framework.",
      "pos": [
        13182,
        13397
      ]
    },
    {
      "content": "Currently, a small subset of features are not yet in the .NET library, so even if you prefer to write managed code, you might need to use the REST API to get the features you want.",
      "pos": [
        13399,
        13579
      ]
    },
    {
      "content": "Features that are only available in the REST API include:",
      "pos": [
        13580,
        13637
      ]
    },
    {
      "content": "Microsoft Natural Language processors - preview only",
      "pos": [
        13642,
        13694
      ]
    },
    {
      "content": "moreLikeThis feature - preview only",
      "pos": [
        13734,
        13769
      ]
    },
    {
      "content": "Management API",
      "pos": [
        13809,
        13823
      ]
    },
    {
      "pos": [
        13876,
        13991
      ],
      "content": "You can periodically check the <bpt id=\"p1\">[</bpt>Whatâ€™s New<ept id=\"p1\">](search-latest-updates.md)</ept> article to monitor changes in feature status."
    },
    {
      "content": "Determine data synchronization methods: Push or Pull",
      "pos": [
        13997,
        14049
      ]
    },
    {
      "content": "Push and pull models refer to how documents are updated in the index.",
      "pos": [
        14051,
        14120
      ]
    },
    {
      "content": "Often, the scenario dictates which model is right for you.",
      "pos": [
        14121,
        14179
      ]
    },
    {
      "content": "If your business is online retail, you most likely need a push model so that you can push or double-write any change in inventory to both your OLTP database and your Azure Search index.",
      "pos": [
        14181,
        14366
      ]
    },
    {
      "content": "When a specific SKU is sold out, or a size or color becomes unavailable, you will want the index to be updated as quickly as possible to avoid customer frustration.",
      "pos": [
        14367,
        14531
      ]
    },
    {
      "content": "Only push models can provide near real-time updates to your search index.",
      "pos": [
        14532,
        14605
      ]
    },
    {
      "content": "There is no specific mechanism in Azure Search for implementing a push model.",
      "pos": [
        14607,
        14684
      ]
    },
    {
      "content": "Your application code, at the data layer, must handle the documents update operation using either the <bpt id=\"p1\">[</bpt>REST API<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798935.aspx)</ept> or <bpt id=\"p2\">[</bpt>.NET Library<ept id=\"p2\">](https://msdn.microsoft.com/library/dn951165.aspx)</ept> to update documents in the collection.",
      "pos": [
        14685,
        14954
      ]
    },
    {
      "content": "As an implementation detail, using a product SKU for the document key can help with this task.",
      "pos": [
        14955,
        15049
      ]
    },
    {
      "content": "Pull models are usually scheduled operations that retrieve data from external data sources.",
      "pos": [
        15051,
        15142
      ]
    },
    {
      "content": "In Azure Search, a pull model is available through <bpt id=\"p1\">[</bpt>Indexers<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn946891.aspx)</ept>, which are in turn available for specific data sources: Azure DocumentDB or Azure SQL Database (and also SQL Server on Azure VMs).",
      "pos": [
        15143,
        15391
      ]
    },
    {
      "content": "Loading documents in batches",
      "pos": [
        15397,
        15425
      ]
    },
    {
      "content": "We recommend adding documents in batches to improve throughput.",
      "pos": [
        15427,
        15490
      ]
    },
    {
      "content": "You can batch up to 1,000 documents, assuming an average document size of about 1 to 2 KB.",
      "pos": [
        15491,
        15581
      ]
    },
    {
      "content": "There is an overall status code for the POST request.",
      "pos": [
        15583,
        15636
      ]
    },
    {
      "content": "Status codes are either HTTP 200 (Success) or HTTP 207 (Multi-Status) if there is combination of successful and failed documents.",
      "pos": [
        15637,
        15766
      ]
    },
    {
      "content": "In addition to the status code for the POST request, Azure Search maintains a status field for each document.",
      "pos": [
        15767,
        15876
      ]
    },
    {
      "content": "Given a batch upload, you need a way to get per-document status that indicates whether the insert succeeded or failed for each document.",
      "pos": [
        15877,
        16013
      ]
    },
    {
      "content": "The status field provides that information.",
      "pos": [
        16014,
        16057
      ]
    },
    {
      "content": "It will be set to false if the document failed to load.",
      "pos": [
        16058,
        16113
      ]
    },
    {
      "content": "Under heavy load, it's not uncommon to have some upload failures.",
      "pos": [
        16115,
        16180
      ]
    },
    {
      "content": "Should this occur, the overall status code is 207, indicating a partial success, and the documents that failed indexing will have the 'status' property set to false.",
      "pos": [
        16181,
        16346
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>  When the service receives documents, they are queued up for indexing and may not be immediately included in search results.",
      "pos": [
        16350,
        16487
      ]
    },
    {
      "content": "When not under a heavy load, documents are typically indexed within a few seconds.",
      "pos": [
        16488,
        16570
      ]
    },
    {
      "content": "When updating an index, you can combine multiple actions (insert, merge, delete) into the same batch, eliminating the need for multiple round trips.",
      "pos": [
        16572,
        16720
      ]
    },
    {
      "content": "Currently Azure Search does not support partial updates (HTTP PATCH), so if you need to update an index, you must resend the index definition.",
      "pos": [
        16721,
        16863
      ]
    },
    {
      "content": "Integrating external data into search results",
      "pos": [
        16869,
        16914
      ]
    },
    {
      "content": "Azure Search uses internal storage for the indexes and documents used in search operations.",
      "pos": [
        16916,
        17007
      ]
    },
    {
      "content": "Text analysis and index parsing is dependent on having all searchable fields and associated attributes readily available.",
      "pos": [
        17008,
        17129
      ]
    },
    {
      "content": "However, not all fields in a document will be searchable.",
      "pos": [
        17131,
        17188
      ]
    },
    {
      "content": "For example, if your application is an online catalog for music or videos, we recommend storing binary files in the Azure Blob service or some other storage format.",
      "pos": [
        17189,
        17353
      ]
    },
    {
      "content": "The binary files themselves are not searchable, hence there is no need to persist them in Azure Search storage.",
      "pos": [
        17354,
        17465
      ]
    },
    {
      "content": "Although you should store images, videos, and audio files in other services or locations, you should include a field that references the URL to the file location.",
      "pos": [
        17466,
        17628
      ]
    },
    {
      "content": "This way, you can return the external data as part of your search results.",
      "pos": [
        17629,
        17703
      ]
    },
    {
      "content": "To use external data, you should define a field in your index that stores a URL pointer to the external data file.",
      "pos": [
        17705,
        17819
      ]
    },
    {
      "content": "If you issue a <bpt id=\"p1\">[</bpt>Lookup Documents<ept id=\"p1\">](https://msdn.microsoft.com/library/dn798929.aspx)</ept> request, or include the field in search results, the binary file appears in the context of a document.",
      "pos": [
        17820,
        18006
      ]
    },
    {
      "content": "Capacity planning",
      "pos": [
        18012,
        18029
      ]
    },
    {
      "content": "One of the more compelling feature in Azure Search is the ease with which you can scale up or scale down resources in response to demand.",
      "pos": [
        18031,
        18168
      ]
    },
    {
      "content": "While this capability doesnâ€™t eliminate the need for capacity planning, it does minimize most of the risk.",
      "pos": [
        18169,
        18275
      ]
    },
    {
      "content": "Youâ€™re not stuck with extra hardware, or the wrong hardware, for running your search workloads.",
      "pos": [
        18276,
        18371
      ]
    },
    {
      "content": "As a last step, review the existing resource levels for both replicas and partitions, and determine whether adjustments are needed.",
      "pos": [
        18373,
        18504
      ]
    },
    {
      "content": "The easiest way to adjust capacity is in the <bpt id=\"p1\">[</bpt>Azure portal<ept id=\"p1\">](https://ms.portal.azure.com/)</ept>.",
      "pos": [
        18505,
        18595
      ]
    },
    {
      "content": "Remember that only the standard pricing tier can be scaled up or down.",
      "pos": [
        18597,
        18667
      ]
    },
    {
      "content": "Additionally, depending on the degree of adjustment, it can take anywhere from several minutes to several hours to deploy additional clusters for your service.",
      "pos": [
        18668,
        18827
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Capacity can be adjusted programmatically by using the Management REST API.",
      "pos": [
        18831,
        18919
      ]
    },
    {
      "content": "For more information, see <bpt id=\"p1\">[</bpt>Management REST API<ept id=\"p1\">](https://msdn.microsoft.com/library/azure/dn832684.aspx)</ept>.",
      "pos": [
        18920,
        19024
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Typical workflow for Azure Search development | Microsoft Azure\"\n    description=\"A workflow or roadmap for building prototype and production applications that integrate with Azure Search.\"\n    services=\"search\"\n    documentationCenter=\"\"\n    authors=\"HeidiSteen\"\n    manager=\"mblythe\"\n    editor=\"\"/>\n\n<tags\n    ms.service=\"search\"\n    ms.devlang=\"rest-api\"\n    ms.workload=\"search\"\n    ms.topic=\"get-started-article\"\n    ms.tgt_pltfrm=\"na\"\n    ms.date=\"07/08/2015\"\n    ms.author=\"heidist\"/>\n\n# Typical workflow for Azure Search development\n\nThis article is a roadmap for including Azure Search as a component that provides the search experience in your custom application. Depending on whether you are testing the waters or ready to dive right in, youâ€™ll want some preliminary guidance on how to integrate Azure Search into your custom development project.\n\nIn the following sections, we break out a typical workflow for an initial prototype that will help you evaluate how well Azure Search meets the search requirements of your application. Part two of this article covers important design decisions that factor into a more serious application development effort.\n\nBefore you start prototyping, we recommend that you ramp up with one of our Getting Started tutorials or this [one-hour deep dive presentation video](http://azure.microsoft.com/documentation/videos/tech-ed-europe-2014-azure-search-deep-dive/). Get Started tutorials are offered in these languages: [.NET](search-get-started-dotnet.md), [Java](search-get-started-java.md), [Node.JS](search-get-started-nodejs.md).\n\n## Prototype development\n\nThe quickest path to a successful prototype typically includes the steps in this section. Steps include provisioning a service, define a schema for your index, load the index with documents, and query the index.\n\nFor applications with volatile data (for example, if the common case includes rapid changes to inventory or content), your prototype should include a component for updating documents as well.\n\n   ![][1]\n\n### Step 1: Provision the service\n\nAzure Search is a fully-managed online service available through an Azure subscription. [Once you sign up for Azure](http://azure.microsoft.com/pricing/free-trial/), adding the Search service is quick. Visit [Create a Search service in the portal](search-create-service-portal.md) for instructions on how to add a Search service to your subscription.\n\nThere are two pricing tiers to choose from. We recommend the shared (free) service for prototyping, with the caveat that you will need to work with a small subset of your data. The shared service is free to existing subscribers (through trial or regular memberships) and is fast to set up, but it constrains the number of indexes and documents you can use to 3 indexes, up to 10,000 documents per index, or 50 MB of storage total, whichever comes first.\n\n### Step 2: Create the index\n\nAfter you create the service, you are ready to create an index, starting with its schema definition.\n\nThe fastest and easiest way to create an index is through the Azure portal. At a minimum, each document must have a unique key and at least one field that contains searchable data. To get started, see [Create an index in the portal](search-create-index-portal.md).\n\n> [AZURE.NOTE] Inside an Azure Search Index\n>\n> An *index* is organized, persisted data that serves as the *search corpus* for all subsequent search operations. Your search corpus is stored in the cloud as part of your Search service subscription, which enables search operations to execute quickly and consistently. In search terminology, an item in your search corpus is called a *document*, and the sum total of all documents is the *documents collection*.\n>\n>An *index schema* defines all of the fields within a document by name, data type, and attributes that specify whether the field is searchable, filterable, facetable, and so forth.\n>\n> Besides document structure, an index schema also specifies scoring profiles that provide criteria for boosting a search score, and configuration settings that enable auto-complete queries (suggesters) and CORS for cross-domain query requests. *For prototypes, we recommend that you start out simply by specifying just the fields in a document*, and then add other features incrementally (see Step 5 for a list of additional functionality to add later).  \n>\n> Applied to a real-world example, consider an e-commerce application. The search index would contain all of the products or services that are searchable in your application (anything that comes back in a search results). There would be one document for each SKU. Each document would include the product name, brand, sizes, price, colors, and even references to images or other resource files that you want returned within search results.\n\n### Step 3: Load documents\n\nAfter saving the index in Azure Search, the next step is to populate the index with documents. In this step, data is uploaded, analyzed, tokenized, and stored in data structures (such as inverted indexes) that are designed for search workloads.\n\nData that you upload to an index must conform to the schema you defined in the previous step. Document data is represented as a set of key/value pairs for each field, in JSON format. If your schema specifies an ID (key) field, a name field, a number field, and a URL field (which you might do if external images are part of your search results), then all the documents you feed into the index must have values (or null) for each field.\n\nThere are several ways to load documents, but right now, all of them require an API. For most prototypes, this step might be the most time consuming due to a coding requirement. Options are described later in this article.\n\n> [AZURE.NOTE] Remember that the shared service limits you to 10,000 documents per index. Be sure to reduce your dataset so that it stays under the limits. See [Limits and constraints](https://msdn.microsoft.com/library/dn798934.aspx) for more information.\n\n#### How to load data into an index\n\nOne approach is to use an indexer. For Azure DocumentDB or SQL Server relational data sources in Azure (specifically Azure SQL Database, or SQL Server in an Azure VM), you can use [indexers](https://msdn.microsoft.com/library/dn946891.aspx) to retrieve documents from a supported data source. Code samples that use indexers for loading documents can be found in any of these getting started tutorials: [.NET](search-get-started-dotnet.md), [Java](search-get-started-java.md), [Node.JS](search-get-started-nodejs.md).\n\nA second option is to write a simple program using either the REST API or the .NET library that loads the documents:\n\n- [Add, update, or delete documents (REST API)](https://msdn.microsoft.com/library/dn798930.aspx)\n- [DocumentOperationsExtensions Class](https://msdn.microsoft.com/library/microsoft.azure.search.documentoperationsextensions.aspx)\n\nA third option that works for very small datasets is to use [Fiddler](search-fiddler.md) or [Chrome Postman](search-chrome-postman.md) to upload documents.\n\nA fourth option, perhaps the easiest one, is to borrow code from either the [Adventure Works C# REST API Example](https://azuresearchadventureworksdemo.codeplex.com/) that loads documents from an embedded database (.mdf) in the solution, or [Scoring Profiles C# REST API Example](https://azuresearchscoringprofiles.codeplex.com/) that loads data from JSON data files included in the solution.\n\n> [AZURE.TIP] You could modify and run the [scoring profiles sample](https://azuresearchscoringprofiles.codeplex.com/), replacing the data JSON files and schema.json file with data that is valid for your application.\n\n### Step 4: Query documents\n\nOnce documents are loaded into the index, you can write your first query.\n\nThe fastest way to get initial search results back from your Search service is to use [Fiddler](search-fiddler.md) or [Chrome Postman](search-chrome-postman.md) to view a response, but realistically, you will want to write some simple UI code to view the results in a readable format.\n\nAPIs for search operations include:\n\n- [Search Documents operation](https://msdn.microsoft.com/library/dn798927.aspx)\n- [SearchIndexClient Class](https://msdn.microsoft.com/library/microsoft.azure.search.searchindexclient.aspx)\n\nQueries in Azure Search can be very simple. Including `search=*` on the URI will return the first 50 items in your search corpus; specifying `search=<some phrase>` will perform a full-text search on the phrase, returning up to 50 documents, assuming there are at least 50 documents that contain a match on the term input.\n\n50 documents is the default. You can change the number of items returned using the `$Count` query parameter. This parameter is documented in [Search Documents](https://msdn.microsoft.com/library/dn798927.aspx).\n\n> [AZURE.TIP] The most comprehensive list of query examples can be found in [Search Documents](https://msdn.microsoft.com/library/dn798927.aspx), but you might also want to review the [syntax reference](https://msdn.microsoft.com/library/dn798920.aspx) to review the list of supported operators.\n\n### Step 5: Explore more features\n\nNow that you have a service and index, you can experiment with features to further evolve the search experience. A short list of features to investigate are listed next.\n\n**Search pages** often include document counts in a result set, or use pagination to subdivide results into more manageable numbers. See [Pagination](search-pagination-page-layout.md) for details.\n\n**searchMode=all** is a query parameter that changes how Azure Search evaluates the NOT operator. By default, queries that include NOT (-) expand rather than narrow the results. You can set this parameter to change how the operator is evaluated. Itâ€™s documented in [Search Documents](https://msdn.microsoft.com/library/dn798927.aspx) or [SearchMode Enumeration](https://msdn.microsoft.com/library/microsoft.azure.search.models.searchmode.aspx).\n\n**Scoring profiles** are used to boost search scores, causing items that meet predefined criteria to appear higher in the search results. See [Get started with scoring profiles](search-get-started-scoring-profiles.md) to step through this feature.\n\n**Filters** are used to narrow search results by providing additional criteria on the selection. Filter expressions are placed within the query. See [Search Documents](https://msdn.microsoft.com/library/dn798927.aspx) for details.\n\n**Faceted navigation** is used for self-directed filtering. Azure Search builds and returns the structure, and your code renders the faceted navigation structure in a search results page. See [Faceted Navigation](search-faceted-navigation.md) for details.\n\n**Suggesters** refers to type-ahead or auto-complete queries that return suggested search terms as the user types in the first characters of a search phrase. See [Suggestions operation](https://msdn.microsoft.com/library/dn798936.aspx) or [Suggesters Class](https://msdn.microsoft.com/library/microsoft.azure.search.models.suggester.aspx) for more information.\n\n**Language analyzers** provide the linguistic rules used during text analysis. The default language analyzer for Azure Search is Lucene English, but you can use different, or even multiple, analyzers by specifying them in your index. Lucene analyzers are available in all APIs. Microsoft natural language processors are only available in [2015-02-28-Preview REST API](search-api-2015-02-28-preview.md). See [Language Support](https://msdn.microsoft.com/library/dn879793.aspx) for more information.\n\n### Step 6: Update indexes and documents\n\nSome of the features that you want to evaluate might require an update to your index, which often has the downstream effect of requiring updates to your documents.\n\nIf you need to update an index or documents, for example to add suggesters or specify language analyzers on fields that youâ€™ve added for that purpose, see the following links for instructions:\n\n- [Update Index operation (REST API)](https://msdn.microsoft.com/library/dn800964.aspx)\n- [Update Indexer operation (REST API)](https://msdn.microsoft.com/library/dn946892.aspx)\n- [Add, update or delete documents operation (REST API)](https://msdn.microsoft.com/library/dn798930.aspx)\n- [Index Class (.NET library)](https://msdn.microsoft.com/library/microsoft.azure.search.models.index.aspx)\n- [Documents Class (.NET library)](https://msdn.microsoft.com/library/microsoft.azure.search.models.document.aspx)\n\nOnce you have built a prototype that establishes proof-of-concept, you can take what youâ€™ve learned to the next level by designing a development project that can support production workloads.\n\n## Application development\n\nAdvancing to the next phase now requires decisions about which APIs to use, how to manage documents and upload frequency, and whether to include external resources in your search results.\n\nYour solution design will still need to include all of the steps described for prototypes, but instead of prioritizing the most expedient path, you will want to consider which approaches are the most compatible with your overall solution.\n\n### Choose an API\n\nAzure Search provides two programming models: the .NET library for managed code, and a REST API for programming languages like Java, JavaScript, or another language that does not target the Microsoft .NET Framework.\n\nCurrently, a small subset of features are not yet in the .NET library, so even if you prefer to write managed code, you might need to use the REST API to get the features you want. Features that are only available in the REST API include:\n\n- [Microsoft Natural Language processors - preview only](../search-api-2015-02-28-preview/)\n- [moreLikeThis feature - preview only](../search-api-2015-02-28-preview/)\n- [Management API](https://msdn.microsoft.com/library/dn832684.aspx)\n\nYou can periodically check the [Whatâ€™s New](search-latest-updates.md) article to monitor changes in feature status.\n\n### Determine data synchronization methods: Push or Pull\n\nPush and pull models refer to how documents are updated in the index. Often, the scenario dictates which model is right for you.\n\nIf your business is online retail, you most likely need a push model so that you can push or double-write any change in inventory to both your OLTP database and your Azure Search index. When a specific SKU is sold out, or a size or color becomes unavailable, you will want the index to be updated as quickly as possible to avoid customer frustration. Only push models can provide near real-time updates to your search index.\n\nThere is no specific mechanism in Azure Search for implementing a push model. Your application code, at the data layer, must handle the documents update operation using either the [REST API](https://msdn.microsoft.com/library/dn798935.aspx) or [.NET Library](https://msdn.microsoft.com/library/dn951165.aspx) to update documents in the collection. As an implementation detail, using a product SKU for the document key can help with this task.\n\nPull models are usually scheduled operations that retrieve data from external data sources. In Azure Search, a pull model is available through [Indexers](https://msdn.microsoft.com/library/azure/dn946891.aspx), which are in turn available for specific data sources: Azure DocumentDB or Azure SQL Database (and also SQL Server on Azure VMs).\n\n### Loading documents in batches\n\nWe recommend adding documents in batches to improve throughput. You can batch up to 1,000 documents, assuming an average document size of about 1 to 2 KB.\n\nThere is an overall status code for the POST request. Status codes are either HTTP 200 (Success) or HTTP 207 (Multi-Status) if there is combination of successful and failed documents. In addition to the status code for the POST request, Azure Search maintains a status field for each document. Given a batch upload, you need a way to get per-document status that indicates whether the insert succeeded or failed for each document. The status field provides that information. It will be set to false if the document failed to load.\n\nUnder heavy load, it's not uncommon to have some upload failures. Should this occur, the overall status code is 207, indicating a partial success, and the documents that failed indexing will have the 'status' property set to false.\n\n> [AZURE.NOTE]  When the service receives documents, they are queued up for indexing and may not be immediately included in search results. When not under a heavy load, documents are typically indexed within a few seconds.\n\nWhen updating an index, you can combine multiple actions (insert, merge, delete) into the same batch, eliminating the need for multiple round trips. Currently Azure Search does not support partial updates (HTTP PATCH), so if you need to update an index, you must resend the index definition.\n\n### Integrating external data into search results\n\nAzure Search uses internal storage for the indexes and documents used in search operations. Text analysis and index parsing is dependent on having all searchable fields and associated attributes readily available.\n\nHowever, not all fields in a document will be searchable. For example, if your application is an online catalog for music or videos, we recommend storing binary files in the Azure Blob service or some other storage format. The binary files themselves are not searchable, hence there is no need to persist them in Azure Search storage. Although you should store images, videos, and audio files in other services or locations, you should include a field that references the URL to the file location. This way, you can return the external data as part of your search results.\n\nTo use external data, you should define a field in your index that stores a URL pointer to the external data file. If you issue a [Lookup Documents](https://msdn.microsoft.com/library/dn798929.aspx) request, or include the field in search results, the binary file appears in the context of a document.\n\n### Capacity planning\n\nOne of the more compelling feature in Azure Search is the ease with which you can scale up or scale down resources in response to demand. While this capability doesnâ€™t eliminate the need for capacity planning, it does minimize most of the risk. Youâ€™re not stuck with extra hardware, or the wrong hardware, for running your search workloads.\n\nAs a last step, review the existing resource levels for both replicas and partitions, and determine whether adjustments are needed. The easiest way to adjust capacity is in the [Azure portal](https://ms.portal.azure.com/).\n\nRemember that only the standard pricing tier can be scaled up or down. Additionally, depending on the degree of adjustment, it can take anywhere from several minutes to several hours to deploy additional clusters for your service.\n\n> [AZURE.NOTE] Capacity can be adjusted programmatically by using the Management REST API. For more information, see [Management REST API](https://msdn.microsoft.com/library/azure/dn832684.aspx).\n\n\n<!--Image references-->\n[1]: ./media/search-workflow/AzSearch-Workflow.png\n"
}