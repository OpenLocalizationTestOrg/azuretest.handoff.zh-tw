{
  "nodes": [
    {
      "content": "Table design in SQL Data Warehouse | Microsoft Azure",
      "pos": [
        26,
        78
      ]
    },
    {
      "content": "Tips for designing tables in Azure SQL Data Warehouse for developing solutions.",
      "pos": [
        96,
        175
      ]
    },
    {
      "content": "Table design in SQL Data Warehouse",
      "pos": [
        513,
        547
      ]
    },
    {
      "content": "SQL Data Warehouse is a massively parallel processing (MPP) distributed database system.",
      "pos": [
        550,
        638
      ]
    },
    {
      "content": "Consequently, it stores data across many different locations known as <bpt id=\"p1\">**</bpt>distributions<ept id=\"p1\">**</ept>.",
      "pos": [
        639,
        727
      ]
    },
    {
      "content": "Each <bpt id=\"p1\">**</bpt>distribution<ept id=\"p1\">**</ept> is like a bucket; storing a unique subset of the data in the data warehouse.",
      "pos": [
        728,
        826
      ]
    },
    {
      "content": "By spreading the data and processing capability across multiple nodes SQL Data Warehouse is able to offer huge scalability - far beyond any single system.",
      "pos": [
        827,
        981
      ]
    },
    {
      "content": "When a table is created in SQL Data Warehouse, it is actually spread across all of the the distributions.",
      "pos": [
        983,
        1088
      ]
    },
    {
      "content": "This article will cover the following topics:",
      "pos": [
        1090,
        1135
      ]
    },
    {
      "content": "Supported data types",
      "pos": [
        1139,
        1159
      ]
    },
    {
      "content": "Principles of data distribution",
      "pos": [
        1162,
        1193
      ]
    },
    {
      "content": "Round Robin Distribution",
      "pos": [
        1196,
        1220
      ]
    },
    {
      "content": "Hash Distribution",
      "pos": [
        1223,
        1240
      ]
    },
    {
      "content": "Table Partitioning",
      "pos": [
        1243,
        1261
      ]
    },
    {
      "content": "Statistics",
      "pos": [
        1264,
        1274
      ]
    },
    {
      "content": "Unsupported features",
      "pos": [
        1277,
        1297
      ]
    },
    {
      "content": "Supported data types",
      "pos": [
        1302,
        1322
      ]
    },
    {
      "content": "SQL Data Warehouse supports the common business data types:",
      "pos": [
        1323,
        1382
      ]
    },
    {
      "content": "bigint",
      "pos": [
        1388,
        1394
      ]
    },
    {
      "content": "binary",
      "pos": [
        1401,
        1407
      ]
    },
    {
      "content": "bit",
      "pos": [
        1414,
        1417
      ]
    },
    {
      "content": "char",
      "pos": [
        1424,
        1428
      ]
    },
    {
      "content": "date",
      "pos": [
        1435,
        1439
      ]
    },
    {
      "content": "datetime",
      "pos": [
        1446,
        1454
      ]
    },
    {
      "content": "datetime2",
      "pos": [
        1461,
        1470
      ]
    },
    {
      "content": "datetimeoffset",
      "pos": [
        1477,
        1491
      ]
    },
    {
      "content": "decimal",
      "pos": [
        1498,
        1505
      ]
    },
    {
      "content": "float",
      "pos": [
        1512,
        1517
      ]
    },
    {
      "content": "int",
      "pos": [
        1524,
        1527
      ]
    },
    {
      "content": "money",
      "pos": [
        1534,
        1539
      ]
    },
    {
      "content": "nchar",
      "pos": [
        1546,
        1551
      ]
    },
    {
      "content": "nvarchar",
      "pos": [
        1558,
        1566
      ]
    },
    {
      "content": "real",
      "pos": [
        1573,
        1577
      ]
    },
    {
      "content": "smalldatetime",
      "pos": [
        1584,
        1597
      ]
    },
    {
      "content": "smallint",
      "pos": [
        1604,
        1612
      ]
    },
    {
      "content": "smallmoney",
      "pos": [
        1619,
        1629
      ]
    },
    {
      "content": "time",
      "pos": [
        1636,
        1640
      ]
    },
    {
      "content": "tinyint",
      "pos": [
        1647,
        1654
      ]
    },
    {
      "content": "varbinary",
      "pos": [
        1661,
        1670
      ]
    },
    {
      "content": "varchar",
      "pos": [
        1677,
        1684
      ]
    },
    {
      "content": "You can identify columns in your data warehouse that contain incompatible types using the following query:",
      "pos": [
        1688,
        1794
      ]
    },
    {
      "content": "The query includes any user defined data types which are also not supported.",
      "pos": [
        2598,
        2674
      ]
    },
    {
      "content": "If you have unsupported types in your database do not worry.",
      "pos": [
        2676,
        2736
      ]
    },
    {
      "content": "Some alternatives you can use instead are proposed below.",
      "pos": [
        2737,
        2794
      ]
    },
    {
      "content": "Instead of:",
      "pos": [
        2796,
        2807
      ]
    },
    {
      "pos": [
        2811,
        2845
      ],
      "content": "<bpt id=\"p1\">**</bpt>geometry<ept id=\"p1\">**</ept>, use a varbinary type"
    },
    {
      "pos": [
        2848,
        2883
      ],
      "content": "<bpt id=\"p1\">**</bpt>geography<ept id=\"p1\">**</ept>, use a varbinary type"
    },
    {
      "pos": [
        2886,
        2922
      ],
      "content": "<bpt id=\"p1\">**</bpt>hierarchyid<ept id=\"p1\">**</ept>, CLR type not native"
    },
    {
      "pos": [
        2925,
        3013
      ],
      "content": "<bpt id=\"p1\">**</bpt>image<ept id=\"p1\">**</ept>, <bpt id=\"p2\">**</bpt>text<ept id=\"p2\">**</ept>, <bpt id=\"p3\">**</bpt>ntext<ept id=\"p3\">**</ept> when text based use varchar/nvarchar (smaller the better)"
    },
    {
      "pos": [
        3016,
        3086
      ],
      "content": "<bpt id=\"p1\">**</bpt>nvarchar(max)<ept id=\"p1\">**</ept>, use varchar(4000) or smaller for better performance"
    },
    {
      "pos": [
        3089,
        3113
      ],
      "content": "<bpt id=\"p1\">**</bpt>numeric<ept id=\"p1\">**</ept>, use decimal"
    },
    {
      "pos": [
        3116,
        3181
      ],
      "content": "<bpt id=\"p1\">**</bpt>sql_variant<ept id=\"p1\">**</ept>, split column into several strongly typed columns"
    },
    {
      "pos": [
        3184,
        3214
      ],
      "content": "<bpt id=\"p1\">**</bpt>sysname<ept id=\"p1\">**</ept>, use nvarchar(128)"
    },
    {
      "pos": [
        3217,
        3255
      ],
      "content": "<bpt id=\"p1\">**</bpt>table<ept id=\"p1\">**</ept>, convert to temporary tables"
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>timestamp<ept id=\"p1\">**</ept>, re-work code to use datetime2 and <ph id=\"ph1\">`CURRENT_TIMESTAMP`</ph> function.",
      "pos": [
        3258,
        3336
      ]
    },
    {
      "content": "Note you cannot have current_timestamp as a default constraint and the value will not automatically update.",
      "pos": [
        3337,
        3444
      ]
    },
    {
      "content": "If you need to migrate rowversion values from a timestamp typed column then use BINARY(8) or VARBINARY(8) for NOT NULL or NULL row version values.",
      "pos": [
        3445,
        3591
      ]
    },
    {
      "pos": [
        3594,
        3663
      ],
      "content": "<bpt id=\"p1\">**</bpt>varchar(max)<ept id=\"p1\">**</ept>, use varchar(8000) or smaller for better performance"
    },
    {
      "pos": [
        3666,
        3704
      ],
      "content": "<bpt id=\"p1\">**</bpt>uniqueidentifier<ept id=\"p1\">**</ept>, use varbinary(8)"
    },
    {
      "pos": [
        3707,
        3780
      ],
      "content": "<bpt id=\"p1\">**</bpt>user defined types<ept id=\"p1\">**</ept>, convert back to their native types where possible"
    },
    {
      "pos": [
        3783,
        3878
      ],
      "content": "<bpt id=\"p1\">**</bpt>xml<ept id=\"p1\">**</ept>, use a varchar(8000) or smaller for better performance - split across columns if needed"
    },
    {
      "content": "Partial support:",
      "pos": [
        3880,
        3896
      ]
    },
    {
      "content": "Default constraints support literals and constants only.",
      "pos": [
        3900,
        3956
      ]
    },
    {
      "content": "Non-deterministic expressions or functions, such as <ph id=\"ph1\">`GETDATE()`</ph> or <ph id=\"ph2\">`CURRENT_TIMESTAMP`</ph>, are not supported.",
      "pos": [
        3957,
        4063
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Define your tables so that the maximum possible row size, including the full length of variable length columns, does not exceed 32,767 bytes.",
      "pos": [
        4067,
        4221
      ]
    },
    {
      "content": "While you can define a row with variable length data that can exceed this figure, you will not be be able to insert data into the table.",
      "pos": [
        4222,
        4358
      ]
    },
    {
      "content": "Also, try to limit the size of your variable length columns for even better throughput for running queries.",
      "pos": [
        4359,
        4466
      ]
    },
    {
      "content": "Principles of data distribution",
      "pos": [
        4471,
        4502
      ]
    },
    {
      "content": "There are two choices for distributing data in SQL Data Warehouse:",
      "pos": [
        4504,
        4570
      ]
    },
    {
      "content": "Distribute data based on hashing values from a single column",
      "pos": [
        4575,
        4635
      ]
    },
    {
      "content": "Distribute data evenly but randomly",
      "pos": [
        4639,
        4674
      ]
    },
    {
      "content": "Data distribution is decided at the table level.",
      "pos": [
        4678,
        4726
      ]
    },
    {
      "content": "All tables are distributed so you will have the opportunity to make this decision for each table in your SQL Data Warehouse database.",
      "pos": [
        4727,
        4860
      ]
    },
    {
      "content": "The first option is known as <bpt id=\"p1\">**</bpt>round-robin<ept id=\"p1\">**</ept> distribution - sometimes known as the random hash.",
      "pos": [
        4862,
        4957
      ]
    },
    {
      "content": "You can think of this as the default or fail safe option.",
      "pos": [
        4958,
        5015
      ]
    },
    {
      "content": "The second option is known as the <bpt id=\"p1\">**</bpt>hash<ept id=\"p1\">**</ept> distribution.",
      "pos": [
        5017,
        5073
      ]
    },
    {
      "content": "You can consider it an optimized form of data distribution.",
      "pos": [
        5074,
        5133
      ]
    },
    {
      "content": "It is preferred where clusters of tables share common joining and/or aggregation criteria.",
      "pos": [
        5134,
        5224
      ]
    },
    {
      "content": "Round-robin distribution",
      "pos": [
        5229,
        5253
      ]
    },
    {
      "content": "Round-Robin distribution is a method of spreading data as evenly as possible across all distributions.",
      "pos": [
        5255,
        5357
      ]
    },
    {
      "content": "Buffers containing rows of data are allocated in turn (hence the name round robin) to each distribution.",
      "pos": [
        5358,
        5462
      ]
    },
    {
      "content": "The process is repeated until all data buffers have been allocated.",
      "pos": [
        5463,
        5530
      ]
    },
    {
      "content": "At no stage is the data sorted or ordered in a round robin distributed table.",
      "pos": [
        5531,
        5608
      ]
    },
    {
      "content": "A round robin distribution is sometimes called a random hash for this reason.",
      "pos": [
        5609,
        5686
      ]
    },
    {
      "content": "The data is simply spread as evenly as possible across the distributions.",
      "pos": [
        5687,
        5760
      ]
    },
    {
      "content": "Below is an example of round robin distributed table:",
      "pos": [
        5762,
        5815
      ]
    },
    {
      "content": "This is also an example of a round robin distributed table:",
      "pos": [
        6339,
        6398
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Notice that the second example above makes no mention of the distribution key.",
      "pos": [
        6893,
        6984
      ]
    },
    {
      "content": "Round Robin is the default and so it is not absolutely required.",
      "pos": [
        6985,
        7049
      ]
    },
    {
      "content": "Being explicit however, is considered to be a good practice as ensures that your peers are aware of your intentions when reviewing the table design.",
      "pos": [
        7050,
        7198
      ]
    },
    {
      "content": "This table type is commonly used when there is no obvious key column to hash the data by.",
      "pos": [
        7200,
        7289
      ]
    },
    {
      "content": "It can also be used by smaller or less significant tables where the movement cost may not be so great.",
      "pos": [
        7290,
        7392
      ]
    },
    {
      "content": "Loading data into a round robin distributed table tends to be faster than loading into a hash distributed table.",
      "pos": [
        7394,
        7506
      ]
    },
    {
      "content": "With a round-robin distributed table there is no need to understand the data or perform the hash prior to loading.",
      "pos": [
        7507,
        7621
      ]
    },
    {
      "content": "For this reason Round-Robin tables often make good good loading targets.",
      "pos": [
        7622,
        7694
      ]
    },
    {
      "pos": [
        7698,
        7812
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> When data is round robin distributed the data is allocated to the distribution at the <bpt id=\"p1\">*</bpt>buffer<ept id=\"p1\">*</ept> level."
    },
    {
      "content": "Recommendations",
      "pos": [
        7818,
        7833
      ]
    },
    {
      "content": "Consider using Round Robin distribution for your table in the following scenarios:",
      "pos": [
        7835,
        7917
      ]
    },
    {
      "content": "When there is no obvious joining key",
      "pos": [
        7921,
        7957
      ]
    },
    {
      "content": "If a candidate hash distribution key is not known",
      "pos": [
        7960,
        8009
      ]
    },
    {
      "content": "If the table does not share a common joining key with other tables",
      "pos": [
        8012,
        8078
      ]
    },
    {
      "content": "If the join is less significant than other joins in the query",
      "pos": [
        8081,
        8142
      ]
    },
    {
      "content": "When the table is an initial loading table",
      "pos": [
        8145,
        8187
      ]
    },
    {
      "content": "Hash distribution",
      "pos": [
        8192,
        8209
      ]
    },
    {
      "content": "Hash distribution uses an internal function to spread a dataset across the distributions by hashing a single column.",
      "pos": [
        8211,
        8327
      ]
    },
    {
      "content": "When data is hashed there is no explicit order to the data being allocated to a distribution.",
      "pos": [
        8328,
        8421
      ]
    },
    {
      "content": "However, the hash itself is a deterministic process.",
      "pos": [
        8422,
        8474
      ]
    },
    {
      "content": "This makes the results of the hash predictable.",
      "pos": [
        8475,
        8522
      ]
    },
    {
      "content": "For example, hashing an integer column containing the value 10 will always yield the same hash value.",
      "pos": [
        8523,
        8624
      ]
    },
    {
      "content": "This means that <bpt id=\"p1\">***</bpt>any<ept id=\"p1\">***</ept> hashed integer column  containing the value 10 would end up being allocated to the same distribution.",
      "pos": [
        8625,
        8752
      ]
    },
    {
      "content": "This is true even across tables.",
      "pos": [
        8753,
        8785
      ]
    },
    {
      "content": "The predictability of the hash is extremely important.",
      "pos": [
        8787,
        8841
      ]
    },
    {
      "content": "It means that hash distributing the data can lead to performance improvements when reading data and joining tables together.",
      "pos": [
        8842,
        8966
      ]
    },
    {
      "content": "As you will see below, hash distribution can be very effective for query optimization.",
      "pos": [
        8968,
        9054
      ]
    },
    {
      "content": "This is why it is considered to be an optimized form of data distribution.",
      "pos": [
        9055,
        9129
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Remember!",
      "pos": [
        9133,
        9155
      ]
    },
    {
      "content": "The hash is not based on the value of the data but rather on the type of the data being hashed.",
      "pos": [
        9156,
        9251
      ]
    },
    {
      "content": "Below is a table that has been hash distributed by ProductKey.",
      "pos": [
        9253,
        9315
      ]
    },
    {
      "pos": [
        9848,
        9950
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> When data is hash distributed the data is allocated to the distribution at the row level."
    },
    {
      "content": "Table partitions",
      "pos": [
        9955,
        9971
      ]
    },
    {
      "content": "Table partitions are supported and easy to define.",
      "pos": [
        9972,
        10022
      ]
    },
    {
      "pos": [
        10024,
        10086
      ],
      "content": "Example SQL Data Warehouse partitioned <ph id=\"ph1\">`CREATE TABLE`</ph> command:"
    },
    {
      "content": "Notice that there is no partitioning function or scheme in the definition.",
      "pos": [
        10813,
        10887
      ]
    },
    {
      "content": "All that is taken care of when the table is created.",
      "pos": [
        10888,
        10940
      ]
    },
    {
      "content": "All you have to do is identify the boundary points for the column that is going to be the partitioning key.",
      "pos": [
        10941,
        11048
      ]
    },
    {
      "content": "Statistics",
      "pos": [
        11053,
        11063
      ]
    },
    {
      "content": "SQL Data Warehouse uses a distributed query optimizer to create the appropriate query plan when users query tables.",
      "pos": [
        11065,
        11180
      ]
    },
    {
      "content": "Once created, the query plan provides the strategy and method used by the database to access the data and fulfill the user request.",
      "pos": [
        11181,
        11312
      ]
    },
    {
      "content": "SQL Data Warehouse's query optimizer is based on cost.",
      "pos": [
        11313,
        11367
      ]
    },
    {
      "content": "In other words it compares various options (plans) based on their relative cost and chooses the most efficient plan available to it.",
      "pos": [
        11368,
        11500
      ]
    },
    {
      "content": "Consequently, SQL Data Warehouse needs a lot of information to make informed, cost based decisions.",
      "pos": [
        11501,
        11600
      ]
    },
    {
      "content": "It holds statistics information about the table (for table size) and in database objects known as <ph id=\"ph1\">`STATISTICS`</ph>.",
      "pos": [
        11601,
        11712
      ]
    },
    {
      "content": "Statistics are held against single or multiple columns of indexes or tables.",
      "pos": [
        11714,
        11790
      ]
    },
    {
      "content": "They provide the cost-based optimizer with important information concerning cardinality and selectivity of values.",
      "pos": [
        11791,
        11905
      ]
    },
    {
      "content": "This is of particular interest when the optimizer needs to evaluate JOINs, GROUP BY, HAVING and WHERE clauses in a query.",
      "pos": [
        11906,
        12027
      ]
    },
    {
      "content": "It is therefore very important that the information contained in these statistics objects <bpt id=\"p1\">*</bpt>accurately<ept id=\"p1\">*</ept> reflects the current state of the table.",
      "pos": [
        12028,
        12171
      ]
    },
    {
      "content": "It is vital to understand that it is the accuracy of the cost that is important.",
      "pos": [
        12172,
        12252
      ]
    },
    {
      "content": "If the statistics accurately reflect the state of the table then plans can be compared for lowest cost.",
      "pos": [
        12253,
        12356
      ]
    },
    {
      "content": "If they aren't accurate then SQL Data Warehouse may choose the wrong plan.",
      "pos": [
        12357,
        12431
      ]
    },
    {
      "content": "Column-level statistics in SQL Data Warehouse are user-defined.",
      "pos": [
        12433,
        12496
      ]
    },
    {
      "content": "In other words we have to create them ourselves.",
      "pos": [
        12498,
        12546
      ]
    },
    {
      "content": "As we have just learned, this is not something to overlook.",
      "pos": [
        12547,
        12606
      ]
    },
    {
      "content": "This is an important difference between SQL Server and SQL Data Warehouse.",
      "pos": [
        12607,
        12681
      ]
    },
    {
      "content": "SQL Server will automatically create statistics when columns are queried.",
      "pos": [
        12682,
        12755
      ]
    },
    {
      "content": "By default, SQL Server will also automatically update those statistics.",
      "pos": [
        12756,
        12827
      ]
    },
    {
      "content": "However, in SQL Data Warehouse statistics need to be created manually and managed manually.",
      "pos": [
        12828,
        12919
      ]
    },
    {
      "content": "Recommendations",
      "pos": [
        12925,
        12940
      ]
    },
    {
      "content": "Apply the following recommendations for generating statistics:",
      "pos": [
        12942,
        13004
      ]
    },
    {
      "pos": [
        13009,
        13122
      ],
      "content": "Create Single column statistics on columns used in <ph id=\"ph1\">`WHERE`</ph>, <ph id=\"ph2\">`JOIN`</ph>, <ph id=\"ph3\">`GROUP BY`</ph>, <ph id=\"ph4\">`ORDER BY`</ph> and <ph id=\"ph5\">`DISTINCT`</ph> clauses"
    },
    {
      "content": "Generate multi-column statistics on composite clauses",
      "pos": [
        13126,
        13179
      ]
    },
    {
      "content": "Update statistics periodically.",
      "pos": [
        13183,
        13214
      ]
    },
    {
      "content": "Remember that this is not done automatically!",
      "pos": [
        13215,
        13260
      ]
    },
    {
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> It is common for SQL Server Data Warehouse to rely solely on <ph id=\"ph2\">`AUTOSTATS`</ph> to keep the column statistics up to date.",
      "pos": [
        13263,
        13390
      ]
    },
    {
      "content": "This is not a best practice even for SQL Server data warehouses.",
      "pos": [
        13391,
        13455
      ]
    },
    {
      "content": "<ph id=\"ph1\">`AUTOSTATS`</ph> are triggered by a 20% rate of change which for large fact tables containing millions or billions of rows may not be sufficient.",
      "pos": [
        13456,
        13596
      ]
    },
    {
      "content": "It is therefore always a good idea to keep on top of statistics updates to ensure that the statistics accurately reflect the cardinality of the table.",
      "pos": [
        13597,
        13747
      ]
    },
    {
      "content": "Unsupported features",
      "pos": [
        13752,
        13772
      ]
    },
    {
      "content": "SQL Data Warehouse does not use or support these features:",
      "pos": [
        13773,
        13831
      ]
    },
    {
      "content": "primary keys",
      "pos": [
        13835,
        13847
      ]
    },
    {
      "content": "foreign keys",
      "pos": [
        13850,
        13862
      ]
    },
    {
      "content": "check constraints",
      "pos": [
        13865,
        13882
      ]
    },
    {
      "content": "unique constraints",
      "pos": [
        13885,
        13903
      ]
    },
    {
      "content": "unique indexes",
      "pos": [
        13906,
        13920
      ]
    },
    {
      "content": "computed columns",
      "pos": [
        13923,
        13939
      ]
    },
    {
      "content": "sparse columns",
      "pos": [
        13942,
        13956
      ]
    },
    {
      "content": "user-defined types",
      "pos": [
        13959,
        13977
      ]
    },
    {
      "content": "indexed views",
      "pos": [
        13980,
        13993
      ]
    },
    {
      "content": "identities",
      "pos": [
        13996,
        14006
      ]
    },
    {
      "content": "sequences",
      "pos": [
        14009,
        14018
      ]
    },
    {
      "content": "triggers",
      "pos": [
        14021,
        14029
      ]
    },
    {
      "content": "synonyms",
      "pos": [
        14032,
        14040
      ]
    },
    {
      "content": "Next steps",
      "pos": [
        14046,
        14056
      ]
    },
    {
      "pos": [
        14057,
        14113
      ],
      "content": "For more development tips, see <bpt id=\"p1\">[</bpt>development overview<ept id=\"p1\">][]</ept>."
    }
  ],
  "content": "<properties\n   pageTitle=\"Table design in SQL Data Warehouse | Microsoft Azure\"\n   description=\"Tips for designing tables in Azure SQL Data Warehouse for developing solutions.\"\n   services=\"sql-data-warehouse\"\n   documentationCenter=\"NA\"\n   authors=\"jrowlandjones\"\n   manager=\"barbkess\"\n   editor=\"\"/>\n\n<tags\n   ms.service=\"sql-data-warehouse\"\n   ms.devlang=\"NA\"\n   ms.topic=\"article\"\n   ms.tgt_pltfrm=\"NA\"\n   ms.workload=\"data-services\"\n   ms.date=\"06/26/2015\"\n   ms.author=\"JRJ@BigBangData.co.uk;barbkess\"/>\n\n# Table design in SQL Data Warehouse #\nSQL Data Warehouse is a massively parallel processing (MPP) distributed database system. Consequently, it stores data across many different locations known as **distributions**. Each **distribution** is like a bucket; storing a unique subset of the data in the data warehouse. By spreading the data and processing capability across multiple nodes SQL Data Warehouse is able to offer huge scalability - far beyond any single system.\n\nWhen a table is created in SQL Data Warehouse, it is actually spread across all of the the distributions.\n\nThis article will cover the following topics:\n\n- Supported data types\n- Principles of data distribution\n- Round Robin Distribution\n- Hash Distribution\n- Table Partitioning\n- Statistics\n- Unsupported features\n\n## Supported data types\nSQL Data Warehouse supports the common business data types:\n\n- **bigint**\n- **binary**\n- **bit**\n- **char**\n- **date**\n- **datetime**\n- **datetime2**\n- **datetimeoffset**\n- **decimal**\n- **float**\n- **int**\n- **money**\n- **nchar**\n- **nvarchar**\n- **real**\n- **smalldatetime**\n- **smallint**\n- **smallmoney**\n- **time**\n- **tinyint**\n- **varbinary**\n- **varchar**\n\nYou can identify columns in your data warehouse that contain incompatible types using the following query:\n\n```\nSELECT  t.[name]\n,       c.[name]\n,       c.[system_type_id]\n,       c.[user_type_id]\n,       y.[is_user_defined]\n,       y.[name]\nFROM sys.tables  t\nJOIN sys.columns c on t.[object_id]    = c.[object_id]\nJOIN sys.types   y on c.[user_type_id] = y.[user_type_id]\nWHERE y.[name] IN\n                (   'geography'\n                ,   'geometry'\n                ,   'hierarchyid'\n                ,   'image'\n                ,   'ntext'\n                ,   'numeric'\n                ,   'sql_variant'\n                ,   'sysname'\n                ,   'text'\n                ,   'timestamp'\n                ,   'uniqueidentifier'\n                ,   'xml'\n                )\n\nOR  (   y.[name] IN (  'nvarchar','varchar','varbinary')\n    AND c.[max_length] = -1\n    )\nOR  y.[is_user_defined] = 1\n;\n\n```\n\nThe query includes any user defined data types which are also not supported.\n\nIf you have unsupported types in your database do not worry. Some alternatives you can use instead are proposed below.\n\nInstead of:\n\n- **geometry**, use a varbinary type\n- **geography**, use a varbinary type\n- **hierarchyid**, CLR type not native\n- **image**, **text**, **ntext** when text based use varchar/nvarchar (smaller the better)\n- **nvarchar(max)**, use varchar(4000) or smaller for better performance\n- **numeric**, use decimal\n- **sql_variant**, split column into several strongly typed columns\n- **sysname**, use nvarchar(128)\n- **table**, convert to temporary tables\n- **timestamp**, re-work code to use datetime2 and `CURRENT_TIMESTAMP` function. Note you cannot have current_timestamp as a default constraint and the value will not automatically update. If you need to migrate rowversion values from a timestamp typed column then use BINARY(8) or VARBINARY(8) for NOT NULL or NULL row version values.\n- **varchar(max)**, use varchar(8000) or smaller for better performance\n- **uniqueidentifier**, use varbinary(8)\n- **user defined types**, convert back to their native types where possible\n- **xml**, use a varchar(8000) or smaller for better performance - split across columns if needed\n\nPartial support:\n\n- Default constraints support literals and constants only. Non-deterministic expressions or functions, such as `GETDATE()` or `CURRENT_TIMESTAMP`, are not supported.\n\n> [AZURE.NOTE] Define your tables so that the maximum possible row size, including the full length of variable length columns, does not exceed 32,767 bytes. While you can define a row with variable length data that can exceed this figure, you will not be be able to insert data into the table. Also, try to limit the size of your variable length columns for even better throughput for running queries.\n\n## Principles of data distribution\n\nThere are two choices for distributing data in SQL Data Warehouse:\n\n1. Distribute data based on hashing values from a single column\n2. Distribute data evenly but randomly  \n\nData distribution is decided at the table level. All tables are distributed so you will have the opportunity to make this decision for each table in your SQL Data Warehouse database.\n\nThe first option is known as **round-robin** distribution - sometimes known as the random hash. You can think of this as the default or fail safe option.\n\nThe second option is known as the **hash** distribution. You can consider it an optimized form of data distribution. It is preferred where clusters of tables share common joining and/or aggregation criteria.\n\n## Round-robin distribution\n\nRound-Robin distribution is a method of spreading data as evenly as possible across all distributions. Buffers containing rows of data are allocated in turn (hence the name round robin) to each distribution. The process is repeated until all data buffers have been allocated. At no stage is the data sorted or ordered in a round robin distributed table. A round robin distribution is sometimes called a random hash for this reason. The data is simply spread as evenly as possible across the distributions.\n\nBelow is an example of round robin distributed table:\n\n```\nCREATE TABLE [dbo].[FactInternetSales]\n(   [ProductKey]            int          NOT NULL\n,   [OrderDateKey]          int          NOT NULL\n,   [CustomerKey]           int          NOT NULL\n,   [PromotionKey]          int          NOT NULL\n,   [SalesOrderNumber]      nvarchar(20) NOT NULL\n,   [OrderQuantity]         smallint     NOT NULL\n,   [UnitPrice]             money        NOT NULL\n,   [SalesAmount]           money        NOT NULL\n)\nWITH\n(   CLUSTERED COLUMNSTORE INDEX\n,   DISTRIBUTION = ROUND_ROBIN\n)\n;\n```\n\nThis is also an example of a round robin distributed table:\n\n```\nCREATE TABLE [dbo].[FactInternetSales]\n(   [ProductKey]            int          NOT NULL\n,   [OrderDateKey]          int          NOT NULL\n,   [CustomerKey]           int          NOT NULL\n,   [PromotionKey]          int          NOT NULL\n,   [SalesOrderNumber]      nvarchar(20) NOT NULL\n,   [OrderQuantity]         smallint     NOT NULL\n,   [UnitPrice]             money        NOT NULL\n,   [SalesAmount]           money        NOT NULL\n)\nWITH\n(   CLUSTERED COLUMNSTORE INDEX\n)\n;\n```\n\n> [AZURE.NOTE] Notice that the second example above makes no mention of the distribution key. Round Robin is the default and so it is not absolutely required. Being explicit however, is considered to be a good practice as ensures that your peers are aware of your intentions when reviewing the table design.\n\nThis table type is commonly used when there is no obvious key column to hash the data by. It can also be used by smaller or less significant tables where the movement cost may not be so great.\n\nLoading data into a round robin distributed table tends to be faster than loading into a hash distributed table. With a round-robin distributed table there is no need to understand the data or perform the hash prior to loading. For this reason Round-Robin tables often make good good loading targets.\n\n> [AZURE.NOTE] When data is round robin distributed the data is allocated to the distribution at the *buffer* level.\n\n### Recommendations\n\nConsider using Round Robin distribution for your table in the following scenarios:\n\n- When there is no obvious joining key\n- If a candidate hash distribution key is not known\n- If the table does not share a common joining key with other tables\n- If the join is less significant than other joins in the query\n- When the table is an initial loading table\n\n## Hash distribution\n\nHash distribution uses an internal function to spread a dataset across the distributions by hashing a single column. When data is hashed there is no explicit order to the data being allocated to a distribution. However, the hash itself is a deterministic process. This makes the results of the hash predictable. For example, hashing an integer column containing the value 10 will always yield the same hash value. This means that ***any*** hashed integer column  containing the value 10 would end up being allocated to the same distribution. This is true even across tables.\n\nThe predictability of the hash is extremely important. It means that hash distributing the data can lead to performance improvements when reading data and joining tables together.\n\nAs you will see below, hash distribution can be very effective for query optimization. This is why it is considered to be an optimized form of data distribution.\n\n> [AZURE.NOTE] Remember! The hash is not based on the value of the data but rather on the type of the data being hashed.\n\nBelow is a table that has been hash distributed by ProductKey.\n\n```\nCREATE TABLE [dbo].[FactInternetSales]\n(   [ProductKey]            int          NOT NULL\n,   [OrderDateKey]          int          NOT NULL\n,   [CustomerKey]           int          NOT NULL\n,   [PromotionKey]          int          NOT NULL\n,   [SalesOrderNumber]      nvarchar(20) NOT NULL\n,   [OrderQuantity]         smallint     NOT NULL\n,   [UnitPrice]             money        NOT NULL\n,   [SalesAmount]           money        NOT NULL\n)\nWITH\n(   CLUSTERED COLUMNSTORE INDEX\n,   DISTRIBUTION = HASH([ProductKey])\n)\n;\n```\n\n> [AZURE.NOTE] When data is hash distributed the data is allocated to the distribution at the row level.\n\n## Table partitions\nTable partitions are supported and easy to define.\n\nExample SQL Data Warehouse partitioned `CREATE TABLE` command:\n\n```\nCREATE TABLE [dbo].[FactInternetSales]\n(\n    [ProductKey]            int          NOT NULL\n,   [OrderDateKey]          int          NOT NULL\n,   [CustomerKey]           int          NOT NULL\n,   [PromotionKey]          int          NOT NULL\n,   [SalesOrderNumber]      nvarchar(20) NOT NULL\n,   [OrderQuantity]         smallint     NOT NULL\n,   [UnitPrice]             money        NOT NULL\n,   [SalesAmount]           money        NOT NULL\n)\nWITH\n(   CLUSTERED COLUMNSTORE INDEX\n,   DISTRIBUTION = HASH([ProductKey])\n,   PARTITION   (   [OrderDateKey] RANGE RIGHT FOR VALUES\n                    (20000101,20010101,20020101\n                    ,20030101,20040101,20050101\n                    )\n                )\n)\n;\n```\n\nNotice that there is no partitioning function or scheme in the definition. All that is taken care of when the table is created. All you have to do is identify the boundary points for the column that is going to be the partitioning key.\n\n## Statistics\n\nSQL Data Warehouse uses a distributed query optimizer to create the appropriate query plan when users query tables. Once created, the query plan provides the strategy and method used by the database to access the data and fulfill the user request. SQL Data Warehouse's query optimizer is based on cost. In other words it compares various options (plans) based on their relative cost and chooses the most efficient plan available to it. Consequently, SQL Data Warehouse needs a lot of information to make informed, cost based decisions. It holds statistics information about the table (for table size) and in database objects known as `STATISTICS`.\n\nStatistics are held against single or multiple columns of indexes or tables. They provide the cost-based optimizer with important information concerning cardinality and selectivity of values. This is of particular interest when the optimizer needs to evaluate JOINs, GROUP BY, HAVING and WHERE clauses in a query. It is therefore very important that the information contained in these statistics objects *accurately* reflects the current state of the table. It is vital to understand that it is the accuracy of the cost that is important. If the statistics accurately reflect the state of the table then plans can be compared for lowest cost. If they aren't accurate then SQL Data Warehouse may choose the wrong plan.\n\nColumn-level statistics in SQL Data Warehouse are user-defined.\n\nIn other words we have to create them ourselves. As we have just learned, this is not something to overlook. This is an important difference between SQL Server and SQL Data Warehouse. SQL Server will automatically create statistics when columns are queried. By default, SQL Server will also automatically update those statistics. However, in SQL Data Warehouse statistics need to be created manually and managed manually.\n\n### Recommendations\n\nApply the following recommendations for generating statistics:\n\n1. Create Single column statistics on columns used in `WHERE`, `JOIN`, `GROUP BY`, `ORDER BY` and `DISTINCT` clauses\n2. Generate multi-column statistics on composite clauses\n3. Update statistics periodically. Remember that this is not done automatically!\n\n>[AZURE.NOTE] It is common for SQL Server Data Warehouse to rely solely on `AUTOSTATS` to keep the column statistics up to date. This is not a best practice even for SQL Server data warehouses. `AUTOSTATS` are triggered by a 20% rate of change which for large fact tables containing millions or billions of rows may not be sufficient. It is therefore always a good idea to keep on top of statistics updates to ensure that the statistics accurately reflect the cardinality of the table.\n\n## Unsupported features\nSQL Data Warehouse does not use or support these features:\n\n- primary keys\n- foreign keys\n- check constraints\n- unique constraints\n- unique indexes\n- computed columns\n- sparse columns\n- user-defined types\n- indexed views\n- identities\n- sequences\n- triggers\n- synonyms\n\n\n## Next steps\nFor more development tips, see [development overview][].\n\n<!--Image references-->\n\n<!--Article references-->\n[development overview]: sql-data-warehouse-overview-develop.md\n\n<!--MSDN references-->\n\n<!--Other Web references-->\n"
}