{
  "nodes": [
    {
      "content": "Compute Linked Services | Microsoft Azure",
      "pos": [
        28,
        69
      ]
    },
    {
      "content": "Learn about compute enviornments that you can use in Azure Data Factory pipelines to transform/process data.",
      "pos": [
        89,
        197
      ]
    },
    {
      "content": "Compute Linked Services",
      "pos": [
        525,
        548
      ]
    },
    {
      "content": "This article explains different compute environments that you can use to process or transform data.",
      "pos": [
        550,
        649
      ]
    },
    {
      "content": "It also provides details about different configurations (on-demand vs. bring your own) supported by Data Factory when configuring linked services linking these compute environments to an Azure data factory.",
      "pos": [
        650,
        856
      ]
    },
    {
      "content": "On-demand compute environment",
      "pos": [
        861,
        890
      ]
    },
    {
      "content": "In this type of configuration, the computing environment is fully managed by the Azure Data Factory service.",
      "pos": [
        892,
        1000
      ]
    },
    {
      "content": "It is automatically created by the Data Factory service before a job is submitted to process data and removed when the job is completed.",
      "pos": [
        1001,
        1137
      ]
    },
    {
      "content": "You can create a linked service for the on-demand compute environment, configure it, and control granular settings for job execution, cluster management, and bootstrapping actions.",
      "pos": [
        1138,
        1318
      ]
    },
    {
      "pos": [
        1322,
        1420
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> The on-demand configuration is currently supported only for Azure HDInsight clusters."
    },
    {
      "content": "Azure HDInsight On-Demand Linked Service",
      "pos": [
        1426,
        1466
      ]
    },
    {
      "content": "The on-demand HDInsight cluster is automatically created by the Azure Data Factory service to process data.",
      "pos": [
        1468,
        1575
      ]
    },
    {
      "content": "The cluster is created in the region that is same as that of the storage account (linkedServiceName property in the JSON) associated with the cluster.",
      "pos": [
        1576,
        1726
      ]
    },
    {
      "pos": [
        1728,
        1809
      ],
      "content": "Note the following <bpt id=\"p1\">**</bpt>important<ept id=\"p1\">**</ept> points about on-demand HDInsight linked service:"
    },
    {
      "content": "You will not see the on-demand HDInsight cluster created in your Azure subscription; the Azure Data Factory service manages the on-demand HDInsight cluster on your behalf.",
      "pos": [
        1814,
        1985
      ]
    },
    {
      "content": "The logs for jobs that are run on an on-demand HDInsight cluster are copied to the storage account associated with the HDInsight cluster.",
      "pos": [
        1988,
        2125
      ]
    },
    {
      "content": "You can access these logs from the Azure Portal in the <bpt id=\"p1\">**</bpt>Activity Run Details<ept id=\"p1\">**</ept> blade.",
      "pos": [
        2126,
        2212
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Monitor and Manage Pipelines<ept id=\"p1\">](data-factory-monitor-manage-pipelines.md)</ept> article for details.",
      "pos": [
        2213,
        2310
      ]
    },
    {
      "content": "You will be charged only for the time when the HDInsight cluster is up and running jobs.",
      "pos": [
        2314,
        2402
      ]
    },
    {
      "pos": [
        2406,
        2518
      ],
      "content": "<ph id=\"ph1\">[AZURE.IMPORTANT]</ph> It typically takes more than <bpt id=\"p1\">**</bpt>15 minutes<ept id=\"p1\">**</ept> to provision an Azure HDInsight cluster on demand."
    },
    {
      "content": "Example",
      "pos": [
        2524,
        2531
      ]
    },
    {
      "content": "Properties",
      "pos": [
        3011,
        3021
      ]
    },
    {
      "content": "Property",
      "pos": [
        3023,
        3031
      ]
    },
    {
      "content": "Description",
      "pos": [
        3034,
        3045
      ]
    },
    {
      "content": "Required",
      "pos": [
        3048,
        3056
      ]
    },
    {
      "content": "type",
      "pos": [
        3091,
        3095
      ]
    },
    {
      "pos": [
        3098,
        3155
      ],
      "content": "The type property should be set to <bpt id=\"p1\">**</bpt>HDInsightOnDemand<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Yes",
      "pos": [
        3158,
        3161
      ]
    },
    {
      "content": "clusterSize",
      "pos": [
        3162,
        3173
      ]
    },
    {
      "content": "The size of the on-demand cluster.",
      "pos": [
        3176,
        3210
      ]
    },
    {
      "content": "Specify how many nodes you want to be in this on-demand cluster.",
      "pos": [
        3211,
        3275
      ]
    },
    {
      "content": "Yes",
      "pos": [
        3278,
        3281
      ]
    },
    {
      "content": "jobscontainer",
      "pos": [
        3283,
        3296
      ]
    },
    {
      "content": "The blob container that holds data used by pig/hive/package jobs and where the cluster logs will be stored.",
      "pos": [
        3299,
        3406
      ]
    },
    {
      "content": "Yes",
      "pos": [
        3409,
        3412
      ]
    },
    {
      "content": "timetolive",
      "pos": [
        3413,
        3423
      ]
    },
    {
      "content": "The allowed idle time for the on-demand HDInsight cluster.",
      "pos": [
        3429,
        3487
      ]
    },
    {
      "content": "Specifies how long the on-demand HDInsight cluster will stay alive after completion of an activity run if there are no other active jobs in the cluster.",
      "pos": [
        3488,
        3640
      ]
    },
    {
      "content": "For example, if an activity run takes 6 minutes and timetolive is set to 5 minutes, the cluster stays alive for 5 minutes after the 6 minutes of processing the activity run.",
      "pos": [
        3647,
        3820
      ]
    },
    {
      "content": "If another activity run is executed with the 6 minutes window, it is processed by the same cluster.",
      "pos": [
        3821,
        3920
      ]
    },
    {
      "content": "Creating an on-demand HDInsight cluster is an expensive operation (could take a while), so use this setting as needed to improve performance of a data factory by reusing an on-demand HDInsight cluster.",
      "pos": [
        3927,
        4128
      ]
    },
    {
      "content": "If you set timetolive value to 0, the cluster is deleted as soon as the activity run in processed.",
      "pos": [
        4135,
        4233
      ]
    },
    {
      "content": "On the other hand, if you set a high value, the cluster may stay idle unnecessarily resulting in high costs.",
      "pos": [
        4234,
        4342
      ]
    },
    {
      "content": "Therefore, it is important that you set the appropriate value based on your needs.",
      "pos": [
        4343,
        4425
      ]
    },
    {
      "content": "Multiple pipelines can share the same instance of the on-demand HDInsight cluster if the timetolive property value is appropriately set",
      "pos": [
        4432,
        4567
      ]
    },
    {
      "content": "Yes",
      "pos": [
        4574,
        4577
      ]
    },
    {
      "content": "version",
      "pos": [
        4578,
        4585
      ]
    },
    {
      "content": "Version of the HDInsight cluster",
      "pos": [
        4588,
        4620
      ]
    },
    {
      "content": "No",
      "pos": [
        4623,
        4625
      ]
    },
    {
      "content": "linkedServiceName",
      "pos": [
        4626,
        4643
      ]
    },
    {
      "content": "The blob store to be used by the on-demand cluster for storing and processing data.",
      "pos": [
        4646,
        4729
      ]
    },
    {
      "content": "Yes",
      "pos": [
        4732,
        4735
      ]
    },
    {
      "content": "additionalLinkedServiceNames",
      "pos": [
        4736,
        4764
      ]
    },
    {
      "content": "Specifies additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf.",
      "pos": [
        4767,
        4904
      ]
    },
    {
      "content": "No",
      "pos": [
        4907,
        4909
      ]
    },
    {
      "content": "Advanced Properties",
      "pos": [
        4915,
        4934
      ]
    },
    {
      "content": "You can also specify the following properties for the granular configuration of the on-demand HDInsight cluster.",
      "pos": [
        4936,
        5048
      ]
    },
    {
      "content": "Property",
      "pos": [
        5051,
        5059
      ]
    },
    {
      "content": "Description",
      "pos": [
        5062,
        5073
      ]
    },
    {
      "content": "Required",
      "pos": [
        5076,
        5084
      ]
    },
    {
      "content": "coreConfiguration",
      "pos": [
        5119,
        5136
      ]
    },
    {
      "content": "Specifies the core configuration parameters (as in core-site.xml) for the HDInsight cluster to be created.",
      "pos": [
        5139,
        5245
      ]
    },
    {
      "content": "No",
      "pos": [
        5248,
        5250
      ]
    },
    {
      "content": "hBaseConfiguration",
      "pos": [
        5251,
        5269
      ]
    },
    {
      "content": "Specifies the HBase configuration parameters (hbase-site.xml) for the HDInsight cluster.",
      "pos": [
        5272,
        5360
      ]
    },
    {
      "content": "No",
      "pos": [
        5363,
        5365
      ]
    },
    {
      "content": "hdfsConfiguration",
      "pos": [
        5366,
        5383
      ]
    },
    {
      "content": "Specifies the HDFS configuration parameters (hdfs-site.xml) for the HDInsight cluster.",
      "pos": [
        5386,
        5472
      ]
    },
    {
      "content": "No",
      "pos": [
        5475,
        5477
      ]
    },
    {
      "content": "hiveConfiguration",
      "pos": [
        5478,
        5495
      ]
    },
    {
      "content": "Specifies the hive configuration parameters (hive-site.xml) for the HDInsight cluster.",
      "pos": [
        5498,
        5584
      ]
    },
    {
      "content": "No",
      "pos": [
        5587,
        5589
      ]
    },
    {
      "content": "mapReduceConfiguration",
      "pos": [
        5590,
        5612
      ]
    },
    {
      "content": "Specifies the MapReduce configuration parameters (mapred-site.xml) for the HDInsight cluster.",
      "pos": [
        5615,
        5708
      ]
    },
    {
      "content": "No",
      "pos": [
        5711,
        5713
      ]
    },
    {
      "content": "oozieConfiguration",
      "pos": [
        5714,
        5732
      ]
    },
    {
      "content": "Specifies the Oozie configuration parameters (oozie-site.xml) for the HDInsight cluster.",
      "pos": [
        5735,
        5823
      ]
    },
    {
      "content": "No",
      "pos": [
        5826,
        5828
      ]
    },
    {
      "content": "stormConfiguration",
      "pos": [
        5829,
        5847
      ]
    },
    {
      "content": "Specifies the Storm configuration parameters (storm-site.xml) for the HDInsight cluster.",
      "pos": [
        5850,
        5938
      ]
    },
    {
      "content": "No",
      "pos": [
        5941,
        5943
      ]
    },
    {
      "content": "yarnConfiguration",
      "pos": [
        5944,
        5961
      ]
    },
    {
      "content": "Specifies the Yarn configuration parameters (yarn-site.xml) for the HDInsight cluster.",
      "pos": [
        5964,
        6050
      ]
    },
    {
      "content": "No",
      "pos": [
        6053,
        6055
      ]
    },
    {
      "content": "Example – On-demand HDInsight cluster configuration with advanced properties",
      "pos": [
        6062,
        6138
      ]
    },
    {
      "content": "Bring your own compute environment",
      "pos": [
        7205,
        7239
      ]
    },
    {
      "content": "In this type of configuration, users can register an already existing computing environment as a linked service in Data Factory.",
      "pos": [
        7242,
        7370
      ]
    },
    {
      "content": "The computing environment is managed by the user and the Data Factory service uses it to execute the activities.",
      "pos": [
        7371,
        7483
      ]
    },
    {
      "content": "This type of configuration is supported for the following compute environments:",
      "pos": [
        7486,
        7565
      ]
    },
    {
      "content": "Azure HDInsight",
      "pos": [
        7570,
        7585
      ]
    },
    {
      "content": "Azure Batch",
      "pos": [
        7588,
        7599
      ]
    },
    {
      "content": "Azure Machine Learning.",
      "pos": [
        7603,
        7626
      ]
    },
    {
      "content": "Azure HDInsight Linked Service",
      "pos": [
        7631,
        7661
      ]
    },
    {
      "content": "You can create an Azure HDInsight linked service to register your own HDInsight cluster with Data Factory.",
      "pos": [
        7663,
        7769
      ]
    },
    {
      "content": "Example",
      "pos": [
        7776,
        7783
      ]
    },
    {
      "content": "Properties",
      "pos": [
        8182,
        8192
      ]
    },
    {
      "content": "Property",
      "pos": [
        8194,
        8202
      ]
    },
    {
      "content": "Description",
      "pos": [
        8205,
        8216
      ]
    },
    {
      "content": "Required",
      "pos": [
        8219,
        8227
      ]
    },
    {
      "content": "type",
      "pos": [
        8262,
        8266
      ]
    },
    {
      "pos": [
        8269,
        8318
      ],
      "content": "The type property should be set to <bpt id=\"p1\">**</bpt>HDInsight<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Yes",
      "pos": [
        8321,
        8324
      ]
    },
    {
      "content": "clusterUri",
      "pos": [
        8325,
        8335
      ]
    },
    {
      "content": "The URI of the HDInsight cluster.",
      "pos": [
        8338,
        8371
      ]
    },
    {
      "content": "Yes",
      "pos": [
        8374,
        8377
      ]
    },
    {
      "content": "username",
      "pos": [
        8378,
        8386
      ]
    },
    {
      "content": "Specify the name of the user to be used to connect to an existing HDInsight cluster.",
      "pos": [
        8389,
        8473
      ]
    },
    {
      "content": "Yes",
      "pos": [
        8476,
        8479
      ]
    },
    {
      "content": "password",
      "pos": [
        8480,
        8488
      ]
    },
    {
      "content": "Specify password for the user account.",
      "pos": [
        8491,
        8529
      ]
    },
    {
      "content": "Yes",
      "pos": [
        8532,
        8535
      ]
    },
    {
      "content": "location",
      "pos": [
        8536,
        8544
      ]
    },
    {
      "content": "Specify the location of the HDInsight cluster (for example: WestUS).",
      "pos": [
        8547,
        8615
      ]
    },
    {
      "content": "Yes",
      "pos": [
        8618,
        8621
      ]
    },
    {
      "content": "linkedServiceName",
      "pos": [
        8622,
        8639
      ]
    },
    {
      "content": "Name of the linked service for the blob storage used by this HDInsight cluster.",
      "pos": [
        8642,
        8721
      ]
    },
    {
      "content": "Yes",
      "pos": [
        8724,
        8727
      ]
    },
    {
      "content": "Azure Batch Linked Service",
      "pos": [
        8732,
        8758
      ]
    },
    {
      "content": "You can create an Azure Batch linked service to register a Batch pool of virtual machines (VMs) to a data factory.",
      "pos": [
        8760,
        8874
      ]
    },
    {
      "content": "You can run .NET custom activities using either Azure Batch or Azure HDInsight.",
      "pos": [
        8875,
        8954
      ]
    },
    {
      "content": "See following topics if you are new to Azure Batch service:",
      "pos": [
        8956,
        9015
      ]
    },
    {
      "pos": [
        9021,
        9135
      ],
      "content": "<bpt id=\"p1\">[</bpt>Azure Batch Technical Overview<ept id=\"p1\">](../batch/batch-technical-overview.md)</ept> for an overview of the Azure Batch service."
    },
    {
      "content": "<bpt id=\"p1\">[</bpt>New-AzureBatchAccount<ept id=\"p1\">](https://msdn.microsoft.com/library/mt125880.aspx)</ept> cmdlet to create an Azure Batch account (or) <bpt id=\"p2\">[</bpt>Azure Management Portal<ept id=\"p2\">](../batch/batch-technical-overview.md)</ept> to create the Azure Batch account using Azure Management Portal.",
      "pos": [
        9138,
        9385
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Using PowerShell to manage Azure Batch Account<ept id=\"p1\">](http://blogs.technet.com/b/windowshpc/archive/2014/10/28/using-azure-powershell-to-manage-azure-batch-account.aspx)</ept> topic for detailed instructions on using the cmdlet.",
      "pos": [
        9386,
        9607
      ]
    },
    {
      "pos": [
        9610,
        9718
      ],
      "content": "<bpt id=\"p1\">[</bpt>New-AzureBatchPool<ept id=\"p1\">](https://msdn.microsoft.com/library/mt125936.aspx)</ept> cmdlet to create an Azure Batch pool."
    },
    {
      "content": "Example",
      "pos": [
        9724,
        9731
      ]
    },
    {
      "content": "Append \"<bpt id=\"p1\">**</bpt>.&lt;region name<ept id=\"p1\">**</ept>\" to the name of your batch account for the <bpt id=\"p2\">**</bpt>accountName<ept id=\"p2\">**</ept> property.",
      "pos": [
        10133,
        10227
      ]
    },
    {
      "content": "Example:",
      "pos": [
        10228,
        10236
      ]
    },
    {
      "content": "Another option is to provide the batchUri endpoint as shown below.",
      "pos": [
        10296,
        10362
      ]
    },
    {
      "content": "Properties",
      "pos": [
        10463,
        10473
      ]
    },
    {
      "content": "Property",
      "pos": [
        10475,
        10483
      ]
    },
    {
      "content": "Description",
      "pos": [
        10486,
        10497
      ]
    },
    {
      "content": "Required",
      "pos": [
        10500,
        10508
      ]
    },
    {
      "content": "type",
      "pos": [
        10543,
        10547
      ]
    },
    {
      "pos": [
        10550,
        10600
      ],
      "content": "The type property should be set to <bpt id=\"p1\">**</bpt>AzureBatch<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Yes",
      "pos": [
        10603,
        10606
      ]
    },
    {
      "content": "accountName",
      "pos": [
        10607,
        10618
      ]
    },
    {
      "content": "Name of the Azure Batch account.",
      "pos": [
        10621,
        10653
      ]
    },
    {
      "content": "Yes",
      "pos": [
        10656,
        10659
      ]
    },
    {
      "content": "accessKey",
      "pos": [
        10660,
        10669
      ]
    },
    {
      "content": "Access key for the Azure Batch account.",
      "pos": [
        10672,
        10711
      ]
    },
    {
      "content": "Yes",
      "pos": [
        10714,
        10717
      ]
    },
    {
      "content": "poolName",
      "pos": [
        10718,
        10726
      ]
    },
    {
      "content": "Name of the pool of virtual machines.",
      "pos": [
        10729,
        10766
      ]
    },
    {
      "content": "Yes",
      "pos": [
        10769,
        10772
      ]
    },
    {
      "content": "linkedServiceName",
      "pos": [
        10773,
        10790
      ]
    },
    {
      "content": "Name of the Azure Storage linked service associated with this Azure Batch linked service.",
      "pos": [
        10793,
        10882
      ]
    },
    {
      "content": "This linked service is used for staging files required to run the activity and storing the activity execution logs.",
      "pos": [
        10883,
        10998
      ]
    },
    {
      "content": "Yes",
      "pos": [
        11001,
        11004
      ]
    },
    {
      "content": "Azure Machine Learning Linked Service",
      "pos": [
        11010,
        11047
      ]
    },
    {
      "content": "You create an Azure Machine Learning linked service to register a Machine Learning batch scoring endpoint to a data factory.",
      "pos": [
        11049,
        11173
      ]
    },
    {
      "content": "Example",
      "pos": [
        11179,
        11186
      ]
    },
    {
      "content": "Properties",
      "pos": [
        11434,
        11444
      ]
    },
    {
      "content": "Property",
      "pos": [
        11446,
        11454
      ]
    },
    {
      "content": "Description",
      "pos": [
        11457,
        11468
      ]
    },
    {
      "content": "Required",
      "pos": [
        11471,
        11479
      ]
    },
    {
      "content": "Type",
      "pos": [
        11514,
        11518
      ]
    },
    {
      "pos": [
        11521,
        11569
      ],
      "content": "The type property should be set to: <bpt id=\"p1\">**</bpt>AzureML<ept id=\"p1\">**</ept>."
    },
    {
      "content": "Yes",
      "pos": [
        11572,
        11575
      ]
    },
    {
      "content": "mlEndpoint",
      "pos": [
        11576,
        11586
      ]
    },
    {
      "content": "The batch scoring URL.",
      "pos": [
        11589,
        11611
      ]
    },
    {
      "content": "Yes",
      "pos": [
        11614,
        11617
      ]
    },
    {
      "content": "apiKey",
      "pos": [
        11618,
        11624
      ]
    },
    {
      "content": "The published workspace model’s API.",
      "pos": [
        11627,
        11663
      ]
    },
    {
      "content": "Yes",
      "pos": [
        11666,
        11669
      ]
    },
    {
      "content": "Azure SQL Linked Service",
      "pos": [
        11675,
        11699
      ]
    },
    {
      "content": "You create an Azure SQL linked service and use it with the <bpt id=\"p1\">[</bpt>Stored Procedure Activity<ept id=\"p1\">](data-factory-stored-proc-activity.md)</ept> to invoke a stored procedure from a Data Factory pipeline.",
      "pos": [
        11701,
        11884
      ]
    },
    {
      "content": "See <bpt id=\"p1\">[</bpt>Azure SQL Connector<ept id=\"p1\">](data-factory-azure-sql-connector.md#azure-sql-linked-service-properties)</ept> article for details about this linked service.",
      "pos": [
        11885,
        12030
      ]
    },
    {
      "content": "test",
      "pos": [
        12052,
        12056
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Compute Linked Services | Microsoft Azure\" \n    description=\"Learn about compute enviornments that you can use in Azure Data Factory pipelines to transform/process data.\" \n    services=\"data-factory\" \n    documentationCenter=\"\" \n    authors=\"spelluru\" \n    manager=\"jhubbard\" \n    editor=\"monicar\"/>\n\n<tags \n    ms.service=\"data-factory\" \n    ms.workload=\"data-services\" \n    ms.tgt_pltfrm=\"na\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.date=\"08/04/2015\" \n    ms.author=\"spelluru\"/>\n\n# Compute Linked Services\n\nThis article explains different compute environments that you can use to process or transform data. It also provides details about different configurations (on-demand vs. bring your own) supported by Data Factory when configuring linked services linking these compute environments to an Azure data factory.\n\n## On-demand compute environment\n\nIn this type of configuration, the computing environment is fully managed by the Azure Data Factory service. It is automatically created by the Data Factory service before a job is submitted to process data and removed when the job is completed. You can create a linked service for the on-demand compute environment, configure it, and control granular settings for job execution, cluster management, and bootstrapping actions.\n\n> [AZURE.NOTE] The on-demand configuration is currently supported only for Azure HDInsight clusters. \n\n## Azure HDInsight On-Demand Linked Service\n\nThe on-demand HDInsight cluster is automatically created by the Azure Data Factory service to process data. The cluster is created in the region that is same as that of the storage account (linkedServiceName property in the JSON) associated with the cluster.\n\nNote the following **important** points about on-demand HDInsight linked service: \n\n- You will not see the on-demand HDInsight cluster created in your Azure subscription; the Azure Data Factory service manages the on-demand HDInsight cluster on your behalf.\n- The logs for jobs that are run on an on-demand HDInsight cluster are copied to the storage account associated with the HDInsight cluster. You can access these logs from the Azure Portal in the **Activity Run Details** blade. See [Monitor and Manage Pipelines](data-factory-monitor-manage-pipelines.md) article for details. \n- You will be charged only for the time when the HDInsight cluster is up and running jobs.\n\n> [AZURE.IMPORTANT] It typically takes more than **15 minutes** to provision an Azure HDInsight cluster on demand.\n\n### Example\n\n    {\n      \"name\": \"HDInsightOnDemandLinkedService\",\n      \"properties\": {\n        \"type\": \"HDInsightOnDemand\",\n        \"typeProperties\": {\n          \"clusterSize\": 4,\n          \"jobsContainer\": \"adfjobs\",\n          \"timeToLive\": \"00:05:00\",\n          \"version\": \"3.1\",\n          \"linkedServiceName\": \"MyBlobStore\"\n          \"additionalLinkedServiceNames\": [\n            \"otherLinkedServiceName1\",\n            \"otherLinkedServiceName2\"\n          ]\n        }\n      }\n    }\n\n### Properties\n\nProperty | Description | Required\n-------- | ----------- | --------\ntype | The type property should be set to **HDInsightOnDemand**. | Yes\nclusterSize | The size of the on-demand cluster. Specify how many nodes you want to be in this on-demand cluster. | Yes \njobscontainer | The blob container that holds data used by pig/hive/package jobs and where the cluster logs will be stored. | Yes\ntimetolive | <p>The allowed idle time for the on-demand HDInsight cluster. Specifies how long the on-demand HDInsight cluster will stay alive after completion of an activity run if there are no other active jobs in the cluster.</p><p>For example, if an activity run takes 6 minutes and timetolive is set to 5 minutes, the cluster stays alive for 5 minutes after the 6 minutes of processing the activity run. If another activity run is executed with the 6 minutes window, it is processed by the same cluster.</p><p>Creating an on-demand HDInsight cluster is an expensive operation (could take a while), so use this setting as needed to improve performance of a data factory by reusing an on-demand HDInsight cluster.</p><p>If you set timetolive value to 0, the cluster is deleted as soon as the activity run in processed. On the other hand, if you set a high value, the cluster may stay idle unnecessarily resulting in high costs. Therefore, it is important that you set the appropriate value based on your needs.</p><p>Multiple pipelines can share the same instance of the on-demand HDInsight cluster if the timetolive property value is appropriately set</p> | Yes\nversion | Version of the HDInsight cluster | No\nlinkedServiceName | The blob store to be used by the on-demand cluster for storing and processing data. | Yes\nadditionalLinkedServiceNames | Specifies additional storage accounts for the HDInsight linked service so that the Data Factory service can register them on your behalf. | No\n\n### Advanced Properties\n\nYou can also specify the following properties for the granular configuration of the on-demand HDInsight cluster. \n\nProperty | Description | Required\n-------- | ----------- | --------\ncoreConfiguration | Specifies the core configuration parameters (as in core-site.xml) for the HDInsight cluster to be created. | No\nhBaseConfiguration | Specifies the HBase configuration parameters (hbase-site.xml) for the HDInsight cluster. | No\nhdfsConfiguration | Specifies the HDFS configuration parameters (hdfs-site.xml) for the HDInsight cluster. | No\nhiveConfiguration | Specifies the hive configuration parameters (hive-site.xml) for the HDInsight cluster. | No\nmapReduceConfiguration | Specifies the MapReduce configuration parameters (mapred-site.xml) for the HDInsight cluster. | No\noozieConfiguration | Specifies the Oozie configuration parameters (oozie-site.xml) for the HDInsight cluster. | No\nstormConfiguration | Specifies the Storm configuration parameters (storm-site.xml) for the HDInsight cluster. | No\nyarnConfiguration | Specifies the Yarn configuration parameters (yarn-site.xml) for the HDInsight cluster. | No\n\n#### Example – On-demand HDInsight cluster configuration with advanced properties\n\n    {\n      \"name\": \" HDInsightOnDemandLinkedService\",\n      \"properties\": {\n        \"type\": \"HDInsightOnDemand\",\n        \"typeProperties\": {\n          \"clusterSize\": 16,\n          \"jobsContainer\": \"adfjobs\",\n          \"timeToLive\": \"01:30:00\",\n          \"version\": \"3.1\",\n          \"linkedServiceName\": \"adfods1\",\n          \"coreConfiguration\": {\n            \"templeton.mapper.memory.mb\": \"5000\"\n          },\n          \"hiveConfiguration\": {\n            \"templeton.mapper.memory.mb\": \"5000\"\n          },\n          \"mapReduceConfiguration\": {\n            \"mapreduce.reduce.java.opts\": \"-Xmx8000m\",\n            \"mapreduce.map.java.opts\": \"-Xmx8000m\",\n            \"mapreduce.map.memory.mb\": \"5000\",\n            \"mapreduce.reduce.memory.mb\": \"5000\",\n            \"mapreduce.job.reduce.slowstart.completedmaps\": \"0.8\"\n          },\n          \"yarnConfiguration\": {\n            \"yarn.app.mapreduce.am.resource.mb\": \"5000\"\n          },\n          \"additionalLinkedServiceNames\": [\n            \"datafeeds\",\n            \"adobedatafeed\"\n          ]\n        }\n      }\n    }\n\n## Bring your own compute environment \n\nIn this type of configuration, users can register an already existing computing environment as a linked service in Data Factory. The computing environment is managed by the user and the Data Factory service uses it to execute the activities.\n \nThis type of configuration is supported for the following compute environments: \n\n- Azure HDInsight\n- Azure Batch \n- Azure Machine Learning.\n\n## Azure HDInsight Linked Service\n\nYou can create an Azure HDInsight linked service to register your own HDInsight cluster with Data Factory. \n\n### Example\n\n    {\n      \"name\": \"HDInsightLinkedService\",\n      \"properties\": {\n        \"type\": \"HDInsight\",\n        \"typeProperties\": {\n          \"clusterUri\": \" https://<hdinsightclustername>.azurehdinsight.net/\",\n          \"userName\": \"admin\",\n          \"password\": \"<password>\",\n          \"location\": \"WestUS\",\n          \"linkedServiceName\": \"MyHDInsightStoragelinkedService\"\n        }\n      }\n    }\n\n### Properties\n\nProperty | Description | Required\n-------- | ----------- | --------\ntype | The type property should be set to **HDInsight**. | Yes\nclusterUri | The URI of the HDInsight cluster. | Yes\nusername | Specify the name of the user to be used to connect to an existing HDInsight cluster. | Yes\npassword | Specify password for the user account. | Yes\nlocation | Specify the location of the HDInsight cluster (for example: WestUS). | Yes\nlinkedServiceName | Name of the linked service for the blob storage used by this HDInsight cluster. | Yes\n\n## Azure Batch Linked Service\n\nYou can create an Azure Batch linked service to register a Batch pool of virtual machines (VMs) to a data factory. You can run .NET custom activities using either Azure Batch or Azure HDInsight.\n\nSee following topics if you are new to Azure Batch service:\n \n\n- [Azure Batch Technical Overview](../batch/batch-technical-overview.md) for an overview of the Azure Batch service.\n- [New-AzureBatchAccount](https://msdn.microsoft.com/library/mt125880.aspx) cmdlet to create an Azure Batch account (or) [Azure Management Portal](../batch/batch-technical-overview.md) to create the Azure Batch account using Azure Management Portal. See [Using PowerShell to manage Azure Batch Account](http://blogs.technet.com/b/windowshpc/archive/2014/10/28/using-azure-powershell-to-manage-azure-batch-account.aspx) topic for detailed instructions on using the cmdlet.\n- [New-AzureBatchPool](https://msdn.microsoft.com/library/mt125936.aspx) cmdlet to create an Azure Batch pool.\n\n### Example\n\n    {\n      \"name\": \"AzureBatchLinkedService\",\n      \"properties\": {\n        \"type\": \"AzureBatch\",\n        \"typeProperties\": {\n          \"accountName\": \"<Azure Batch account name>\",\n          \"accessKey\": \"<Azure Batch account key>\",\n          \"poolName\": \"<Azure Batch pool name>\",\n          \"linkedServiceName\": \"<Specify associated storage linked service reference here>\"\n        }\n      }\n    }\n\nAppend \"**.<region name**\" to the name of your batch account for the **accountName** property. Example: \n    \n            \"accountName\": \"mybatchaccount.eastus\" \n\nAnother option is to provide the batchUri endpoint as shown below.  \n\n            accountName: \"adfteam\",\n            batchUri: \"https://eastus.batch.azure.com\",\n\n### Properties\n\nProperty | Description | Required\n-------- | ----------- | --------\ntype | The type property should be set to **AzureBatch**. | Yes\naccountName | Name of the Azure Batch account. | Yes\naccessKey | Access key for the Azure Batch account. | Yes\npoolName | Name of the pool of virtual machines. | Yes\nlinkedServiceName | Name of the Azure Storage linked service associated with this Azure Batch linked service. This linked service is used for staging files required to run the activity and storing the activity execution logs. | Yes\n\n\n## Azure Machine Learning Linked Service\n\nYou create an Azure Machine Learning linked service to register a Machine Learning batch scoring endpoint to a data factory.\n\n### Example\n\n    {\n      \"name\": \"AzureMLLinkedService\",\n      \"properties\": {\n        \"type\": \"AzureML\",\n        \"typeProperties\": {\n          \"mlEndpoint\": \"https://[batch scoring endpoint]/jobs\",\n          \"apiKey\": \"<apikey>\"\n        }\n      }\n    }\n\n### Properties\n\nProperty | Description | Required\n-------- | ----------- | --------\nType | The type property should be set to: **AzureML**. | Yes\nmlEndpoint | The batch scoring URL. | Yes\napiKey | The published workspace model’s API. | Yes\n\n\n## Azure SQL Linked Service\n\nYou create an Azure SQL linked service and use it with the [Stored Procedure Activity](data-factory-stored-proc-activity.md) to invoke a stored procedure from a Data Factory pipeline. See [Azure SQL Connector](data-factory-azure-sql-connector.md#azure-sql-linked-service-properties) article for details about this linked service.\n\n\n  \n\n\n\n     \n \n   \n\ntest\n"
}