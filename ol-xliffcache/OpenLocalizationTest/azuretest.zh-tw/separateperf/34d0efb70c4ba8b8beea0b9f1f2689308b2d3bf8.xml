{
  "nodes": [
    {
      "content": "Consume a Machine Learning web service | Microsoft Azure",
      "pos": [
        28,
        84
      ]
    },
    {
      "content": "Once a machine learning service is published, the RESTFul web service that is made available can be consumed either as request-response service or as a batch execution service.",
      "pos": [
        104,
        280
      ]
    },
    {
      "content": "How to consume an Azure Machine Learning web service that has been published from a Machine Learning experiment",
      "pos": [
        634,
        745
      ]
    },
    {
      "content": "Introduction",
      "pos": [
        750,
        762
      ]
    },
    {
      "content": "When published as a web service, Azure Machine Learning experiments provide a REST API that can be consumed by a wide range of devices and platforms.",
      "pos": [
        764,
        913
      ]
    },
    {
      "content": "This is because the simple REST API accepts and responds with JSON formatted messages.",
      "pos": [
        914,
        1000
      ]
    },
    {
      "content": "The Azure Machine Learning portal provides code that can be used to call the web service in R, C#, and Python.",
      "pos": [
        1001,
        1111
      ]
    },
    {
      "content": "But these services can be called with any programming language and from any device that satisfies three criteria:",
      "pos": [
        1112,
        1225
      ]
    },
    {
      "content": "Has a network connection",
      "pos": [
        1229,
        1253
      ]
    },
    {
      "content": "Has SSL capabilities to perform HTTPS requests",
      "pos": [
        1256,
        1302
      ]
    },
    {
      "content": "Has the ability to parse JSON (by hand or support libraries)",
      "pos": [
        1305,
        1365
      ]
    },
    {
      "content": "This means the services can be consumed from web applications, mobile applications, custom desktop applications and even from within Excel.",
      "pos": [
        1367,
        1506
      ]
    },
    {
      "content": "An Azure Machine Learning web service can be consumed in two different ways, either as a request-response service or as a batch execution service.",
      "pos": [
        1604,
        1750
      ]
    },
    {
      "content": "In each scenario the functionality is provided through the RESTFul web service that is made available for consumption once the experiment has been published.",
      "pos": [
        1751,
        1908
      ]
    },
    {
      "content": "Deploying a Machine Learning web service in Azure with an Azure web service end-point, where the service is automatically scaled based on usage, you can avoid upfront and ongoing costs for hardware resources.",
      "pos": [
        1909,
        2117
      ]
    },
    {
      "content": "For information about how to create and publish an Azure Machine Learning web service, see <bpt id=\"p1\">[</bpt>Publish an Azure Machine Learning web service<ept id=\"p1\">][publish]</ept>.",
      "pos": [
        2348,
        2496
      ]
    },
    {
      "content": "For a step-by-step walkthrough of creating a Machine Learning experiment and publishing it, see <bpt id=\"p1\">[</bpt>Develop a predictive solution by using Azure Machine Learning<ept id=\"p1\">][walkthrough]</ept>.",
      "pos": [
        2497,
        2670
      ]
    },
    {
      "content": "Request-Response Service (RRS)",
      "pos": [
        2822,
        2852
      ]
    },
    {
      "content": "A Request-Response Service (RRS) is a low-latency, highly scalable web service used to provide an interface to the stateless models that have been created and published from an Azure Machine Learning Studio experiment.",
      "pos": [
        2854,
        3072
      ]
    },
    {
      "content": "RRS accepts a single row of input parameters and generates a single row as output.",
      "pos": [
        3074,
        3156
      ]
    },
    {
      "content": "The output row can contain multiple columns.",
      "pos": [
        3157,
        3201
      ]
    },
    {
      "content": "An example for RRS is validating the authenticity of an application.",
      "pos": [
        3203,
        3271
      ]
    },
    {
      "content": "Hundreds to millions of installations of an application can be expected in this case.",
      "pos": [
        3272,
        3357
      ]
    },
    {
      "content": "When the application starts up, it makes a call to the RRS service with the relevant input.",
      "pos": [
        3358,
        3449
      ]
    },
    {
      "content": "The application then receives a validation response from the service that either allows or blocks the application from performing.",
      "pos": [
        3450,
        3580
      ]
    },
    {
      "content": "Batch Execution Service (BES)",
      "pos": [
        3586,
        3615
      ]
    },
    {
      "content": "A Batch Execution Service (BES) is a service that handles high volume, asynchronous, scoring of a batch of data records.",
      "pos": [
        3618,
        3738
      ]
    },
    {
      "content": "The input for the BES contains a batch of records from a variety of sources, such as blobs, tables in Azure, SQL Azure, HDInsight (results of a Hive Query, for example), and HTTP sources.",
      "pos": [
        3739,
        3926
      ]
    },
    {
      "content": "The output for the BES contains the results of the scoring.",
      "pos": [
        3927,
        3986
      ]
    },
    {
      "content": "Results are output to a file in Azure blob storage and data from the storage endpoint is returned in the response.",
      "pos": [
        3987,
        4101
      ]
    },
    {
      "content": "A BES would be useful when responses are not needed immediately, such as for regularly scheduled scoring for individuals or internet of things (IOT) devices.",
      "pos": [
        4103,
        4260
      ]
    },
    {
      "content": "Examples",
      "pos": [
        4265,
        4273
      ]
    },
    {
      "content": "To show how both RRS and BES work, we use an example Azure Web Service.",
      "pos": [
        4274,
        4345
      ]
    },
    {
      "content": "This service would be used in an IOT (Internet Of Things) scenario.",
      "pos": [
        4346,
        4413
      ]
    },
    {
      "content": "To keep it simple, our device only sends up one value, <ph id=\"ph1\">`cog_speed`</ph>, and gets a single answer back.",
      "pos": [
        4414,
        4512
      ]
    },
    {
      "content": "There are four pieces of information that are needed to call either the RRS or BES service.",
      "pos": [
        4515,
        4606
      ]
    },
    {
      "content": "This information is readily available from the service pages in <bpt id=\"p1\">[</bpt>Azure Machine Learning service pages<ept id=\"p1\">](https://studio.azureml.net)</ept> once the experiment has been published.",
      "pos": [
        4607,
        4777
      ]
    },
    {
      "content": "Click on the WEB SERVICES link at the left of the screen and you will see the published services.",
      "pos": [
        4778,
        4875
      ]
    },
    {
      "content": "To find information about a specific service, there are API help page links for both RRS and BES.",
      "pos": [
        4876,
        4973
      ]
    },
    {
      "pos": [
        4979,
        5039
      ],
      "content": "The <bpt id=\"p1\">**</bpt>service API Key<ept id=\"p1\">**</ept>, available on the services main page"
    },
    {
      "pos": [
        5044,
        5118
      ],
      "content": "The <bpt id=\"p1\">**</bpt>service URI<ept id=\"p1\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "pos": [
        5123,
        5211
      ],
      "content": "The expected <bpt id=\"p1\">**</bpt>API request body<ept id=\"p1\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "pos": [
        5216,
        5305
      ],
      "content": "The expected <bpt id=\"p1\">**</bpt>API response body<ept id=\"p1\">**</ept>, available on the API help page for the chosen service"
    },
    {
      "content": "In the two examples below, the C# language is used to illustrate the code needed and the targeted platform is a Windows 8 desktop.",
      "pos": [
        5307,
        5437
      ]
    },
    {
      "content": "RRS Example",
      "pos": [
        5444,
        5455
      ]
    },
    {
      "content": "On the API help page, aside from the URI, you will input and output definitions and code samples.",
      "pos": [
        5456,
        5553
      ]
    },
    {
      "content": "The API input is called out, for this service specifically, and is the payload of the API call.",
      "pos": [
        5554,
        5649
      ]
    },
    {
      "content": "Sample Request",
      "pos": [
        5654,
        5668
      ]
    },
    {
      "content": "Similarly, the API response is also called out, again for this service specifically.",
      "pos": [
        5963,
        6047
      ]
    },
    {
      "content": "Sample Response",
      "pos": [
        6051,
        6066
      ]
    },
    {
      "content": "Towards the bottom of the page you will find the code examples.",
      "pos": [
        6488,
        6551
      ]
    },
    {
      "content": "Below is the code sample for the C# implementation",
      "pos": [
        6552,
        6602
      ]
    },
    {
      "content": "Sample Code",
      "pos": [
        6626,
        6637
      ]
    },
    {
      "content": "BES Example",
      "pos": [
        9602,
        9613
      ]
    },
    {
      "content": "On the API help page, in addition to the URI, you will find information about several calls that are available.",
      "pos": [
        9614,
        9725
      ]
    },
    {
      "content": "Unlike the RRS service, the BES service is asynchronous.",
      "pos": [
        9726,
        9782
      ]
    },
    {
      "content": "This means that the BES API is simply queuing up a job to be executed, and the caller polls the job's status to see when it has completed.",
      "pos": [
        9783,
        9921
      ]
    },
    {
      "content": "Here are the operations currently supported for batch jobs:",
      "pos": [
        9922,
        9981
      ]
    },
    {
      "content": "Create (submit) a batch job",
      "pos": [
        9986,
        10013
      ]
    },
    {
      "content": "Start this batch job",
      "pos": [
        10017,
        10037
      ]
    },
    {
      "content": "Get the status or result of the batch job",
      "pos": [
        10041,
        10082
      ]
    },
    {
      "content": "Cancel a running batch job",
      "pos": [
        10086,
        10112
      ]
    },
    {
      "content": "1. Create a Batch Execution Job",
      "pos": [
        10116,
        10147
      ]
    },
    {
      "content": "When creating a batch job for your Azure Machine Learning service endpoint, one can specify several parameters that will define this batch execution:",
      "pos": [
        10151,
        10300
      ]
    },
    {
      "pos": [
        10304,
        10384
      ],
      "content": "<bpt id=\"p1\">**</bpt>Input<ept id=\"p1\">**</ept>: represents a blob reference to where the batch job's input is stored."
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>GlobalParameters<ept id=\"p1\">**</ept>: represents the set of global parameters one can define for their experiment.",
      "pos": [
        10387,
        10485
      ]
    },
    {
      "content": "An Azure Machine Learning experiment can have both required and optional parameters that customize the service's execution, and the caller is expected to provide all required parameters, if applicable.",
      "pos": [
        10486,
        10687
      ]
    },
    {
      "content": "These parameters are specified as a collection of key-value pairs.",
      "pos": [
        10688,
        10754
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>Outputs<ept id=\"p1\">**</ept>: if the service has defined one or more outputs, we allow the caller to redirect any of them to an Azure blob location of their choice.",
      "pos": [
        10757,
        10904
      ]
    },
    {
      "content": "This will allow you to save the service's output(s) in a preferred location and under a predictable name, as otherwise the output blob name is randomly generated.",
      "pos": [
        10905,
        11067
      ]
    },
    {
      "content": "<bpt id=\"p1\">**</bpt>NOTE<ept id=\"p1\">**</ept> that the service expects the output content, based on its type, to be saved as supported formats:",
      "pos": [
        11068,
        11174
      ]
    },
    {
      "pos": [
        11179,
        11230
      ],
      "content": "data set outputs: can save as <bpt id=\"p1\">**</bpt>.csv, .tsv, .arff<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        11235,
        11283
      ],
      "content": "trained model outputs: can save as <bpt id=\"p1\">**</bpt>.ilearner<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        11289,
        11610
      ],
      "content": "Output location overrides are specified as a collection of <bpt id=\"p1\">*</bpt>&lt;output name, blob reference&gt;<ept id=\"p1\">*</ept> pairs, where the <bpt id=\"p2\">*</bpt>output name<ept id=\"p2\">*</ept> is the user defined name for a specific output node (also shown on the service's API help page), and <bpt id=\"p3\">*</bpt>blob reference<ept id=\"p3\">*</ept> is a reference to an Azure blob location where the output is to be redirected to."
    },
    {
      "content": "All these job creation parameters can be optional depending on the nature of your service.",
      "pos": [
        11614,
        11704
      ]
    },
    {
      "content": "For example, services with no input node defined, do not require passing in an <bpt id=\"p1\">*</bpt>Input<ept id=\"p1\">*</ept> parameter, and the output location override feature is completely optional, as outputs will otherwise be stored in the default storage account that was set up for your Azure Machine Learning workspace.",
      "pos": [
        11705,
        11993
      ]
    },
    {
      "content": "Below, we show a sample request payload, as passed to the REST API, for a service where only the input information is passed in:",
      "pos": [
        11994,
        12122
      ]
    },
    {
      "content": "Sample Request",
      "pos": [
        12126,
        12140
      ]
    },
    {
      "content": "The response to the batch job creation API is the unique job id that was associated to your job.",
      "pos": [
        12484,
        12580
      ]
    },
    {
      "content": "This id is very important because it provides the only means for you to reference this job in the system for other operations.",
      "pos": [
        12581,
        12707
      ]
    },
    {
      "content": "Sample Response",
      "pos": [
        12715,
        12730
      ]
    },
    {
      "content": "2. Start a Batch Execution Job",
      "pos": [
        12790,
        12820
      ]
    },
    {
      "content": "Creating a batch job only registers it within the system, and places it in a <bpt id=\"p1\">*</bpt>Not started<ept id=\"p1\">*</ept> state.",
      "pos": [
        12824,
        12921
      ]
    },
    {
      "content": "To actually schedule the job for execution, you will have to call the <bpt id=\"p1\">**</bpt>start<ept id=\"p1\">**</ept> API described on the service endpoint's API help page and provide the job id obtained when the job was created.",
      "pos": [
        12922,
        13113
      ]
    },
    {
      "content": "3. Get the Status of a Batch Execution Job",
      "pos": [
        13119,
        13161
      ]
    },
    {
      "content": "You can poll the status of your asynchronous batch job at any time by passing the job's id to the GetJobStatus API.",
      "pos": [
        13165,
        13280
      ]
    },
    {
      "content": "The API response will contain an indicator of the job's current state, as well as the actual results of the batch job if this has completed successfully.",
      "pos": [
        13281,
        13434
      ]
    },
    {
      "content": "In the case of an error, more information about the actual reasons behind the failure are returned in the <bpt id=\"p1\">*</bpt>Details<ept id=\"p1\">*</ept> property.",
      "pos": [
        13435,
        13560
      ]
    },
    {
      "content": "Response Payload",
      "pos": [
        13565,
        13581
      ]
    },
    {
      "pos": [
        13688,
        13729
      ],
      "content": "<bpt id=\"p1\">*</bpt>StatusCode<ept id=\"p1\">*</ept> can be one of the following:"
    },
    {
      "content": "Not started",
      "pos": [
        13733,
        13744
      ]
    },
    {
      "content": "Running",
      "pos": [
        13747,
        13754
      ]
    },
    {
      "content": "Failed",
      "pos": [
        13757,
        13763
      ]
    },
    {
      "content": "Cancelled",
      "pos": [
        13766,
        13775
      ]
    },
    {
      "content": "Finished",
      "pos": [
        13778,
        13786
      ]
    },
    {
      "content": "The <bpt id=\"p1\">*</bpt>Results<ept id=\"p1\">*</ept> property is populated only if the job has completed successfully (it is <bpt id=\"p2\">**</bpt>null<ept id=\"p2\">**</ept> otherwise).",
      "pos": [
        13788,
        13894
      ]
    },
    {
      "content": "Upon the job's completion and if the service has at least one output node defined, the results will be returned as a collection of <bpt id=\"p1\">*</bpt>[output name, blob reference]<ept id=\"p1\">*</ept> pairs, where the blob reference is a SAS read-only reference to the blob containing the actual result.",
      "pos": [
        13895,
        14160
      ]
    },
    {
      "content": "Sample Response",
      "pos": [
        14165,
        14180
      ]
    },
    {
      "content": "4. Cancel a Batch Execution Job",
      "pos": [
        15114,
        15145
      ]
    },
    {
      "content": "A running batch job can be cancelled at any time by calling the designated CancelJob API and passing in the job's id.",
      "pos": [
        15149,
        15266
      ]
    },
    {
      "content": "This would be done for various reasons such as that the job is taking too long to complete.",
      "pos": [
        15267,
        15358
      ]
    },
    {
      "pos": [
        15368,
        15457
      ],
      "content": "Using the <bpt id=\"p1\">[</bpt>BES SDK<ept id=\"p1\">](machine-learning-consume-web-services.md#batch-execution-service-sdk)</ept>"
    },
    {
      "content": "The <bpt id=\"p1\">[</bpt>BES SDK Nugget package<ept id=\"p1\">](http://www.nuget.org/packages/Microsoft.Azure.MachineLearning/)</ept> provides functions that simplify calling BES to score in batch mode.",
      "pos": [
        15459,
        15620
      ]
    },
    {
      "content": "To install the Nuget package, in Visual Studio, go to Tools, then select Nuget Package Manager, and click Package Manager Console.",
      "pos": [
        15621,
        15751
      ]
    },
    {
      "content": "AzureML experiments that are published as web services can include web service input modules which means they expect the input to be provided through the web service call in the form of a reference to a blob location.",
      "pos": [
        15754,
        15971
      ]
    },
    {
      "content": "There is also the option of not using a web service input module and using a Reader module instead.",
      "pos": [
        15972,
        16071
      ]
    },
    {
      "content": "In this case, the Reader typically would read from a SQL DB using a query at run time to get the data.",
      "pos": [
        16072,
        16174
      ]
    },
    {
      "content": "Web service parameters can be used to dynamically point to other servers or tables, etc. The SDK supports both of these patterns.",
      "pos": [
        16175,
        16304
      ]
    },
    {
      "content": "The code sample below demonstrates how you can submit and monitor a batch job against an Azure Machine Learning service endpoint using the BES SDK.",
      "pos": [
        16306,
        16453
      ]
    },
    {
      "content": "Note the comments for details on the settings and calls.",
      "pos": [
        16454,
        16510
      ]
    },
    {
      "content": "Sample Code",
      "pos": [
        16519,
        16530
      ]
    },
    {
      "content": "test",
      "pos": [
        23383,
        23387
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"Consume a Machine Learning web service | Microsoft Azure\" \n    description=\"Once a machine learning service is published, the RESTFul web service that is made available can be consumed either as request-response service or as a batch execution service.\" \n    services=\"machine-learning\" \n    solutions=\"big-data\" \n    documentationCenter=\"\" \n    authors=\"bradsev\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\" />\n\n<tags \n    ms.service=\"machine-learning\" \n    ms.devlang=\"na\" \n    ms.topic=\"article\" \n    ms.tgt_pltfrm=\"na\" \n    ms.workload=\"tbd\" \n    ms.date=\"06/29/2015\" \n    ms.author=\"bradsev\" />\n\n\n# How to consume an Azure Machine Learning web service that has been published from a Machine Learning experiment\n\n## Introduction\n\nWhen published as a web service, Azure Machine Learning experiments provide a REST API that can be consumed by a wide range of devices and platforms. This is because the simple REST API accepts and responds with JSON formatted messages. The Azure Machine Learning portal provides code that can be used to call the web service in R, C#, and Python. But these services can be called with any programming language and from any device that satisfies three criteria:\n\n* Has a network connection\n* Has SSL capabilities to perform HTTPS requests\n* Has the ability to parse JSON (by hand or support libraries)\n\nThis means the services can be consumed from web applications, mobile applications, custom desktop applications and even from within Excel.\n\n[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]  \n\nAn Azure Machine Learning web service can be consumed in two different ways, either as a request-response service or as a batch execution service. In each scenario the functionality is provided through the RESTFul web service that is made available for consumption once the experiment has been published. Deploying a Machine Learning web service in Azure with an Azure web service end-point, where the service is automatically scaled based on usage, you can avoid upfront and ongoing costs for hardware resources.\n\n<!-- When this article gets published, fix the link and uncomment\nFor more information on how to manage Azure Machine Learning web service endpoints using the REST API, see **Azure machine learning web service endpoints**. \n-->\n\nFor information about how to create and publish an Azure Machine Learning web service, see [Publish an Azure Machine Learning web service][publish]. For a step-by-step walkthrough of creating a Machine Learning experiment and publishing it, see [Develop a predictive solution by using Azure Machine Learning][walkthrough].\n\n[publish]: machine-learning-publish-a-machine-learning-web-service.md\n[walkthrough]: machine-learning-walkthrough-develop-predictive-solution.md\n\n\n## Request-Response Service (RRS)\n\nA Request-Response Service (RRS) is a low-latency, highly scalable web service used to provide an interface to the stateless models that have been created and published from an Azure Machine Learning Studio experiment.\n\nRRS accepts a single row of input parameters and generates a single row as output. The output row can contain multiple columns.\n\nAn example for RRS is validating the authenticity of an application. Hundreds to millions of installations of an application can be expected in this case. When the application starts up, it makes a call to the RRS service with the relevant input. The application then receives a validation response from the service that either allows or blocks the application from performing.\n\n\n## Batch Execution Service (BES)\n \nA Batch Execution Service (BES) is a service that handles high volume, asynchronous, scoring of a batch of data records. The input for the BES contains a batch of records from a variety of sources, such as blobs, tables in Azure, SQL Azure, HDInsight (results of a Hive Query, for example), and HTTP sources. The output for the BES contains the results of the scoring. Results are output to a file in Azure blob storage and data from the storage endpoint is returned in the response.\n\nA BES would be useful when responses are not needed immediately, such as for regularly scheduled scoring for individuals or internet of things (IOT) devices.\n\n## Examples\nTo show how both RRS and BES work, we use an example Azure Web Service. This service would be used in an IOT (Internet Of Things) scenario. To keep it simple, our device only sends up one value, `cog_speed`, and gets a single answer back. \n\nThere are four pieces of information that are needed to call either the RRS or BES service. This information is readily available from the service pages in [Azure Machine Learning service pages](https://studio.azureml.net) once the experiment has been published. Click on the WEB SERVICES link at the left of the screen and you will see the published services. To find information about a specific service, there are API help page links for both RRS and BES.\n\n1.  The **service API Key**, available on the services main page\n2.  The **service URI**, available on the API help page for the chosen service\n3.  The expected **API request body**, available on the API help page for the chosen service\n4.  The expected **API response body**, available on the API help page for the chosen service\n\nIn the two examples below, the C# language is used to illustrate the code needed and the targeted platform is a Windows 8 desktop. \n\n### RRS Example\nOn the API help page, aside from the URI, you will input and output definitions and code samples. The API input is called out, for this service specifically, and is the payload of the API call. \n\n**Sample Request**\n\n    {\n      \"Inputs\": {\n        \"input1\": {\n          \"ColumnNames\": [\n            \"cog_speed\"\n          ],\n          \"Values\": [\n            [\n              \"0\"\n            ],\n            [\n              \"1\"\n            ]\n          ]\n        }\n      },\n      \"GlobalParameters\": {}\n    }\n\n\nSimilarly, the API response is also called out, again for this service specifically.\n\n**Sample Response**\n\n    {\n      \"Results\": {\n        \"output1\": {\n          \"type\": \"DataTable\",\n          \"value\": {\n            \"ColumnNames\": [\n              \"cog_speed\"\n            ],\n            \"ColumnTypes\": [\n              \"Numeric\"\n            ].\n          \"Values\": [\n            [\n              \"0\"\n            ],\n            [\n              \"1\"\n            ]\n          ]\n        }\n      },\n      \"GlobalParameters\": {}\n    }\n\nTowards the bottom of the page you will find the code examples. Below is the code sample for the C# implementation \n                   \n**Sample Code**\n\n    using System;\n    using System.Collections.Generic;\n    using System.IO;\n    using System.Net.Http;\n    using System.Net.Http.Formatting;\n    using System.Net.Http.Headers;\n    using System.Text;\n    using System.Threading.Tasks;\n    \n    namespace CallRequestResponseService\n    {\n        public class StringTable\n        {\n            public string[] ColumnNames { get; set; }\n            public string[,] Values { get; set; }\n        }\n    \n        class Program\n        {\n            static void Main(string[] args)\n            {\n                InvokeRequestResponseService().Wait();\n            }\n    \n            static async Task InvokeRequestResponseService()\n            {\n                using (var client = new HttpClient())\n                {\n                    var scoreRequest = new\n                    {\n                        Inputs = new Dictionary<string, StringTable> () { \n                            { \n                                \"input1\", \n                                new StringTable() \n                                {\n                                    ColumnNames = new string[] {\"cog_speed\"},\n                                    Values = new string[,] {  { \"0\"},  { \"1\"}  }\n                                }\n                            },\n                        GlobalParameters = new Dictionary<string, string>() { }\n                    };\n                    \n                    const string apiKey = \"abc123\"; // Replace this with the API key for the web service\n                    client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue( \"Bearer\", apiKey);\n    \n                    client.BaseAddress = new Uri(\"https://ussouthcentral.services.azureml.net/workspaces/<workspace id>/services/<service id>/execute?api-version=2.0&details=true\");\n                    \n                    // WARNING: The 'await' statement below can result in a deadlock if you are calling this code from the UI thread of an ASP.Net application.\n                    // One way to address this would be to call ConfigureAwait(false) so that the execution does not attempt to resume on the original context.\n                    // For instance, replace code such as:\n                    //      result = await DoSomeTask()\n                    // with the following:\n                    //      result = await DoSomeTask().ConfigureAwait(false)\n\n                    HttpResponseMessage response = await client.PostAsJsonAsync(\"\", scoreRequest);\n    \n                    if (response.IsSuccessStatusCode)\n                    {\n                        string result = await response.Content.ReadAsStringAsync();\n                        Console.WriteLine(\"Result: {0}\", result);\n                    }\n                    else\n                    {\n                        Console.WriteLine(\"Failed with status code: {0}\", response.StatusCode);\n                    }\n                }\n            }\n        }\n    }\n\n### BES Example\nOn the API help page, in addition to the URI, you will find information about several calls that are available. Unlike the RRS service, the BES service is asynchronous. This means that the BES API is simply queuing up a job to be executed, and the caller polls the job's status to see when it has completed. Here are the operations currently supported for batch jobs:\n\n1. Create (submit) a batch job\n1. Start this batch job\n1. Get the status or result of the batch job\n1. Cancel a running batch job\n\n**1. Create a Batch Execution Job**\n\nWhen creating a batch job for your Azure Machine Learning service endpoint, one can specify several parameters that will define this batch execution:\n\n* **Input**: represents a blob reference to where the batch job's input is stored.\n* **GlobalParameters**: represents the set of global parameters one can define for their experiment. An Azure Machine Learning experiment can have both required and optional parameters that customize the service's execution, and the caller is expected to provide all required parameters, if applicable. These parameters are specified as a collection of key-value pairs.\n* **Outputs**: if the service has defined one or more outputs, we allow the caller to redirect any of them to an Azure blob location of their choice. This will allow you to save the service's output(s) in a preferred location and under a predictable name, as otherwise the output blob name is randomly generated. **NOTE** that the service expects the output content, based on its type, to be saved as supported formats:\n  - data set outputs: can save as **.csv, .tsv, .arff**\n  - trained model outputs: can save as **.ilearner**\n  \n  Output location overrides are specified as a collection of *<output name, blob reference>* pairs, where the *output name* is the user defined name for a specific output node (also shown on the service's API help page), and *blob reference* is a reference to an Azure blob location where the output is to be redirected to.\n  \nAll these job creation parameters can be optional depending on the nature of your service. For example, services with no input node defined, do not require passing in an *Input* parameter, and the output location override feature is completely optional, as outputs will otherwise be stored in the default storage account that was set up for your Azure Machine Learning workspace. Below, we show a sample request payload, as passed to the REST API, for a service where only the input information is passed in:\n\n**Sample Request**\n\n    {\n      \"Input\": {\n        \"ConnectionString\":     \n        \"DefaultEndpointsProtocol=https;AccountName=mystorageacct;AccountKey=mystorageacctKey\",\n        \"RelativeLocation\": \"/mycontainer/mydatablob.csv\",\n        \"BaseLocation\": null,\n        \"SasBlobToken\": null\n      },\n      \"Outputs\": null,\n      \"GlobalParameters\": null\n    }\n\nThe response to the batch job creation API is the unique job id that was associated to your job. This id is very important because it provides the only means for you to reference this job in the system for other operations.  \n  \n**Sample Response**\n\n    \"539d0bc2fde945b6ac986b851d0000f0\" // The JOB_ID\n\n**2. Start a Batch Execution Job**\n\nCreating a batch job only registers it within the system, and places it in a *Not started* state. To actually schedule the job for execution, you will have to call the **start** API described on the service endpoint's API help page and provide the job id obtained when the job was created.\n  \n**3. Get the Status of a Batch Execution Job**\n\nYou can poll the status of your asynchronous batch job at any time by passing the job's id to the GetJobStatus API. The API response will contain an indicator of the job's current state, as well as the actual results of the batch job if this has completed successfully. In the case of an error, more information about the actual reasons behind the failure are returned in the *Details* property.\n \n**Response Payload**\n\n    {\n        \"StatusCode\": STATUS_CODE,\n        \"Results\": RESULTS,\n        \"Details\": DETAILS\n    }\n\n*StatusCode* can be one of the following:\n\n* Not started\n* Running\n* Failed\n* Cancelled\n* Finished\n\nThe *Results* property is populated only if the job has completed successfully (it is **null** otherwise). Upon the job's completion and if the service has at least one output node defined, the results will be returned as a collection of *[output name, blob reference]* pairs, where the blob reference is a SAS read-only reference to the blob containing the actual result. \n\n**Sample Response**\n\n    {\n        \"Status Code\": \"Finished\",\n        \"Results\":\n        {\n            \"dataOutput\":\n            {              \n                \"ConnectionString\": null,\n                \"RelativeLocation\": \"outputs/dataOutput.csv\",\n                \"BaseLocation\": \"https://mystorageaccount.blob.core.windows.net/\",\n                \"SasBlobToken\": \"?sv=2013-08-15&sr=b&sig=ABCD&st=2015-04-04T05%3A39%3A55Z&se=2015-04-05T05%3A44%3A55Z&sp=r\"              \n            },\n            \"trainedModelOutput\":\n            {              \n                \"ConnectionString\": null,\n                \"RelativeLocation\": \"models/trainedModel.ilearner\",\n                \"BaseLocation\": \"https://mystorageaccount.blob.core.windows.net/\",\n                \"SasBlobToken\": \"?sv=2013-08-15&sr=b&sig=EFGH%3D&st=2015-04-04T05%3A39%3A55Z&se=2015-04-05T05%3A44%3A55Z&sp=r\"              \n            },           \n        },\n        \"Details\": null\n    }\n\n**4. Cancel a Batch Execution Job**\n\nA running batch job can be cancelled at any time by calling the designated CancelJob API and passing in the job's id. This would be done for various reasons such as that the job is taking too long to complete. \n\n\n\n#### Using the [BES SDK](machine-learning-consume-web-services.md#batch-execution-service-sdk)\n\nThe [BES SDK Nugget package](http://www.nuget.org/packages/Microsoft.Azure.MachineLearning/) provides functions that simplify calling BES to score in batch mode. To install the Nuget package, in Visual Studio, go to Tools, then select Nuget Package Manager, and click Package Manager Console. \n\nAzureML experiments that are published as web services can include web service input modules which means they expect the input to be provided through the web service call in the form of a reference to a blob location. There is also the option of not using a web service input module and using a Reader module instead. In this case, the Reader typically would read from a SQL DB using a query at run time to get the data. Web service parameters can be used to dynamically point to other servers or tables, etc. The SDK supports both of these patterns.\n\nThe code sample below demonstrates how you can submit and monitor a batch job against an Azure Machine Learning service endpoint using the BES SDK. Note the comments for details on the settings and calls.\n\n#### **Sample Code**\n\n    // This code requires the Nuget package Microsoft.Azure.MachineLearning to be installed.\n    // Instructions for doing this in Visual Studio:\n    // Tools -> Nuget Package Manager -> Package Manager Console\n    // Install-Package Microsoft.Azure.MachineLearning \n    \n      using System;\n      using System.Collections.Generic;\n      using System.Threading.Tasks;\n      \n      using Microsoft.Azure.MachineLearning;\n      using Microsoft.Azure.MachineLearning.Contracts;\n      using Microsoft.Azure.MachineLearning.Exceptions;\n    \n    namespace CallBatchExecutionService\n    {\n        class Program\n        {\n            static void Main(string[] args)\n            {               \n                InvokeBatchExecutionService().Wait();\n            }\n    \n            static async Task InvokeBatchExecutionService()\n            {\n                // First collect and fill in the URI and access key for your web service endpoint.\n                // These are available on your service's API help page.\n                var endpointUri = \"https://ussouthcentral.services.azureml.net/workspaces/YOUR_WORKSPACE_ID/services/YOUR_SERVICE_ENDPOINT_ID/\";\n                string accessKey = \"YOUR_SERVICE_ENDPOINT_ACCESS_KEY\";\n    \n                // Create an Azure Machine Learning runtime client for this endpoint\n                var runtimeClient = new RuntimeClient(endpointUri, accessKey);\n    \n                // Define the request information for your batch job. This information can contain:\n                // -- A reference to the AzureBlob containing the input for your job run\n                // -- A set of values for global parameters defined as part of your experiment and service\n                // -- A set of output blob locations that allow you to redirect the job's results\n    \n                // NOTE: This sample is applicable, as is, for a service with explicit input port and\n                // potential global parameters. Also, we choose to also demo how you could override the\n                // location of one of the output blobs that could be generated by your service. You might \n                // need to tweak these features to adjust the sample to your service.\n                //\n                // All of these properties of a BatchJobRequest shown below can be optional, depending on\n                // your service, so it is not required to specify all with any request.  If you do not want to\n                // use any of the parameters, a null value should be passed in its place.\n                \n                // Define the reference to the blob containing your input data. You can refer to this blob by its\n                    // connection string / container / blob name values; alternatively, we also support references \n                    // based on a blob SAS URI\n                    \n                    BlobReference inputBlob = BlobReference.CreateFromConnectionStringData(connectionString:                                         \"DefaultEndpointsProtocol=https;AccountName=YOUR_ACCOUNT_NAME;AccountKey=YOUR_ACCOUNT_KEY\",\n                        containerName: \"YOUR_CONTAINER_NAME\",\n                        blobName: \"YOUR_INPUT_BLOB_NAME\");\n                              \n                    // If desired, one can override the location where the job outputs are to be stored, by passing in\n                    // the storage account details and name of the blob where we want the output to be redirected to.\n                    \n                    var outputLocations = new Dictionary<string, BlobReference>\n                        {\n                          {\n                           \"YOUR_OUTPUT_NODE_NAME\", \n                           BlobReference.CreateFromConnectionStringData(                                     connectionString: \"DefaultEndpointsProtocol=https;AccountName=YOUR_ACCOUNT_NAME;AccountKey=YOUR_ACCOUNT_KEY\",\n                                containerName: \"YOUR_CONTAINER_NAME\",\n                                blobName: \"YOUR_DESIRED_OUTPUT_BLOB_NAME\")\n                           }\n                        };\n                \n                // If applicable, you can also set the global parameters for your service\n                var globalParameters = new Dictionary<string, string>\n                {\n                    { \"YOUR_GLOBAL_PARAMETER\", \"PARAMETER_VALUE\" }\n                };\n                    \n                var jobRequest = new BatchJobRequest\n                {\n                    Input = inputBlob,\n                    GlobalParameters = globalParameters,\n                    Outputs = outputLocations\n                };\n    \n                try\n                {\n                    // Register the batch job with the system, which will grant you access to a job object\n                    BatchJob job = await runtimeClient.RegisterBatchJobAsync(jobRequest);\n    \n                    // Start the job to allow it to be scheduled in the running queue\n                    await job.StartAsync();\n    \n                    // Wait for the job's completion and handle the output\n                    BatchJobStatus jobStatus = await job.WaitForCompletionAsync();\n                    if (jobStatus.JobState == JobState.Finished)\n                    {\n                        // Process job outputs\n                        Console.WriteLine(@\"Job {0} has completed successfully and returned {1} outputs\", job.Id, jobStatus.Results.Count);\n                        foreach (var output in jobStatus.Results)\n                        {\n                            Console.WriteLine(@\"\\t{0}: {1}\", output.Key, output.Value.AbsoluteUri);\n                        }\n                    }\n                    else if (jobStatus.JobState == JobState.Failed)\n                    {\n                        // Handle job failure\n                        Console.WriteLine(@\"Job {0} has failed with this error: {1}\", job.Id, jobStatus.Details);\n                    }\n                }\n                catch (ArgumentException aex)\n                {\n                    Console.WriteLine(\"Argument {0} is invalid: {1}\", aex.ParamName, aex.Message);\n                }\n                catch (RuntimeException runtimeError)\n                {\n                    Console.WriteLine(\"Runtime error occurred: {0} - {1}\", runtimeError.ErrorCode, runtimeError.Message);\n                    Console.WriteLine(\"Error details:\");\n                    foreach (var errorDetails in runtimeError.Details)\n                    {\n                        Console.WriteLine(\"\\t{0} - {1}\", errorDetails.Code, errorDetails.Message);\n                    }\n                }\n                catch (Exception ex)\n                {\n                    Console.WriteLine(\"Unexpected error occurred: {0} - {1}\", ex.GetType().Name, ex.Message);\n                }\n            }\n        }\n    }\n\n \n\ntest\n"
}