<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Linux tutorial: Get started with Hadoop and Hive | Microsoft Azure</source>
          <target state="new">Linux tutorial: Get started with Hadoop and Hive | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Follow this Linux tutorial to get started using Hadoop in HDInsight.</source>
          <target state="new">Follow this Linux tutorial to get started using Hadoop in HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Learn how to provision Linux clusters, and query data with Hive.</source>
          <target state="new">Learn how to provision Linux clusters, and query data with Hive.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Hadoop tutorial: Get started using Hadoop with Hive in HDInsight on Linux (preview)</source>
          <target state="new">Hadoop tutorial: Get started using Hadoop with Hive in HDInsight on Linux (preview)</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>[AZURE.SELECTOR]</source>
          <target state="new">[AZURE.SELECTOR]</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Linux</source>
          <target state="new">Linux</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This Hadoop tutorial gets you started quickly with Azure HDInsight on Linux by showing you how to provision an Hadoop cluster on Linux and run a Hive query.</source>
          <target state="new">This Hadoop tutorial gets you started quickly with Azure HDInsight on Linux by showing you how to provision an Hadoop cluster on Linux and run a Hive query.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you are new to Hadoop and big data, you can read more about the terms <ph id="ph2">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510084" target="_blank"&gt;</ph>Apache Hadoop<ph id="ph3">&lt;/a&gt;</ph>, <ph id="ph4">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510086" target="_blank"&gt;</ph>MapReduce<ph id="ph5">&lt;/a&gt;</ph>, <ph id="ph6">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510087" target="_blank"&gt;</ph>Hadoop Distributed File System (HDFS)<ph id="ph7">&lt;/a&gt;</ph>, and <ph id="ph8">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510085" target="_blank"&gt;</ph>Hive<ph id="ph9">&lt;/a&gt;</ph>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you are new to Hadoop and big data, you can read more about the terms <ph id="ph2">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510084" target="_blank"&gt;</ph>Apache Hadoop<ph id="ph3">&lt;/a&gt;</ph>, <ph id="ph4">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510086" target="_blank"&gt;</ph>MapReduce<ph id="ph5">&lt;/a&gt;</ph>, <ph id="ph6">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510087" target="_blank"&gt;</ph>Hadoop Distributed File System (HDFS)<ph id="ph7">&lt;/a&gt;</ph>, and <ph id="ph8">&lt;a href="http://go.microsoft.com/fwlink/?LinkId=510085" target="_blank"&gt;</ph>Hive<ph id="ph9">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>To understand how HDInsight enables Hadoop in Azure, see <bpt id="p1">[</bpt>Introduction to Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-introduction.md)</ept>.</source>
          <target state="new">To understand how HDInsight enables Hadoop in Azure, see <bpt id="p1">[</bpt>Introduction to Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-introduction.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>What does this tutorial accomplish?</source>
          <target state="new">What does this tutorial accomplish?</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Assume you have a large unstructured data set and you want to run queries on it to extract some meaningful information.</source>
          <target state="new">Assume you have a large unstructured data set and you want to run queries on it to extract some meaningful information.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Here's how you achieve this:</source>
          <target state="new">Here's how you achieve this:</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Hadoop tutorial steps: Create a Storage account; provision a Hadoop cluster; query data with Hive.</source>
          <target state="new">Hadoop tutorial steps: Create a Storage account; provision a Hadoop cluster; query data with Hive.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Prerequisites</source>
          <target state="new">Prerequisites</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Before you begin this Linux tutorial for Hadoop, you must have the following:</source>
          <target state="new">Before you begin this Linux tutorial for Hadoop, you must have the following:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>An Azure subscription<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Get Azure free trial<ept id="p1">](http://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Secure Shell (SSH) keys<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Secure Shell (SSH) keys<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>If you want to remote into a Linux cluster by using SSH with a key instead of a password.</source>
          <target state="new">If you want to remote into a Linux cluster by using SSH with a key instead of a password.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Using a key is the recommended method as it is more secure.</source>
          <target state="new">Using a key is the recommended method as it is more secure.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>For instructions on how to generate SSH keys, refer to the following articles:</source>
          <target state="new">For instructions on how to generate SSH keys, refer to the following articles:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>From a Linux computer - <bpt id="p1">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Linux, Unix, or OS X<ept id="p1">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>.</source>
          <target state="new">From a Linux computer - <bpt id="p1">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Linux, Unix, or OS X<ept id="p1">](hdinsight-hadoop-linux-use-ssh-unix.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>From a Windows computer - <bpt id="p1">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Windows<ept id="p1">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>.</source>
          <target state="new">From a Windows computer - <bpt id="p1">[</bpt>Use SSH with Linux-based HDInsight (Hadoop) from Windows<ept id="p1">](hdinsight-hadoop-linux-use-ssh-windows.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Estimated time to complete:<ept id="p1">**</ept> 30 minutes</source>
          <target state="new"><bpt id="p1">**</bpt>Estimated time to complete:<ept id="p1">**</ept> 30 minutes</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="provision"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Provision an HDInsight cluster on Linux</source>
          <target state="new"><ph id="ph1">&lt;a name="provision"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Provision an HDInsight cluster on Linux</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>When you provision a cluster, you provision Azure compute resources that contain Hadoop and related applications.</source>
          <target state="new">When you provision a cluster, you provision Azure compute resources that contain Hadoop and related applications.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>In this section, you provision an HDInsight version 3.2 cluster.</source>
          <target state="new">In this section, you provision an HDInsight version 3.2 cluster.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>You can also create Hadoop clusters for other versions.</source>
          <target state="new">You can also create Hadoop clusters for other versions.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Provision HDInsight clusters using custom options<ept id="p1">][hdinsight-provision]</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Provision HDInsight clusters using custom options<ept id="p1">][hdinsight-provision]</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>For information about HDInsight versions and their SLAs, see <bpt id="p1">[</bpt>HDInsight component versioning<ept id="p1">](hdinsight-component-versioning.md)</ept>.</source>
          <target state="new">For information about HDInsight versions and their SLAs, see <bpt id="p1">[</bpt>HDInsight component versioning<ept id="p1">](hdinsight-component-versioning.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>  You can also create Hadoop clusters running the Windows Server operating system.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>  You can also create Hadoop clusters running the Windows Server operating system.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Get Started with HDInsight on Windows<ept id="p1">](hdinsight-hadoop-tutorial-get-started-windows.md)</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Get Started with HDInsight on Windows<ept id="p1">](hdinsight-hadoop-tutorial-get-started-windows.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>To provision an HDInsight cluster</source>
          <target state="new">To provision an HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Sign in to the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">](https://ms.portal.azure.com/)</ept>.</source>
          <target state="new">Sign in to the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">](https://ms.portal.azure.com/)</ept>.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>NEW<ept id="p1">**</ept>, Click <bpt id="p2">**</bpt>Data Analytics<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>HDInsight<ept id="p3">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>NEW<ept id="p1">**</ept>, Click <bpt id="p2">**</bpt>Data Analytics<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>HDInsight<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Creating a new cluster in the Azure Preview Portal</source>
          <target state="new">Creating a new cluster in the Azure Preview Portal</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Enter a <bpt id="p1">**</bpt>Cluster Name<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Hadoop<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Cluster Type<ept id="p3">**</ept>, and from the <bpt id="p4">**</bpt>Cluster Operating System<ept id="p4">**</ept> drop-down, select <bpt id="p5">**</bpt>Ubuntu<ept id="p5">**</ept>.</source>
          <target state="new">Enter a <bpt id="p1">**</bpt>Cluster Name<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Hadoop<ept id="p2">**</ept> for the <bpt id="p3">**</bpt>Cluster Type<ept id="p3">**</ept>, and from the <bpt id="p4">**</bpt>Cluster Operating System<ept id="p4">**</ept> drop-down, select <bpt id="p5">**</bpt>Ubuntu<ept id="p5">**</ept>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>A green check will appear beside the cluster name if it is available.</source>
          <target state="new">A green check will appear beside the cluster name if it is available.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Enter cluster name and type</source>
          <target state="new">Enter cluster name and type</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>If you have more than one subscription, click the <bpt id="p1">**</bpt>Subscription<ept id="p1">**</ept> entry to select the Azure subscription that will be used for the cluster.</source>
          <target state="new">If you have more than one subscription, click the <bpt id="p1">**</bpt>Subscription<ept id="p1">**</ept> entry to select the Azure subscription that will be used for the cluster.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Resource Group<ept id="p1">**</ept> to see a list of existing resource groups and then select the one to create the cluster in.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Resource Group<ept id="p1">**</ept> to see a list of existing resource groups and then select the one to create the cluster in.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Or, you can click <bpt id="p1">**</bpt>Create New<ept id="p1">**</ept> and then enter the name of the new resource group.</source>
          <target state="new">Or, you can click <bpt id="p1">**</bpt>Create New<ept id="p1">**</ept> and then enter the name of the new resource group.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>A green check will appear to indicate if the new group name is available.</source>
          <target state="new">A green check will appear to indicate if the new group name is available.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This entry will default to one of your existing resource groups, if any are available.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This entry will default to one of your existing resource groups, if any are available.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Credentials<ept id="p1">**</ept> and then enter a password for the admin user.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Credentials<ept id="p1">**</ept> and then enter a password for the admin user.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>You must also enter an <bpt id="p1">**</bpt>SSH Username<ept id="p1">**</ept> and either a <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> or <bpt id="p3">**</bpt>PUBLIC KEY<ept id="p3">**</ept>, which will be used to authenticate the SSH user.</source>
          <target state="new">You must also enter an <bpt id="p1">**</bpt>SSH Username<ept id="p1">**</ept> and either a <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> or <bpt id="p3">**</bpt>PUBLIC KEY<ept id="p3">**</ept>, which will be used to authenticate the SSH user.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Using a public key is the recommended approach.</source>
          <target state="new">Using a public key is the recommended approach.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> at the bottom to save the credentials configuration.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> at the bottom to save the credentials configuration.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Provide cluster credentials</source>
          <target state="new">Provide cluster credentials</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>For more information on using SSH with HDInsight, see one of the following articles:</source>
          <target state="new">For more information on using SSH with HDInsight, see one of the following articles:</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X</source>
          <target state="new">Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Use SSH with Linux-based Hadoop on HDInsight from Windows</source>
          <target state="new">Use SSH with Linux-based Hadoop on HDInsight from Windows</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Data Source<ept id="p1">**</ept> to choose an existing data source for the cluster, or create a new one.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Data Source<ept id="p1">**</ept> to choose an existing data source for the cluster, or create a new one.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>When you provision a Hadoop cluster in HDInsight, you specify an Azure Storage account.</source>
          <target state="new">When you provision a Hadoop cluster in HDInsight, you specify an Azure Storage account.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>A specific Blob storage container from that account is designated as the default file system, like in the Hadoop distributed file system (HDFS).</source>
          <target state="new">A specific Blob storage container from that account is designated as the default file system, like in the Hadoop distributed file system (HDFS).</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>By default, the HDInsight cluster is provisioned in the same data center as the storage account you specify.</source>
          <target state="new">By default, the HDInsight cluster is provisioned in the same data center as the storage account you specify.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Use Azure Blob storage with HDInsight<ept id="p1">](hdinsight-use-blob-storage.md)</ept></source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Use Azure Blob storage with HDInsight<ept id="p1">](hdinsight-use-blob-storage.md)</ept></target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Data source blade</source>
          <target state="new">Data source blade</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Currently you can select an Azure Storage Account as the data source for an HDInsight cluster.</source>
          <target state="new">Currently you can select an Azure Storage Account as the data source for an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Use the following to understand the entries on the <bpt id="p1">**</bpt>Data Source<ept id="p1">**</ept> blade.</source>
          <target state="new">Use the following to understand the entries on the <bpt id="p1">**</bpt>Data Source<ept id="p1">**</ept> blade.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Selection Method<ept id="p1">**</ept>: Set this to <bpt id="p2">**</bpt>From all subscriptions<ept id="p2">**</ept> to enable browsing of storage accounts from all your subscriptions.</source>
          <target state="new"><bpt id="p1">**</bpt>Selection Method<ept id="p1">**</ept>: Set this to <bpt id="p2">**</bpt>From all subscriptions<ept id="p2">**</ept> to enable browsing of storage accounts from all your subscriptions.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Set this to <bpt id="p1">**</bpt>Access Key<ept id="p1">**</ept> if you want to enter the <bpt id="p2">**</bpt>Storage Name<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Access Key<ept id="p3">**</ept> of an existing storage account.</source>
          <target state="new">Set this to <bpt id="p1">**</bpt>Access Key<ept id="p1">**</ept> if you want to enter the <bpt id="p2">**</bpt>Storage Name<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Access Key<ept id="p3">**</ept> of an existing storage account.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Select storage account / Create New<ept id="p1">**</ept>: Click <bpt id="p2">**</bpt>Select storage account<ept id="p2">**</ept> to browse and select an existing storage account you want to associate with the cluster.</source>
          <target state="new"><bpt id="p1">**</bpt>Select storage account / Create New<ept id="p1">**</ept>: Click <bpt id="p2">**</bpt>Select storage account<ept id="p2">**</ept> to browse and select an existing storage account you want to associate with the cluster.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Or, click <bpt id="p1">**</bpt>Create New<ept id="p1">**</ept> to create a new storage account.</source>
          <target state="new">Or, click <bpt id="p1">**</bpt>Create New<ept id="p1">**</ept> to create a new storage account.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Use the field that appears to enter the name of the storage account.</source>
          <target state="new">Use the field that appears to enter the name of the storage account.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>A green check will appear if the name is available.</source>
          <target state="new">A green check will appear if the name is available.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Choose Default Container<ept id="p1">**</ept>: Use this to enter the name of the default container to use for the cluster.</source>
          <target state="new"><bpt id="p1">**</bpt>Choose Default Container<ept id="p1">**</ept>: Use this to enter the name of the default container to use for the cluster.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>While you can enter any name here, we recommend using the same name as the cluster so that you can easily recognize that the container is used for this specific cluster.</source>
          <target state="new">While you can enter any name here, we recommend using the same name as the cluster so that you can easily recognize that the container is used for this specific cluster.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Location<ept id="p1">**</ept>: The geographic region that the storage account is in, or will be created in.</source>
          <target state="new"><bpt id="p1">**</bpt>Location<ept id="p1">**</ept>: The geographic region that the storage account is in, or will be created in.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.IMPORTANT]</ph> Selecting the location for the default data source will also set the location of the HDInsight cluster.</source>
          <target state="new"><ph id="ph1">[AZURE.IMPORTANT]</ph> Selecting the location for the default data source will also set the location of the HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>The cluster and default data source must be located in the same region.</source>
          <target state="new">The cluster and default data source must be located in the same region.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> to save the data source configuration.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> to save the data source configuration.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Node Pricing Tiers<ept id="p1">**</ept> to display information about the nodes that will be created for this cluster.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Node Pricing Tiers<ept id="p1">**</ept> to display information about the nodes that will be created for this cluster.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Set the number of worker nodes that you need for the cluster.</source>
          <target state="new">Set the number of worker nodes that you need for the cluster.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>The estimated cost of the cluster will be shown within the blade.</source>
          <target state="new">The estimated cost of the cluster will be shown within the blade.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Node pricing tiers blade</source>
          <target state="new">Node pricing tiers blade</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> to save the node pricing configuration.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Select<ept id="p1">**</ept> to save the node pricing configuration.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>On the <bpt id="p1">**</bpt>New HDInsight Cluster<ept id="p1">**</ept> blade, ensure that <bpt id="p2">**</bpt>Pin to Startboard<ept id="p2">**</ept> is selected, and then click <bpt id="p3">**</bpt>Create<ept id="p3">**</ept>.</source>
          <target state="new">On the <bpt id="p1">**</bpt>New HDInsight Cluster<ept id="p1">**</ept> blade, ensure that <bpt id="p2">**</bpt>Pin to Startboard<ept id="p2">**</ept> is selected, and then click <bpt id="p3">**</bpt>Create<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>This will create the cluster and add a tile for it to the Startboard of your Azure Portal.</source>
          <target state="new">This will create the cluster and add a tile for it to the Startboard of your Azure Portal.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>The icon will indicate that the cluster is provisioning, and will change to display the HDInsight icon once provisioning has completed.</source>
          <target state="new">The icon will indicate that the cluster is provisioning, and will change to display the HDInsight icon once provisioning has completed.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>While provisioning</source>
          <target state="new">While provisioning</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Provisioning complete</source>
          <target state="new">Provisioning complete</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Provisioning indicator on startboard</source>
          <target state="new">Provisioning indicator on startboard</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Provisioned cluster tile</source>
          <target state="new">Provisioned cluster tile</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> It will take some time for the cluster to be created, usually around 15 minutes.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> It will take some time for the cluster to be created, usually around 15 minutes.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Use the tile on the Startboard, or the <bpt id="p1">**</bpt>Notifications<ept id="p1">**</ept> entry on the left of the page to check on the provisioning process.</source>
          <target state="new">Use the tile on the Startboard, or the <bpt id="p1">**</bpt>Notifications<ept id="p1">**</ept> entry on the left of the page to check on the provisioning process.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Once the provisioning is completed, click the tile for the cluster from the Startboard to launch the cluster blade.</source>
          <target state="new">Once the provisioning is completed, click the tile for the cluster from the Startboard to launch the cluster blade.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hivequery"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Submit a Hive job on the cluster</source>
          <target state="new"><ph id="ph1">&lt;a name="hivequery"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Submit a Hive job on the cluster</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Now that you have an HDInsight Linux cluster provisioned, the next step is to run a sample Hive job to query sample data (sample.log) that comes with HDInsight clusters.</source>
          <target state="new">Now that you have an HDInsight Linux cluster provisioned, the next step is to run a sample Hive job to query sample data (sample.log) that comes with HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>The sample data contains log information, including trace, warnings, info, and errors.</source>
          <target state="new">The sample data contains log information, including trace, warnings, info, and errors.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>We query this data to retrieve all the error logs with a specific severity.</source>
          <target state="new">We query this data to retrieve all the error logs with a specific severity.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>You must perform the following steps to run a Hive query on an HDInsight Linux cluster:</source>
          <target state="new">You must perform the following steps to run a Hive query on an HDInsight Linux cluster:</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Connect to a Linux cluster</source>
          <target state="new">Connect to a Linux cluster</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>Run a Hive job</source>
          <target state="new">Run a Hive job</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>To connect to a cluster</source>
          <target state="new">To connect to a cluster</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>You can connect to an HDInsight cluster on Linux from a Linux computer or a Windows-based computer by using SSH.</source>
          <target state="new">You can connect to an HDInsight cluster on Linux from a Linux computer or a Windows-based computer by using SSH.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>To connect from a Linux computer</source>
          <target state="new">To connect from a Linux computer</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Open a terminal and enter the following command:</source>
          <target state="new">Open a terminal and enter the following command:</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Because you provisioned a cluster with the Quick Create option, the default SSH user name is <bpt id="p1">**</bpt>hdiuser<ept id="p1">**</ept>.</source>
          <target state="new">Because you provisioned a cluster with the Quick Create option, the default SSH user name is <bpt id="p1">**</bpt>hdiuser<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>So, the command must be:</source>
          <target state="new">So, the command must be:</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>When prompted, enter the password that you provided while provisioning the cluster.</source>
          <target state="new">When prompted, enter the password that you provided while provisioning the cluster.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>After you are successfully connected, the prompt will change to the following:</source>
          <target state="new">After you are successfully connected, the prompt will change to the following:</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>To connect from a Windows-based computer</source>
          <target state="new">To connect from a Windows-based computer</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Download <ph id="ph1">&lt;a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" target="_blank"&gt;</ph>PuTTY<ph id="ph2">&lt;/a&gt;</ph> for Windows-based clients.</source>
          <target state="new">Download <ph id="ph1">&lt;a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" target="_blank"&gt;</ph>PuTTY<ph id="ph2">&lt;/a&gt;</ph> for Windows-based clients.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Open PuTTY.</source>
          <target state="new">Open PuTTY.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>In <bpt id="p1">**</bpt>Category<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Session<ept id="p2">**</ept>.</source>
          <target state="new">In <bpt id="p1">**</bpt>Category<ept id="p1">**</ept>, click <bpt id="p2">**</bpt>Session<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p1">**</bpt>Basic options for your PuTTY session<ept id="p1">**</ept> screen, enter the SSH address of your HDInsight server in the <bpt id="p2">**</bpt>Host Name (or IP address)<ept id="p2">**</ept> field.</source>
          <target state="new">From the <bpt id="p1">**</bpt>Basic options for your PuTTY session<ept id="p1">**</ept> screen, enter the SSH address of your HDInsight server in the <bpt id="p2">**</bpt>Host Name (or IP address)<ept id="p2">**</ept> field.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>The SSH address is your cluster name, followed by<bpt id="p1">**</bpt>-ssh.azurehdinsight.net<ept id="p1">**</ept>.</source>
          <target state="new">The SSH address is your cluster name, followed by<bpt id="p1">**</bpt>-ssh.azurehdinsight.net<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>For example, <bpt id="p1">**</bpt>myhdinsightcluster-ssh.azurehdinsight.net<ept id="p1">**</ept>.</source>
          <target state="new">For example, <bpt id="p1">**</bpt>myhdinsightcluster-ssh.azurehdinsight.net<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Connect to an HDInsight cluster on Linux using PuTTY</source>
          <target state="new">Connect to an HDInsight cluster on Linux using PuTTY</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>To save the connection information for future use, enter a name for this connection under <bpt id="p1">**</bpt>Saved Sessions<ept id="p1">**</ept>, and then click <bpt id="p2">**</bpt>Save<ept id="p2">**</ept>.</source>
          <target state="new">To save the connection information for future use, enter a name for this connection under <bpt id="p1">**</bpt>Saved Sessions<ept id="p1">**</ept>, and then click <bpt id="p2">**</bpt>Save<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>The connection will be added to the list of saved sessions.</source>
          <target state="new">The connection will be added to the list of saved sessions.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Open<ept id="p1">**</ept> to connect to the cluster.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Open<ept id="p1">**</ept> to connect to the cluster.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>When prompted for the user name, enter <bpt id="p1">**</bpt>hdiuser<ept id="p1">**</ept>.</source>
          <target state="new">When prompted for the user name, enter <bpt id="p1">**</bpt>hdiuser<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>For the password, enter the password you specified while provisioning the cluster.</source>
          <target state="new">For the password, enter the password you specified while provisioning the cluster.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>After you are successfully connected, the prompt will change to the following:</source>
          <target state="new">After you are successfully connected, the prompt will change to the following:</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>To run a Hive job</source>
          <target state="new">To run a Hive job</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Once you are connected to the cluster via SSH, use the following commands to run a Hive query.</source>
          <target state="new">Once you are connected to the cluster via SSH, use the following commands to run a Hive query.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Start the Hive command-line interface (CLI) by using the following command at the prompt:</source>
          <target state="new">Start the Hive command-line interface (CLI) by using the following command at the prompt:</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>Using the CLI, enter the following statements to create a new table named <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> by using the sample data already available on the cluster:</source>
          <target state="new">Using the CLI, enter the following statements to create a new table named <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> by using the sample data already available on the cluster:</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>These statements perform the following actions:</source>
          <target state="new">These statements perform the following actions:</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept> - Deletes the table and the data file, in case the table already exists.</source>
          <target state="new"><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept> - Deletes the table and the data file, in case the table already exists.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept> - Creates a new "external" table in Hive.</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept> - Creates a new "external" table in Hive.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>External tables store only the table definition in Hive; the data is left in the original location.</source>
          <target state="new">External tables store only the table definition in Hive; the data is left in the original location.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept> - Tells Hive how the data is formatted.</source>
          <target state="new"><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept> - Tells Hive how the data is formatted.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>In this case, the fields in each log are separated by a space.</source>
          <target state="new">In this case, the fields in each log are separated by a space.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept> - Tells Hive where the data is stored (the example/data directory), and that it is stored as text.</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept> - Tells Hive where the data is stored (the example/data directory), and that it is stored as text.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - Selects a count of all rows where column t4 contains the value [ERROR].</source>
          <target state="new"><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - Selects a count of all rows where column t4 contains the value [ERROR].</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> External tables should be used when you expect the underlying data to be updated by an external source, such as an automated data upload process, or by another MapReduce operation, but you always want Hive queries to use the latest data.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> External tables should be used when you expect the underlying data to be updated by an external source, such as an automated data upload process, or by another MapReduce operation, but you always want Hive queries to use the latest data.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Dropping an external table does <bpt id="p1">*</bpt>not<ept id="p1">*</ept> delete the data, only the table definition.</source>
          <target state="new">Dropping an external table does <bpt id="p1">*</bpt>not<ept id="p1">*</ept> delete the data, only the table definition.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>This returns the following output:</source>
          <target state="new">This returns the following output:</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Note that the output contains <bpt id="p1">**</bpt>[ERROR]  3<ept id="p1">**</ept>, as there are three rows that contain this value.</source>
          <target state="new">Note that the output contains <bpt id="p1">**</bpt>[ERROR]  3<ept id="p1">**</ept>, as there are three rows that contain this value.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Use the following statements to create a new "internal" table named <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept>:</source>
          <target state="new">Use the following statements to create a new "internal" table named <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept>:</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>These statements perform the following actions:</source>
          <target state="new">These statements perform the following actions:</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept> - Creates a table, if it does not already exist.</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept> - Creates a table, if it does not already exist.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Since the <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.</source>
          <target state="new">Since the <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>Unlike external tables, dropping an internal table will delete the underlying data as well.</source>
          <target state="new">Unlike external tables, dropping an internal table will delete the underlying data as well.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept> - Stores the data in Optimized Row Columnar (ORC) format.</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept> - Stores the data in Optimized Row Columnar (ORC) format.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>This is a highly optimized and efficient format for storing Hive data.</source>
          <target state="new">This is a highly optimized and efficient format for storing Hive data.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INSERT OVERWRITE ... SELECT<ept id="p1">**</ept> - Selects rows from the <bpt id="p2">**</bpt>log4jLogs<ept id="p2">**</ept> table that contain [ERROR], and then inserts the data into the <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept> table.</source>
          <target state="new"><bpt id="p1">**</bpt>INSERT OVERWRITE ... SELECT<ept id="p1">**</ept> - Selects rows from the <bpt id="p2">**</bpt>log4jLogs<ept id="p2">**</ept> table that contain [ERROR], and then inserts the data into the <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept> table.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>To verify that only rows containing [ERROR] in column t4 were stored to the <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> table, use the following statement to return all the rows from <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept>:</source>
          <target state="new">To verify that only rows containing [ERROR] in column t4 were stored to the <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> table, use the following statement to return all the rows from <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept>:</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>The following output should be displayed on the console:</source>
          <target state="new">The following output should be displayed on the console:</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>The returned data should all correspond to [ERROR] logs.</source>
          <target state="new">The returned data should all correspond to [ERROR] logs.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a name="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>In this Linux tutorial, you have learned how to provision a Hadoop cluster on Linux with HDInsight and run a Hive query on it by using SSH.</source>
          <target state="new">In this Linux tutorial, you have learned how to provision a Hadoop cluster on Linux with HDInsight and run a Hive query on it by using SSH.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>To learn more, see the following articles:</source>
          <target state="new">To learn more, see the following articles:</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Manage HDInsight clusters using Ambari<ept id="p1">](hdinsight-hadoop-manage-ambari.md)</ept>: Linux-based HDInsight clusters use Ambari for management and monitoring of Hadoop services.</source>
          <target state="new"><bpt id="p1">[</bpt>Manage HDInsight clusters using Ambari<ept id="p1">](hdinsight-hadoop-manage-ambari.md)</ept>: Linux-based HDInsight clusters use Ambari for management and monitoring of Hadoop services.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>The Ambari web UI is available on each cluster at https://CLUSTERNAME.azurehdinsight.net.</source>
          <target state="new">The Ambari web UI is available on each cluster at https://CLUSTERNAME.azurehdinsight.net.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.IMPORTANT]</ph> While many sections of the Ambari web are directly accessible through the Internet, the web UI for Hadoop services such as Resource Manager or Job History require the use of an SSH tunnel.</source>
          <target state="new"><ph id="ph1">[AZURE.IMPORTANT]</ph> While many sections of the Ambari web are directly accessible through the Internet, the web UI for Hadoop services such as Resource Manager or Job History require the use of an SSH tunnel.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>For more information on using an SSH tunnel with HDInsight, see the following articles:</source>
          <target state="new">For more information on using an SSH tunnel with HDInsight, see the following articles:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X</source>
          <target state="new">Use SSH with Linux-based Hadoop on HDInsight from Linux, Unix, or OS X</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Use SSH with Linux-based Hadoop on HDInsight from Windows</source>
          <target state="new">Use SSH with Linux-based Hadoop on HDInsight from Windows</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Provision HDInsight on Linux using custom options<ept id="p1">](hdinsight-hadoop-provision-linux-clusters.md)</ept>: Learn more details about how to provision HDInsight clusters.</source>
          <target state="new"><bpt id="p1">[</bpt>Provision HDInsight on Linux using custom options<ept id="p1">](hdinsight-hadoop-provision-linux-clusters.md)</ept>: Learn more details about how to provision HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Working with HDInsight on Linux<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>: If you are already familiar with Hadoop on Linux platforms, this document provides guidance on Azure specific information, such as:</source>
          <target state="new"><bpt id="p1">[</bpt>Working with HDInsight on Linux<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>: If you are already familiar with Hadoop on Linux platforms, this document provides guidance on Azure specific information, such as:</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>URLs for services hosted on the cluster, such as Ambari and WebHCat</source>
          <target state="new">URLs for services hosted on the cluster, such as Ambari and WebHCat</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>The location of Hadoop files and examples on the local file system</source>
          <target state="new">The location of Hadoop files and examples on the local file system</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>The use of Azure Storage (WASB) instead of HDFS as the default data store</source>
          <target state="new">The use of Azure Storage (WASB) instead of HDFS as the default data store</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>For more information on Hive, or to learn about Pig and MapReduce, see the following:</source>
          <target state="new">For more information on Hive, or to learn about Pig and MapReduce, see the following:</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Use MapReduce with HDInsight</source>
          <target state="new">Use MapReduce with HDInsight</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>For more information on how to work with the Azure Storage used by your HDInsight cluster, see the following:</source>
          <target state="new">For more information on how to work with the Azure Storage used by your HDInsight cluster, see the following:</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Use Azure Blob storage with HDInsight</source>
          <target state="new">Use Azure Blob storage with HDInsight</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Upload data to HDInsight</source>
          <target state="new">Upload data to HDInsight</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">625f043f64347f52a8faaa4aa7353eef3e9f1ac1</xliffext:olfilehash>
  </header>
</xliff>