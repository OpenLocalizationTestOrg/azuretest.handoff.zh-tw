<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Analyze and Process JSON documents with Hive in HDInsight | Microsoft Azure</source>
          <target state="new">Analyze and Process JSON documents with Hive in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use JSON documents and analyze them using Hive in HDInsight.</source>
          <target state="new">Learn how to use JSON documents and analyze them using Hive in HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Process and analyze JSON documents using Hive in HDInsight</source>
          <target state="new">Process and analyze JSON documents using Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Learn how to process and analyze JSON files using Hive in HDInsight.</source>
          <target state="new">Learn how to process and analyze JSON files using Hive in HDInsight.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The following JSON document will be used in the tutorial</source>
          <target state="new">The following JSON document will be used in the tutorial</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The file can be found at wasb://processjson@hditutorialdata.blob.core.windows.net/.</source>
          <target state="new">The file can be found at wasb://processjson@hditutorialdata.blob.core.windows.net/.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>For more information on using Azure Blob storage with HDInsight, see <bpt id="p1">[</bpt>Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-use-blob-storage.md)</ept>.</source>
          <target state="new">For more information on using Azure Blob storage with HDInsight, see <bpt id="p1">[</bpt>Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-use-blob-storage.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>You can copy the file to the default container of your cluster if you want.</source>
          <target state="new">You can copy the file to the default container of your cluster if you want.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will use the Hive console.</source>
          <target state="new">In this tutorial, you will use the Hive console.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>For instructions of opening the Hive console, see <bpt id="p1">[</bpt>Use Hive with Hadoop on HDInsight with Remote Desktop<ept id="p1">](hdinsight-hadoop-use-hive-remote-desktop.md)</ept>.</source>
          <target state="new">For instructions of opening the Hive console, see <bpt id="p1">[</bpt>Use Hive with Hadoop on HDInsight with Remote Desktop<ept id="p1">](hdinsight-hadoop-use-hive-remote-desktop.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Flatten JSON documents</source>
          <target state="new">Flatten JSON documents</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The methods listed in the next section require the JSON document in a single row.</source>
          <target state="new">The methods listed in the next section require the JSON document in a single row.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>So you must flatten the JSON document to a string.</source>
          <target state="new">So you must flatten the JSON document to a string.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>If your JSON document is already flattened, you can skip this step and go straight to the next section on Analyzing JSON data.</source>
          <target state="new">If your JSON document is already flattened, you can skip this step and go straight to the next section on Analyzing JSON data.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The raw JSON file is located at <bpt id="p1">**</bpt>wasb://processjson@hditutorialdata.blob.core.windows.net/<ept id="p1">**</ept>.</source>
          <target state="new">The raw JSON file is located at <bpt id="p1">**</bpt>wasb://processjson@hditutorialdata.blob.core.windows.net/<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">*</bpt>StudentsRaw<ept id="p1">*</ept> Hive table points to the raw un-flattened JSON document.</source>
          <target state="new">The <bpt id="p1">*</bpt>StudentsRaw<ept id="p1">*</ept> Hive table points to the raw un-flattened JSON document.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">*</bpt>StudentsOneLine<ept id="p1">*</ept> Hive table will store the data in the HDInsight default file system under the <bpt id="p2">*</bpt>/json/students/<ept id="p2">*</ept> path.</source>
          <target state="new">The <bpt id="p1">*</bpt>StudentsOneLine<ept id="p1">*</ept> Hive table will store the data in the HDInsight default file system under the <bpt id="p2">*</bpt>/json/students/<ept id="p2">*</ept> path.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The INSERT statement populate the StudentOneLine table with the flattened JSON data.</source>
          <target state="new">The INSERT statement populate the StudentOneLine table with the flattened JSON data.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The SELECT statement shall only return 1 row.</source>
          <target state="new">The SELECT statement shall only return 1 row.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Here is the output of the SELECT statement:</source>
          <target state="new">Here is the output of the SELECT statement:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Flattening of the JSON document.</source>
          <target state="new">Flattening of the JSON document.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Analyze JSON documents in Hive</source>
          <target state="new">Analyze JSON documents in Hive</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Hive provides three different mechanisms to run queries on JSON documents:</source>
          <target state="new">Hive provides three different mechanisms to run queries on JSON documents:</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>use the GET\_JSON\_OBJECT UDF (User Defined Function)</source>
          <target state="new">use the GET\_JSON\_OBJECT UDF (User Defined Function)</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>use the JSON_TUPLE UDF</source>
          <target state="new">use the JSON_TUPLE UDF</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>use custom SerDe</source>
          <target state="new">use custom SerDe</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>write you own UDF using Python or other languages.</source>
          <target state="new">write you own UDF using Python or other languages.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>this article<ept id="p1">][hdinsight-python]</ept> on running your own Python code with Hive.</source>
          <target state="new">See <bpt id="p1">[</bpt>this article<ept id="p1">][hdinsight-python]</ept> on running your own Python code with Hive.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Use the GET\_JSON_OBJECT UDF</source>
          <target state="new">Use the GET\_JSON_OBJECT UDF</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Hive provides a built-in UDF called <bpt id="p1">[</bpt>get json object<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> which can perform JSON querying during run time.</source>
          <target state="new">Hive provides a built-in UDF called <bpt id="p1">[</bpt>get json object<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> which can perform JSON querying during run time.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>This method takes two arguments – the table name and method name which has the flattened JSON document and the JSON field that needs to be parsed.</source>
          <target state="new">This method takes two arguments – the table name and method name which has the flattened JSON document and the JSON field that needs to be parsed.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Let’s look at an example to see how this UDF works.</source>
          <target state="new">Let’s look at an example to see how this UDF works.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Get the first name and last name for each student</source>
          <target state="new">Get the first name and last name for each student</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Here is the output when running this query in console window.</source>
          <target state="new">Here is the output when running this query in console window.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>get_json_object UDF</source>
          <target state="new">get_json_object UDF</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>There are a few limitations of the get-json_object UDF.</source>
          <target state="new">There are a few limitations of the get-json_object UDF.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Because each field in the query requires re-parsing the query, it affects the performance.</source>
          <target state="new">Because each field in the query requires re-parsing the query, it affects the performance.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>GET\_JSON_OBJECT() returns the string representation of an array.</source>
          <target state="new">GET\_JSON_OBJECT() returns the string representation of an array.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>To convert this to a Hive array, you will have to use regular expressions to replace the square brackets ‘[‘ and ‘]’ and then also call split to get the array.</source>
          <target state="new">To convert this to a Hive array, you will have to use regular expressions to replace the square brackets ‘[‘ and ‘]’ and then also call split to get the array.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>This is why the Hive wiki recommends using json_tuple.</source>
          <target state="new">This is why the Hive wiki recommends using json_tuple.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Use the JSON_TUPLE UDF</source>
          <target state="new">Use the JSON_TUPLE UDF</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Another UDF provided by Hive is called <bpt id="p1">[</bpt>json_tuple<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)</ept> which performs better than <bpt id="p2">[</bpt>get_ json _object<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept>.</source>
          <target state="new">Another UDF provided by Hive is called <bpt id="p1">[</bpt>json_tuple<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)</ept> which performs better than <bpt id="p2">[</bpt>get_ json _object<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept>.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>This method takes a set of keys and a JSON string, and returns a tuple of values using one function.</source>
          <target state="new">This method takes a set of keys and a JSON string, and returns a tuple of values using one function.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>The following query returns the student id and the grade from the JSON document:</source>
          <target state="new">The following query returns the student id and the grade from the JSON document:</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The output of this script in the Hive console:</source>
          <target state="new">The output of this script in the Hive console:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>json_tuple UDF</source>
          <target state="new">json_tuple UDF</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>JSON\_TUPLE uses the <bpt id="p1">[</bpt>lateral view<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> syntax in Hive which allows json\_tuple to create a virtual table by applying the UDT function to each row of the original table.</source>
          <target state="new">JSON\_TUPLE uses the <bpt id="p1">[</bpt>lateral view<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> syntax in Hive which allows json\_tuple to create a virtual table by applying the UDT function to each row of the original table.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Complex JSONs become too unwieldy because of the repeated use of LATERAL VIEW.</source>
          <target state="new">Complex JSONs become too unwieldy because of the repeated use of LATERAL VIEW.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Furthermore, JSON_TUPLE cannot handle nested JSONs.</source>
          <target state="new">Furthermore, JSON_TUPLE cannot handle nested JSONs.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Use custom SerDe</source>
          <target state="new">Use custom SerDe</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>SerDe is the best choice for parsing nested JSON documents, it allows you to define the JSON schema, and use the schema to parse the documents.</source>
          <target state="new">SerDe is the best choice for parsing nested JSON documents, it allows you to define the JSON schema, and use the schema to parse the documents.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>In this tutorial, you will use one of the more popular SerDe that has been developed by <bpt id="p1">[</bpt>rcongiu<ept id="p1">](https://github.com/rcongiu)</ept>.</source>
          <target state="new">In this tutorial, you will use one of the more popular SerDe that has been developed by <bpt id="p1">[</bpt>rcongiu<ept id="p1">](https://github.com/rcongiu)</ept>.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>To use the custom SerDe:</source>
          <target state="new">To use the custom SerDe:</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Install <bpt id="p1">[</bpt>Java SE Development Kit 7u55 JDK 1.7.0_55<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)</ept>.</source>
          <target state="new">Install <bpt id="p1">[</bpt>Java SE Development Kit 7u55 JDK 1.7.0_55<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)</ept>.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Choose the Windows X64 version of the JDK if you are going to be using the Windows deployment of HDInsight</source>
          <target state="new">Choose the Windows X64 version of the JDK if you are going to be using the Windows deployment of HDInsight</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.WARNING]</ph> JDK 1.8 doesn't work with this SerDe.</source>
          <target state="new"><ph id="ph1">[AZURE.WARNING]</ph> JDK 1.8 doesn't work with this SerDe.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>After the installation is completed, add a new user environment variable:</source>
          <target state="new">After the installation is completed, add a new user environment variable:</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Open <bpt id="p1">**</bpt>View advanced system settings<ept id="p1">**</ept> from the Windows screen.</source>
          <target state="new">Open <bpt id="p1">**</bpt>View advanced system settings<ept id="p1">**</ept> from the Windows screen.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Environment Variables<ept id="p1">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Environment Variables<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Add a new <bpt id="p1">**</bpt>JAVA_HOME<ept id="p1">**</ept> environment variable is pointing to <bpt id="p2">**</bpt>C:\Program Files\Java\jdk1.7.0_55<ept id="p2">**</ept> or wherever your JDK is installed.</source>
          <target state="new">Add a new <bpt id="p1">**</bpt>JAVA_HOME<ept id="p1">**</ept> environment variable is pointing to <bpt id="p2">**</bpt>C:\Program Files\Java\jdk1.7.0_55<ept id="p2">**</ept> or wherever your JDK is installed.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Setting up correct config values for JDK</source>
          <target state="new">Setting up correct config values for JDK</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Install <bpt id="p1">[</bpt>Maven 3.3.1<ept id="p1">](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)</ept></source>
          <target state="new">Install <bpt id="p1">[</bpt>Maven 3.3.1<ept id="p1">](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)</ept></target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Add the bin folder to your path by going to Control Panel--&gt;Edit the System Variables for your account Environment variables.</source>
          <target state="new">Add the bin folder to your path by going to Control Panel--&gt;Edit the System Variables for your account Environment variables.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The screenshot below shows you how to do this.</source>
          <target state="new">The screenshot below shows you how to do this.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Setting up Maven</source>
          <target state="new">Setting up Maven</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Clone the project from <bpt id="p1">[</bpt>Hive-JSON-SerDe<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> github site.</source>
          <target state="new">Clone the project from <bpt id="p1">[</bpt>Hive-JSON-SerDe<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> github site.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>You can do this by clicking on the “Download Zip” button as shown in the screenshot below.</source>
          <target state="new">You can do this by clicking on the “Download Zip” button as shown in the screenshot below.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Cloning the project</source>
          <target state="new">Cloning the project</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>4: Go to the folder where you have downloaded this package and  type “mvn package”.</source>
          <target state="new">4: Go to the folder where you have downloaded this package and  type “mvn package”.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>This should create the necessary jar files that you can then copy over to the cluster.</source>
          <target state="new">This should create the necessary jar files that you can then copy over to the cluster.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>5: Go to the target folder under the root folder where you downloaded the package.</source>
          <target state="new">5: Go to the target folder under the root folder where you downloaded the package.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Upload the json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar file to head-node of your cluster.</source>
          <target state="new">Upload the json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar file to head-node of your cluster.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>I usually put it under the hive binary folder: C:\apps\dist\hive-0.13.0.2.1.11.0-2316\bin or something similar.</source>
          <target state="new">I usually put it under the hive binary folder: C:\apps\dist\hive-0.13.0.2.1.11.0-2316\bin or something similar.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>6: In the hive prompt, type “add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”.</source>
          <target state="new">6: In the hive prompt, type “add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Since in my case, the jar is in the C:\apps\dist\hive-0.13.x\bin folder, I can directly add the jar with the name as shown below:</source>
          <target state="new">Since in my case, the jar is in the C:\apps\dist\hive-0.13.x\bin folder, I can directly add the jar with the name as shown below:</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Now, you are ready to use the SerDe to run queries against the JSON document.</source>
          <target state="new">Now, you are ready to use the SerDe to run queries against the JSON document.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>The following statement create a table with a defined schema</source>
          <target state="new">The following statement create a table with a defined schema</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>To list the first name and last name of the student</source>
          <target state="new">To list the first name and last name of the student</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Here is the result from the Hive console.</source>
          <target state="new">Here is the result from the Hive console.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>SerDe Query 1</source>
          <target state="new">SerDe Query 1</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>To calculate the sum of scores of the JSON document</source>
          <target state="new">To calculate the sum of scores of the JSON document</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>The query above uses <bpt id="p1">[</bpt>lateral view explode<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> UDF to expand the array of scores so that they can be summed.</source>
          <target state="new">The query above uses <bpt id="p1">[</bpt>lateral view explode<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> UDF to expand the array of scores so that they can be summed.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Here is the output from the Hive console.</source>
          <target state="new">Here is the output from the Hive console.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>SerDe Query 2</source>
          <target state="new">SerDe Query 2</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>To find which subjects a given student has scored more than 80 points</source>
          <target state="new">To find which subjects a given student has scored more than 80 points</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>SELECT</source>
          <target state="new">SELECT</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>jt.StudentClassCollection.ClassId</source>
          <target state="new">jt.StudentClassCollection.ClassId</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>FROM json_table jt</source>
          <target state="new">FROM json_table jt</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>lateral view explode(jt.StudentClassCollection.Score) collection as score  where score &gt; 80;</source>
          <target state="new">lateral view explode(jt.StudentClassCollection.Score) collection as score  where score &gt; 80;</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>The query above returns a Hive array unlike get\_json\_object which returns a string.</source>
          <target state="new">The query above returns a Hive array unlike get\_json\_object which returns a string.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>SerDe Query 3</source>
          <target state="new">SerDe Query 3</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>If you want to skil malformed JSON, then as explained in the <bpt id="p1">[</bpt>wiki page<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> of this SerDe you can achieve that by typing the code below:</source>
          <target state="new">If you want to skil malformed JSON, then as explained in the <bpt id="p1">[</bpt>wiki page<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> of this SerDe you can achieve that by typing the code below:</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Summary</source>
          <target state="new">Summary</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>In conclusion, the type of JSON operator in Hive that you choose depends on your scenario.</source>
          <target state="new">In conclusion, the type of JSON operator in Hive that you choose depends on your scenario.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>If you have a simple JSON document and you only have one field to look up on – you can choose to use the Hive UDF get\_json\_object.</source>
          <target state="new">If you have a simple JSON document and you only have one field to look up on – you can choose to use the Hive UDF get\_json\_object.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>If you have more than one keys to look up on then you can use json_tuple.</source>
          <target state="new">If you have more than one keys to look up on then you can use json_tuple.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>If you have a nested document, then you should use the JSON SerDe.</source>
          <target state="new">If you have a nested document, then you should use the JSON SerDe.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>For other related articles, see</source>
          <target state="new">For other related articles, see</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Use Hive and HiveQL with Hadoop in HDInsight to analyze a sample Apache log4j file</source>
          <target state="new">Use Hive and HiveQL with Hadoop in HDInsight to analyze a sample Apache log4j file</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>Analyze flight delay data by using Hive in HDInsight</source>
          <target state="new">Analyze flight delay data by using Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Analyze Twitter data using Hive in HDInsight</source>
          <target state="new">Analyze Twitter data using Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Run a Hadoop job using DocumentDB and HDInsight</source>
          <target state="new">Run a Hadoop job using DocumentDB and HDInsight</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d4966f8ccbc2f8c9a701e963fcbfbd8252ba6cb2</xliffext:olfilehash>
  </header>
</xliff>