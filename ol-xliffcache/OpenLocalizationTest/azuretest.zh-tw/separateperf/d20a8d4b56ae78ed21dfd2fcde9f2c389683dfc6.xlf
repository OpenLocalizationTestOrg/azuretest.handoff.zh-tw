<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Data warehouse workload</source>
          <target state="new">Data warehouse workload</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>SQL Data Warehouse's elasticity lets you grow, shrink, or pause compute power by using a sliding scale of data warehouse units (DWUs).</source>
          <target state="new">SQL Data Warehouse's elasticity lets you grow, shrink, or pause compute power by using a sliding scale of data warehouse units (DWUs).</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>This article explains the data warehouse metrics and how they relate to DWUs.</source>
          <target state="new">This article explains the data warehouse metrics and how they relate to DWUs.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Data warehouse workload</source>
          <target state="new">Data warehouse workload</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>A data warehouse workload refers to all of the operations that transpire against a data warehouse.</source>
          <target state="new">A data warehouse workload refers to all of the operations that transpire against a data warehouse.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The data warehouse workload encompasses the entire process of loading data into the warehouse, performing analysis and reporting on the data warehouse, managing data in the data warehouse, and exporting data from the data warehouse.</source>
          <target state="new">The data warehouse workload encompasses the entire process of loading data into the warehouse, performing analysis and reporting on the data warehouse, managing data in the data warehouse, and exporting data from the data warehouse.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>The depth and breadth of these components are often commensurate with the maturity level of the data warehouse.</source>
          <target state="new">The depth and breadth of these components are often commensurate with the maturity level of the data warehouse.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>New to data warehousing?</source>
          <target state="new">New to data warehousing?</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>A data warehouse is a collection of data that is loaded from one or more data sources and is used to perform business intelligence tasks such as reporting and data analysis.</source>
          <target state="new">A data warehouse is a collection of data that is loaded from one or more data sources and is used to perform business intelligence tasks such as reporting and data analysis.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Data warehouses are characterized by queries that scan larger numbers of rows, large ranges of data and may return relatively large results for the purposes of analysis and reporting.</source>
          <target state="new">Data warehouses are characterized by queries that scan larger numbers of rows, large ranges of data and may return relatively large results for the purposes of analysis and reporting.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Data warehouses are also characterized by relatively large data loads versus small transaction-level inserts/updates/deletes.</source>
          <target state="new">Data warehouses are also characterized by relatively large data loads versus small transaction-level inserts/updates/deletes.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>A data warehouse performs best when the data is stored in a way that optimizes queries that need to scan large numbers of rows or large ranges of data.</source>
          <target state="new">A data warehouse performs best when the data is stored in a way that optimizes queries that need to scan large numbers of rows or large ranges of data.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This type of scanning works best when the data is stored and searched by columns, instead of by rows.</source>
          <target state="new">This type of scanning works best when the data is stored and searched by columns, instead of by rows.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The in-memory columnstore index, which uses column storage, provides up to 5x compression gains and 10x query performance gains over traditional binary trees for reporting and analytics queries.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The in-memory columnstore index, which uses column storage, provides up to 5x compression gains and 10x query performance gains over traditional binary trees for reporting and analytics queries.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>We consider columnstore indexes as the standard for storing and scanning large data in a data warehouse.</source>
          <target state="new">We consider columnstore indexes as the standard for storing and scanning large data in a data warehouse.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>A data warehouse has different requirements than a system that optimizes for online transaction processing (OLTP).</source>
          <target state="new">A data warehouse has different requirements than a system that optimizes for online transaction processing (OLTP).</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The OLTP system has many insert, update, and delete operations.</source>
          <target state="new">The OLTP system has many insert, update, and delete operations.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>These operations seek to specific rows in the table.</source>
          <target state="new">These operations seek to specific rows in the table.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Table seeks perform best when the data is stored in a row-by-row manner.</source>
          <target state="new">Table seeks perform best when the data is stored in a row-by-row manner.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The data can be sorted and quickly searched with a divide and conquer approach called a binary tree or btree search.</source>
          <target state="new">The data can be sorted and quickly searched with a divide and conquer approach called a binary tree or btree search.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Data loading</source>
          <target state="new">Data loading</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Data loading is a big part of the data warehouse workload.</source>
          <target state="new">Data loading is a big part of the data warehouse workload.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Businesses usually have a busy OLTP system that tracks changes throughout the day when customers are generating business transactions.</source>
          <target state="new">Businesses usually have a busy OLTP system that tracks changes throughout the day when customers are generating business transactions.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Periodically, often at night during a maintenance window, the transactions are moved or copied to the data warehouse.</source>
          <target state="new">Periodically, often at night during a maintenance window, the transactions are moved or copied to the data warehouse.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Once the data is in the data warehouse, analysts can perform analysis and make business decisions on the data.</source>
          <target state="new">Once the data is in the data warehouse, analysts can perform analysis and make business decisions on the data.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Traditionally, the process of loading is called ETL for Extract, Transform, and Load.</source>
          <target state="new">Traditionally, the process of loading is called ETL for Extract, Transform, and Load.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Data usually needs to be transformed so it is consistent with other data in the data warehouse.</source>
          <target state="new">Data usually needs to be transformed so it is consistent with other data in the data warehouse.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Previously, businesses used dedicated ETL servers to perform the transformations.</source>
          <target state="new">Previously, businesses used dedicated ETL servers to perform the transformations.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Now, with such fast massively parallel processing you can load data into SQL Data Warehouse first, and then perform the transformations.</source>
          <target state="new">Now, with such fast massively parallel processing you can load data into SQL Data Warehouse first, and then perform the transformations.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>This process is called Extract, Load, and Transform (ELT), and is becoming a new standard for the data warehouse workload.</source>
          <target state="new">This process is called Extract, Load, and Transform (ELT), and is becoming a new standard for the data warehouse workload.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>[AZURE NOTE] With SQL Server CTP2, you can now perform analytics in real-time on an OLTP table.</source>
          <target state="new">[AZURE NOTE] With SQL Server CTP2, you can now perform analytics in real-time on an OLTP table.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>This does not replace the need for a data warehouse to store and analyze data, but it does provide a way to perform analysis in real-time.</source>
          <target state="new">This does not replace the need for a data warehouse to store and analyze data, but it does provide a way to perform analysis in real-time.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Reporting and analysis queries</source>
          <target state="new">Reporting and analysis queries</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Reporting and analysis queries are often categorized into small, medium and large based on a number of criteria, but usually it is based on time.</source>
          <target state="new">Reporting and analysis queries are often categorized into small, medium and large based on a number of criteria, but usually it is based on time.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>In most data warehouses, there is a mixed workload of fast-running versus long-running queries.</source>
          <target state="new">In most data warehouses, there is a mixed workload of fast-running versus long-running queries.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>In each case, it is important to determine this mix and to determine its frequency (hourly, daily, month-end, quarter-end, and so on).</source>
          <target state="new">In each case, it is important to determine this mix and to determine its frequency (hourly, daily, month-end, quarter-end, and so on).</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>It is important to understand that the mixed query workload, coupled with concurrency, lead to proper capacity planning for a data warehouse.</source>
          <target state="new">It is important to understand that the mixed query workload, coupled with concurrency, lead to proper capacity planning for a data warehouse.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Capacity planning can be a complex task for a mixed query workload, especially when you need a long lead time to add capacity to the data warehouse.</source>
          <target state="new">Capacity planning can be a complex task for a mixed query workload, especially when you need a long lead time to add capacity to the data warehouse.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>SQL Data Warehouse removes the urgency of capacity planning since you can grow and shrink compute capacity at any time, and since storage and compute capacity are independently sized.</source>
          <target state="new">SQL Data Warehouse removes the urgency of capacity planning since you can grow and shrink compute capacity at any time, and since storage and compute capacity are independently sized.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Data management</source>
          <target state="new">Data management</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Managing data is important, especially when you know you might run out of disk space in the near future.</source>
          <target state="new">Managing data is important, especially when you know you might run out of disk space in the near future.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Data warehouses usually divide the data into meaningful ranges, which are stored as partitions in a table.</source>
          <target state="new">Data warehouses usually divide the data into meaningful ranges, which are stored as partitions in a table.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>All SQL Server-based products let you move partitions in and out of the table.</source>
          <target state="new">All SQL Server-based products let you move partitions in and out of the table.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>This partition switching lets you move older data to less expensive storage and keep the latest data available on online storage.</source>
          <target state="new">This partition switching lets you move older data to less expensive storage and keep the latest data available on online storage.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Columnstore indexes support partitioned tables.</source>
          <target state="new">Columnstore indexes support partitioned tables.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>For columnstore indexes, partitioned tables are used for data management and archival.</source>
          <target state="new">For columnstore indexes, partitioned tables are used for data management and archival.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For tables stored row-by-row, partitions have a larger role in query performance.</source>
          <target state="new">For tables stored row-by-row, partitions have a larger role in query performance.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>PolyBase plays an important role in managing data.</source>
          <target state="new">PolyBase plays an important role in managing data.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Using PolyBase, you have the option to archive older data to Hadoop or Azure blob storage.</source>
          <target state="new">Using PolyBase, you have the option to archive older data to Hadoop or Azure blob storage.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>This provides lots of options since the data is still online.</source>
          <target state="new">This provides lots of options since the data is still online.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>It might take longer to retrieve data from Hadoop, but the tradeoff of retrieval time might outweigh the storage cost.</source>
          <target state="new">It might take longer to retrieve data from Hadoop, but the tradeoff of retrieval time might outweigh the storage cost.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Exporting data</source>
          <target state="new">Exporting data</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>One way to make data available for reports and analysis is to send data from the data warehouse to servers dedicated for running reports and analysis.</source>
          <target state="new">One way to make data available for reports and analysis is to send data from the data warehouse to servers dedicated for running reports and analysis.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>These servers are called data marts.</source>
          <target state="new">These servers are called data marts.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>For example, you could pre-process report data and then export it from the data warehouse to many servers around the world, to make it broadly available for customers and analysts.</source>
          <target state="new">For example, you could pre-process report data and then export it from the data warehouse to many servers around the world, to make it broadly available for customers and analysts.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>For generating reports, each night you could populate read-only reporting servers with a snapshot of the daily data.</source>
          <target state="new">For generating reports, each night you could populate read-only reporting servers with a snapshot of the daily data.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>This gives higher bandwidth for customers while lowering the compute resource needs on the data warehouse.</source>
          <target state="new">This gives higher bandwidth for customers while lowering the compute resource needs on the data warehouse.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>From a security aspect, data marts allow you to reduce the number of users who have access to the data warehouse.</source>
          <target state="new">From a security aspect, data marts allow you to reduce the number of users who have access to the data warehouse.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>For analytics, you can either build an analysis cube on the data warehouse and run analysis against the data warehouse, or pre-process data and export it to the analysis server for further analytics.</source>
          <target state="new">For analytics, you can either build an analysis cube on the data warehouse and run analysis against the data warehouse, or pre-process data and export it to the analysis server for further analytics.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>To start developing your data warehouse, see <bpt id="p1">[</bpt>development overview<ept id="p1">][]</ept>.</source>
          <target state="new">To start developing your data warehouse, see <bpt id="p1">[</bpt>development overview<ept id="p1">][]</ept>.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Books</source>
          <target state="new">Books</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Big Data Warehousing<ept id="p1">](https://www.manning.com/books/big-data-warehousing)</ept> by Karthik Ramachandran, Istvan Szededi, and Richard L. Saltzer (Manning Publications).</source>
          <target state="new"><bpt id="p1">[</bpt>Big Data Warehousing<ept id="p1">](https://www.manning.com/books/big-data-warehousing)</ept> by Karthik Ramachandran, Istvan Szededi, and Richard L. Saltzer (Manning Publications).</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Chapter 1<ept id="p1">](https://manning-content.s3.amazonaws.com/download/e/3d94acd-9512-46c8-b0b0-8c9c3c6a303b/BDW_MEAP_ch1.pdf)</ept></source>
          <target state="new"><bpt id="p1">[</bpt>Chapter 1<ept id="p1">](https://manning-content.s3.amazonaws.com/download/e/3d94acd-9512-46c8-b0b0-8c9c3c6a303b/BDW_MEAP_ch1.pdf)</ept></target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">d20a8d4b56ae78ed21dfd2fcde9f2c389683dfc6</xliffext:olfilehash>
  </header>
</xliff>