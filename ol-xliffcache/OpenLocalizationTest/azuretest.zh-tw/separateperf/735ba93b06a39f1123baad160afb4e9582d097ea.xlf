<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Hadoop Hive and Remote Desktop in HDInsight | Microsoft Azure</source>
          <target state="new">Use Hadoop Hive and Remote Desktop in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to connect to Hadoop cluster in HDInsight by using Remote Desktop, and then run Hive queries by using the Hive Command-Line Interface.</source>
          <target state="new">Learn how to connect to Hadoop cluster in HDInsight by using Remote Desktop, and then run Hive queries by using the Hive Command-Line Interface.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use Hive with Hadoop on HDInsight with Remote Desktop</source>
          <target state="new">Use Hive with Hadoop on HDInsight with Remote Desktop</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>In this article, you will learn how to connect to an HDInsight cluster by using Remote Desktop, and then run Hive queries by using the Hive Command-Line Interface (CLI).</source>
          <target state="new">In this article, you will learn how to connect to an HDInsight cluster by using Remote Desktop, and then run Hive queries by using the Hive Command-Line Interface (CLI).</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This document does not provide a detailed description of what the HiveQL statements that are used in the examples do.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This document does not provide a detailed description of what the HiveQL statements that are used in the examples do.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For information about the HiveQL that is used in this example, see <bpt id="p1">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p1">](hdinsight-use-hive.md)</ept>.</source>
          <target state="new">For information about the HiveQL that is used in this example, see <bpt id="p1">[</bpt>Use Hive with Hadoop on HDInsight<ept id="p1">](hdinsight-use-hive.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</source>
          <target state="new"><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following:</source>
          <target state="new">To complete the steps in this article, you will need the following:</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>A Windows-based HDInsight (Hadoop on HDInsight) cluster</source>
          <target state="new">A Windows-based HDInsight (Hadoop on HDInsight) cluster</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A client computer running Windows 10, Window 8, or Windows 7</source>
          <target state="new">A client computer running Windows 10, Window 8, or Windows 7</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="connect"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Connect with Remote Desktop</source>
          <target state="new"><ph id="ph1">&lt;a id="connect"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Connect with Remote Desktop</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="p1">[</bpt>Connect to HDInsight clusters using RDP<ept id="p1">](hdinsight-administer-use-management-portal.md#rdp)</ept>.</source>
          <target state="new">Enable Remote Desktop for the HDInsight cluster, then connect to it by following the instructions at <bpt id="p1">[</bpt>Connect to HDInsight clusters using RDP<ept id="p1">](hdinsight-administer-use-management-portal.md#rdp)</ept>.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="hive"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Use the Hive command</source>
          <target state="new"><ph id="ph1">&lt;a id="hive"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Use the Hive command</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>When you have connected to the desktop for the HDInsight cluster, use the following steps to work with Hive:</source>
          <target state="new">When you have connected to the desktop for the HDInsight cluster, use the following steps to work with Hive:</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>From the HDInsight desktop, start the <bpt id="p1">**</bpt>Hadoop Command Line<ept id="p1">**</ept>.</source>
          <target state="new">From the HDInsight desktop, start the <bpt id="p1">**</bpt>Hadoop Command Line<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Enter the following command to start the Hive CLI:</source>
          <target state="new">Enter the following command to start the Hive CLI:</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>When the CLI has started, you will see the Hive CLI prompt: <ph id="ph1">`hive&gt;`</ph>.</source>
          <target state="new">When the CLI has started, you will see the Hive CLI prompt: <ph id="ph1">`hive&gt;`</ph>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Using the CLI, enter the following statements to create a new table named <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> using sample data:</source>
          <target state="new">Using the CLI, enter the following statements to create a new table named <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> using sample data:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>These statements perform the following actions:</source>
          <target state="new">These statements perform the following actions:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept>: Deletes the table and the data file if the table already exists.</source>
          <target state="new"><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept>: Deletes the table and the data file if the table already exists.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept>: Creates a new 'external' table in Hive.</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept>: Creates a new 'external' table in Hive.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>External tables store only the table definition in Hive (the data is left in the original location).</source>
          <target state="new">External tables store only the table definition in Hive (the data is left in the original location).</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> External tables should be used when you expect the underlying data to be updated by an external source (such as an automated data upload process) or by another MapReduce operation, but you always want Hive queries to use the latest data.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> External tables should be used when you expect the underlying data to be updated by an external source (such as an automated data upload process) or by another MapReduce operation, but you always want Hive queries to use the latest data.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Dropping an external table does <bpt id="p1">**</bpt>not<ept id="p1">**</ept> delete the data, only the table definition.</source>
          <target state="new">Dropping an external table does <bpt id="p1">**</bpt>not<ept id="p1">**</ept> delete the data, only the table definition.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept>: Tells Hive how the data is formatted.</source>
          <target state="new"><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept>: Tells Hive how the data is formatted.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>In this case, the fields in each log are separated by a space.</source>
          <target state="new">In this case, the fields in each log are separated by a space.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept>: Tells Hive where the data is stored (the example/data directory) and that it is stored as text.</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept>: Tells Hive where the data is stored (the example/data directory) and that it is stored as text.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept>: Selects a count of all rows where column <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> contains the value <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept>: Selects a count of all rows where column <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> contains the value <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>This should return a value of <bpt id="p1">**</bpt>3<ept id="p1">**</ept> because there are three rows that contain this value.</source>
          <target state="new">This should return a value of <bpt id="p1">**</bpt>3<ept id="p1">**</ept> because there are three rows that contain this value.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INPUT__FILE__NAME LIKE '%.log'<ept id="p1">**</ept> - Tells Hive that we should only return data from files ending in .log.</source>
          <target state="new"><bpt id="p1">**</bpt>INPUT__FILE__NAME LIKE '%.log'<ept id="p1">**</ept> - Tells Hive that we should only return data from files ending in .log.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>This restricts the search to the sample.log file that contains the data, and keeps it from returning data from other example data files that do not match the schema we defined.</source>
          <target state="new">This restricts the search to the sample.log file that contains the data, and keeps it from returning data from other example data files that do not match the schema we defined.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Use the following statements to create a new 'internal' table named <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept>:</source>
          <target state="new">Use the following statements to create a new 'internal' table named <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept>:</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>These statements perform the following actions:</source>
          <target state="new">These statements perform the following actions:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept>: Creates a table if it does not already exist.</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept>: Creates a table if it does not already exist.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Because the <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.</source>
          <target state="new">Because the <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> keyword is not used, this is an internal table, which is stored in the Hive data warehouse and is managed completely by Hive.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> Unlike <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> tables, dropping an internal table also deletes the underlying data.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> Unlike <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> tables, dropping an internal table also deletes the underlying data.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept>: Stores the data in optimized row columnar (ORC) format.</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept>: Stores the data in optimized row columnar (ORC) format.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>This is a highly optimized and efficient format for storing Hive data.</source>
          <target state="new">This is a highly optimized and efficient format for storing Hive data.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INSERT OVERWRITE ... SELECT<ept id="p1">**</ept>: Selects rows from the <bpt id="p2">**</bpt>log4jLogs<ept id="p2">**</ept> table that contain <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept>, then inserts the data into the <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> table.</source>
          <target state="new"><bpt id="p1">**</bpt>INSERT OVERWRITE ... SELECT<ept id="p1">**</ept>: Selects rows from the <bpt id="p2">**</bpt>log4jLogs<ept id="p2">**</ept> table that contain <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept>, then inserts the data into the <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> table.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>To verify that only rows that contain <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> in column t4 were stored to the <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> table, use the following statement to return all the rows from <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept>:</source>
          <target state="new">To verify that only rows that contain <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> in column t4 were stored to the <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> table, use the following statement to return all the rows from <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept>:</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Three rows of data should be returned, all containing <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> in column t4.</source>
          <target state="new">Three rows of data should be returned, all containing <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> in column t4.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Summary</source>
          <target state="new"><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Summary</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>As you can see, the the Hive command provides an easy way to interactively run Hive queries on an HDInsight cluster, monitor the job status, and retrieve the output.</source>
          <target state="new">As you can see, the the Hive command provides an easy way to interactively run Hive queries on an HDInsight cluster, monitor the job status, and retrieve the output.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>For general information about Hive in HDInsight:</source>
          <target state="new">For general information about Hive in HDInsight:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Use Hive with Hadoop on HDInsight</source>
          <target state="new">Use Hive with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For information about other ways you can work with Hadoop on HDInsight:</source>
          <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Use Pig with Hadoop on HDInsight</source>
          <target state="new">Use Pig with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Use MapReduce with Hadoop on HDInsight</source>
          <target state="new">Use MapReduce with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">735ba93b06a39f1123baad160afb4e9582d097ea</xliffext:olfilehash>
  </header>
</xliff>