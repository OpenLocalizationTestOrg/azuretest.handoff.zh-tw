<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Query data from HDFS-compatible Blob storage | Microsoft Azure</source>
          <target state="new">Query data from HDFS-compatible Blob storage | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>HDInsight uses Blob storage as the big data store for HDFS.</source>
          <target state="new">HDInsight uses Blob storage as the big data store for HDFS.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Learn how to query data from Blob storage and store results of your analysis.</source>
          <target state="new">Learn how to query data from Blob storage and store results of your analysis.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight</source>
          <target state="new">Use HDFS-compatible Azure Blob storage with Hadoop in HDInsight</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>In this tutorial, learn how to use low-cost Azure Blob storage with HDInsight, create Azure storage account and Blob storage container, and then address the data inside.</source>
          <target state="new">In this tutorial, learn how to use low-cost Azure Blob storage with HDInsight, create Azure storage account and Blob storage container, and then address the data inside.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Azure Blob storage is a robust, general-purpose storage solution that integrates seamlessly with HDInsight.</source>
          <target state="new">Azure Blob storage is a robust, general-purpose storage solution that integrates seamlessly with HDInsight.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Through a Hadoop distributed file system (HDFS) interface, the full set of components in HDInsight can operate directly on structured or unstructured data in Blob storage.</source>
          <target state="new">Through a Hadoop distributed file system (HDFS) interface, the full set of components in HDInsight can operate directly on structured or unstructured data in Blob storage.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Storing data in Blob storage enables you to safely delete the HDInsight clusters that are used for computation without losing user data.</source>
          <target state="new">Storing data in Blob storage enables you to safely delete the HDInsight clusters that are used for computation without losing user data.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>  The <bpt id="p1">*</bpt>asv://<ept id="p1">*</ept> syntax is not supported in HDInsight version 3.0 clusters.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>  The <bpt id="p1">*</bpt>asv://<ept id="p1">*</ept> syntax is not supported in HDInsight version 3.0 clusters.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>This means that any jobs submitted to an HDInsight version 3.0 cluster that explicitly use the <bpt id="p1">*</bpt>asv://<ept id="p1">*</ept> syntax will fail.</source>
          <target state="new">This means that any jobs submitted to an HDInsight version 3.0 cluster that explicitly use the <bpt id="p1">*</bpt>asv://<ept id="p1">*</ept> syntax will fail.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">*</bpt>wasb://<ept id="p1">*</ept> syntax should be used instead.</source>
          <target state="new">The <bpt id="p1">*</bpt>wasb://<ept id="p1">*</ept> syntax should be used instead.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Also, jobs submitted to any HDInsight version 3.0 clusters that are created with an existing metastore that contains explicit references to resources that use the asv:// syntax will fail.</source>
          <target state="new">Also, jobs submitted to any HDInsight version 3.0 clusters that are created with an existing metastore that contains explicit references to resources that use the asv:// syntax will fail.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>These metastores need to be re-created using the wasb:// syntax to address resources.</source>
          <target state="new">These metastores need to be re-created using the wasb:// syntax to address resources.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>HDInsight currently only supports block blobs.</source>
          <target state="new">HDInsight currently only supports block blobs.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Most HDFS commands (for example, <ph id="ph1">&lt;b&gt;</ph>ls<ph id="ph2">&lt;/b&gt;</ph>, <ph id="ph3">&lt;b&gt;</ph>copyFromLocal<ph id="ph4">&lt;/b&gt;</ph> and <ph id="ph5">&lt;b&gt;</ph>mkdir<ph id="ph6">&lt;/b&gt;</ph>) still work as expected.</source>
          <target state="new">Most HDFS commands (for example, <ph id="ph1">&lt;b&gt;</ph>ls<ph id="ph2">&lt;/b&gt;</ph>, <ph id="ph3">&lt;b&gt;</ph>copyFromLocal<ph id="ph4">&lt;/b&gt;</ph> and <ph id="ph5">&lt;b&gt;</ph>mkdir<ph id="ph6">&lt;/b&gt;</ph>) still work as expected.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Only the commands that are specific to the native HDFS implementation (which is referred to as DFS), such as <ph id="ph1">&lt;b&gt;</ph>fschk<ph id="ph2">&lt;/b&gt;</ph> and <ph id="ph3">&lt;b&gt;</ph>dfsadmin<ph id="ph4">&lt;/b&gt;</ph>, will show different behavior in Azure Blob storage.</source>
          <target state="new">Only the commands that are specific to the native HDFS implementation (which is referred to as DFS), such as <ph id="ph1">&lt;b&gt;</ph>fschk<ph id="ph2">&lt;/b&gt;</ph> and <ph id="ph3">&lt;b&gt;</ph>dfsadmin<ph id="ph4">&lt;/b&gt;</ph>, will show different behavior in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>For information about provisioning an HDInsight cluster, see <bpt id="p1">[</bpt>Get Started with HDInsight<ept id="p1">][hdinsight-get-started]</ept> or <bpt id="p2">[</bpt>Provision HDInsight clusters<ept id="p2">][hdinsight-provision]</ept>.</source>
          <target state="new">For information about provisioning an HDInsight cluster, see <bpt id="p1">[</bpt>Get Started with HDInsight<ept id="p1">][hdinsight-get-started]</ept> or <bpt id="p2">[</bpt>Provision HDInsight clusters<ept id="p2">][hdinsight-provision]</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="architecture"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>HDInsight storage architecture</source>
          <target state="new"><ph id="ph1">&lt;a id="architecture"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>HDInsight storage architecture</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>The following diagram provides an abstract view of the HDInsight storage architecture:</source>
          <target state="new">The following diagram provides an abstract view of the HDInsight storage architecture:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Hadoop clusters use the HDFS API to access and store structured and unstructured data in Blob storage.</source>
          <target state="new">Hadoop clusters use the HDFS API to access and store structured and unstructured data in Blob storage.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>HDInsight provides access to the distributed file system that is locally attached to the compute nodes.</source>
          <target state="new">HDInsight provides access to the distributed file system that is locally attached to the compute nodes.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This file system can be accessed by using the fully qualified URI, for example:</source>
          <target state="new">This file system can be accessed by using the fully qualified URI, for example:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>In addition, HDInsight provides the ability to access data that is stored in Azure Blob storage.</source>
          <target state="new">In addition, HDInsight provides the ability to access data that is stored in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The syntax is:</source>
          <target state="new">The syntax is:</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Hadoop supports a notion of the default file system.</source>
          <target state="new">Hadoop supports a notion of the default file system.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The default file system implies a default scheme and authority.</source>
          <target state="new">The default file system implies a default scheme and authority.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>It can also be used to resolve relative paths.</source>
          <target state="new">It can also be used to resolve relative paths.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>During the HDInsight provisioning process, an Azure Storage account and a specific Azure Blob storage container from that account is designated as the default file system.</source>
          <target state="new">During the HDInsight provisioning process, an Azure Storage account and a specific Azure Blob storage container from that account is designated as the default file system.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>In addition to this storage account, you can add additional storage accounts from the same Azure subscription or different Azure subscriptions during the provisioning process.</source>
          <target state="new">In addition to this storage account, you can add additional storage accounts from the same Azure subscription or different Azure subscriptions during the provisioning process.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For instructions about adding additional storage accounts, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">][hdinsight-provision]</ept>.</source>
          <target state="new">For instructions about adding additional storage accounts, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">][hdinsight-provision]</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Containers in the storage accounts that are connected to a cluster:<ept id="p1">**</ept> Because the account name and key are associated with the cluster during provisioning, you have full access to the blobs in those containers.</source>
          <target state="new"><bpt id="p1">**</bpt>Containers in the storage accounts that are connected to a cluster:<ept id="p1">**</ept> Because the account name and key are associated with the cluster during provisioning, you have full access to the blobs in those containers.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Public containers or public blobs in storage accounts that are NOT connected to a cluster:<ept id="p1">**</ept> You have read-only permission to the blobs in the containers.</source>
          <target state="new"><bpt id="p1">**</bpt>Public containers or public blobs in storage accounts that are NOT connected to a cluster:<ept id="p1">**</ept> You have read-only permission to the blobs in the containers.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Public containers allow you to get a list of all blobs that are available in that container and get container metadata.</source>
          <target state="new">Public containers allow you to get a list of all blobs that are available in that container and get container metadata.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Public blobs allow you to access the blobs only if you know the exact URL.</source>
          <target state="new">Public blobs allow you to access the blobs only if you know the exact URL.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>For more information, see <ph id="ph1">&lt;a href="http://msdn.microsoft.com/library/windowsazure/dd179354.aspx"&gt;</ph>Restrict access to containers and blobs<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">For more information, see <ph id="ph1">&lt;a href="http://msdn.microsoft.com/library/windowsazure/dd179354.aspx"&gt;</ph>Restrict access to containers and blobs<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Private containers in storage accounts that are NOT connected to a cluster:<ept id="p1">**</ept> You can't access the blobs in the containers unless you define the storage account when you submit the WebHCat jobs.</source>
          <target state="new"><bpt id="p1">**</bpt>Private containers in storage accounts that are NOT connected to a cluster:<ept id="p1">**</ept> You can't access the blobs in the containers unless you define the storage account when you submit the WebHCat jobs.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>This is explained later in this article.</source>
          <target state="new">This is explained later in this article.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The storage accounts that are defined in the provisioning process and their keys are stored in %HADOOP_HOME%/conf/core-site.xml on the cluster nodes.</source>
          <target state="new">The storage accounts that are defined in the provisioning process and their keys are stored in %HADOOP_HOME%/conf/core-site.xml on the cluster nodes.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The default behavior of HDInsight is to use the storage accounts defined in the core-site.xml file.</source>
          <target state="new">The default behavior of HDInsight is to use the storage accounts defined in the core-site.xml file.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>It is not recommended to edit the core-site.xml file because the cluster head node(master) may be reimaged or migrated at any time, and any changes to those files will be lost.</source>
          <target state="new">It is not recommended to edit the core-site.xml file because the cluster head node(master) may be reimaged or migrated at any time, and any changes to those files will be lost.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Multiple WebHCat jobs, including Hive, MapReduce, Hadoop streaming, and Pig, can carry a description of storage accounts and metadata with them.</source>
          <target state="new">Multiple WebHCat jobs, including Hive, MapReduce, Hadoop streaming, and Pig, can carry a description of storage accounts and metadata with them.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>(This currently works for Pig with storage accounts, but not for metadata.) In the <bpt id="p1">[</bpt>Access blobs using Azure PowerShell<ept id="p1">](#powershell)</ept> section of this article, there is a sample of this feature.</source>
          <target state="new">(This currently works for Pig with storage accounts, but not for metadata.) In the <bpt id="p1">[</bpt>Access blobs using Azure PowerShell<ept id="p1">](#powershell)</ept> section of this article, there is a sample of this feature.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Using an HDInsight Cluster with Alternate Storage Accounts and Metastores<ept id="p1">](http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Using an HDInsight Cluster with Alternate Storage Accounts and Metastores<ept id="p1">](http://social.technet.microsoft.com/wiki/contents/articles/23256.using-an-hdinsight-cluster-with-alternate-storage-accounts-and-metastores.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Blob storage can be used for structured and unstructured data.</source>
          <target state="new">Blob storage can be used for structured and unstructured data.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Blob storage containers store data as key/value pairs, and there is no directory hierarchy.</source>
          <target state="new">Blob storage containers store data as key/value pairs, and there is no directory hierarchy.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>However the slash character ( / ) can be used within the key name to make it appear as if a file is stored within a directory structure.</source>
          <target state="new">However the slash character ( / ) can be used within the key name to make it appear as if a file is stored within a directory structure.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For example, a blob's key may be <bpt id="p1">*</bpt>input/log1.txt<ept id="p1">*</ept>.</source>
          <target state="new">For example, a blob's key may be <bpt id="p1">*</bpt>input/log1.txt<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>No actual <bpt id="p1">*</bpt>input<ept id="p1">*</ept> directory exists, but due to the presence of the slash character in the key name, it has the appearance of a file path.</source>
          <target state="new">No actual <bpt id="p1">*</bpt>input<ept id="p1">*</ept> directory exists, but due to the presence of the slash character in the key name, it has the appearance of a file path.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="benefits"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Benefits of Blob storage</source>
          <target state="new"><ph id="ph1">&lt;a id="benefits"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Benefits of Blob storage</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The implied performance cost of not co-locating compute clusters and storage resources is mitigated by the way the compute clusters are provisioned close to the storage account resources inside the Azure datacenter, where the high-speed network makes it very efficient for the compute nodes to access the data inside Azure Blob storage.</source>
          <target state="new">The implied performance cost of not co-locating compute clusters and storage resources is mitigated by the way the compute clusters are provisioned close to the storage account resources inside the Azure datacenter, where the high-speed network makes it very efficient for the compute nodes to access the data inside Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>There are several benefits associated with storing the data in Azure Blob storage instead of HDFS:</source>
          <target state="new">There are several benefits associated with storing the data in Azure Blob storage instead of HDFS:</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Data reuse and sharing:<ept id="p1">**</ept> The data in HDFS is located inside the compute cluster.</source>
          <target state="new"><bpt id="p1">**</bpt>Data reuse and sharing:<ept id="p1">**</ept> The data in HDFS is located inside the compute cluster.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Only the applications that have access to the compute cluster can use the data by using HDFS APIs.</source>
          <target state="new">Only the applications that have access to the compute cluster can use the data by using HDFS APIs.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>The data in Azure Blob storage can be accessed either through the HDFS APIs or through the <bpt id="p1">[</bpt>Blob Storage REST APIs<ept id="p1">][blob-storage-restAPI]</ept>.</source>
          <target state="new">The data in Azure Blob storage can be accessed either through the HDFS APIs or through the <bpt id="p1">[</bpt>Blob Storage REST APIs<ept id="p1">][blob-storage-restAPI]</ept>.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Thus, a larger set of applications (including other HDInsight clusters) and tools can be used to produce and consume the data.</source>
          <target state="new">Thus, a larger set of applications (including other HDInsight clusters) and tools can be used to produce and consume the data.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Data archiving:<ept id="p1">**</ept> Storing data in Azure Blob storage enables the HDInsight clusters used for computation to be safely deleted without losing user data.</source>
          <target state="new"><bpt id="p1">**</bpt>Data archiving:<ept id="p1">**</ept> Storing data in Azure Blob storage enables the HDInsight clusters used for computation to be safely deleted without losing user data.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Data storage cost:<ept id="p1">**</ept> Storing data in DFS for the long term is more costly than storing the data in Azure Blob storage because the cost of a compute cluster is higher than the cost of an Azure Blob storage container.</source>
          <target state="new"><bpt id="p1">**</bpt>Data storage cost:<ept id="p1">**</ept> Storing data in DFS for the long term is more costly than storing the data in Azure Blob storage because the cost of a compute cluster is higher than the cost of an Azure Blob storage container.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>In addition, because the data does not have to be reloaded for every compute cluster generation, you are also saving data loading costs.</source>
          <target state="new">In addition, because the data does not have to be reloaded for every compute cluster generation, you are also saving data loading costs.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Elastic scale-out:<ept id="p1">**</ept> Although HDFS provides you with a scaled-out file system, the scale is determined by the number of nodes that you provision for your cluster.</source>
          <target state="new"><bpt id="p1">**</bpt>Elastic scale-out:<ept id="p1">**</ept> Although HDFS provides you with a scaled-out file system, the scale is determined by the number of nodes that you provision for your cluster.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Changing the scale can become a more complicated process than relying on the elastic scaling capabilities that you get automatically in Azure  Blob storage.</source>
          <target state="new">Changing the scale can become a more complicated process than relying on the elastic scaling capabilities that you get automatically in Azure  Blob storage.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Geo-replication:<ept id="p1">**</ept> Your Azure Blob storage containers can be geo-replicated.</source>
          <target state="new"><bpt id="p1">**</bpt>Geo-replication:<ept id="p1">**</ept> Your Azure Blob storage containers can be geo-replicated.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Although this gives you geographic recovery and data redundancy, a failover to the geo-replicated location severely impacts your performance, and it may incur additional costs.</source>
          <target state="new">Although this gives you geographic recovery and data redundancy, a failover to the geo-replicated location severely impacts your performance, and it may incur additional costs.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>So our recommendation is to choose the geo-replication wisely and only if the value of the data is worth the additional cost.</source>
          <target state="new">So our recommendation is to choose the geo-replication wisely and only if the value of the data is worth the additional cost.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Certain MapReduce jobs and packages may create intermediate results that you don't really want to store in Azure Blob storage.</source>
          <target state="new">Certain MapReduce jobs and packages may create intermediate results that you don't really want to store in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>In that case, you can elect to store the data in the local HDFS.</source>
          <target state="new">In that case, you can elect to store the data in the local HDFS.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>In fact, HDInsight uses DFS for several of these intermediate results in Hive jobs and other processes.</source>
          <target state="new">In fact, HDInsight uses DFS for several of these intermediate results in Hive jobs and other processes.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="preparingblobstorage"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Create a blob container</source>
          <target state="new"><ph id="ph1">&lt;a id="preparingblobstorage"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Create a blob container</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>To use blobs, you first create an <bpt id="p1">[</bpt>Azure Storage account<ept id="p1">][azure-storage-create]</ept>.</source>
          <target state="new">To use blobs, you first create an <bpt id="p1">[</bpt>Azure Storage account<ept id="p1">][azure-storage-create]</ept>.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>As part of this, you specify an Azure datacenter that will store the objects you create using this account.</source>
          <target state="new">As part of this, you specify an Azure datacenter that will store the objects you create using this account.</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>The cluster and the storage account must be hosted in the same datacenter.</source>
          <target state="new">The cluster and the storage account must be hosted in the same datacenter.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>The Hive metastore SQL Server database and Oozie metastore SQL Server database must also be located in the same datacenter.</source>
          <target state="new">The Hive metastore SQL Server database and Oozie metastore SQL Server database must also be located in the same datacenter.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Wherever it lives, each blob you create belongs to a container in your Azure Storage account.</source>
          <target state="new">Wherever it lives, each blob you create belongs to a container in your Azure Storage account.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>This container may be an existing blob that was created outside of HDInsight, or it may be a container that is created for an HDInsight cluster.</source>
          <target state="new">This container may be an existing blob that was created outside of HDInsight, or it may be a container that is created for an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Don't share a default storage container with multiple HDInsight clusters.</source>
          <target state="new">Don't share a default storage container with multiple HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>If you need to use a shared container to provide access to data for multiple HDInsight clusters then you should add it as an additional storage account in the cluster configuration.</source>
          <target state="new">If you need to use a shared container to provide access to data for multiple HDInsight clusters then you should add it as an additional storage account in the cluster configuration.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">][hdinsight-provision]</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">][hdinsight-provision]</ept>.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>However you can reuse a default storage container after the original HDInsight cluster has been deleted.</source>
          <target state="new">However you can reuse a default storage container after the original HDInsight cluster has been deleted.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>For HBase clusters, you can actually retain the HBase table schema and data by provision a new HBase cluster using the default blob storage container that is used by an HBase cluster that has been deleted.</source>
          <target state="new">For HBase clusters, you can actually retain the HBase table schema and data by provision a new HBase cluster using the default blob storage container that is used by an HBase cluster that has been deleted.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Using the Azure preview portal</source>
          <target state="new">Using the Azure preview portal</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>When provisioning an HDInsight cluster from the preview portal, you have the options to use an existing storage account or create a new storage account:</source>
          <target state="new">When provisioning an HDInsight cluster from the preview portal, you have the options to use an existing storage account or create a new storage account:</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>hdinsight hadoop provision data source</source>
          <target state="new">hdinsight hadoop provision data source</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Using Azure CLI</source>
          <target state="new">Using Azure CLI</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>If you have <bpt id="p1">[</bpt>installed and configured the Azure CLI<ept id="p1">](../xplat-cli.md)</ept>, the following command can be used to a storage account and container.</source>
          <target state="new">If you have <bpt id="p1">[</bpt>installed and configured the Azure CLI<ept id="p1">](../xplat-cli.md)</ept>, the following command can be used to a storage account and container.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The <ph id="ph2">`--type`</ph> parameter indicates how the storage account will be replicated.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The <ph id="ph2">`--type`</ph> parameter indicates how the storage account will be replicated.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Azure Storage Replication<ept id="p1">](../storage-redundancy.md)</ept></source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Azure Storage Replication<ept id="p1">](../storage-redundancy.md)</ept></target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>You will be prompted to specify the geographic region that the storage account will be located in.</source>
          <target state="new">You will be prompted to specify the geographic region that the storage account will be located in.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>You should create the storage account in the same region that you plan on creating your HDInsight cluster.</source>
          <target state="new">You should create the storage account in the same region that you plan on creating your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Once the storage account is created, use the following command to retrieve the storage account keys:</source>
          <target state="new">Once the storage account is created, use the following command to retrieve the storage account keys:</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>To create a container, use the following command:</source>
          <target state="new">To create a container, use the following command:</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Using Azure PowerShell</source>
          <target state="new">Using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>If you <bpt id="p1">[</bpt>installed and configured Azure PowerShell<ept id="p1">][powershell-install]</ept>, you can use the following from the Azure PowerShell prompt to create a storage account and container:</source>
          <target state="new">If you <bpt id="p1">[</bpt>installed and configured Azure PowerShell<ept id="p1">][powershell-install]</ept>, you can use the following from the Azure PowerShell prompt to create a storage account and container:</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="addressing"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Address files in Blob storage</source>
          <target state="new"><ph id="ph1">&lt;a id="addressing"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Address files in Blob storage</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>The URI scheme for accessing files in Blob storage from HDInsight is:</source>
          <target state="new">The URI scheme for accessing files in Blob storage from HDInsight is:</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The syntax for addressing the files on the storage emulator (running on HDInsight emulator) is <ph id="ph2">&lt;i&gt;</ph>wasb://&amp;lt;ContainerName&amp;gt;@storageemulator<ph id="ph3">&lt;/i&gt;</ph>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The syntax for addressing the files on the storage emulator (running on HDInsight emulator) is <ph id="ph2">&lt;i&gt;</ph>wasb://&amp;lt;ContainerName&amp;gt;@storageemulator<ph id="ph3">&lt;/i&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The URI scheme provides unencrypted access (with the <bpt id="p1">*</bpt>wasb:<ept id="p1">*</ept> prefix) and SSL encrypted access (with <bpt id="p2">*</bpt>wasbs<ept id="p2">*</ept>).</source>
          <target state="new">The URI scheme provides unencrypted access (with the <bpt id="p1">*</bpt>wasb:<ept id="p1">*</ept> prefix) and SSL encrypted access (with <bpt id="p2">*</bpt>wasbs<ept id="p2">*</ept>).</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>We recommend using <bpt id="p1">*</bpt>wasbs<ept id="p1">*</ept> wherever possible, even when accessing data that lives inside the same datacenter in Azure.</source>
          <target state="new">We recommend using <bpt id="p1">*</bpt>wasbs<ept id="p1">*</ept> wherever possible, even when accessing data that lives inside the same datacenter in Azure.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The &amp;lt;BlobStorageContainerName&amp;gt; identifies the name of the container in Azure Blob storage.</source>
          <target state="new">The &amp;lt;BlobStorageContainerName&amp;gt; identifies the name of the container in Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>The &amp;lt;StorageAccountName&amp;gt; identifies the Azure Storage account name.</source>
          <target state="new">The &amp;lt;StorageAccountName&amp;gt; identifies the Azure Storage account name.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>A fully qualified domain name (FQDN) is required.</source>
          <target state="new">A fully qualified domain name (FQDN) is required.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>If neither &amp;lt;BlobStorageContainerName&amp;gt; nor &amp;lt;StorageAccountName&amp;gt; has been specified, the default file system is used.</source>
          <target state="new">If neither &amp;lt;BlobStorageContainerName&amp;gt; nor &amp;lt;StorageAccountName&amp;gt; has been specified, the default file system is used.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>For the files on the default file system, you can use a relative path or an absolute path.</source>
          <target state="new">For the files on the default file system, you can use a relative path or an absolute path.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>For example, the <bpt id="p1">*</bpt>hadoop-mapreduce-examples.jar<ept id="p1">*</ept> file that comes with HDInsight clusters can be referred to by using one of the following:</source>
          <target state="new">For example, the <bpt id="p1">*</bpt>hadoop-mapreduce-examples.jar<ept id="p1">*</ept> file that comes with HDInsight clusters can be referred to by using one of the following:</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The file name is <ph id="ph2">&lt;i&gt;</ph>hadoop-examples.jar<ph id="ph3">&lt;/i&gt;</ph> in HDInsight versions 2.1 and 1.6 clusters.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The file name is <ph id="ph2">&lt;i&gt;</ph>hadoop-examples.jar<ph id="ph3">&lt;/i&gt;</ph> in HDInsight versions 2.1 and 1.6 clusters.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>The &amp;lt;path&amp;gt; is the file or directory HDFS path name.</source>
          <target state="new">The &amp;lt;path&amp;gt; is the file or directory HDFS path name.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Because containers in Azure Blob storage are simply key-value stores, there is no true hierarchical file system.</source>
          <target state="new">Because containers in Azure Blob storage are simply key-value stores, there is no true hierarchical file system.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>A slash character ( / ) inside a blob key is interpreted as a directory separator.</source>
          <target state="new">A slash character ( / ) inside a blob key is interpreted as a directory separator.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>For example, the blob name for <bpt id="p1">*</bpt>hadoop-mapreduce-examples.jar<ept id="p1">*</ept> is:</source>
          <target state="new">For example, the blob name for <bpt id="p1">*</bpt>hadoop-mapreduce-examples.jar<ept id="p1">*</ept> is:</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> When working with blobs outside of HDInsight, most utilities do not recognize the WASB format and instead expect a basic path format, such as <ph id="ph2">`example/jars/hadoop-mapreduce-examples.jar`</ph>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> When working with blobs outside of HDInsight, most utilities do not recognize the WASB format and instead expect a basic path format, such as <ph id="ph2">`example/jars/hadoop-mapreduce-examples.jar`</ph>.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="azurecli"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Access blobs with Azure CLI</source>
          <target state="new"><ph id="ph1">&lt;a id="azurecli"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Access blobs with Azure CLI</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Use the following command to list the blob-related commands:</source>
          <target state="new">Use the following command to list the blob-related commands:</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Example of using Azure CLI to upload a file</source>
          <target state="new">Example of using Azure CLI to upload a file</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Example of using Azure CLI to download a file</source>
          <target state="new">Example of using Azure CLI to download a file</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>Example of using Azure CLI to delete a file</source>
          <target state="new">Example of using Azure CLI to delete a file</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Example of using Azure CLI to list files</source>
          <target state="new">Example of using Azure CLI to list files</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="powershell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Access blobs with Azure PowerShell</source>
          <target state="new"><ph id="ph1">&lt;a id="powershell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Access blobs with Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The commands in this section provide a basic example of using PowerShell to access data stored in blobs.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The commands in this section provide a basic example of using PowerShell to access data stored in blobs.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>For a more full-featured example that is customized for working with HDInsight, see the <bpt id="p1">[</bpt>HDInsight Tools<ept id="p1">](https://github.com/Blackmist/hdinsight-tools)</ept>.</source>
          <target state="new">For a more full-featured example that is customized for working with HDInsight, see the <bpt id="p1">[</bpt>HDInsight Tools<ept id="p1">](https://github.com/Blackmist/hdinsight-tools)</ept>.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Use the following command to list the blob-related cmdlets:</source>
          <target state="new">Use the following command to list the blob-related cmdlets:</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>List of blob-related PowerShell cmdlets.</source>
          <target state="new">List of blob-related PowerShell cmdlets.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Example of using Azure PowerShell to upload a file</source>
          <target state="new">Example of using Azure PowerShell to upload a file</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>Upload data to HDInsight<ept id="p1">][hdinsight-upload-data]</ept>.</source>
          <target state="new">See <bpt id="p1">[</bpt>Upload data to HDInsight<ept id="p1">][hdinsight-upload-data]</ept>.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Example of using Azure PowerShell to download a file</source>
          <target state="new">Example of using Azure PowerShell to download a file</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>The following scrip downloads a block blob to the current folder.</source>
          <target state="new">The following scrip downloads a block blob to the current folder.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Before running the script, change the directory to a folder where you have write permissions.</source>
          <target state="new">Before running the script, change the directory to a folder where you have write permissions.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Example of using Azure PowerShell to delete a file</source>
          <target state="new">Example of using Azure PowerShell to delete a file</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>The following script shows how to delete a file.</source>
          <target state="new">The following script shows how to delete a file.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Example of using Azure PowerShell to list files in a folder</source>
          <target state="new">Example of using Azure PowerShell to list files in a folder</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>The following script shows how to list files inside a folder.</source>
          <target state="new">The following script shows how to list files inside a folder.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>(The next example shows how to use the <bpt id="p1">**</bpt>Invoke-Hive<ept id="p1">**</ept> cmdlet to execute the <bpt id="p2">**</bpt>dfs ls<ept id="p2">**</ept> command to list a folder.)</source>
          <target state="new">(The next example shows how to use the <bpt id="p1">**</bpt>Invoke-Hive<ept id="p1">**</ept> cmdlet to execute the <bpt id="p2">**</bpt>dfs ls<ept id="p2">**</ept> command to list a folder.)</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Example of using Azure PowerShell to run a Hive query using an undefined storage account</source>
          <target state="new">Example of using Azure PowerShell to run a Hive query using an undefined storage account</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>This example shows how to list a folder from storage account that is not defined during the provisioning process.</source>
          <target state="new">This example shows how to list a folder from storage account that is not defined during the provisioning process.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>$clusterName = "</source>
          <target state="new">$clusterName = "</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>In this article, you learned how to use HDFS-compatible Azure Blob storage with HDInsight, and you learned that Azure Blob storage is a fundamental component of HDInsight.</source>
          <target state="new">In this article, you learned how to use HDFS-compatible Azure Blob storage with HDInsight, and you learned that Azure Blob storage is a fundamental component of HDInsight.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>This allows you to build scalable, long-term, archiving data acquisition solutions with Azure Blob storage and use HDInsight to unlock the information inside the stored  structured and unstructured data.</source>
          <target state="new">This allows you to build scalable, long-term, archiving data acquisition solutions with Azure Blob storage and use HDInsight to unlock the information inside the stored  structured and unstructured data.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>For more information, see:</source>
          <target state="new">For more information, see:</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>Get Started with Azure HDInsight</source>
          <target state="new">Get Started with Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Upload data to HDInsight</source>
          <target state="new">Upload data to HDInsight</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight</source>
          <target state="new">Use Hive with HDInsight</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Use Pig with HDInsight</source>
          <target state="new">Use Pig with HDInsight</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3628eda49f495fa97d8cbbd77050fc560341b259</xliffext:olfilehash>
  </header>
</xliff>