<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Apache Spark Job Server on HDInsight | Microsoft Azure</source>
          <target state="new">Apache Spark Job Server on HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use the Spark Job Server to remotely submit and manage jobs on a Spark cluster.</source>
          <target state="new">Learn how to use the Spark Job Server to remotely submit and manage jobs on a Spark cluster.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Spark Job Server on Azure HDInsight clusters</source>
          <target state="new">Spark Job Server on Azure HDInsight clusters</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Apache Spark cluster on Azure HDInight packages the Spark Job Server as part of the cluster deployment.</source>
          <target state="new">Apache Spark cluster on Azure HDInight packages the Spark Job Server as part of the cluster deployment.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Spark Job Server provides REST APIs to create Spark context, submit Spark application to context, check job status, kill context, etc. This article provides some examples on how to use Curl to perform some common tasks on a Spark cluster using a Job Server.</source>
          <target state="new">Spark Job Server provides REST APIs to create Spark context, submit Spark application to context, check job status, kill context, etc. This article provides some examples on how to use Curl to perform some common tasks on a Spark cluster using a Job Server.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> For complete documentation for the Spark Job Server, see <bpt id="p1">[</bpt>https://github.com/spark-jobserver/spark-jobserver<ept id="p1">](https://github.com/spark-jobserver/spark-jobserver)</ept>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> For complete documentation for the Spark Job Server, see <bpt id="p1">[</bpt>https://github.com/spark-jobserver/spark-jobserver<ept id="p1">](https://github.com/spark-jobserver/spark-jobserver)</ept>.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="uploadjar"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Upload a jar to a Spark cluster</source>
          <target state="new"><ph id="ph1">&lt;a name="uploadjar"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Upload a jar to a Spark cluster</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="createcontext"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Create new persistent context in job server</source>
          <target state="new"><ph id="ph1">&lt;a name="createcontext"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Create new persistent context in job server</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="submitapp"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Submit an application to the cluster</source>
          <target state="new"><ph id="ph1">&lt;a name="submitapp"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Submit an application to the cluster</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>where mypostdata.txt defines your application.</source>
          <target state="new">where mypostdata.txt defines your application.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="submitapp"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Delete a job</source>
          <target state="new"><ph id="ph1">&lt;a name="submitapp"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Delete a job</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Example:</source>
          <target state="new">Example:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="seealso"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>See also</source>
          <target state="new"><ph id="ph1">&lt;a name="seealso"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>See also</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Overview: Apache Spark on Azure HDInsight</source>
          <target state="new">Overview: Apache Spark on Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Provision a Spark on HDInsight cluster</source>
          <target state="new">Provision a Spark on HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Perform interactive data analysis using Spark in HDInsight with BI tools</source>
          <target state="new">Perform interactive data analysis using Spark in HDInsight with BI tools</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Use Spark in HDInsight for building machine learning applications</source>
          <target state="new">Use Spark in HDInsight for building machine learning applications</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Use Spark in HDInsight for building real-time streaming applications</source>
          <target state="new">Use Spark in HDInsight for building real-time streaming applications</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Manage resources for the Apache Spark cluster in Azure HDInsight</source>
          <target state="new">Manage resources for the Apache Spark cluster in Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">88d8a4b919f35262dd618589deacd0e3aa0a52ae</xliffext:olfilehash>
  </header>
</xliff>