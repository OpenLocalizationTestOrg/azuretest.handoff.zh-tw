<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Autoscaling guidance | Microsoft Azure</source>
          <target state="new">Autoscaling guidance | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Guidance upon how to autoscale to dynamically allocate resources required by an application.</source>
          <target state="new">Guidance upon how to autoscale to dynamically allocate resources required by an application.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Autoscaling guidance</source>
          <target state="new">Autoscaling guidance</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Overview</source>
          <target state="new">Overview</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Autoscaling is the process of dynamically allocating the resources required by an application to match performance requirements and satisfy service level agreements (SLAs) while minimizing runtime costs.</source>
          <target state="new">Autoscaling is the process of dynamically allocating the resources required by an application to match performance requirements and satisfy service level agreements (SLAs) while minimizing runtime costs.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>As the volume of work grows, an application may require additional resources to enable it to perform its tasks in a timely manner.</source>
          <target state="new">As the volume of work grows, an application may require additional resources to enable it to perform its tasks in a timely manner.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>As demand slackens, resources can be de-allocated to minimize costs while still maintaining adequate performance and meeting SLAs.</source>
          <target state="new">As demand slackens, resources can be de-allocated to minimize costs while still maintaining adequate performance and meeting SLAs.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Autoscaling takes advantage of the elasticity of cloud-hosted environments while easing management overhead by reducing the need for an operator to continually monitor the performance of a system and make decisions about adding or removing resources.</source>
          <target state="new">Autoscaling takes advantage of the elasticity of cloud-hosted environments while easing management overhead by reducing the need for an operator to continually monitor the performance of a system and make decisions about adding or removing resources.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Autoscaling applies to all of the resources used by an application, not just the compute resources.</source>
          <target state="new">Autoscaling applies to all of the resources used by an application, not just the compute resources.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>For example, if your system uses message queues to send and receive information, it could create additional queues as it scales.</source>
          <target state="new">For example, if your system uses message queues to send and receive information, it could create additional queues as it scales.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Types of scaling</source>
          <target state="new">Types of scaling</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Scaling typically takes one of two forms—vertical and horizontal scaling:</source>
          <target state="new">Scaling typically takes one of two forms—vertical and horizontal scaling:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Vertical Scaling<ept id="p1">**</ept> (often referred to as <bpt id="p2">_</bpt>scaling up and down<ept id="p2">_</ept>) requires that you modify the hardware (expand or reduce its capacity and performance), or redeploy the solution using alternative hardware that has the appropriate capacity and performance.</source>
          <target state="new"><bpt id="p1">**</bpt>Vertical Scaling<ept id="p1">**</ept> (often referred to as <bpt id="p2">_</bpt>scaling up and down<ept id="p2">_</ept>) requires that you modify the hardware (expand or reduce its capacity and performance), or redeploy the solution using alternative hardware that has the appropriate capacity and performance.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>In a cloud environment, the hardware platform is typically a virtualized environment.</source>
          <target state="new">In a cloud environment, the hardware platform is typically a virtualized environment.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Unless the original hardware was substantially overprovisioned, with the consequent upfront capital expense, vertically scaling up in this environment involves provisioning more powerful resources, and then moving the system onto these new resources.</source>
          <target state="new">Unless the original hardware was substantially overprovisioned, with the consequent upfront capital expense, vertically scaling up in this environment involves provisioning more powerful resources, and then moving the system onto these new resources.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Vertical scaling is often a disruptive process that requires making the system temporarily unavailable while it is being redeployed.</source>
          <target state="new">Vertical scaling is often a disruptive process that requires making the system temporarily unavailable while it is being redeployed.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>It may be possible to keep the original system running while the new hardware is provisioned and brought online, but there will likely be some interruption while the processing transitions from the old environment to the new one.</source>
          <target state="new">It may be possible to keep the original system running while the new hardware is provisioned and brought online, but there will likely be some interruption while the processing transitions from the old environment to the new one.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>It is uncommon to use autoscaling to implement a vertical scaling strategy.</source>
          <target state="new">It is uncommon to use autoscaling to implement a vertical scaling strategy.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Horizontal Scaling<ept id="p1">**</ept> (often referred to as <bpt id="p2">_</bpt>scaling out and in<ept id="p2">_</ept>) requires deploying the solution on additional or fewer resources, which are typically commodity resources rather than high-powered systems.</source>
          <target state="new"><bpt id="p1">**</bpt>Horizontal Scaling<ept id="p1">**</ept> (often referred to as <bpt id="p2">_</bpt>scaling out and in<ept id="p2">_</ept>) requires deploying the solution on additional or fewer resources, which are typically commodity resources rather than high-powered systems.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The solution can continue running without interruption while these resources are provisioned.</source>
          <target state="new">The solution can continue running without interruption while these resources are provisioned.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>When the provisioning process is complete, copies of the elements that comprise the solution can be deployed on these additional resources and made available.</source>
          <target state="new">When the provisioning process is complete, copies of the elements that comprise the solution can be deployed on these additional resources and made available.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>If demand drops, the additional resources can be reclaimed after the elements using them have been shut down cleanly.</source>
          <target state="new">If demand drops, the additional resources can be reclaimed after the elements using them have been shut down cleanly.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Many cloud-based systems, including Microsoft Azure, support automation of this form of scaling.</source>
          <target state="new">Many cloud-based systems, including Microsoft Azure, support automation of this form of scaling.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Implementing an autoscaling strategy</source>
          <target state="new">Implementing an autoscaling strategy</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Implementing an autoscaling strategy typically involves the following components and processes:</source>
          <target state="new">Implementing an autoscaling strategy typically involves the following components and processes:</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Instrumentation and monitoring systems at the application, service, and infrastructure levels that capture key metrics such as response times, queue lengths, CPU utilization, and memory usage.</source>
          <target state="new">Instrumentation and monitoring systems at the application, service, and infrastructure levels that capture key metrics such as response times, queue lengths, CPU utilization, and memory usage.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Decision-making logic that can evaluate the monitored scaling factors against predefined system thresholds or schedules and make decisions regarding whether to scale or not.</source>
          <target state="new">Decision-making logic that can evaluate the monitored scaling factors against predefined system thresholds or schedules and make decisions regarding whether to scale or not.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Components that are responsible for carrying out tasks associated with scaling the system, such as provisioning or de-provisioning resources.</source>
          <target state="new">Components that are responsible for carrying out tasks associated with scaling the system, such as provisioning or de-provisioning resources.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Testing, monitoring, and tuning of the autoscaling strategy to ensure that it functions as expected.</source>
          <target state="new">Testing, monitoring, and tuning of the autoscaling strategy to ensure that it functions as expected.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Most cloud-based environments, such as Microsoft Azure, provide built-in autoscaling mechanisms that address common scenarios.</source>
          <target state="new">Most cloud-based environments, such as Microsoft Azure, provide built-in autoscaling mechanisms that address common scenarios.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>If the environment or service you use does not provide the necessary automated scaling functionality, or if you have extreme autoscaling requirements beyond its capabilities, a custom implementation may be necessary to collect operational and system metrics, analyze them to identify relevant data, and then scale resources accordingly.</source>
          <target state="new">If the environment or service you use does not provide the necessary automated scaling functionality, or if you have extreme autoscaling requirements beyond its capabilities, a custom implementation may be necessary to collect operational and system metrics, analyze them to identify relevant data, and then scale resources accordingly.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Considerations for implementing autoscaling</source>
          <target state="new">Considerations for implementing autoscaling</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Autoscaling is not an instant solution.</source>
          <target state="new">Autoscaling is not an instant solution.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Simply adding resources to a system or running more instances of a process does not guarantee that the performance of the system will improve.</source>
          <target state="new">Simply adding resources to a system or running more instances of a process does not guarantee that the performance of the system will improve.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Consider the following points when designing an autoscaling strategy:</source>
          <target state="new">Consider the following points when designing an autoscaling strategy:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>The system must be designed to be horizontally scalable.</source>
          <target state="new">The system must be designed to be horizontally scalable.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Avoid making assumptions about instance affinity; do not design solutions that require that the code is always running in a specific instance of a process.</source>
          <target state="new">Avoid making assumptions about instance affinity; do not design solutions that require that the code is always running in a specific instance of a process.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>When scaling a cloud service or web site horizontally, do not assume that a series of requests from the same source will always be routed to the same instance.</source>
          <target state="new">When scaling a cloud service or web site horizontally, do not assume that a series of requests from the same source will always be routed to the same instance.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>For the same reason, design services to be stateless to avoid requiring a series of requests from an application to always be routed to the same instance of a service.</source>
          <target state="new">For the same reason, design services to be stateless to avoid requiring a series of requests from an application to always be routed to the same instance of a service.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>When designing a service that reads messages from a queue and processes them, do not make any assumptions about which instance of the service handles a specific message because autoscaling could start additional instances of a service as the queue length grows.</source>
          <target state="new">When designing a service that reads messages from a queue and processes them, do not make any assumptions about which instance of the service handles a specific message because autoscaling could start additional instances of a service as the queue length grows.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt>Competing Consumers pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568101.aspx)</ept> describes how to handle this scenario.</source>
          <target state="new">The <bpt id="p1">[</bpt>Competing Consumers pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568101.aspx)</ept> describes how to handle this scenario.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>If the solution implements a long-running task, design this task to support both scaling out and scaling in.</source>
          <target state="new">If the solution implements a long-running task, design this task to support both scaling out and scaling in.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Without due care, such a task could prevent an instance of a process from being shutdown cleanly when the system scales in, or it could lose data if the process is forcibly terminated.</source>
          <target state="new">Without due care, such a task could prevent an instance of a process from being shutdown cleanly when the system scales in, or it could lose data if the process is forcibly terminated.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Ideally, refactor a long-running task and break up the processing that it performs into smaller, discrete chunks.</source>
          <target state="new">Ideally, refactor a long-running task and break up the processing that it performs into smaller, discrete chunks.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt>Pipes and Filters pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568100.aspx)</ept> provides an example of how you can achieve this.</source>
          <target state="new">The <bpt id="p1">[</bpt>Pipes and Filters pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568100.aspx)</ept> provides an example of how you can achieve this.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Alternatively, you can implement a checkpoint mechanism that records state information about the task at regular intervals, and save this state in durable storage that can be accessed by any instance of the process running the task.</source>
          <target state="new">Alternatively, you can implement a checkpoint mechanism that records state information about the task at regular intervals, and save this state in durable storage that can be accessed by any instance of the process running the task.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>In this way, if the process is shutdown, the work that it was performing can be resumed from the last checkpoint by using another instance.</source>
          <target state="new">In this way, if the process is shutdown, the work that it was performing can be resumed from the last checkpoint by using another instance.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>When background tasks run on separate compute instances, such as in worker roles of a Cloud Services hosted application, you may need to scale different parts of the application using different scaling policies.</source>
          <target state="new">When background tasks run on separate compute instances, such as in worker roles of a Cloud Services hosted application, you may need to scale different parts of the application using different scaling policies.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>For example, you may need to deploy additional UI compute instances without increasing the number of background compute instances, or the opposite of this.</source>
          <target state="new">For example, you may need to deploy additional UI compute instances without increasing the number of background compute instances, or the opposite of this.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>If you offer different levels of service (such as basic and premium service packages), you may need to scale out the compute resources for premium service packages more aggressively than those for basic service packages in order to meet SLAs.</source>
          <target state="new">If you offer different levels of service (such as basic and premium service packages), you may need to scale out the compute resources for premium service packages more aggressively than those for basic service packages in order to meet SLAs.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Consider using the length of the queue over which UI and background compute instances communicate as a driver for your autoscaling strategy.</source>
          <target state="new">Consider using the length of the queue over which UI and background compute instances communicate as a driver for your autoscaling strategy.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>This is the best indicator of an imbalance or difference between the current load and the processing capacity of the background task.</source>
          <target state="new">This is the best indicator of an imbalance or difference between the current load and the processing capacity of the background task.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>If you base your autoscaling strategy on counters that measure business processes, such as the number of orders placed per hour or the average execution time of a complex transaction, ensure that you fully understand the relationship between the results from these types of counters and the actual compute capacity requirements.</source>
          <target state="new">If you base your autoscaling strategy on counters that measure business processes, such as the number of orders placed per hour or the average execution time of a complex transaction, ensure that you fully understand the relationship between the results from these types of counters and the actual compute capacity requirements.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>It may be necessary to scale more than one component or compute unit in response to changes in business process counters.</source>
          <target state="new">It may be necessary to scale more than one component or compute unit in response to changes in business process counters.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>To prevent a system from attempting to scale out excessively, and to avoid the costs associated with running many thousands of instances, consider limiting the maximum number of instances that can be automatically added.</source>
          <target state="new">To prevent a system from attempting to scale out excessively, and to avoid the costs associated with running many thousands of instances, consider limiting the maximum number of instances that can be automatically added.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Most autoscaling mechanisms allow you to specify the minimum and maximum number of instances for a rule.</source>
          <target state="new">Most autoscaling mechanisms allow you to specify the minimum and maximum number of instances for a rule.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>In addition, consider gracefully degrading the functionality that the system provides if the maximum number of instances have been deployed and the system is still overloaded.</source>
          <target state="new">In addition, consider gracefully degrading the functionality that the system provides if the maximum number of instances have been deployed and the system is still overloaded.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Keep in mind that autoscaling might not be the most appropriate mechanism to handle a sudden burst in workload.</source>
          <target state="new">Keep in mind that autoscaling might not be the most appropriate mechanism to handle a sudden burst in workload.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>It takes time to provision and start new instances of a service or add resources to a system, and the peak may have passed by the time these additional resources have been made available.</source>
          <target state="new">It takes time to provision and start new instances of a service or add resources to a system, and the peak may have passed by the time these additional resources have been made available.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>In this scenario, it may be better to throttle the service.</source>
          <target state="new">In this scenario, it may be better to throttle the service.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>For more information, see the <bpt id="p1">[</bpt>Throttling pattern<ept id="p1">](http://msdn.microsoft.com/library/dn589798.aspx)</ept>.</source>
          <target state="new">For more information, see the <bpt id="p1">[</bpt>Throttling pattern<ept id="p1">](http://msdn.microsoft.com/library/dn589798.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Conversely, if you do need the capacity to process all requests when the volume fluctuates rapidly, and cost is not a major contributing factor, consider using an aggressive auto-scaling strategy that starts additional instances more quickly, or by using a scheduled policy that starts a sufficient number of instances to meet the maximum load before that load is expected.</source>
          <target state="new">Conversely, if you do need the capacity to process all requests when the volume fluctuates rapidly, and cost is not a major contributing factor, consider using an aggressive auto-scaling strategy that starts additional instances more quickly, or by using a scheduled policy that starts a sufficient number of instances to meet the maximum load before that load is expected.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>The autoscaling mechanism should monitor the autoscaling process and log the details of each autoscaling event (what triggered it, what resources were added or removed, and when).</source>
          <target state="new">The autoscaling mechanism should monitor the autoscaling process and log the details of each autoscaling event (what triggered it, what resources were added or removed, and when).</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>If you create a custom autoscaling mechanism, ensure that it incorporates this capability.</source>
          <target state="new">If you create a custom autoscaling mechanism, ensure that it incorporates this capability.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The information can be analyzed to help measure the effectiveness of the autoscaling strategy, and tune it if necessary—both in the short term as the usage patterns become more obvious, and over the long term as the business expands or the requirements of the application evolve.</source>
          <target state="new">The information can be analyzed to help measure the effectiveness of the autoscaling strategy, and tune it if necessary—both in the short term as the usage patterns become more obvious, and over the long term as the business expands or the requirements of the application evolve.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>If an application reaches the upper limit defined for autoscaling, the mechanism might also alert an operator who could manually start additional resources if the situation warrants this.</source>
          <target state="new">If an application reaches the upper limit defined for autoscaling, the mechanism might also alert an operator who could manually start additional resources if the situation warrants this.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Note that, under these circumstances, the operator may also be responsible for manually removing these resources after the workload eases.</source>
          <target state="new">Note that, under these circumstances, the operator may also be responsible for manually removing these resources after the workload eases.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Autoscaling in an Azure solution</source>
          <target state="new">Autoscaling in an Azure solution</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>There are several options for configuring autoscaling for your Azure solutions:</source>
          <target state="new">There are several options for configuring autoscaling for your Azure solutions:</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Azure Autoscaling<ept id="p1">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>Azure Autoscaling<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>This feature supports the most common scaling scenarios based on a schedule and, optionally, triggered scaling operations based on runtime metrics (such as processor utilization, queue length, or built in and custom counters).</source>
          <target state="new">This feature supports the most common scaling scenarios based on a schedule and, optionally, triggered scaling operations based on runtime metrics (such as processor utilization, queue length, or built in and custom counters).</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>You can configure simple autoscaling policies for a solution quickly and easily by using the Azure Management Portal, and you can use the Azure Monitoring Services Management Library to configure autoscaling rules with a finer degree of control.</source>
          <target state="new">You can configure simple autoscaling policies for a solution quickly and easily by using the Azure Management Portal, and you can use the Azure Monitoring Services Management Library to configure autoscaling rules with a finer degree of control.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>For more information, see the section <bpt id="p1">[</bpt>The Azure Monitoring Services Management Library<ept id="p1">](#the-azure-monitoring-services-management-library)</ept>.</source>
          <target state="new">For more information, see the section <bpt id="p1">[</bpt>The Azure Monitoring Services Management Library<ept id="p1">](#the-azure-monitoring-services-management-library)</ept>.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>A custom solution<ept id="p1">**</ept> based on the diagnostics, monitoring, and service management features of Azure.</source>
          <target state="new"><bpt id="p1">**</bpt>A custom solution<ept id="p1">**</ept> based on the diagnostics, monitoring, and service management features of Azure.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>For example, you could use Azure diagnostics, custom code, or the <bpt id="p1">[</bpt>System Center Management Pack for Azure<ept id="p1">](http://www.microsoft.com/download/details.aspx?id=38414)</ept> to continually monitor performance of the application; and the <bpt id="p2">[</bpt>Azure Service Management REST API<ept id="p2">](http://msdn.microsoft.com/library/azure/ee460799.aspx)</ept>, the <bpt id="p3">[</bpt>Microsoft Azure Management Libraries<ept id="p3">](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Libraries)</ept>, or the <bpt id="p4">[</bpt>Autoscaling Application Block<ept id="p4">](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx)</ept> to scale out and in.</source>
          <target state="new">For example, you could use Azure diagnostics, custom code, or the <bpt id="p1">[</bpt>System Center Management Pack for Azure<ept id="p1">](http://www.microsoft.com/download/details.aspx?id=38414)</ept> to continually monitor performance of the application; and the <bpt id="p2">[</bpt>Azure Service Management REST API<ept id="p2">](http://msdn.microsoft.com/library/azure/ee460799.aspx)</ept>, the <bpt id="p3">[</bpt>Microsoft Azure Management Libraries<ept id="p3">](https://www.nuget.org/packages/Microsoft.WindowsAzure.Management.Libraries)</ept>, or the <bpt id="p4">[</bpt>Autoscaling Application Block<ept id="p4">](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx)</ept> to scale out and in.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>The metrics for triggering a scaling operation can be any built-in or custom counter, or other instrumentation you implement within the application.</source>
          <target state="new">The metrics for triggering a scaling operation can be any built-in or custom counter, or other instrumentation you implement within the application.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>However, a custom solution is not simple to implement, and should be considered only if none of the previous approaches can fulfil your requirements.</source>
          <target state="new">However, a custom solution is not simple to implement, and should be considered only if none of the previous approaches can fulfil your requirements.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Note that the Autoscaling Application Block is an open sourced framework, and is not supported directly by Microsoft.</source>
          <target state="new">Note that the Autoscaling Application Block is an open sourced framework, and is not supported directly by Microsoft.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Third party services<ept id="p1">**</ept> such as <bpt id="p2">[</bpt>Paraleap AzureWatch<ept id="p2">](http://www.paraleap.com/AzureWatch)</ept> that enable you to scale a solution based on schedules, service load and system performance indicators, custom rules, and combinations of different types of rules.</source>
          <target state="new"><bpt id="p1">**</bpt>Third party services<ept id="p1">**</ept> such as <bpt id="p2">[</bpt>Paraleap AzureWatch<ept id="p2">](http://www.paraleap.com/AzureWatch)</ept> that enable you to scale a solution based on schedules, service load and system performance indicators, custom rules, and combinations of different types of rules.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>When choosing which autoscaling solution to adopt, consider the following points:</source>
          <target state="new">When choosing which autoscaling solution to adopt, consider the following points:</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>Use the built in autoscaling features of the platform, if they can meet your requirements.</source>
          <target state="new">Use the built in autoscaling features of the platform, if they can meet your requirements.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>If not, carefully consider whether you really do need more complex scaling features.</source>
          <target state="new">If not, carefully consider whether you really do need more complex scaling features.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Some examples of additional requirements beyond those the built-in auto-scaling capability offers may include more granularity of control, different ways to detect trigger events for scaling, scaling across subscriptions, scaling other types of resources, and more.</source>
          <target state="new">Some examples of additional requirements beyond those the built-in auto-scaling capability offers may include more granularity of control, different ways to detect trigger events for scaling, scaling across subscriptions, scaling other types of resources, and more.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Consider if you can predict the load on the application with sufficient accuracy to depend only on scheduled autoscaling (adding and removing instances to meet anticipated peaks in demand).</source>
          <target state="new">Consider if you can predict the load on the application with sufficient accuracy to depend only on scheduled autoscaling (adding and removing instances to meet anticipated peaks in demand).</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Where this is not possible, use reactive autoscaling based on metrics collected at runtime to allow the application to handle unpredictable changes in demand.</source>
          <target state="new">Where this is not possible, use reactive autoscaling based on metrics collected at runtime to allow the application to handle unpredictable changes in demand.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>However, it is typically appropriate to combine these approaches.</source>
          <target state="new">However, it is typically appropriate to combine these approaches.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>For example, create a strategy that adds resources such as compute, storage, and queues based on a schedule of the times when you know the application is most busy.</source>
          <target state="new">For example, create a strategy that adds resources such as compute, storage, and queues based on a schedule of the times when you know the application is most busy.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>This helps to ensure that capacity is available when required without the delay encountered when starting new instances.</source>
          <target state="new">This helps to ensure that capacity is available when required without the delay encountered when starting new instances.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>In addition, for each scheduled rule, define metrics that allow reactive autoscaling during that period to ensure that the application can handle sustained but unpredictable peaks in demand.</source>
          <target state="new">In addition, for each scheduled rule, define metrics that allow reactive autoscaling during that period to ensure that the application can handle sustained but unpredictable peaks in demand.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>It is often difficult to understand the relationship between metrics and capacity requirements, especially when an application is initially deployed.</source>
          <target state="new">It is often difficult to understand the relationship between metrics and capacity requirements, especially when an application is initially deployed.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Prefer to provision a little extra capacity at the beginning, and then monitor and tune the autoscaling rules to bring the capacity closer to the actual load.</source>
          <target state="new">Prefer to provision a little extra capacity at the beginning, and then monitor and tune the autoscaling rules to bring the capacity closer to the actual load.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Using Azure Autoscaling</source>
          <target state="new">Using Azure Autoscaling</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Azure Autoscaling enables you to configure scale out and scale in options for a solution.</source>
          <target state="new">Azure Autoscaling enables you to configure scale out and scale in options for a solution.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Azure Autoscaling can automatically add and remove instances of Azure Cloud Services web and worker roles, Azure Mobile Services, and Azure Web Sites applications.</source>
          <target state="new">Azure Autoscaling can automatically add and remove instances of Azure Cloud Services web and worker roles, Azure Mobile Services, and Azure Web Sites applications.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>It can also enable automatic scaling by starting and stopping instances of Azure Virtual Machines.</source>
          <target state="new">It can also enable automatic scaling by starting and stopping instances of Azure Virtual Machines.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>An Azure autoscaling strategy comprises two sets of factors:</source>
          <target state="new">An Azure autoscaling strategy comprises two sets of factors:</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Schedule-based autoscaling that can ensure additional instances are available to coincide with an expected peak in usage, and can scale in once the peak time has passed.</source>
          <target state="new">Schedule-based autoscaling that can ensure additional instances are available to coincide with an expected peak in usage, and can scale in once the peak time has passed.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>This enables you to ensure that you have sufficient instances already running without waiting for the system to react to the load.</source>
          <target state="new">This enables you to ensure that you have sufficient instances already running without waiting for the system to react to the load.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Metrics-based autoscaling that reacts to factors such as average CPU utilization over the last hour, or the backlog of messages that the solution is processing in an Azure storage or Service Bus queue.</source>
          <target state="new">Metrics-based autoscaling that reacts to factors such as average CPU utilization over the last hour, or the backlog of messages that the solution is processing in an Azure storage or Service Bus queue.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>This allows the application to react separately from the scheduled autoscaling rules to accommodate unplanned or unforeseen changes in demand.</source>
          <target state="new">This allows the application to react separately from the scheduled autoscaling rules to accommodate unplanned or unforeseen changes in demand.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Consider the following points when using Azure Autoscaling:</source>
          <target state="new">Consider the following points when using Azure Autoscaling:</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Your autoscaling strategy combines both scheduled and metrics-based scaling.</source>
          <target state="new">Your autoscaling strategy combines both scheduled and metrics-based scaling.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>You can specify both types of rules for a service, so that an application scales both on a schedule and in response to changes in load.</source>
          <target state="new">You can specify both types of rules for a service, so that an application scales both on a schedule and in response to changes in load.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>You should configure the Azure Autoscaling rules and then monitor the performance of your application over time.</source>
          <target state="new">You should configure the Azure Autoscaling rules and then monitor the performance of your application over time.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>Use the results of this monitoring to adjust the way in which the system scales if necessary.</source>
          <target state="new">Use the results of this monitoring to adjust the way in which the system scales if necessary.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>However, keep in mind that autoscaling is not an instantaneous process—it takes time to react to a metric such as average CPU utilization exceeding (or falling below) a specified threshold.</source>
          <target state="new">However, keep in mind that autoscaling is not an instantaneous process—it takes time to react to a metric such as average CPU utilization exceeding (or falling below) a specified threshold.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Autoscaling rules that use a detection mechanism based on a measured trigger attribute (such as CPU usage or queue length) use an aggregated value over time, rather than the instantaneous values, to trigger an autoscaling action.</source>
          <target state="new">Autoscaling rules that use a detection mechanism based on a measured trigger attribute (such as CPU usage or queue length) use an aggregated value over time, rather than the instantaneous values, to trigger an autoscaling action.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>By default, the aggregate is an average of the values.</source>
          <target state="new">By default, the aggregate is an average of the values.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>This prevents the system from reacting too quickly, or causing rapid oscillation.</source>
          <target state="new">This prevents the system from reacting too quickly, or causing rapid oscillation.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>It also allows time for new instances that are auto-started to settle into running mode, preventing additional autoscaling actions from occurring while the new instances are starting up.</source>
          <target state="new">It also allows time for new instances that are auto-started to settle into running mode, preventing additional autoscaling actions from occurring while the new instances are starting up.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>For Cloud Services and Virtual Machines, the default period for the aggregation is 45 minutes, so it can take up to this period of time for the metric to trigger autoscaling in response to spikes in demand.</source>
          <target state="new">For Cloud Services and Virtual Machines, the default period for the aggregation is 45 minutes, so it can take up to this period of time for the metric to trigger autoscaling in response to spikes in demand.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>You can change the aggregation period by using the SDK, but be aware that periods of less than 25 minutes may cause unpredictable results (see <bpt id="p1">[</bpt>Auto Scaling Cloud Services on CPU Percentage with the Azure Monitoring Services Management Library<ept id="p1">](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/)</ept> for more information).</source>
          <target state="new">You can change the aggregation period by using the SDK, but be aware that periods of less than 25 minutes may cause unpredictable results (see <bpt id="p1">[</bpt>Auto Scaling Cloud Services on CPU Percentage with the Azure Monitoring Services Management Library<ept id="p1">](http://rickrainey.com/2013/12/15/auto-scaling-cloud-services-on-cpu-percentage-with-the-windows-azure-monitoring-services-management-library/)</ept> for more information).</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>For Azure Web Sites, the averaging period is much shorter, allowing new instances to be available in around five minutes after a change to the average trigger measure.</source>
          <target state="new">For Azure Web Sites, the averaging period is much shorter, allowing new instances to be available in around five minutes after a change to the average trigger measure.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>If you configure autoscaling using the SDK rather than the web portal, you can specify a more detailed schedule during which the rules are active.</source>
          <target state="new">If you configure autoscaling using the SDK rather than the web portal, you can specify a more detailed schedule during which the rules are active.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>You can also create your own metrics and use them with or without any of the existing ones in your autoscaling rules.</source>
          <target state="new">You can also create your own metrics and use them with or without any of the existing ones in your autoscaling rules.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>For example, you may wish to use alternative counters such as the number of requests per second or the average memory availability, or use custom counters that measure specific business processes.</source>
          <target state="new">For example, you may wish to use alternative counters such as the number of requests per second or the average memory availability, or use custom counters that measure specific business processes.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>For more information, see the section <bpt id="p1">[</bpt>The Azure Monitoring Services Management Library<ept id="p1">](#the-azure-monitoring-services-management-library)</ept>.</source>
          <target state="new">For more information, see the section <bpt id="p1">[</bpt>The Azure Monitoring Services Management Library<ept id="p1">](#the-azure-monitoring-services-management-library)</ept>.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>When autoscaling Azure Virtual Machines, you must deploy a number of instances of the virtual machine that is equal to the maximum number you will allow autoscaling to start.</source>
          <target state="new">When autoscaling Azure Virtual Machines, you must deploy a number of instances of the virtual machine that is equal to the maximum number you will allow autoscaling to start.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>These instances must be part of the same Availability Set.</source>
          <target state="new">These instances must be part of the same Availability Set.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>The Virtual Machines autoscaling mechanism does not create or delete instances of the virtual machine; instead, the autoscaling rules you configure will start and stop an appropriate number of these instances.</source>
          <target state="new">The Virtual Machines autoscaling mechanism does not create or delete instances of the virtual machine; instead, the autoscaling rules you configure will start and stop an appropriate number of these instances.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Automatically scale an application running Web Roles, Worker Roles, or Virtual Machines<ept id="p1">](cloud-services-how-to-scale.md#autoscale)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Automatically scale an application running Web Roles, Worker Roles, or Virtual Machines<ept id="p1">](cloud-services-how-to-scale.md#autoscale)</ept>.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>If new instances cannot be started, perhaps because the maximum for a subscription has been reached (such as the maximum number of cores when using the Virtual Machines service) or an error occurs during startup, the portal may show that an autoscaling operation succeeded.</source>
          <target state="new">If new instances cannot be started, perhaps because the maximum for a subscription has been reached (such as the maximum number of cores when using the Virtual Machines service) or an error occurs during startup, the portal may show that an autoscaling operation succeeded.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>However, subsequent <bpt id="p1">**</bpt>ChangeDeploymentConfiguration<ept id="p1">**</ept> events displayed in the portal will show only that a service startup was requested, and there will be no event to indicate it was successfully completed.</source>
          <target state="new">However, subsequent <bpt id="p1">**</bpt>ChangeDeploymentConfiguration<ept id="p1">**</ept> events displayed in the portal will show only that a service startup was requested, and there will be no event to indicate it was successfully completed.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>In Azure Autoscaling, you can use the web portal UI to link resources such as SQL Database instances and queues to a compute service instance.</source>
          <target state="new">In Azure Autoscaling, you can use the web portal UI to link resources such as SQL Database instances and queues to a compute service instance.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>This allows you to more easily access the separate manual and automatic scaling configuration options for each of the linked resources.</source>
          <target state="new">This allows you to more easily access the separate manual and automatic scaling configuration options for each of the linked resources.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>How to: Link a resource to a cloud service<ept id="p1">](cloud-services-how-to-manage.md#linkresources)</ept> in the page How to Manage Cloud Services and the page <bpt id="p2">[</bpt>How to Scale an Application<ept id="p2">](cloud-services-how-to-scale.md)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>How to: Link a resource to a cloud service<ept id="p1">](cloud-services-how-to-manage.md#linkresources)</ept> in the page How to Manage Cloud Services and the page <bpt id="p2">[</bpt>How to Scale an Application<ept id="p2">](cloud-services-how-to-scale.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>When you configure multiple policies and rules, there is a possibility that they could conflict with each other.</source>
          <target state="new">When you configure multiple policies and rules, there is a possibility that they could conflict with each other.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Azure Autoscaling uses the following conflict resolution rules to ensure that there is always a sufficient number of instances running:</source>
          <target state="new">Azure Autoscaling uses the following conflict resolution rules to ensure that there is always a sufficient number of instances running:</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Scale out operations always take precedence over scale in operations.</source>
          <target state="new">Scale out operations always take precedence over scale in operations.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>When scale out operations conflict, the rule that initiates the largest increase in the number of instances takes precedence.</source>
          <target state="new">When scale out operations conflict, the rule that initiates the largest increase in the number of instances takes precedence.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>When scale in operations conflict, the rule that initiates the smallest decrease in the number of instances takes precedence.</source>
          <target state="new">When scale in operations conflict, the rule that initiates the smallest decrease in the number of instances takes precedence.</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>The Azure Monitoring Services Management Library</source>
          <target state="new">The Azure Monitoring Services Management Library</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>You can use the Service Management API to configure Azure Autoscaling with a finer degree of control and to access capabilities that are not available through the web portal.</source>
          <target state="new">You can use the Service Management API to configure Azure Autoscaling with a finer degree of control and to access capabilities that are not available through the web portal.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>This API is accessed directly as a REST Web API, or through the Azure Monitoring Services Management Library.</source>
          <target state="new">This API is accessed directly as a REST Web API, or through the Azure Monitoring Services Management Library.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Azure Autoscaling is configured by specifying autoscaling profiles for Cloud Services roles, Virtual Machines availability sets, Azure Web Sites (as server farms in a webspace), or Azure Mobile Services.</source>
          <target state="new">Azure Autoscaling is configured by specifying autoscaling profiles for Cloud Services roles, Virtual Machines availability sets, Azure Web Sites (as server farms in a webspace), or Azure Mobile Services.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Each profile, of which a target can have up to 20, indicates:</source>
          <target state="new">Each profile, of which a target can have up to 20, indicates:</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>When it is to be applied (using a recurrence or a fixed date interval),</source>
          <target state="new">When it is to be applied (using a recurrence or a fixed date interval),</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>The permitted number of instances (the minimum, maximum, and default number)</source>
          <target state="new">The permitted number of instances (the minimum, maximum, and default number)</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Which autoscaling rules are in effect</source>
          <target state="new">Which autoscaling rules are in effect</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>The web portal allows for the configuration of a fixed set of profiles, essentially distinguishing day/night and weekday/weekend profiles, with a single pair of scale rules based on CPU utilization or queue length.</source>
          <target state="new">The web portal allows for the configuration of a fixed set of profiles, essentially distinguishing day/night and weekday/weekend profiles, with a single pair of scale rules based on CPU utilization or queue length.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>By using the Service Management API instead you can configure finer-grained applicability dates for profiles, and specify up to ten rules with triggers based on any metric available to the Azure Monitoring Service.</source>
          <target state="new">By using the Service Management API instead you can configure finer-grained applicability dates for profiles, and specify up to ten rules with triggers based on any metric available to the Azure Monitoring Service.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>Autoscaling rules are composed of a trigger that indicates when a rule applies, and a scale action that indicates the change to perform on the configuration of the target.</source>
          <target state="new">Autoscaling rules are composed of a trigger that indicates when a rule applies, and a scale action that indicates the change to perform on the configuration of the target.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>At the time of writing, the only supported action was an increase or decrease in the instance count.</source>
          <target state="new">At the time of writing, the only supported action was an increase or decrease in the instance count.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>The triggers for autoscaling rules are based on available metrics.</source>
          <target state="new">The triggers for autoscaling rules are based on available metrics.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>Values for the configured metrics are sampled periodically from the appropriate sources, as defined in the autoscaling configuration.</source>
          <target state="new">Values for the configured metrics are sampled periodically from the appropriate sources, as defined in the autoscaling configuration.</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>When each rule from an active profile is evaluated, the values of the metric specified on the trigger are aggregated in time and across instances (if appropriate), and this aggregate is compared against a threshold to indicate whether the rule applies.</source>
          <target state="new">When each rule from an active profile is evaluated, the values of the metric specified on the trigger are aggregated in time and across instances (if appropriate), and this aggregate is compared against a threshold to indicate whether the rule applies.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>Valid aggregates over time are average (the default), minimum, maximum, last, total, and count.</source>
          <target state="new">Valid aggregates over time are average (the default), minimum, maximum, last, total, and count.</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>Valid aggregates over instances are average (the default), maximum, and minimum.</source>
          <target state="new">Valid aggregates over instances are average (the default), maximum, and minimum.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>The metrics available for triggers are Azure storage and Service Bus queue lengths, the standard performance counters published by Azure Diagnostics, and any custom performance counter published by each role or virtual machine.</source>
          <target state="new">The metrics available for triggers are Azure storage and Service Bus queue lengths, the standard performance counters published by Azure Diagnostics, and any custom performance counter published by each role or virtual machine.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>In a Cloud Services solution, when dealing with performance counters other than those available by default, you must change the monitoring level setting in the UI from “Minimum” to “Verbose” for the service.</source>
          <target state="new">In a Cloud Services solution, when dealing with performance counters other than those available by default, you must change the monitoring level setting in the UI from “Minimum” to “Verbose” for the service.</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>For more information, see:</source>
          <target state="new">For more information, see:</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Monitoring SDK <bpt id="p1">[</bpt>Class Library<ept id="p1">](http://msdn.microsoft.com/library/azure/dn510414.aspx)</ept></source>
          <target state="new">Monitoring SDK <bpt id="p1">[</bpt>Class Library<ept id="p1">](http://msdn.microsoft.com/library/azure/dn510414.aspx)</ept></target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>How to Configure Performance Counters</source>
          <target state="new">How to Configure Performance Counters</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Operations on Autoscaling</source>
          <target state="new">Operations on Autoscaling</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>Add Autoscale Settings</source>
          <target state="new">Add Autoscale Settings</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>Auto Scaling Cloud Services on CPU Percentage with the Azure Monitoring Services Management Library</source>
          <target state="new">Auto Scaling Cloud Services on CPU Percentage with the Azure Monitoring Services Management Library</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>How to use Azure Monitoring Services Management Library to create an Autoscale Rule</source>
          <target state="new">How to use Azure Monitoring Services Management Library to create an Autoscale Rule</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Related patterns and guidance</source>
          <target state="new">Related patterns and guidance</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>The following patterns and guidance may also be relevant to your scenario when implementing autoscaling:</source>
          <target state="new">The following patterns and guidance may also be relevant to your scenario when implementing autoscaling:</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Throttling Pattern<ept id="p1">](http://msdn.microsoft.com/library/dn589798.aspx)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Throttling Pattern<ept id="p1">](http://msdn.microsoft.com/library/dn589798.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>This pattern describes how an application can continue to function and meet service level agreements when an increase in demand places an extreme load on resources.</source>
          <target state="new">This pattern describes how an application can continue to function and meet service level agreements when an increase in demand places an extreme load on resources.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Throttling can be used with autoscaling to prevent a system from being overwhelmed while the system scales out.</source>
          <target state="new">Throttling can be used with autoscaling to prevent a system from being overwhelmed while the system scales out.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Competing Consumers Pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568101.aspx)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Competing Consumers Pattern<ept id="p1">](http://msdn.microsoft.com/library/dn568101.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>This pattern describes how to implement a pool of service instances that can handle messages from any application instance.</source>
          <target state="new">This pattern describes how to implement a pool of service instances that can handle messages from any application instance.</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Autoscaling can be used to start and stop service instances to match the anticipated workload.</source>
          <target state="new">Autoscaling can be used to start and stop service instances to match the anticipated workload.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>This approach enables a system to process multiple messages concurrently to optimize throughput, improve scalability and availability, and balance the workload.</source>
          <target state="new">This approach enables a system to process multiple messages concurrently to optimize throughput, improve scalability and availability, and balance the workload.</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Instrumentation and Telemetry Guidance<ept id="p1">](http://msdn.microsoft.com/library/dn589775.aspx)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Instrumentation and Telemetry Guidance<ept id="p1">](http://msdn.microsoft.com/library/dn589775.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>Instrumentation and telemetry are vital for gathering the information that can drive the autoscaling process.</source>
          <target state="new">Instrumentation and telemetry are vital for gathering the information that can drive the autoscaling process.</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>More information</source>
          <target state="new">More information</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>How to Scale an Application</source>
          <target state="new">How to Scale an Application</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Automatically scale an application running Web Roles, Worker Roles, or Virtual Machines</source>
          <target state="new">Automatically scale an application running Web Roles, Worker Roles, or Virtual Machines</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>How to: Link a resource to a cloud service</source>
          <target state="new">How to: Link a resource to a cloud service</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>Scale linked resources</source>
          <target state="new">Scale linked resources</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Azure Monitoring Services Management Library</source>
          <target state="new">Azure Monitoring Services Management Library</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>Azure Service Management REST API</source>
          <target state="new">Azure Service Management REST API</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>Operations on Autoscaling</source>
          <target state="new">Operations on Autoscaling</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>Microsoft.WindowsAzure.Management.Monitoring.Autoscale Namespace</source>
          <target state="new">Microsoft.WindowsAzure.Management.Monitoring.Autoscale Namespace</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">[</bpt>Autoscaling Application Block<ept id="p1">](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx)</ept> documentation and key scenarios on MSDN.</source>
          <target state="new">The <bpt id="p1">[</bpt>Autoscaling Application Block<ept id="p1">](http://msdn.microsoft.com/library/hh680892%28v=pandp.50%29.aspx)</ept> documentation and key scenarios on MSDN.</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">0efc29872661d8badbb028b0dd7279ee8956c16c</xliffext:olfilehash>
  </header>
</xliff>