<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use MapReduce and Curl with Hadoop in HDInsight | Microsoft Azure</source>
          <target state="new">Use MapReduce and Curl with Hadoop in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to remotely run MapReduce jobs with Hadoop on HDInsight using Curl.</source>
          <target state="new">Learn how to remotely run MapReduce jobs with Hadoop on HDInsight using Curl.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Run MapReduce jobs with Hadoop on HDInsight using Curl</source>
          <target state="new">Run MapReduce jobs with Hadoop on HDInsight using Curl</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>In this document, you will learn how to use Curl to run MapReduce jobs on a Hadoop on HDInsight cluster.</source>
          <target state="new">In this document, you will learn how to use Curl to run MapReduce jobs on a Hadoop on HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Curl is used to demonstrate how you can interact with HDInsight by using raw HTTP requests to run MapReduce jobs.</source>
          <target state="new">Curl is used to demonstrate how you can interact with HDInsight by using raw HTTP requests to run MapReduce jobs.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>This works by using the WebHCat REST API (formerly known as Templeton) provided by your HDInsight cluster.</source>
          <target state="new">This works by using the WebHCat REST API (formerly known as Templeton) provided by your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="p1">[</bpt>What you need to know about Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> If you are already familiar with using Linux-based Hadoop servers, but you are new to HDInsight, see <bpt id="p1">[</bpt>What you need to know about Linux-based Hadoop on HDInsight<ept id="p1">](hdinsight-hadoop-linux-information.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</source>
          <target state="new"><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Prerequisites</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>To complete the steps in this article, you will need the following:</source>
          <target state="new">To complete the steps in this article, you will need the following:</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A Hadoop on HDInsight cluster (Linux or Windows-based)</source>
          <target state="new">A Hadoop on HDInsight cluster (Linux or Windows-based)</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Curl</source>
          <target state="new">Curl</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>jq</source>
          <target state="new">jq</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="curl"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Run MapReduce jobs using Curl</source>
          <target state="new"><ph id="ph1">&lt;a id="curl"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Run MapReduce jobs using Curl</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> When you use Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the HDInsight cluster administrator user name and password.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> When you use Curl or any other REST communication with WebHCat, you must authenticate the requests by providing the HDInsight cluster administrator user name and password.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>You must also use the cluster name as part of the URI that is used to send the requests to the server.</source>
          <target state="new">You must also use the cluster name as part of the URI that is used to send the requests to the server.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>For the commands in this section, replace <bpt id="p1">**</bpt>USERNAME<ept id="p1">**</ept> with the user to authenticate to the cluster, and <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> with the password for the user account.</source>
          <target state="new">For the commands in this section, replace <bpt id="p1">**</bpt>USERNAME<ept id="p1">**</ept> with the user to authenticate to the cluster, and <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> with the password for the user account.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Replace <bpt id="p1">**</bpt>CLUSTERNAME<ept id="p1">**</ept> with the name of your cluster.</source>
          <target state="new">Replace <bpt id="p1">**</bpt>CLUSTERNAME<ept id="p1">**</ept> with the name of your cluster.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The REST API is secured by using <bpt id="p1">[</bpt>basic access authentication<ept id="p1">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>.</source>
          <target state="new">The REST API is secured by using <bpt id="p1">[</bpt>basic access authentication<ept id="p1">](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>You should always make requests by using HTTPS to ensure that your credentials are securely sent to the server.</source>
          <target state="new">You should always make requests by using HTTPS to ensure that your credentials are securely sent to the server.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>From a command-line, use the following command to verify that you can connect to your HDInsight cluster:</source>
          <target state="new">From a command-line, use the following command to verify that you can connect to your HDInsight cluster:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>You should receive a response similar to the following:</source>
          <target state="new">You should receive a response similar to the following:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The parameters used in this command are as follows:</source>
          <target state="new">The parameters used in this command are as follows:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-u<ept id="p1">**</ept>: Indicates the user name and password used to authenticate the request</source>
          <target state="new"><bpt id="p1">**</bpt>-u<ept id="p1">**</ept>: Indicates the user name and password used to authenticate the request</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-G<ept id="p1">**</ept>: Indicates that this is a GET request</source>
          <target state="new"><bpt id="p1">**</bpt>-G<ept id="p1">**</ept>: Indicates that this is a GET request</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The beginning of the URI, <bpt id="p1">**</bpt>https://CLUSTERNAME.azurehdinsight.net/templeton/v1<ept id="p1">**</ept>, is the same for all requests.</source>
          <target state="new">The beginning of the URI, <bpt id="p1">**</bpt>https://CLUSTERNAME.azurehdinsight.net/templeton/v1<ept id="p1">**</ept>, is the same for all requests.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>To submit a MapReduce job, use the following command:</source>
          <target state="new">To submit a MapReduce job, use the following command:</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>The end of the URI (/mapreduce/jar) tells WebHCat that this request will start a MapReduce job from a class in a jar file.</source>
          <target state="new">The end of the URI (/mapreduce/jar) tells WebHCat that this request will start a MapReduce job from a class in a jar file.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The parameters used in this command are as follows:</source>
          <target state="new">The parameters used in this command are as follows:</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-d<ept id="p1">**</ept>: <ph id="ph1">`-G`</ph> is not used, so the request defaults to the POST method.</source>
          <target state="new"><bpt id="p1">**</bpt>-d<ept id="p1">**</ept>: <ph id="ph1">`-G`</ph> is not used, so the request defaults to the POST method.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`-d`</ph> specifies the data values that are sent with the request.</source>
          <target state="new"><ph id="ph1">`-d`</ph> specifies the data values that are sent with the request.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>user.name<ept id="p1">**</ept>: The user who is running the command</source>
          <target state="new"><bpt id="p1">**</bpt>user.name<ept id="p1">**</ept>: The user who is running the command</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>jar<ept id="p1">**</ept>: The location of the jar file that contains class to be ran</source>
          <target state="new"><bpt id="p1">**</bpt>jar<ept id="p1">**</ept>: The location of the jar file that contains class to be ran</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>class<ept id="p1">**</ept>: The class that contains the MapReduce logic</source>
          <target state="new"><bpt id="p1">**</bpt>class<ept id="p1">**</ept>: The class that contains the MapReduce logic</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>arg<ept id="p1">**</ept>: The arguments to be passed to the MapReduce job; in this case, the input text file and the directory that are used for the output</source>
          <target state="new"><bpt id="p1">**</bpt>arg<ept id="p1">**</ept>: The arguments to be passed to the MapReduce job; in this case, the input text file and the directory that are used for the output</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>This command should return a job ID that can be used to check the status of the job:</source>
          <target state="new">This command should return a job ID that can be used to check the status of the job:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>To check the status of the job, use the following command.</source>
          <target state="new">To check the status of the job, use the following command.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Replace the <bpt id="p1">**</bpt>JOBID<ept id="p1">**</ept> with the value returned in the previous step.</source>
          <target state="new">Replace the <bpt id="p1">**</bpt>JOBID<ept id="p1">**</ept> with the value returned in the previous step.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>For example, if the return value was <ph id="ph1">`{"id":"job_1415651640909_0026"}`</ph>, then the JOBID would be <ph id="ph2">`job_1415651640909_0026`</ph>.</source>
          <target state="new">For example, if the return value was <ph id="ph1">`{"id":"job_1415651640909_0026"}`</ph>, then the JOBID would be <ph id="ph2">`job_1415651640909_0026`</ph>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>If the job is complete, the state will be "SUCCEEDED".</source>
          <target state="new">If the job is complete, the state will be "SUCCEEDED".</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> This Curl request returns a JSON document with information about the job; jq is used to retrieve only the state value.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> This Curl request returns a JSON document with information about the job; jq is used to retrieve only the state value.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>When the state of the job has changed to <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept>, you can retrieve the results of the job from Azure Blob storage.</source>
          <target state="new">When the state of the job has changed to <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept>, you can retrieve the results of the job from Azure Blob storage.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`statusdir`</ph> parameter that is passed with the query contains the location of the output file; in this case, <bpt id="p1">**</bpt>wasb:///example/curl<ept id="p1">**</ept>.</source>
          <target state="new">The <ph id="ph1">`statusdir`</ph> parameter that is passed with the query contains the location of the output file; in this case, <bpt id="p1">**</bpt>wasb:///example/curl<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>This address stores the output of the job in the <bpt id="p1">**</bpt>example/curl<ept id="p1">**</ept> directory in the default storage container used by your HDInsight cluster.</source>
          <target state="new">This address stores the output of the job in the <bpt id="p1">**</bpt>example/curl<ept id="p1">**</ept> directory in the default storage container used by your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>You can list and download these files by using the <bpt id="p1">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p1">](../xplat-cli.md)</ept>.</source>
          <target state="new">You can list and download these files by using the <bpt id="p1">[</bpt>Azure CLI for Mac, Linux and Windows<ept id="p1">](../xplat-cli.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>For example, to list files in the <bpt id="p1">**</bpt>example/curl<ept id="p1">**</ept>, use the following command:</source>
          <target state="new">For example, to list files in the <bpt id="p1">**</bpt>example/curl<ept id="p1">**</ept>, use the following command:</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>To download a file, use the following:</source>
          <target state="new">To download a file, use the following:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> You must specify the storage account name that contains the blob by using the <ph id="ph2">`-a`</ph> and <ph id="ph3">`-k`</ph> parameters, or set the <bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept> and <bpt id="p2">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p2">**</ept> environment variables.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> You must specify the storage account name that contains the blob by using the <ph id="ph2">`-a`</ph> and <ph id="ph3">`-k`</ph> parameters, or set the <bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept> and <bpt id="p2">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p2">**</ept> environment variables.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>See <bpt id="p1">[</bpt>how to upload data to HDInsight<ept id="p1">](hdinsight-upload-data.md)</ept> for more information.</source>
          <target state="new">See <bpt id="p1">[</bpt>how to upload data to HDInsight<ept id="p1">](hdinsight-upload-data.md)</ept> for more information.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Summary</source>
          <target state="new"><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Summary</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>As demonstrated in this document, you can use raw HTTP request to run, monitor, and view the results of Hive jobs in your HDInsight cluster.</source>
          <target state="new">As demonstrated in this document, you can use raw HTTP request to run, monitor, and view the results of Hive jobs in your HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>For more information about the REST interface that is used in this article, see the <bpt id="p1">[</bpt>WebHCat Reference<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference)</ept>.</source>
          <target state="new">For more information about the REST interface that is used in this article, see the <bpt id="p1">[</bpt>WebHCat Reference<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference)</ept>.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Next steps</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>For general information about MapReduce jobs in HDInsight:</source>
          <target state="new">For general information about MapReduce jobs in HDInsight:</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Use MapReduce with Hadoop on HDInsight</source>
          <target state="new">Use MapReduce with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>For information about other ways you can work with Hadoop on HDInsight:</source>
          <target state="new">For information about other ways you can work with Hadoop on HDInsight:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Use Hive with Hadoop on HDInsight</source>
          <target state="new">Use Hive with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Use Pig with Hadoop on HDInsight</source>
          <target state="new">Use Pig with Hadoop on HDInsight</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7c60b4b04b7f7993c580ca56aef60280482db84e</xliffext:olfilehash>
  </header>
</xliff>