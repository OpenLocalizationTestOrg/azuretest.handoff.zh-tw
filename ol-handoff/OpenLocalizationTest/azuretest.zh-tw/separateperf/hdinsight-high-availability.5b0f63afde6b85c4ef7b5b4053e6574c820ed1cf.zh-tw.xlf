<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Availability of Hadoop clusters in HDInsight | Microsoft Azure</source>
          <target state="new">Availability of Hadoop clusters in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>HDInsight deploys highly available and reliable clusters with an addtional head node.</source>
          <target state="new">HDInsight deploys highly available and reliable clusters with an addtional head node.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Availability and reliability of Hadoop clusters in HDInsight</source>
          <target state="new">Availability and reliability of Hadoop clusters in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>HDInsight allows customers to deploy a variety of cluster types, for different data analytics workloads.</source>
          <target state="new">HDInsight allows customers to deploy a variety of cluster types, for different data analytics workloads.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Cluster types offered today are Hadoop clusters for query and analysis workloads, HBase clusters for NoSQL workloads, and Storm clusters for real time event processing workloads.</source>
          <target state="new">Cluster types offered today are Hadoop clusters for query and analysis workloads, HBase clusters for NoSQL workloads, and Storm clusters for real time event processing workloads.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Within a given cluster type, there are different roles for the various nodes.</source>
          <target state="new">Within a given cluster type, there are different roles for the various nodes.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new">For example:</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Hadoop clusters for HDInsight are deployed with two roles:</source>
          <target state="new">Hadoop clusters for HDInsight are deployed with two roles:</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Head node (2 nodes)</source>
          <target state="new">Head node (2 nodes)</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Data node (at least 1 node)</source>
          <target state="new">Data node (at least 1 node)</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>HBase clusters for HDInsight are deployed with three roles:</source>
          <target state="new">HBase clusters for HDInsight are deployed with three roles:</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Head servers (2 nodes)</source>
          <target state="new">Head servers (2 nodes)</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Region servers (at least 1 node)</source>
          <target state="new">Region servers (at least 1 node)</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Master/Zookeeper nodes (3 nodes)</source>
          <target state="new">Master/Zookeeper nodes (3 nodes)</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Storm clusters for HDInsight are deployed with three roles:</source>
          <target state="new">Storm clusters for HDInsight are deployed with three roles:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Nimbus nodes (2 nodes)</source>
          <target state="new">Nimbus nodes (2 nodes)</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Supervisor servers (at least 1 node)</source>
          <target state="new">Supervisor servers (at least 1 node)</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Zookeeper nodes (3 nodes)</source>
          <target state="new">Zookeeper nodes (3 nodes)</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Standard implementations of Hadoop clusters typically have a single head node.</source>
          <target state="new">Standard implementations of Hadoop clusters typically have a single head node.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>HDInsight removes this single point of failure with the addition of a secondary head node /head server/Nimbus node to increase the availability and reliability of the service needed to manage workloads.</source>
          <target state="new">HDInsight removes this single point of failure with the addition of a secondary head node /head server/Nimbus node to increase the availability and reliability of the service needed to manage workloads.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>These head  nodes/head servers/Nimbus nodes are designed to manage the failure of worker nodes smoothly, but any outages of master services running on the head node would cause the cluster to cease to work.</source>
          <target state="new">These head  nodes/head servers/Nimbus nodes are designed to manage the failure of worker nodes smoothly, but any outages of master services running on the head node would cause the cluster to cease to work.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>ZooKeeper<ept id="p1">](http://zookeeper.apache.org/ )</ept> nodes (ZKs) have been added and are used for leader election of head nodes and to insure that worker nodes and gateways (GWs) know when to fail over to the secondary head node (Head Node1) when the active head node (Head Node0) becomes inactive.</source>
          <target state="new"><bpt id="p1">[</bpt>ZooKeeper<ept id="p1">](http://zookeeper.apache.org/ )</ept> nodes (ZKs) have been added and are used for leader election of head nodes and to insure that worker nodes and gateways (GWs) know when to fail over to the secondary head node (Head Node1) when the active head node (Head Node0) becomes inactive.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Diagram of the highly reliable head nodes in the HDInsight Hadoop implementation.</source>
          <target state="new">Diagram of the highly reliable head nodes in the HDInsight Hadoop implementation.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Check the active head node service status</source>
          <target state="new">Check the active head node service status</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>To determine which head node is active and to check on the status of the services running on that head node, you must connect to the Hadoop cluster by using the Remote Desktop Protocol (RDP).</source>
          <target state="new">To determine which head node is active and to check on the status of the services running on that head node, you must connect to the Hadoop cluster by using the Remote Desktop Protocol (RDP).</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>For the RDP instructions, see <bpt id="p1">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure preview portal<ept id="p1">](hdinsight-administer-use-management-portal.md#connect-to-hdinsight-clusters-by-using-rdp)</ept>.</source>
          <target state="new">For the RDP instructions, see <bpt id="p1">[</bpt>Manage Hadoop clusters in HDInsight by using the Azure preview portal<ept id="p1">](hdinsight-administer-use-management-portal.md#connect-to-hdinsight-clusters-by-using-rdp)</ept>.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Once you have remoted into the cluster, double-click on the **Hadoop Service Available ** icon located on the desktop to obtain status about which head node the Namenode, Jobtracker, Templeton, Oozieservice, Metastore, and Hiveserver2 services are running, or for HDI 3.0, the Namenode, Resource Manager, History Server, Templeton, Oozieservice, Metastore, and Hiveserver2 services.</source>
          <target state="new">Once you have remoted into the cluster, double-click on the **Hadoop Service Available ** icon located on the desktop to obtain status about which head node the Namenode, Jobtracker, Templeton, Oozieservice, Metastore, and Hiveserver2 services are running, or for HDI 3.0, the Namenode, Resource Manager, History Server, Templeton, Oozieservice, Metastore, and Hiveserver2 services.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>On the screenshot, the active head node is <bpt id="p1">*</bpt>headnode0<ept id="p1">*</ept>.</source>
          <target state="new">On the screenshot, the active head node is <bpt id="p1">*</bpt>headnode0<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Access log files on the secondary head node</source>
          <target state="new">Access log files on the secondary head node</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>To access job logs on the secondary head node in the event that it has become the active head node, browsing the JobTracker UI still works as it does for the primary active node.</source>
          <target state="new">To access job logs on the secondary head node in the event that it has become the active head node, browsing the JobTracker UI still works as it does for the primary active node.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>To access JobTracker, you must connect to the Hadoop cluster by using RDP as described in the previous section.</source>
          <target state="new">To access JobTracker, you must connect to the Hadoop cluster by using RDP as described in the previous section.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Once you have remoted into the cluster, double-click on the <bpt id="p1">**</bpt>Hadoop Name Node Status<ept id="p1">**</ept> icon located on the desktop and then click on the <bpt id="p2">**</bpt>NameNode logs<ept id="p2">**</ept> to get to the directory of logs on the secondary head node.</source>
          <target state="new">Once you have remoted into the cluster, double-click on the <bpt id="p1">**</bpt>Hadoop Name Node Status<ept id="p1">**</ept> icon located on the desktop and then click on the <bpt id="p2">**</bpt>NameNode logs<ept id="p2">**</ept> to get to the directory of logs on the secondary head node.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Configure the size of the head node</source>
          <target state="new">Configure the size of the head node</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>The head nodes are allocated as large virtual machines (VMs) by default.</source>
          <target state="new">The head nodes are allocated as large virtual machines (VMs) by default.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>This size is adequate for the management of most Hadoop jobs run on the cluster.</source>
          <target state="new">This size is adequate for the management of most Hadoop jobs run on the cluster.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>But there are scenarios that may require extra-large VMs for the head nodes.</source>
          <target state="new">But there are scenarios that may require extra-large VMs for the head nodes.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>One example is when the cluster has to manage a large number of small Oozie jobs.</source>
          <target state="new">One example is when the cluster has to manage a large number of small Oozie jobs.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Extra-large VMs can be configured by using either Azure PowerShell cmdlets or the HDInsight SDK.</source>
          <target state="new">Extra-large VMs can be configured by using either Azure PowerShell cmdlets or the HDInsight SDK.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>The creation and provisioning of a cluster by using Azure PowerShell is documented in <bpt id="p1">[</bpt>Administer HDInsight using PowerShell<ept id="p1">](hdinsight-administer-use-powershell.md)</ept>.</source>
          <target state="new">The creation and provisioning of a cluster by using Azure PowerShell is documented in <bpt id="p1">[</bpt>Administer HDInsight using PowerShell<ept id="p1">](hdinsight-administer-use-powershell.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The configuration of an extra-large head node requires the addition of the <ph id="ph1">`-HeadNodeVMSize ExtraLarge`</ph> parameter to the <ph id="ph2">`New-AzureHDInsightcluster`</ph> cmdlet used in this code.</source>
          <target state="new">The configuration of an extra-large head node requires the addition of the <ph id="ph1">`-HeadNodeVMSize ExtraLarge`</ph> parameter to the <ph id="ph2">`New-AzureHDInsightcluster`</ph> cmdlet used in this code.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>For the SDK, the story is similar.</source>
          <target state="new">For the SDK, the story is similar.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>The creation and provisioning of a cluster by using the SDK is documented in <bpt id="p1">[</bpt>Using HDInsight .NET SDK<ept id="p1">](hdinsight-provision-clusters.md#sdk)</ept>.</source>
          <target state="new">The creation and provisioning of a cluster by using the SDK is documented in <bpt id="p1">[</bpt>Using HDInsight .NET SDK<ept id="p1">](hdinsight-provision-clusters.md#sdk)</ept>.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The configuration of an extra-large head node requires the addition of the <ph id="ph1">`HeadNodeSize = NodeVMSize.ExtraLarge`</ph> parameter to the <ph id="ph2">`ClusterCreateParameters()`</ph> method used in this code.</source>
          <target state="new">The configuration of an extra-large head node requires the addition of the <ph id="ph1">`HeadNodeSize = NodeVMSize.ExtraLarge`</ph> parameter to the <ph id="ph2">`ClusterCreateParameters()`</ph> method used in this code.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>References</source>
          <target state="new">References</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>ZooKeeper</source>
          <target state="new">ZooKeeper</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Connect to HDInsight clusters using RDP</source>
          <target state="new">Connect to HDInsight clusters using RDP</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Using HDInsight .NET SDK</source>
          <target state="new">Using HDInsight .NET SDK</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">44433a0888cca57614bfb7c802a5910c6e1c54cb</xliffext:olfilehash>
  </header>
</xliff>