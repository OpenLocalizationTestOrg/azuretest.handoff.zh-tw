<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Spark on Ubuntu Resource Manager Template</source>
          <target state="new">Spark on Ubuntu Resource Manager Template</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn to easily deploy a new Spark cluster on Ubuntu VMs using Azure PowerShell or the Azure CLI and a Resource Manager template</source>
          <target state="new">Learn to easily deploy a new Spark cluster on Ubuntu VMs using Azure PowerShell or the Azure CLI and a Resource Manager template</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Spark on Ubuntu with a Resource Manager template</source>
          <target state="new">Spark on Ubuntu with a Resource Manager template</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Apache Spark is a fast engine for large-scale data processing.</source>
          <target state="new">Apache Spark is a fast engine for large-scale data processing.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Spark has an advanced DAG execution engine that supports cyclic data flow and in-memory computing, and it can access diverse data sources, including HDFS, Spark, HBase, and S3.</source>
          <target state="new">Spark has an advanced DAG execution engine that supports cyclic data flow and in-memory computing, and it can access diverse data sources, including HDFS, Spark, HBase, and S3.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In addition to running on the Mesos or YARN cluster managers, Spark provides a simple standalone deployment mode.</source>
          <target state="new">In addition to running on the Mesos or YARN cluster managers, Spark provides a simple standalone deployment mode.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>This tutorial will walk you through how to use a sample Azure Resource Manager template to deploy a Spark cluster on Ubuntu VMs through <bpt id="p1">[</bpt>Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept> or the <bpt id="p2">[</bpt>Azure CLI<ept id="p2">](../xplat-cli.md)</ept>.</source>
          <target state="new">This tutorial will walk you through how to use a sample Azure Resource Manager template to deploy a Spark cluster on Ubuntu VMs through <bpt id="p1">[</bpt>Azure PowerShell<ept id="p1">](../powershell-install-configure.md)</ept> or the <bpt id="p2">[</bpt>Azure CLI<ept id="p2">](../xplat-cli.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This template deploys a Spark cluster on the Ubuntu virtual machines.</source>
          <target state="new">This template deploys a Spark cluster on the Ubuntu virtual machines.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>This template also provisions a storage account, virtual network, availability sets, public IP addresses and network interfaces required by the installation.</source>
          <target state="new">This template also provisions a storage account, virtual network, availability sets, public IP addresses and network interfaces required by the installation.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The Spark cluster is created behind a subnet, so there is no public IP access to the cluster.</source>
          <target state="new">The Spark cluster is created behind a subnet, so there is no public IP access to the cluster.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>As part of the deployment, an optional "jump box" can be deployed.</source>
          <target state="new">As part of the deployment, an optional "jump box" can be deployed.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>This "jump box" is an Ubuntu VM deployed in the subnet as well, but it <bpt id="p1">*</bpt>does<ept id="p1">*</ept> expose a public IP address with an open SSH port that you can connect to.</source>
          <target state="new">This "jump box" is an Ubuntu VM deployed in the subnet as well, but it <bpt id="p1">*</bpt>does<ept id="p1">*</ept> expose a public IP address with an open SSH port that you can connect to.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Then from the "jump box", you can SSH to all the Spark VMs in the subnet.</source>
          <target state="new">Then from the "jump box", you can SSH to all the Spark VMs in the subnet.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The template utilizes a "t-shirt size" concept in order to specify a "Small", "Medium", or "Large" Spark cluster setup.</source>
          <target state="new">The template utilizes a "t-shirt size" concept in order to specify a "Small", "Medium", or "Large" Spark cluster setup.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>When the template language supports more dynamic template sizing, this could be changed to specify the number of Spark cluster master nodes and slave nodes, VM size, etc. For now, you can see the VM size and the number of masters and slaves defined in the file azuredeploy.json in the variables <bpt id="p1">**</bpt>tshirtSizeS<ept id="p1">**</ept>, <bpt id="p2">**</bpt>tshirtSizeM<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>tshirtSizeL<ept id="p3">**</ept>:</source>
          <target state="new">When the template language supports more dynamic template sizing, this could be changed to specify the number of Spark cluster master nodes and slave nodes, VM size, etc. For now, you can see the VM size and the number of masters and slaves defined in the file azuredeploy.json in the variables <bpt id="p1">**</bpt>tshirtSizeS<ept id="p1">**</ept>, <bpt id="p2">**</bpt>tshirtSizeM<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>tshirtSizeL<ept id="p3">**</ept>:</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>S: 1 master, 1 slave</source>
          <target state="new">S: 1 master, 1 slave</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>M: 1 master, 4 slaves</source>
          <target state="new">M: 1 master, 4 slaves</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>L: 1 master, 6 slaves</source>
          <target state="new">L: 1 master, 6 slaves</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Newly deployed clusters based on this template will have the topology described in the following diagram, although other topologies can be easily achieved by customizing the template presented in this article:</source>
          <target state="new">Newly deployed clusters based on this template will have the topology described in the following diagram, although other topologies can be easily achieved by customizing the template presented in this article:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>cluster-architecture</source>
          <target state="new">cluster-architecture</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>As shown in the above image, the deployment topology consists of the following elements:</source>
          <target state="new">As shown in the above image, the deployment topology consists of the following elements:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>A new storage account hosting the OS disk of newly created virtual machines.</source>
          <target state="new">A new storage account hosting the OS disk of newly created virtual machines.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>A virtual network with a subnet.</source>
          <target state="new">A virtual network with a subnet.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>All the virtual machines created by the template are provisioned inside this virtual network.</source>
          <target state="new">All the virtual machines created by the template are provisioned inside this virtual network.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>An availability set for master and slave nodes.</source>
          <target state="new">An availability set for master and slave nodes.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>A master node in the newly created availability set.</source>
          <target state="new">A master node in the newly created availability set.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Four slave nodes running in the same virtual subnet and availability set as the master node.</source>
          <target state="new">Four slave nodes running in the same virtual subnet and availability set as the master node.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>A jump-box VM located in the same virtual network and subnet that can be used to access the cluster.</source>
          <target state="new">A jump-box VM located in the same virtual network and subnet that can be used to access the cluster.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Spark version 3.0.0 is the default version and can be changed to any pre-built binaries available on the Spark repository.</source>
          <target state="new">Spark version 3.0.0 is the default version and can be changed to any pre-built binaries available on the Spark repository.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>There is also a provision in the script to uncomment the build from source.</source>
          <target state="new">There is also a provision in the script to uncomment the build from source.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>A static IP address will be assigned to each Spark master node: 10.0.0.10.</source>
          <target state="new">A static IP address will be assigned to each Spark master node: 10.0.0.10.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>A static IP address will be assigned to each Spark slave node in order to work around the current limitation of not being able to dynamically compose a list of IP addresses from within the template.</source>
          <target state="new">A static IP address will be assigned to each Spark slave node in order to work around the current limitation of not being able to dynamically compose a list of IP addresses from within the template.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>(By default, the first node will be assigned the private IP address of 10.0.0.30, the second node will be assigned 10.0.0.31, and so on.) To check deployment errors, go to the new Azure portal and look under <bpt id="p1">**</bpt>Resource Group<ept id="p1">**</ept> &gt; <bpt id="p2">**</bpt>Last deployment<ept id="p2">**</ept> &gt; <bpt id="p3">**</bpt>Check Operation Details<ept id="p3">**</ept>.</source>
          <target state="new">(By default, the first node will be assigned the private IP address of 10.0.0.30, the second node will be assigned 10.0.0.31, and so on.) To check deployment errors, go to the new Azure portal and look under <bpt id="p1">**</bpt>Resource Group<ept id="p1">**</ept> &gt; <bpt id="p2">**</bpt>Last deployment<ept id="p2">**</ept> &gt; <bpt id="p3">**</bpt>Check Operation Details<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Before diving into more details related to Azure Resource Manager and the template we will use for this deployment, make sure you have Azure PowerShell or the Azure CLI configured correctly.</source>
          <target state="new">Before diving into more details related to Azure Resource Manager and the template we will use for this deployment, make sure you have Azure PowerShell or the Azure CLI configured correctly.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Create a Spark cluster by using a Resource Manager template</source>
          <target state="new">Create a Spark cluster by using a Resource Manager template</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Follow these steps to create a Spark cluster by using a Resource Manager template from the GitHub template repository, via either Azure PowerShell or the Azure CLI.</source>
          <target state="new">Follow these steps to create a Spark cluster by using a Resource Manager template from the GitHub template repository, via either Azure PowerShell or the Azure CLI.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Step 1-a: Download the template files by using Azure PowerShell</source>
          <target state="new">Step 1-a: Download the template files by using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Create a local folder for the JSON template and other associated files (for example, C:\Azure\Templates\Spark).</source>
          <target state="new">Create a local folder for the JSON template and other associated files (for example, C:\Azure\Templates\Spark).</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Substitute in the folder name of your local folder and run these commands:</source>
          <target state="new">Substitute in the folder name of your local folder and run these commands:</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Step 1-b: Download the template files by using the Azure CLI</source>
          <target state="new">Step 1-b: Download the template files by using the Azure CLI</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Clone the entire template repository by using a Git client of your choice, for example:</source>
          <target state="new">Clone the entire template repository by using a Git client of your choice, for example:</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>When the cloning is completed, look for the <bpt id="p1">**</bpt>spark-on-ubuntu<ept id="p1">**</ept> folder in your C:\Azure\Templates directory.</source>
          <target state="new">When the cloning is completed, look for the <bpt id="p1">**</bpt>spark-on-ubuntu<ept id="p1">**</ept> folder in your C:\Azure\Templates directory.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Step 2: (optional) Understand the template parameters</source>
          <target state="new">Step 2: (optional) Understand the template parameters</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>When you create a Spark cluster by using a template, you must specify a set of configuration parameters to deal with a number of required settings.</source>
          <target state="new">When you create a Spark cluster by using a template, you must specify a set of configuration parameters to deal with a number of required settings.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>By declaring these parameters in template definition, it's possible to specify values during deployment execution through an external file or at a command line.</source>
          <target state="new">By declaring these parameters in template definition, it's possible to specify values during deployment execution through an external file or at a command line.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>In the "parameters" section at the top of the azuredeploy.json file, you'll find the set of parameters that are required by the template to configure a Spark cluster.</source>
          <target state="new">In the "parameters" section at the top of the azuredeploy.json file, you'll find the set of parameters that are required by the template to configure a Spark cluster.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Here is an example of the "parameters" section from this template's azuredeploy.json file:</source>
          <target state="new">Here is an example of the "parameters" section from this template's azuredeploy.json file:</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Each parameter has details such as data type and allowed values.</source>
          <target state="new">Each parameter has details such as data type and allowed values.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>This allows for validation of parameters passed during template execution in an interactive mode (e.g., Azure PowerShell or Azure CLI), as well as a self-discovery UI that could be dynamically built by parsing the list of required parameters and their descriptions.</source>
          <target state="new">This allows for validation of parameters passed during template execution in an interactive mode (e.g., Azure PowerShell or Azure CLI), as well as a self-discovery UI that could be dynamically built by parsing the list of required parameters and their descriptions.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Step 3-a: Deploy a Spark cluster by using a template via Azure PowerShell</source>
          <target state="new">Step 3-a: Deploy a Spark cluster by using a template via Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Prepare a parameters file for your deployment by creating a JSON file containing runtime values for all parameters.</source>
          <target state="new">Prepare a parameters file for your deployment by creating a JSON file containing runtime values for all parameters.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>This file will then be passed as a single entity to the deployment command.</source>
          <target state="new">This file will then be passed as a single entity to the deployment command.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>If you do not include a parameters file, Azure PowerShell will use any default values specified in the template, and then prompt you to fill in the remaining values.</source>
          <target state="new">If you do not include a parameters file, Azure PowerShell will use any default values specified in the template, and then prompt you to fill in the remaining values.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Here is an example set of parameters from the azuredeploy-parameters.json file.</source>
          <target state="new">Here is an example set of parameters from the azuredeploy-parameters.json file.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Note that you will need to provide valid values for the parameters <bpt id="p1">**</bpt>storageAccountName<ept id="p1">**</ept>, <bpt id="p2">**</bpt>adminUsername<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>adminPassword<ept id="p3">**</ept>, plus any customizations to the other parameters:</source>
          <target state="new">Note that you will need to provide valid values for the parameters <bpt id="p1">**</bpt>storageAccountName<ept id="p1">**</ept>, <bpt id="p2">**</bpt>adminUsername<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>adminPassword<ept id="p3">**</ept>, plus any customizations to the other parameters:</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Fill in an Azure deployment name, resource group name, Azure location, and the folder of your saved JSON deployment file.</source>
          <target state="new">Fill in an Azure deployment name, resource group name, Azure location, and the folder of your saved JSON deployment file.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Then run these commands:</source>
          <target state="new">Then run these commands:</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> <bpt id="p1">**</bpt>$RGName<ept id="p1">**</ept> must be unique within your subscription.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> <bpt id="p1">**</bpt>$RGName<ept id="p1">**</ept> must be unique within your subscription.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>When you run the <bpt id="p1">**</bpt>New-AzureResourceGroupDeployment<ept id="p1">**</ept> command, this will extract parameter values from the JSON parameters file, and will start executing the template accordingly.</source>
          <target state="new">When you run the <bpt id="p1">**</bpt>New-AzureResourceGroupDeployment<ept id="p1">**</ept> command, this will extract parameter values from the JSON parameters file, and will start executing the template accordingly.</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Defining and using multiple parameter files with your different environments (test, production, etc.) will promote template reuse and simplify complex multi-environment solutions.</source>
          <target state="new">Defining and using multiple parameter files with your different environments (test, production, etc.) will promote template reuse and simplify complex multi-environment solutions.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>When deploying, please keep in mind that a new Azure Storage account needs to be created, so the name you provide as the Storage account parameter must be unique and meet all requirements for an Azure Storage account (lowercase letters and numbers only).</source>
          <target state="new">When deploying, please keep in mind that a new Azure Storage account needs to be created, so the name you provide as the Storage account parameter must be unique and meet all requirements for an Azure Storage account (lowercase letters and numbers only).</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>During the deployment, you will see something like this:</source>
          <target state="new">During the deployment, you will see something like this:</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>During and after deployment, you can check all the requests that were made during provisioning, including any errors that occurred.</source>
          <target state="new">During and after deployment, you can check all the requests that were made during provisioning, including any errors that occurred.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>To do that, go to the <bpt id="p1">[</bpt>Azure portal<ept id="p1">](https://portal.azure.com)</ept> and do the following:</source>
          <target state="new">To do that, go to the <bpt id="p1">[</bpt>Azure portal<ept id="p1">](https://portal.azure.com)</ept> and do the following:</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>Browse<ept id="p1">**</ept> on the left-hand navigation bar, and then scroll down and click <bpt id="p2">**</bpt>Resource Groups<ept id="p2">**</ept>.</source>
          <target state="new">Click <bpt id="p1">**</bpt>Browse<ept id="p1">**</ept> on the left-hand navigation bar, and then scroll down and click <bpt id="p2">**</bpt>Resource Groups<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Click the resource group that you just created, to bring up the "Resource Group" blade.</source>
          <target state="new">Click the resource group that you just created, to bring up the "Resource Group" blade.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>By clicking the <bpt id="p1">**</bpt>Events<ept id="p1">**</ept> bar graph in the <bpt id="p2">**</bpt>Monitoring<ept id="p2">**</ept> part of the "Resource Group" blade, you can see the events for your deployment.</source>
          <target state="new">By clicking the <bpt id="p1">**</bpt>Events<ept id="p1">**</ept> bar graph in the <bpt id="p2">**</bpt>Monitoring<ept id="p2">**</ept> part of the "Resource Group" blade, you can see the events for your deployment.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>By clicking individual events, you can drill further down into the details of each individual operation made on behalf of the template.</source>
          <target state="new">By clicking individual events, you can drill further down into the details of each individual operation made on behalf of the template.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>portal-events</source>
          <target state="new">portal-events</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>After your tests, if you need to remove this resource group and all of its resources (the storage account, virtual machine, and virtual network), use this single command:</source>
          <target state="new">After your tests, if you need to remove this resource group and all of its resources (the storage account, virtual machine, and virtual network), use this single command:</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Step 3-b: Deploy a Spark cluster by using a template via the Azure CLI</source>
          <target state="new">Step 3-b: Deploy a Spark cluster by using a template via the Azure CLI</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>To deploy a Spark cluster via the Azure CLI, first create a resource group by specifying a name and a location:</source>
          <target state="new">To deploy a Spark cluster via the Azure CLI, first create a resource group by specifying a name and a location:</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Pass this resource group name, the location of the JSON template file, and the location of the parameters file (see the above Azure PowerShell section for details) into the following command:</source>
          <target state="new">Pass this resource group name, the location of the JSON template file, and the location of the parameters file (see the above Azure PowerShell section for details) into the following command:</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>You can check the status of individual resources deployments by using the following command:</source>
          <target state="new">You can check the status of individual resources deployments by using the following command:</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>A tour of the Spark template structure and file organization</source>
          <target state="new">A tour of the Spark template structure and file organization</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>In order to design a robust and reusable Resource Manager template, additional thinking is needed to organize the series of complex and interrelated tasks required during the deployment of a complex solution like Spark.</source>
          <target state="new">In order to design a robust and reusable Resource Manager template, additional thinking is needed to organize the series of complex and interrelated tasks required during the deployment of a complex solution like Spark.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Leveraging Resource Manager template linking and resource looping in addition to script execution through related extensions, it's possible to implement a modular approach that can be reused with virtually any complex template-based deployment.</source>
          <target state="new">Leveraging Resource Manager template linking and resource looping in addition to script execution through related extensions, it's possible to implement a modular approach that can be reused with virtually any complex template-based deployment.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>This diagram describes the relationships between all the files downloaded from GitHub for this deployment:</source>
          <target state="new">This diagram describes the relationships between all the files downloaded from GitHub for this deployment:</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>spark-files</source>
          <target state="new">spark-files</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>This section steps you through the structure of the azuredeploy.json file for the Spark cluster.</source>
          <target state="new">This section steps you through the structure of the azuredeploy.json file for the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>If you have not already downloaded a copy of the template file, designate a local folder as the location for the file and create it (for example, C:\Azure\Templates\Spark).</source>
          <target state="new">If you have not already downloaded a copy of the template file, designate a local folder as the location for the file and create it (for example, C:\Azure\Templates\Spark).</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>Fill in the folder name and run these commands:</source>
          <target state="new">Fill in the folder name and run these commands:</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Open the azuredeploy.json template in a text editor or tool of your choice.</source>
          <target state="new">Open the azuredeploy.json template in a text editor or tool of your choice.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>The following information describes the structure of the template file and the purpose of each section.</source>
          <target state="new">The following information describes the structure of the template file and the purpose of each section.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Alternately, you can see the contents of this template in your browser from <bpt id="p1">[</bpt>here<ept id="p1">](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/spark-on-ubuntu/azuredeploy.json)</ept>.</source>
          <target state="new">Alternately, you can see the contents of this template in your browser from <bpt id="p1">[</bpt>here<ept id="p1">](https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/spark-on-ubuntu/azuredeploy.json)</ept>.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>"parameters" section</source>
          <target state="new">"parameters" section</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The "parameters" section of azuredeploy.json specifies modifiable parameters that are used in this template.</source>
          <target state="new">The "parameters" section of azuredeploy.json specifies modifiable parameters that are used in this template.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>The aforementioned azuredeploy-parameters.json file is used to pass values into the "parameters" section of azuredeploy.json during template execution.</source>
          <target state="new">The aforementioned azuredeploy-parameters.json file is used to pass values into the "parameters" section of azuredeploy.json during template execution.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Here is an example of a parameter for the "t-shirt size":</source>
          <target state="new">Here is an example of a parameter for the "t-shirt size":</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> Notice that <bpt id="p1">**</bpt>defaultValue<ept id="p1">**</ept> may be specified, as well as <bpt id="p2">**</bpt>allowedValues<ept id="p2">**</ept>.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> Notice that <bpt id="p1">**</bpt>defaultValue<ept id="p1">**</ept> may be specified, as well as <bpt id="p2">**</bpt>allowedValues<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>"variables" section</source>
          <target state="new">"variables" section</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>The "variables" section specifies variables that can be used throughout this template.</source>
          <target state="new">The "variables" section specifies variables that can be used throughout this template.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>This contains a number of fields (JSON data types or fragments) that will be set to constants or calculated values at execution time.</source>
          <target state="new">This contains a number of fields (JSON data types or fragments) that will be set to constants or calculated values at execution time.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>Here are some examples that range from simple to more complex:</source>
          <target state="new">Here are some examples that range from simple to more complex:</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>vmStorageAccountContainerName<ept id="p1">**</ept> variable is an example of a simple name/value variable.</source>
          <target state="new">The <bpt id="p1">**</bpt>vmStorageAccountContainerName<ept id="p1">**</ept> variable is an example of a simple name/value variable.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>vnetID<ept id="p1">**</ept> is an example of a variable that is calculated at run time using the functions <bpt id="p2">**</bpt>resourceId<ept id="p2">**</ept> and <bpt id="p3">**</bpt>parameters<ept id="p3">**</ept>.</source>
          <target state="new"><bpt id="p1">**</bpt>vnetID<ept id="p1">**</ept> is an example of a variable that is calculated at run time using the functions <bpt id="p2">**</bpt>resourceId<ept id="p2">**</ept> and <bpt id="p3">**</bpt>parameters<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>The value of the <bpt id="p1">**</bpt>numberOfMasterInstances<ept id="p1">**</ept> and <bpt id="p2">**</bpt>vmSize<ept id="p2">**</ept> variables are calculated at run time using the <bpt id="p3">**</bpt>concat<ept id="p3">**</ept>, <bpt id="p4">**</bpt>variables<ept id="p4">**</ept>, and <bpt id="p5">**</bpt>parameters<ept id="p5">**</ept> functions.</source>
          <target state="new">The value of the <bpt id="p1">**</bpt>numberOfMasterInstances<ept id="p1">**</ept> and <bpt id="p2">**</bpt>vmSize<ept id="p2">**</ept> variables are calculated at run time using the <bpt id="p3">**</bpt>concat<ept id="p3">**</ept>, <bpt id="p4">**</bpt>variables<ept id="p4">**</ept>, and <bpt id="p5">**</bpt>parameters<ept id="p5">**</ept> functions.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>If you want to customize the size of the Spark cluster deployment, then you can change the properties of the variables <bpt id="p1">**</bpt>tshirtSizeS<ept id="p1">**</ept>, <bpt id="p2">**</bpt>tshirtSizeM<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>tshirtSizeL<ept id="p3">**</ept> in the azuredeploy.json template.</source>
          <target state="new">If you want to customize the size of the Spark cluster deployment, then you can change the properties of the variables <bpt id="p1">**</bpt>tshirtSizeS<ept id="p1">**</ept>, <bpt id="p2">**</bpt>tshirtSizeM<ept id="p2">**</ept>, and <bpt id="p3">**</bpt>tshirtSizeL<ept id="p3">**</ept> in the azuredeploy.json template.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>More information regarding the template language can be found on MSDN at <bpt id="p1">[</bpt>Azure Resource Manager Template Language<ept id="p1">](../resource-group-authoring-templates.md)</ept>.</source>
          <target state="new">More information regarding the template language can be found on MSDN at <bpt id="p1">[</bpt>Azure Resource Manager Template Language<ept id="p1">](../resource-group-authoring-templates.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>"resources" section</source>
          <target state="new">"resources" section</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>The "resources" section is where most of the action happens.</source>
          <target state="new">The "resources" section is where most of the action happens.</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Looking carefully inside this section, you can immediately identify two different cases.</source>
          <target state="new">Looking carefully inside this section, you can immediately identify two different cases.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>The first is an element defined of type <ph id="ph1">`Microsoft.Resources/deployments`</ph> that essentially invokes a nested deployment within the main one.</source>
          <target state="new">The first is an element defined of type <ph id="ph1">`Microsoft.Resources/deployments`</ph> that essentially invokes a nested deployment within the main one.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>The second is the <bpt id="p1">**</bpt>templateLink<ept id="p1">**</ept> property (and related <bpt id="p2">**</bpt>contentVersion<ept id="p2">**</ept> property) that makes it possible to specify a linked template file that will be invoked, passing a set of parameters as input.</source>
          <target state="new">The second is the <bpt id="p1">**</bpt>templateLink<ept id="p1">**</ept> property (and related <bpt id="p2">**</bpt>contentVersion<ept id="p2">**</ept> property) that makes it possible to specify a linked template file that will be invoked, passing a set of parameters as input.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>These can be seen in this template fragment:</source>
          <target state="new">These can be seen in this template fragment:</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>From this first example, it is clear how azuredeploy.json in this scenario has been organized as a sort of orchestration mechanism, invoking a number of other template files.</source>
          <target state="new">From this first example, it is clear how azuredeploy.json in this scenario has been organized as a sort of orchestration mechanism, invoking a number of other template files.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Each file is responsible for part of the required deployment activities.</source>
          <target state="new">Each file is responsible for part of the required deployment activities.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>In particular, the following linked templates will be used for this deployment:</source>
          <target state="new">In particular, the following linked templates will be used for this deployment:</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>shared-resource.json<ept id="p1">**</ept>: contains the definition of all resources that will be shared across the deployment.</source>
          <target state="new"><bpt id="p1">**</bpt>shared-resource.json<ept id="p1">**</ept>: contains the definition of all resources that will be shared across the deployment.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Examples are Storage accounts used to store a VM's OS disks and virtual networks.</source>
          <target state="new">Examples are Storage accounts used to store a VM's OS disks and virtual networks.</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>jumpbox-resources-enabled.json<ept id="p1">**</ept>: deploys the "jump box" VM and all related resources, such as network interface, public IP address, and the input endpoint used to SSH into the environment.</source>
          <target state="new"><bpt id="p1">**</bpt>jumpbox-resources-enabled.json<ept id="p1">**</ept>: deploys the "jump box" VM and all related resources, such as network interface, public IP address, and the input endpoint used to SSH into the environment.</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>After invoking these two templates, azuredeploy.json provisions all Spark cluster node VMs and connected resources (network adapters, private IPs, etc.).</source>
          <target state="new">After invoking these two templates, azuredeploy.json provisions all Spark cluster node VMs and connected resources (network adapters, private IPs, etc.).</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>This template will also deploy VM extensions (custom scripts for Linux) and invoke a bash script (spark-cluster-install.sh) to physically install and set up Spark on each node.</source>
          <target state="new">This template will also deploy VM extensions (custom scripts for Linux) and invoke a bash script (spark-cluster-install.sh) to physically install and set up Spark on each node.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Let's drill down into <bpt id="p1">*</bpt>how<ept id="p1">*</ept> this last template, azuredeploy.json, is used, as it is one of the most interesting from a template development perspective.</source>
          <target state="new">Let's drill down into <bpt id="p1">*</bpt>how<ept id="p1">*</ept> this last template, azuredeploy.json, is used, as it is one of the most interesting from a template development perspective.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>One important concept to highlight is how a single template file can deploy multiple copies of a single resource type, and for each instance, it can set unique values for required settings.</source>
          <target state="new">One important concept to highlight is how a single template file can deploy multiple copies of a single resource type, and for each instance, it can set unique values for required settings.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>This concept is known as <bpt id="p1">**</bpt>resource looping<ept id="p1">**</ept>.</source>
          <target state="new">This concept is known as <bpt id="p1">**</bpt>resource looping<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>A resource that uses the <bpt id="p1">**</bpt>copy<ept id="p1">**</ept> element will "copy" itself for the number of times specified in the <bpt id="p2">**</bpt>count<ept id="p2">**</ept> parameter of the <bpt id="p3">**</bpt>copy<ept id="p3">**</ept> element.</source>
          <target state="new">A resource that uses the <bpt id="p1">**</bpt>copy<ept id="p1">**</ept> element will "copy" itself for the number of times specified in the <bpt id="p2">**</bpt>count<ept id="p2">**</ept> parameter of the <bpt id="p3">**</bpt>copy<ept id="p3">**</ept> element.</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>For all settings where it is necessary to specify unique values between different instances of the deployed resource, the <bpt id="p1">**</bpt>copyindex()<ept id="p1">**</ept> function can be used to obtain a numeric value indicating the current index in that particular resource loop creation.</source>
          <target state="new">For all settings where it is necessary to specify unique values between different instances of the deployed resource, the <bpt id="p1">**</bpt>copyindex()<ept id="p1">**</ept> function can be used to obtain a numeric value indicating the current index in that particular resource loop creation.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>In the following fragment from azuredeploy.json, you can see this concept applied to multiple network adapters, VMs, and VM extensions being created for the Spark cluster:</source>
          <target state="new">In the following fragment from azuredeploy.json, you can see this concept applied to multiple network adapters, VMs, and VM extensions being created for the Spark cluster:</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Another important concept in resource creation is the ability to specify dependencies and precedencies between resources, as you can see in the <bpt id="p1">**</bpt>dependsOn<ept id="p1">**</ept> JSON array.</source>
          <target state="new">Another important concept in resource creation is the ability to specify dependencies and precedencies between resources, as you can see in the <bpt id="p1">**</bpt>dependsOn<ept id="p1">**</ept> JSON array.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>In this particular template, you can see that the Spark cluster nodes are dependent on the shared resources and <bpt id="p1">**</bpt>networkInterfaces<ept id="p1">**</ept> resources being created first.</source>
          <target state="new">In this particular template, you can see that the Spark cluster nodes are dependent on the shared resources and <bpt id="p1">**</bpt>networkInterfaces<ept id="p1">**</ept> resources being created first.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Another interesting fragment to explore is the one related to <bpt id="p1">**</bpt>CustomScriptForLinux<ept id="p1">**</ept> VM extensions.</source>
          <target state="new">Another interesting fragment to explore is the one related to <bpt id="p1">**</bpt>CustomScriptForLinux<ept id="p1">**</ept> VM extensions.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>These are installed as a separate type of resource, with a dependency on each cluster node.</source>
          <target state="new">These are installed as a separate type of resource, with a dependency on each cluster node.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>In this case, this is used to install and set up Spark on each VM node.</source>
          <target state="new">In this case, this is used to install and set up Spark on each VM node.</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Let's look at a snippet from the azuredeploy.json template that uses these:</source>
          <target state="new">Let's look at a snippet from the azuredeploy.json template that uses these:</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Notice that the extension for the master and slave node resources executes different commands, defined in the <bpt id="p1">**</bpt>commandToExecute<ept id="p1">**</ept> property, as part of the provisioning process.</source>
          <target state="new">Notice that the extension for the master and slave node resources executes different commands, defined in the <bpt id="p1">**</bpt>commandToExecute<ept id="p1">**</ept> property, as part of the provisioning process.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>If you look at the JSON snippet of the latest virtual machine extension, you can see that this resource depends on the virtual manchine resource and its network interface.</source>
          <target state="new">If you look at the JSON snippet of the latest virtual machine extension, you can see that this resource depends on the virtual manchine resource and its network interface.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>This indicates that these two resources need to be already deployed before provisioning and running this VM extension.</source>
          <target state="new">This indicates that these two resources need to be already deployed before provisioning and running this VM extension.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Also note the use of the <bpt id="p1">**</bpt>copyindex()<ept id="p1">**</ept> function to repeat this step for each slave virtual machine.</source>
          <target state="new">Also note the use of the <bpt id="p1">**</bpt>copyindex()<ept id="p1">**</ept> function to repeat this step for each slave virtual machine.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>By familiarizing yourself with the other files included in this deployment, you will be able to understand all the details and best practices required to organize and orchestrate complex deployment strategies for multi-node solutions, based on any technology, leveraging Azure Resource Manager templates.</source>
          <target state="new">By familiarizing yourself with the other files included in this deployment, you will be able to understand all the details and best practices required to organize and orchestrate complex deployment strategies for multi-node solutions, based on any technology, leveraging Azure Resource Manager templates.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>While not mandatory, a recommended approach is to structure your template files as highlighted by the following diagram:</source>
          <target state="new">While not mandatory, a recommended approach is to structure your template files as highlighted by the following diagram:</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>spark-template-structure</source>
          <target state="new">spark-template-structure</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>In essence, this approach suggests to:</source>
          <target state="new">In essence, this approach suggests to:</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Define your core template file as a central orchestration point for all specific deployment activities, leveraging template linking to invoke sub-template executions.</source>
          <target state="new">Define your core template file as a central orchestration point for all specific deployment activities, leveraging template linking to invoke sub-template executions.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Create a specific template file that will deploy all resources shared across all other specific deployment tasks (storage accounts, virtual network configuration, etc.).</source>
          <target state="new">Create a specific template file that will deploy all resources shared across all other specific deployment tasks (storage accounts, virtual network configuration, etc.).</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>This can be heavily reused between deployments that have similar requirements in terms of common infrastructure.</source>
          <target state="new">This can be heavily reused between deployments that have similar requirements in terms of common infrastructure.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Include optional resource templates for spot requirements specific to a given resource.</source>
          <target state="new">Include optional resource templates for spot requirements specific to a given resource.</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>For identical members of a group of resources (nodes in a cluster, etc.), create specific templates that leverage resource looping in order to deploy multiple instances with unique properties.</source>
          <target state="new">For identical members of a group of resources (nodes in a cluster, etc.), create specific templates that leverage resource looping in order to deploy multiple instances with unique properties.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>For all post-deployment tasks (product installation, configurations, etc.), leverage script deployment extensions and create scripts specific to each technology.</source>
          <target state="new">For all post-deployment tasks (product installation, configurations, etc.), leverage script deployment extensions and create scripts specific to each technology.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Azure Resource Manager Template Language<ept id="p1">](../resource-group-authoring-templates.md)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Azure Resource Manager Template Language<ept id="p1">](../resource-group-authoring-templates.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Next steps</source>
          <target state="new">Next steps</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>Read more details on <bpt id="p1">[</bpt>deploying a template<ept id="p1">](../resource-group-template-deploy.md)</ept>.</source>
          <target state="new">Read more details on <bpt id="p1">[</bpt>deploying a template<ept id="p1">](../resource-group-template-deploy.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Discover more <bpt id="p1">[</bpt>application frameworks<ept id="p1">](virtual-machines-app-frameworks.md)</ept>.</source>
          <target state="new">Discover more <bpt id="p1">[</bpt>application frameworks<ept id="p1">](virtual-machines-app-frameworks.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Troubleshoot template deployments<ept id="p1">](resource-group-deploy-debug.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Troubleshoot template deployments<ept id="p1">](resource-group-deploy-debug.md)</ept>.</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">03d260f3fe9d620ae9c8730aa52caf3eab5a0cea</xliffext:olfilehash>
  </header>
</xliff>