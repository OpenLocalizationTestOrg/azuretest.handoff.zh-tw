<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</source>
          <target state="new">Use Script Action to install Spark on Hadoop cluster | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to customize an HDInsight cluster with Spark.</source>
          <target state="new">Learn how to customize an HDInsight cluster with Spark.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>You'll use a Script Action configuration option to use a script to install Spark.</source>
          <target state="new">You'll use a Script Action configuration option to use a script to install Spark.</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Install and use Spark on HDInsight Hadoop clusters</source>
          <target state="new">Install and use Spark on HDInsight Hadoop clusters</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>You can install Spark on any type of cluster in Hadoop on Azure HDInsight by using <bpt id="p1">**</bpt>Script Action<ept id="p1">**</ept> cluster customization.</source>
          <target state="new">You can install Spark on any type of cluster in Hadoop on Azure HDInsight by using <bpt id="p1">**</bpt>Script Action<ept id="p1">**</ept> cluster customization.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</source>
          <target state="new">Script Action lets you run scripts to customize a cluster, only when the cluster is being created.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Customize HDInsight cluster using Script Action<ept id="p1">][hdinsight-cluster-customize]</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Customize HDInsight cluster using Script Action<ept id="p1">][hdinsight-cluster-customize]</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>In this topic, you will learn how to install Spark by using Script Action.</source>
          <target state="new">In this topic, you will learn how to install Spark by using Script Action.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</source>
          <target state="new">Once you have installed Spark, you'll also learn how to run a Spark query on HDInsight clusters.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> HDInsight now provides Spark as a first-class cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> HDInsight now provides Spark as a first-class cluster type, which means you can now directly provision a Spark cluster without modifying a Hadoop cluster.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Using the Spark cluster type, you get an HDInsight version 3.2 cluster with Spark version 1.3.1.</source>
          <target state="new">Using the Spark cluster type, you get an HDInsight version 3.2 cluster with Spark version 1.3.1.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Get Started with Apache Spark on HDInsight<ept id="p1">](hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql.md)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Get Started with Apache Spark on HDInsight<ept id="p1">](hdinsight-apache-spark-zeppelin-notebook-jupyter-spark-sql.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>What is Spark?</source>
          <target state="new"><ph id="ph1">&lt;a name="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>What is Spark?</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a href="http://spark.apache.org/docs/latest/index.html" target="_blank"&gt;</ph>Apache Spark<ph id="ph2">&lt;/a&gt;</ph> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</source>
          <target state="new"><ph id="ph1">&lt;a href="http://spark.apache.org/docs/latest/index.html" target="_blank"&gt;</ph>Apache Spark<ph id="ph2">&lt;/a&gt;</ph> is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</source>
          <target state="new">Spark's in-memory computation capabilities make it a good choice for iterative algorithms in machine learning and graph computations.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Spark can also be used to perform conventional disk-based data processing.</source>
          <target state="new">Spark can also be used to perform conventional disk-based data processing.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</source>
          <target state="new">Spark improves the traditional MapReduce framework by avoiding writes to disk in the intermediate stages.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</source>
          <target state="new">Also, Spark is compatible with the Hadoop Distributed File System (HDFS) and Azure Blob storage so the existing data can easily be processed via Spark.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>This topic provides instructions on how to customize an HDInsight cluster to install Spark.</source>
          <target state="new">This topic provides instructions on how to customize an HDInsight cluster to install Spark.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Which version of Spark can I install?</source>
          <target state="new"><ph id="ph1">&lt;a name="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Which version of Spark can I install?</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</source>
          <target state="new">In this topic, we use a Script Action custom script to install Spark on an HDInsight cluster.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This script can install Spark 1.2.0 or Spark 1.0.2 depending on the version of the HDInsight cluster you provision.</source>
          <target state="new">This script can install Spark 1.2.0 or Spark 1.0.2 depending on the version of the HDInsight cluster you provision.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>If you use the script while provisioning an <bpt id="p1">**</bpt>HDInsight 3.2<ept id="p1">**</ept> cluster, it installs <bpt id="p2">**</bpt>Spark 1.2.0<ept id="p2">**</ept>.</source>
          <target state="new">If you use the script while provisioning an <bpt id="p1">**</bpt>HDInsight 3.2<ept id="p1">**</ept> cluster, it installs <bpt id="p2">**</bpt>Spark 1.2.0<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>If you use the script while provisioning an <bpt id="p1">**</bpt>HDInsight 3.1<ept id="p1">**</ept> cluster, it installs <bpt id="p2">**</bpt>Spark 1.0.2<ept id="p2">**</ept>.</source>
          <target state="new">If you use the script while provisioning an <bpt id="p1">**</bpt>HDInsight 3.1<ept id="p1">**</ept> cluster, it installs <bpt id="p2">**</bpt>Spark 1.0.2<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>You can modify this script or create your own script to install other versions of Spark.</source>
          <target state="new">You can modify this script or create your own script to install other versions of Spark.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="install"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I install Spark?</source>
          <target state="new"><ph id="ph1">&lt;a name="install"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I install Spark?</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="p1">[</bpt>https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1<ept id="p1">](https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1)</ept>.</source>
          <target state="new">A sample script to install Spark on an HDInsight cluster is available from a read-only Azure storage blob at <bpt id="p1">[</bpt>https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1<ept id="p1">](https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1)</ept>.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</source>
          <target state="new">This section provides instructions on how to use the sample script while provisioning the cluster by using the Azure portal.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The sample script works only with HDInsight 3.1 and 3.2 clusters.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The sample script works only with HDInsight 3.1 and 3.2 clusters.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>For more information on HDInsight cluster versions, see <bpt id="p1">[</bpt>HDInsight cluster versions<ept id="p1">](hdinsight-component-versioning.md)</ept>.</source>
          <target state="new">For more information on HDInsight cluster versions, see <bpt id="p1">[</bpt>HDInsight cluster versions<ept id="p1">](hdinsight-component-versioning.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Start provisioning a cluster by using the <bpt id="p1">**</bpt>CUSTOM CREATE<ept id="p1">**</ept> option, as described at <bpt id="p2">[</bpt>Provisioning a cluster using custom options<ept id="p2">](hdinsight-provision-clusters.md#portal)</ept>.</source>
          <target state="new">Start provisioning a cluster by using the <bpt id="p1">**</bpt>CUSTOM CREATE<ept id="p1">**</ept> option, as described at <bpt id="p2">[</bpt>Provisioning a cluster using custom options<ept id="p2">](hdinsight-provision-clusters.md#portal)</ept>.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Pick the cluster version depending on the following:</source>
          <target state="new">Pick the cluster version depending on the following:</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>If you want to install <bpt id="p1">**</bpt>Spark 1.2.0<ept id="p1">**</ept>, provision an HDInsight 3.2 cluster.</source>
          <target state="new">If you want to install <bpt id="p1">**</bpt>Spark 1.2.0<ept id="p1">**</ept>, provision an HDInsight 3.2 cluster.</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>If you want to install <bpt id="p1">**</bpt>Spark 1.0.2<ept id="p1">**</ept>, provision an HDInsight 3.1 cluster.</source>
          <target state="new">If you want to install <bpt id="p1">**</bpt>Spark 1.0.2<ept id="p1">**</ept>, provision an HDInsight 3.1 cluster.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>On the <bpt id="p1">**</bpt>Script Actions<ept id="p1">**</ept> page of the wizard, click <bpt id="p2">**</bpt>add script action<ept id="p2">**</ept> to provide details about the script action, as shown below:</source>
          <target state="new">On the <bpt id="p1">**</bpt>Script Actions<ept id="p1">**</ept> page of the wizard, click <bpt id="p2">**</bpt>add script action<ept id="p2">**</ept> to provide details about the script action, as shown below:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Use Script Action to customize a cluster</source>
          <target state="new">Use Script Action to customize a cluster</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Property</source>
          <target state="new">Property</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Value</source>
          <target state="new">Value</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="new">Name</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Specify a name for the script action.</source>
          <target state="new">Specify a name for the script action.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph1">&lt;b&gt;</ph>Install Spark<ph id="ph2">&lt;/b&gt;</ph>.</source>
          <target state="new">For example, <ph id="ph1">&lt;b&gt;</ph>Install Spark<ph id="ph2">&lt;/b&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Script URI</source>
          <target state="new">Script URI</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Specify the Uniform Resource Identifier (URI) to the script that is invoked to customize the cluster.</source>
          <target state="new">Specify the Uniform Resource Identifier (URI) to the script that is invoked to customize the cluster.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>For example, <ph id="ph1">&lt;i&gt;</ph>https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1<ph id="ph2">&lt;/i&gt;</ph></source>
          <target state="new">For example, <ph id="ph1">&lt;i&gt;</ph>https://hdiconfigactions.blob.core.windows.net/sparkconfigactionv03/spark-installer-v03.ps1<ph id="ph2">&lt;/i&gt;</ph></target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Node Type</source>
          <target state="new">Node Type</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Specify the nodes on which the customization script is run.</source>
          <target state="new">Specify the nodes on which the customization script is run.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>You can choose <ph id="ph1">&lt;b&gt;</ph>All nodes<ph id="ph2">&lt;/b&gt;</ph>, <ph id="ph3">&lt;b&gt;</ph>Head nodes only<ph id="ph4">&lt;/b&gt;</ph>, or <ph id="ph5">&lt;b&gt;</ph>Worker nodes only<ph id="ph6">&lt;/b&gt;</ph>.</source>
          <target state="new">You can choose <ph id="ph1">&lt;b&gt;</ph>All nodes<ph id="ph2">&lt;/b&gt;</ph>, <ph id="ph3">&lt;b&gt;</ph>Head nodes only<ph id="ph4">&lt;/b&gt;</ph>, or <ph id="ph5">&lt;b&gt;</ph>Worker nodes only<ph id="ph6">&lt;/b&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="new">Parameters</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Specify the parameters, if required by the script.</source>
          <target state="new">Specify the parameters, if required by the script.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>The script to install Spark does not require any parameters so you can leave this blank.</source>
          <target state="new">The script to install Spark does not require any parameters so you can leave this blank.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>You can add more than one script action to install multiple components on the cluster.</source>
          <target state="new">You can add more than one script action to install multiple components on the cluster.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>After you have added the scripts, click the checkmark to start provisioning the cluster.</source>
          <target state="new">After you have added the scripts, click the checkmark to start provisioning the cluster.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>You can also use the script to install Spark on HDInsight by using Azure PowerShell or the HDInsight .NET SDK.</source>
          <target state="new">You can also use the script to install Spark on HDInsight by using Azure PowerShell or the HDInsight .NET SDK.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Instructions for these procedures are provided later in this topic.</source>
          <target state="new">Instructions for these procedures are provided later in this topic.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="usespark"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I use Spark in HDInsight?</source>
          <target state="new"><ph id="ph1">&lt;a name="usespark"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I use Spark in HDInsight?</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Spark provides APIs in Scala, Python, and Java.</source>
          <target state="new">Spark provides APIs in Scala, Python, and Java.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>You can also use the interactive Spark shell to run Spark queries.</source>
          <target state="new">You can also use the interactive Spark shell to run Spark queries.</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>This section provides instructions on how to use the different approaches to work with Spark:</source>
          <target state="new">This section provides instructions on how to use the different approaches to work with Spark:</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Using the Spark shell to run interactive queries</source>
          <target state="new">Using the Spark shell to run interactive queries</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Using the Spark shell to run Spark SQL queries</source>
          <target state="new">Using the Spark shell to run Spark SQL queries</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Using a standalone Scala program</source>
          <target state="new">Using a standalone Scala program</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="sparkshell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using the Spark shell to run interactive queries</source>
          <target state="new"><ph id="ph1">&lt;a name="sparkshell"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using the Spark shell to run interactive queries</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Perform the following steps to run Spark queries from an interactive Spark shell.</source>
          <target state="new">Perform the following steps to run Spark queries from an interactive Spark shell.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>In this section, we run a Spark query on a sample data file (/example/data/gutenberg/davinci.txt) that is available on HDInsight clusters by default.</source>
          <target state="new">In this section, we run a Spark query on a sample data file (/example/data/gutenberg/davinci.txt) that is available on HDInsight clusters by default.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>From the Azure portal, enable Remote Desktop for the cluster you created with Spark installed, and then remote into the cluster.</source>
          <target state="new">From the Azure portal, enable Remote Desktop for the cluster you created with Spark installed, and then remote into the cluster.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>For instructions, see <ph id="ph1">&lt;a href="http://azure.microsoft.com/documentation/articles/hdinsight-administer-use-management-portal/#rdp" target="_blank"&gt;</ph>Connect to HDInsight clusters using RDP<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">For instructions, see <ph id="ph1">&lt;a href="http://azure.microsoft.com/documentation/articles/hdinsight-administer-use-management-portal/#rdp" target="_blank"&gt;</ph>Connect to HDInsight clusters using RDP<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>In the Remote Desktop Protocol (RDP) session, from the desktop, open the Hadoop command line (from a desktop shortcut), and navigate to the location where Spark is installed; for example, <bpt id="p1">**</bpt>C:\apps\dist\spark-1.2.0<ept id="p1">**</ept>.</source>
          <target state="new">In the Remote Desktop Protocol (RDP) session, from the desktop, open the Hadoop command line (from a desktop shortcut), and navigate to the location where Spark is installed; for example, <bpt id="p1">**</bpt>C:\apps\dist\spark-1.2.0<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Run the following command to start the Spark shell:</source>
          <target state="new">Run the following command to start the Spark shell:</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>After the command finishes running, you should get a Scala prompt:</source>
          <target state="new">After the command finishes running, you should get a Scala prompt:</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>On the Scala prompt, enter the Spark query shown below.</source>
          <target state="new">On the Scala prompt, enter the Spark query shown below.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</source>
          <target state="new">This query counts the occurrence of each word in the davinci.txt file that is available at the /example/data/gutenberg/ location on the Azure Blob storage associated with the cluster.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>The output should resemble the following:</source>
          <target state="new">The output should resemble the following:</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Output from running Scala interactive shell in an HDInsight cluster</source>
          <target state="new">Output from running Scala interactive shell in an HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Enter :q to exit the Scala prompt.</source>
          <target state="new">Enter :q to exit the Scala prompt.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="sparksql"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using the Spark shell to run Spark SQL queries</source>
          <target state="new"><ph id="ph1">&lt;a name="sparksql"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using the Spark shell to run Spark SQL queries</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</source>
          <target state="new">Spark SQL allows you to use Spark to run relational queries expressed in Structured Query Language (SQL), HiveQL, or Scala.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>In this section, we look at using Spark to run a Hive query on a sample Hive table.</source>
          <target state="new">In this section, we look at using Spark to run a Hive query on a sample Hive table.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The Hive table used in this section (called <bpt id="p1">**</bpt>hivesampletable<ept id="p1">**</ept>) is available by default when you provision a cluster.</source>
          <target state="new">The Hive table used in this section (called <bpt id="p1">**</bpt>hivesampletable<ept id="p1">**</ept>) is available by default when you provision a cluster.</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> The sample below was created against <bpt id="p1">**</bpt>Spark 1.2.0<ept id="p1">**</ept>, which is installed if you run the script action while provisioning HDInsight 3.2 cluster.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> The sample below was created against <bpt id="p1">**</bpt>Spark 1.2.0<ept id="p1">**</ept>, which is installed if you run the script action while provisioning HDInsight 3.2 cluster.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>From the Azure portal, enable Remote Desktop for the cluster you created with Spark installed, and then remote into the cluster.</source>
          <target state="new">From the Azure portal, enable Remote Desktop for the cluster you created with Spark installed, and then remote into the cluster.</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>For instructions, see <ph id="ph1">&lt;a href="http://azure.microsoft.com/documentation/articles/hdinsight-administer-use-management-portal/#rdp" target="_blank"&gt;</ph>Connect to HDInsight clusters using RDP<ph id="ph2">&lt;/a&gt;</ph>.</source>
          <target state="new">For instructions, see <ph id="ph1">&lt;a href="http://azure.microsoft.com/documentation/articles/hdinsight-administer-use-management-portal/#rdp" target="_blank"&gt;</ph>Connect to HDInsight clusters using RDP<ph id="ph2">&lt;/a&gt;</ph>.</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>In the RDP session, from the desktop, open the Hadoop command line (from a desktop shortcut), and navigate to the location where Spark is installed; for example, <bpt id="p1">**</bpt>C:\apps\dist\spark-1.2.0<ept id="p1">**</ept>.</source>
          <target state="new">In the RDP session, from the desktop, open the Hadoop command line (from a desktop shortcut), and navigate to the location where Spark is installed; for example, <bpt id="p1">**</bpt>C:\apps\dist\spark-1.2.0<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Run the following command to start the Spark shell:</source>
          <target state="new">Run the following command to start the Spark shell:</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>After the command finishes running, you should get a Scala prompt:</source>
          <target state="new">After the command finishes running, you should get a Scala prompt:</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>On the Scala prompt, set the Hive context.</source>
          <target state="new">On the Scala prompt, set the Hive context.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>This is required to work with Hive queries by using Spark.</source>
          <target state="new">This is required to work with Hive queries by using Spark.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Note that <bpt id="p1">**</bpt>sc<ept id="p1">**</ept> is default Spark context that is set when you start the Spark shell.</source>
          <target state="new">Note that <bpt id="p1">**</bpt>sc<ept id="p1">**</ept> is default Spark context that is set when you start the Spark shell.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>Run a Hive query by using the Hive context and print the output to the console.</source>
          <target state="new">Run a Hive query by using the Hive context and print the output to the console.</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</source>
          <target state="new">The query retrieves data on devices of a specific make and limits the number of records retrieved to 20.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>You should see an output like the following:</source>
          <target state="new">You should see an output like the following:</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Output from running Spark SQL on an HDInsight cluster</source>
          <target state="new">Output from running Spark SQL on an HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Enter :q to exit the Scala prompt.</source>
          <target state="new">Enter :q to exit the Scala prompt.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="standalone"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using a standalone Scala program</source>
          <target state="new"><ph id="ph1">&lt;a name="standalone"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Using a standalone Scala program</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>In this section, we write a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt) that is available on HDInsight clusters by default.</source>
          <target state="new">In this section, we write a Scala application that counts the number of lines containing the letters 'a' and 'b' in a sample data file (/example/data/gutenberg/davinci.txt) that is available on HDInsight clusters by default.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>To write and use a standalone Scala program with a cluster customized with Spark installation, you must perform the following steps:</source>
          <target state="new">To write and use a standalone Scala program with a cluster customized with Spark installation, you must perform the following steps:</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>Write a Scala program</source>
          <target state="new">Write a Scala program</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>Build the Scala program to get the .jar file</source>
          <target state="new">Build the Scala program to get the .jar file</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Run the job on the cluster</source>
          <target state="new">Run the job on the cluster</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Write a Scala program</source>
          <target state="new">Write a Scala program</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>In this section, you write a Scala program that counts the number of lines containing 'a' and 'b' in the sample data file.</source>
          <target state="new">In this section, you write a Scala program that counts the number of lines containing 'a' and 'b' in the sample data file.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Open a text editor and paste the following code:</source>
          <target state="new">Open a text editor and paste the following code:</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>Save the file with the name <bpt id="p1">**</bpt>SimpleApp.scala<ept id="p1">**</ept>.</source>
          <target state="new">Save the file with the name <bpt id="p1">**</bpt>SimpleApp.scala<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Build the Scala program</source>
          <target state="new">Build the Scala program</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>In this section, you use the <ph id="ph1">&lt;a href="http://www.scala-sbt.org/0.13/docs/index.html" target="_blank"&gt;</ph>Simple Build Tool<ph id="ph2">&lt;/a&gt;</ph> (or sbt) to build the Scala program.</source>
          <target state="new">In this section, you use the <ph id="ph1">&lt;a href="http://www.scala-sbt.org/0.13/docs/index.html" target="_blank"&gt;</ph>Simple Build Tool<ph id="ph2">&lt;/a&gt;</ph> (or sbt) to build the Scala program.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>sbt requires Java 1.6 or later, so make sure you have the right version of Java installed before continuing with this section.</source>
          <target state="new">sbt requires Java 1.6 or later, so make sure you have the right version of Java installed before continuing with this section.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Install sbt from http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Windows.html.</source>
          <target state="new">Install sbt from http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Windows.html.</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Create a folder called <bpt id="p1">**</bpt>SimpleScalaApp<ept id="p1">**</ept>, and within this folder create a file called <bpt id="p2">**</bpt>simple.sbt<ept id="p2">**</ept>.</source>
          <target state="new">Create a folder called <bpt id="p1">**</bpt>SimpleScalaApp<ept id="p1">**</ept>, and within this folder create a file called <bpt id="p2">**</bpt>simple.sbt<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>This is a configuration file that contains information about the Scala version, library dependencies, etc. Paste the following into the simple.sbt file and save it:</source>
          <target state="new">This is a configuration file that contains information about the Scala version, library dependencies, etc. Paste the following into the simple.sbt file and save it:</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Under the <bpt id="p1">**</bpt>SimpleScalaApp<ept id="p1">**</ept> folder, create a directory structure <bpt id="p2">**</bpt>\src\main\scala<ept id="p2">**</ept> and paste the Scala program (<bpt id="p3">**</bpt>SimpleApp.scala<ept id="p3">**</ept>) you created earlier under the \src\main\scala folder.</source>
          <target state="new">Under the <bpt id="p1">**</bpt>SimpleScalaApp<ept id="p1">**</ept> folder, create a directory structure <bpt id="p2">**</bpt>\src\main\scala<ept id="p2">**</ept> and paste the Scala program (<bpt id="p3">**</bpt>SimpleApp.scala<ept id="p3">**</ept>) you created earlier under the \src\main\scala folder.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>Open a command prompt, navigate to the SimpleScalaApp directory, and enter the following command:</source>
          <target state="new">Open a command prompt, navigate to the SimpleScalaApp directory, and enter the following command:</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>Run the job on the cluster</source>
          <target state="new">Run the job on the cluster</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>In this section, you remote into the cluster that has Spark installed and then copy the SimpleScalaApp project's target folder.</source>
          <target state="new">In this section, you remote into the cluster that has Spark installed and then copy the SimpleScalaApp project's target folder.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>You then use the <bpt id="p1">**</bpt>spark-submit<ept id="p1">**</ept> command to submit the job on the cluster.</source>
          <target state="new">You then use the <bpt id="p1">**</bpt>spark-submit<ept id="p1">**</ept> command to submit the job on the cluster.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>Remote into the cluster that has Spark installed.</source>
          <target state="new">Remote into the cluster that has Spark installed.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>From the computer where you wrote and built the SimpleApp.scala program, copy the <bpt id="p1">**</bpt>SimpleScalaApp\target<ept id="p1">**</ept> folder and paste it to a location on the cluster.</source>
          <target state="new">From the computer where you wrote and built the SimpleApp.scala program, copy the <bpt id="p1">**</bpt>SimpleScalaApp\target<ept id="p1">**</ept> folder and paste it to a location on the cluster.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>In the RDP session, from the desktop, open the Hadoop command line, and navigate to the location where you pasted the <bpt id="p1">**</bpt>target<ept id="p1">**</ept> folder.</source>
          <target state="new">In the RDP session, from the desktop, open the Hadoop command line, and navigate to the location where you pasted the <bpt id="p1">**</bpt>target<ept id="p1">**</ept> folder.</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Enter the following command to run the SimpleApp.scala program:</source>
          <target state="new">Enter the following command to run the SimpleApp.scala program:</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>When the program finishes running, the output is displayed on the console.</source>
          <target state="new">When the program finishes running, the output is displayed on the console.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="usingPS"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Install Spark on HDInsight Hadoop clusters by using Azure PowerShell</source>
          <target state="new"><ph id="ph1">&lt;a name="usingPS"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Install Spark on HDInsight Hadoop clusters by using Azure PowerShell</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>In this section, we use the <bpt id="p1">**</bpt><ph id="ph1">&lt;a href = "http://msdn.microsoft.com/library/dn858088.aspx" target="_blank"&gt;</ph>Add-AzureHDInsightScriptAction<ph id="ph2">&lt;/a&gt;</ph><ept id="p1">**</ept> cmdlet to invoke scripts by using Script Action to customize a cluster.</source>
          <target state="new">In this section, we use the <bpt id="p1">**</bpt><ph id="ph1">&lt;a href = "http://msdn.microsoft.com/library/dn858088.aspx" target="_blank"&gt;</ph>Add-AzureHDInsightScriptAction<ph id="ph2">&lt;/a&gt;</ph><ept id="p1">**</ept> cmdlet to invoke scripts by using Script Action to customize a cluster.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>Before proceeding, make sure you have installed and configured Azure PowerShell.</source>
          <target state="new">Before proceeding, make sure you have installed and configured Azure PowerShell.</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>For information on configuring a workstation to run Azure PowerShell cmdlets for HDInsight, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">][powershell-install-configure]</ept>.</source>
          <target state="new">For information on configuring a workstation to run Azure PowerShell cmdlets for HDInsight, see <bpt id="p1">[</bpt>Install and configure Azure PowerShell<ept id="p1">][powershell-install-configure]</ept>.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>Perform the following steps:</source>
          <target state="new">Perform the following steps:</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>Open an Azure PowerShell window and declare the following variables:</source>
          <target state="new">Open an Azure PowerShell window and declare the following variables:</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Specify the configuration values such as nodes in the cluster and the default storage to be used.</source>
          <target state="new">Specify the configuration values such as nodes in the cluster and the default storage to be used.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Use the <bpt id="p1">**</bpt>Add-AzureHDInsightScriptAction<ept id="p1">**</ept> cmdlet to add a script action to cluster configuration.</source>
          <target state="new">Use the <bpt id="p1">**</bpt>Add-AzureHDInsightScriptAction<ept id="p1">**</ept> cmdlet to add a script action to cluster configuration.</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>Later, when the cluster is being created, the script action gets executed.</source>
          <target state="new">Later, when the cluster is being created, the script action gets executed.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Add-AzureHDInsightScriptAction<ept id="p1">**</ept> cmdlet takes the following parameters:</source>
          <target state="new"><bpt id="p1">**</bpt>Add-AzureHDInsightScriptAction<ept id="p1">**</ept> cmdlet takes the following parameters:</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>Parameter</source>
          <target state="new">Parameter</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Definition</source>
          <target state="new">Definition</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Config</source>
          <target state="new">Config</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>The configuration object to which script action information is added.</source>
          <target state="new">The configuration object to which script action information is added.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="new">Name</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Name of the script action.</source>
          <target state="new">Name of the script action.</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>ClusterRoleCollection</source>
          <target state="new">ClusterRoleCollection</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Specifies the nodes on which the customization script is run.</source>
          <target state="new">Specifies the nodes on which the customization script is run.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>The valid values are HeadNode (to install on the head node) or DataNode (to install on all the data nodes).</source>
          <target state="new">The valid values are HeadNode (to install on the head node) or DataNode (to install on all the data nodes).</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>You can use either or both values.</source>
          <target state="new">You can use either or both values.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>Uri</source>
          <target state="new">Uri</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>Specifies the URI to the script that is executed.</source>
          <target state="new">Specifies the URI to the script that is executed.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Parameters</source>
          <target state="new">Parameters</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>Parameters required by the script.</source>
          <target state="new">Parameters required by the script.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>The sample script used in this topic does not require any parameters, and hence you do not see this parameter in the snippet above.</source>
          <target state="new">The sample script used in this topic does not require any parameters, and hence you do not see this parameter in the snippet above.</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Finally, start provisioning a customized cluster with Spark installed.</source>
          <target state="new">Finally, start provisioning a customized cluster with Spark installed.</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>When prompted, enter the credentials for the cluster.</source>
          <target state="new">When prompted, enter the credentials for the cluster.</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>It can take several minutes before the cluster is created.</source>
          <target state="new">It can take several minutes before the cluster is created.</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="usingSDK"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Install Spark on HDInsight Hadoop clusters by using the .NET SDK</source>
          <target state="new"><ph id="ph1">&lt;a name="usingSDK"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>Install Spark on HDInsight Hadoop clusters by using the .NET SDK</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>The HDInsight .NET SDK provides .NET client libraries that make it easier to work with HDInsight from a .NET Framework application.</source>
          <target state="new">The HDInsight .NET SDK provides .NET client libraries that make it easier to work with HDInsight from a .NET Framework application.</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>This section provides instructions on how to use Script Action from the SDK to provision a cluster that has Spark installed.</source>
          <target state="new">This section provides instructions on how to use Script Action from the SDK to provision a cluster that has Spark installed.</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>The following procedures must be performed:</source>
          <target state="new">The following procedures must be performed:</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Install the HDInsight .NET SDK</source>
          <target state="new">Install the HDInsight .NET SDK</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Create a self-signed certificate</source>
          <target state="new">Create a self-signed certificate</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>Create a console application</source>
          <target state="new">Create a console application</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Run the application</source>
          <target state="new">Run the application</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>To install the HDInsight .NET SDK</source>
          <target state="new">To install the HDInsight .NET SDK</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>You can install latest published build of the SDK from <bpt id="p1">[</bpt>NuGet<ept id="p1">](http://nuget.codeplex.com/wikipage?title=Getting%20Started)</ept>.</source>
          <target state="new">You can install latest published build of the SDK from <bpt id="p1">[</bpt>NuGet<ept id="p1">](http://nuget.codeplex.com/wikipage?title=Getting%20Started)</ept>.</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>The instructions will be shown in the next procedure.</source>
          <target state="new">The instructions will be shown in the next procedure.</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>To create a self-signed certificate</source>
          <target state="new">To create a self-signed certificate</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Create a self-signed certificate, install it on your workstation, and upload it to your Azure subscription.</source>
          <target state="new">Create a self-signed certificate, install it on your workstation, and upload it to your Azure subscription.</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>For instructions, see <bpt id="p1">[</bpt>Create a self-signed certificate<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=511138)</ept>.</source>
          <target state="new">For instructions, see <bpt id="p1">[</bpt>Create a self-signed certificate<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=511138)</ept>.</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>To create a Visual Studio application</source>
          <target state="new">To create a Visual Studio application</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>Open Visual Studio 2013.</source>
          <target state="new">Open Visual Studio 2013.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p1">**</bpt>File<ept id="p1">**</ept> menu, click <bpt id="p2">**</bpt>New<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Project<ept id="p3">**</ept>.</source>
          <target state="new">From the <bpt id="p1">**</bpt>File<ept id="p1">**</ept> menu, click <bpt id="p2">**</bpt>New<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Project<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>From <bpt id="p1">**</bpt>New Project<ept id="p1">**</ept>, type or select the following values:</source>
          <target state="new">From <bpt id="p1">**</bpt>New Project<ept id="p1">**</ept>, type or select the following values:</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Property</source>
          <target state="new">Property</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Value</source>
          <target state="new">Value</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>Category</source>
          <target state="new">Category</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>Templates/Visual C#/Windows</source>
          <target state="new">Templates/Visual C#/Windows</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Template</source>
          <target state="new">Template</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>Console Application</source>
          <target state="new">Console Application</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>Name</source>
          <target state="new">Name</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>CreateSparkCluster</source>
          <target state="new">CreateSparkCluster</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>Click <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> to create the project.</source>
          <target state="new">Click <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> to create the project.</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p1">**</bpt>Tools<ept id="p1">**</ept> menu, click <bpt id="p2">**</bpt>Nuget Package Manager<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Package Manager Console<ept id="p3">**</ept>.</source>
          <target state="new">From the <bpt id="p1">**</bpt>Tools<ept id="p1">**</ept> menu, click <bpt id="p2">**</bpt>Nuget Package Manager<ept id="p2">**</ept>, and then click <bpt id="p3">**</bpt>Package Manager Console<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>Run the following command in the console to install the package:</source>
          <target state="new">Run the following command in the console to install the package:</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>This command adds the .NET libraries and references to them from the current Visual Studio project.</source>
          <target state="new">This command adds the .NET libraries and references to them from the current Visual Studio project.</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>From Solution Explorer, double-click <bpt id="p1">**</bpt>Program.cs<ept id="p1">**</ept> to open it.</source>
          <target state="new">From Solution Explorer, double-click <bpt id="p1">**</bpt>Program.cs<ept id="p1">**</ept> to open it.</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>Add the following using statements to the top of the file:</source>
          <target state="new">Add the following using statements to the top of the file:</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>In the Main() function, copy and paste the following code, and provide values for the variables:</source>
          <target state="new">In the Main() function, copy and paste the following code, and provide values for the variables:</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>Append the following code to the Main() function to use the <bpt id="p1">[</bpt>ScriptAction<ept id="p1">](http://msdn.microsoft.com/library/microsoft.windowsazure.management.hdinsight.clusterprovisioning.data.scriptaction.aspx)</ept> class to invoke a custom script to install Spark.</source>
          <target state="new">Append the following code to the Main() function to use the <bpt id="p1">[</bpt>ScriptAction<ept id="p1">](http://msdn.microsoft.com/library/microsoft.windowsazure.management.hdinsight.clusterprovisioning.data.scriptaction.aspx)</ept> class to invoke a custom script to install Spark.</target>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve">
          <source>Finally, create the cluster.</source>
          <target state="new">Finally, create the cluster.</target>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>Save changes to the application and build the solution.</source>
          <target state="new">Save changes to the application and build the solution.</target>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>To run the application</source>
          <target state="new">To run the application</target>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve">
          <source>Open an Azure PowerShell console, navigate to the location where you saved the Visual Studio project, navigate to the \bin\debug directory within the project, and then run the following command:</source>
          <target state="new">Open an Azure PowerShell console, navigate to the location where you saved the Visual Studio project, navigate to the \bin\debug directory within the project, and then run the following command:</target>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve">
          <source>Provide a cluster name and press ENTER to provision a cluster with Spark installed.</source>
          <target state="new">Provide a cluster name and press ENTER to provision a cluster with Spark installed.</target>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve">
          <source>See also</source>
          <target state="new">See also</target>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Install R on HDInsight clusters<ept id="p1">][hdinsight-install-r]</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</source>
          <target state="new"><bpt id="p1">[</bpt>Install R on HDInsight clusters<ept id="p1">][hdinsight-install-r]</ept> provides instructions on how to use cluster customization to install and use R on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve">
          <source>R is an open-source language and environment for statistical computing.</source>
          <target state="new">R is an open-source language and environment for statistical computing.</target>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve">
          <source>It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</source>
          <target state="new">It provides hundreds of built-in statistical functions and its own programming language that combines aspects of functional and object-oriented programming.</target>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve">
          <source>It also provides extensive graphical capabilities.</source>
          <target state="new">It also provides extensive graphical capabilities.</target>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Install Giraph on HDInsight clusters<ept id="p1">](hdinsight-hadoop-giraph-install.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Install Giraph on HDInsight clusters<ept id="p1">](hdinsight-hadoop-giraph-install.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve">
          <source>Use cluster customization to install Giraph on HDInsight Hadoop clusters.</source>
          <target state="new">Use cluster customization to install Giraph on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve">
          <source>Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</source>
          <target state="new">Giraph allows you to perform graph processing by using Hadoop, and can be used with Azure HDInsight.</target>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Install Solr on HDInsight clusters<ept id="p1">](hdinsight-hadoop-solr-install.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Install Solr on HDInsight clusters<ept id="p1">](hdinsight-hadoop-solr-install.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>Use cluster customization to install Solr on HDInsight Hadoop clusters.</source>
          <target state="new">Use cluster customization to install Solr on HDInsight Hadoop clusters.</target>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve">
          <source>Solr allows you to perform powerful search operations on data stored.</source>
          <target state="new">Solr allows you to perform powerful search operations on data stored.</target>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9395de5689d1d54aa49b09c71d70e682c45c907d</xliffext:olfilehash>
  </header>
</xliff>