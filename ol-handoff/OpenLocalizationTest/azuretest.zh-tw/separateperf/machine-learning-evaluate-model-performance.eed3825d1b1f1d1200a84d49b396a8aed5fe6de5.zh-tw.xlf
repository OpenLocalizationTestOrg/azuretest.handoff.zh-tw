<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Evaluate model performance in Machine Learning | Microsoft Azure</source>
          <target state="new">Evaluate model performance in Machine Learning | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Explains how to evaluate model performance in Azure Machine Learning.</source>
          <target state="new">Explains how to evaluate model performance in Azure Machine Learning.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>How to evaluate model performance in Azure Machine Learning</source>
          <target state="new">How to evaluate model performance in Azure Machine Learning</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This topic demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</source>
          <target state="new">This topic demonstrates how to evaluate the performance of a model in Azure Machine Learning Studio and provides a brief explanation of the metrics available for this task.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Three common supervised learning scenarios are presented:</source>
          <target state="new">Three common supervised learning scenarios are presented:</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>regression</source>
          <target state="new">regression</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>binary classification</source>
          <target state="new">binary classification</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>multiclass classification</source>
          <target state="new">multiclass classification</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Evaluating the performance of a model is one of the core stages in the data science process.</source>
          <target state="new">Evaluating the performance of a model is one of the core stages in the data science process.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</source>
          <target state="new">It indicates how successful the scoring (predictions) of a dataset has been by a trained model.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</source>
          <target state="new">Azure Machine Learning supports model evaluation through two of its main machine learning modules: [Evaluate Model][evaluate-model] and [Cross-Validate Model][cross-validate-model].</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</source>
          <target state="new">These modules allow you to see how your model performs in terms of a number of metrics that are commonly used in machine learning and statistics.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Evaluation vs. Cross Validation</source>
          <target state="new">Evaluation vs. Cross Validation</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Evaluation and cross validation are standard ways to measure the performance of your model.</source>
          <target state="new">Evaluation and cross validation are standard ways to measure the performance of your model.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>They both generate evaluation metrics that you can inspect or compare against those of other models.</source>
          <target state="new">They both generate evaluation metrics that you can inspect or compare against those of other models.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</source>
          <target state="new">[Evaluate Model][evaluate-model] expects a scored dataset as input (or 2 in case you would like to compare the performance of 2 different models).</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</source>
          <target state="new">This means that you need to train your model using the [Train Model][train-model] module and make predictions on some dataset using the [Score Model][score-model] module, before you can evaluate the results.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The evaluation is the based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</source>
          <target state="new">The evaluation is the based on the scored labels/probabilities along with the true labels, all of which are output by the [Score Model][score-model] module.</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</source>
          <target state="new">Alternatively, you can use cross validation to perform a number of train-score-evaluate operations (10 folds) automatically on different subsets of the input data.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</source>
          <target state="new">The input data is split into 10 parts, where one is reserved for testing, and the other 9 for training.</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>This process is repeated 10 times and the evaluation metrics are averaged.</source>
          <target state="new">This process is repeated 10 times and the evaluation metrics are averaged.</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This helps in determining how well a model would generalize to new datasets.</source>
          <target state="new">This helps in determining how well a model would generalize to new datasets.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</source>
          <target state="new">The [Cross-Validate Model][cross-validate-model] module takes in an untrained model and some labeled dataset and outputs the evaluation results of each of the 10 folds, in addition to the averaged results.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</source>
          <target state="new">In the following sections, we will build simple regression and classification models and evaluate their performance, using both the [Evaluate Model][evaluate-model] and the [Cross-Validate Model][cross-validate-model] modules.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Evaluating a Regression Model</source>
          <target state="new">Evaluating a Regression Model</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</source>
          <target state="new">Assume we want to predict a car’s price using some features such as dimensions, horsepower, engine specs, and so on.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>This is a typical regression problem, where the target variable (<bpt id="p1">*</bpt>price<ept id="p1">*</ept>) is a continuous numeric value.</source>
          <target state="new">This is a typical regression problem, where the target variable (<bpt id="p1">*</bpt>price<ept id="p1">*</ept>) is a continuous numeric value.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</source>
          <target state="new">We can fit a simple linear regression model that, given the feature values of a certain car, can predict the price of that car.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>This regression model can be used to score the same dataset we trained on.</source>
          <target state="new">This regression model can be used to score the same dataset we trained on.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</source>
          <target state="new">Once we have the predicted prices for all of the cars, we can evaluate the performance of the model by looking at how much the predictions deviate from the actual prices on average.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>To illustrate this, we use the <bpt id="p1">*</bpt>Automobile price data (Raw) dataset<ept id="p1">*</ept> available in the <bpt id="p2">**</bpt>Saved Datasets<ept id="p2">**</ept> section in Azure Machine Learning Studio.</source>
          <target state="new">To illustrate this, we use the <bpt id="p1">*</bpt>Automobile price data (Raw) dataset<ept id="p1">*</ept> available in the <bpt id="p2">**</bpt>Saved Datasets<ept id="p2">**</ept> section in Azure Machine Learning Studio.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Creating the Experiment</source>
          <target state="new">Creating the Experiment</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Add the following modules to your workspace in Azure Machine Learning Studio:</source>
          <target state="new">Add the following modules to your workspace in Azure Machine Learning Studio:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Automobile price data (Raw)</source>
          <target state="new">Automobile price data (Raw)</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>[Linear Regression][linear-regression]</source>
          <target state="new">[Linear Regression][linear-regression]</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>[Train Model][train-model]</source>
          <target state="new">[Train Model][train-model]</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>[Score Model][score-model]</source>
          <target state="new">[Score Model][score-model]</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>[Evaluate Model][evaluate-model]</source>
          <target state="new">[Evaluate Model][evaluate-model]</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to <bpt id="p1">*</bpt>price<ept id="p1">*</ept>.</source>
          <target state="new">Connect the ports as shown below in Figure 1 and set the Label column of the [Train Model][train-model] module to <bpt id="p1">*</bpt>price<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Evaluating a Regression Model</source>
          <target state="new">Evaluating a Regression Model</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Figure 1.</source>
          <target state="new">Figure 1.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Evaluating a Regression Model.</source>
          <target state="new">Evaluating a Regression Model.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Inspecting the Evaluation Results</source>
          <target state="new">Inspecting the Evaluation Results</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select <bpt id="p1">*</bpt>Visualize<ept id="p1">*</ept> to see the evaluation results.</source>
          <target state="new">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select <bpt id="p1">*</bpt>Visualize<ept id="p1">*</ept> to see the evaluation results.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The evaluation metrics available for regression models are: <bpt id="p1">*</bpt>Mean Absolute Error<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Root Mean Absolute Error<ept id="p2">*</ept>, <bpt id="p3">*</bpt>Relative Absolute Error<ept id="p3">*</ept>, <bpt id="p4">*</bpt>Relative Squared Error<ept id="p4">*</ept>, and the <bpt id="p5">*</bpt>Coefficient of Determination<ept id="p5">*</ept>.</source>
          <target state="new">The evaluation metrics available for regression models are: <bpt id="p1">*</bpt>Mean Absolute Error<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Root Mean Absolute Error<ept id="p2">*</ept>, <bpt id="p3">*</bpt>Relative Absolute Error<ept id="p3">*</ept>, <bpt id="p4">*</bpt>Relative Squared Error<ept id="p4">*</ept>, and the <bpt id="p5">*</bpt>Coefficient of Determination<ept id="p5">*</ept>.</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The term "error" here represents the difference between the predicted value and the true value.</source>
          <target state="new">The term "error" here represents the difference between the predicted value and the true value.</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</source>
          <target state="new">The absolute value or the square of this difference are usually computed to capture the total magnitude of error across all instances, as the difference between the predicted and true value could be negative in some cases.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</source>
          <target state="new">The error metrics measure the predictive performance of a regression model in terms of the mean deviation of its predictions from the true values.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Lower error values mean the model is more accurate in making predictions.</source>
          <target state="new">Lower error values mean the model is more accurate in making predictions.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>An overall error metric of 0 means that the model fits the data perfectly.</source>
          <target state="new">An overall error metric of 0 means that the model fits the data perfectly.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</source>
          <target state="new">The coefficient of determination, which is also known as R squared, is also a standard way of measuring how well the model fits the data.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>It can be interpreted as the proportion of variation explained by the model.</source>
          <target state="new">It can be interpreted as the proportion of variation explained by the model.</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>A higher proportion is better in this case, where 1 indicates a perfect fit.</source>
          <target state="new">A higher proportion is better in this case, where 1 indicates a perfect fit.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Linear Regression Evaluation Metrics</source>
          <target state="new">Linear Regression Evaluation Metrics</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Figure 2.</source>
          <target state="new">Figure 2.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>Linear Regression Evaluation Metrics.</source>
          <target state="new">Linear Regression Evaluation Metrics.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Using Cross Validation</source>
          <target state="new">Using Cross Validation</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</source>
          <target state="new">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</source>
          <target state="new">All you need in this case is a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Note that you need to set the label column to <bpt id="p1">*</bpt>price<ept id="p1">*</ept> in the [Cross-Validate Model][cross-validate-model] module’s properties.</source>
          <target state="new">Note that you need to set the label column to <bpt id="p1">*</bpt>price<ept id="p1">*</ept> in the [Cross-Validate Model][cross-validate-model] module’s properties.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Regression Model</source>
          <target state="new">Cross-Validating a Regression Model</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Figure 3.</source>
          <target state="new">Figure 3.</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Regression Model.</source>
          <target state="new">Cross-Validating a Regression Model.</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</source>
          <target state="new">After running the experiment, you can inspect the evaluation results by clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module.</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</source>
          <target state="new">This will provide a detailed view of the metrics for each iteration (fold), and the averaged results of each of the metrics (Figure 4).</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Regression Model</source>
          <target state="new">Cross-Validation Results of a Regression Model</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Figure 4.</source>
          <target state="new">Figure 4.</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Regression Model.</source>
          <target state="new">Cross-Validation Results of a Regression Model.</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Evaluating a Binary Classification Model</source>
          <target state="new">Evaluating a Binary Classification Model</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</source>
          <target state="new">In a binary classification scenario, the target variable has only two possible outcomes, for example: {0, 1} or {false, true}, {negative, positive}.</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“&lt;=50K”, “&gt;50K”}.</source>
          <target state="new">Assume you are given a dataset of adult employees with some demographic and employment variables, and that you are asked to predict the income level, a binary variable with the values {“&lt;=50K”, “&gt;50K”}.</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</source>
          <target state="new">In other words, the negative class represents the employees who make less than or equal to 50K per year, and the positive class represents all other employees.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>As in the regression scenario, we would train a model, score some data, and evaluate the results.</source>
          <target state="new">As in the regression scenario, we would train a model, score some data, and evaluate the results.</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</source>
          <target state="new">The main difference here is the choice of metrics Azure Machine Learning computes and outputs.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>To illustrate the income level prediction scenario, we will use the <bpt id="p1">[</bpt>Adult<ept id="p1">](http://archive.ics.uci.edu/ml/datasets/Adult)</ept> dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</source>
          <target state="new">To illustrate the income level prediction scenario, we will use the <bpt id="p1">[</bpt>Adult<ept id="p1">](http://archive.ics.uci.edu/ml/datasets/Adult)</ept> dataset to create an Azure Machine Learning experiment and evaluate the performance of a two-class logistic regression model, a commonly used binary classifier.</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Creating the Experiment</source>
          <target state="new">Creating the Experiment</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>Add the following modules to your workspace in Azure Machine Learning Studio:</source>
          <target state="new">Add the following modules to your workspace in Azure Machine Learning Studio:</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Adult Census Income Binary Classification dataset</source>
          <target state="new">Adult Census Income Binary Classification dataset</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>[Two-Class Logistic Regression][two-class-logistic-regression]</source>
          <target state="new">[Two-Class Logistic Regression][two-class-logistic-regression]</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>[Train Model][train-model]</source>
          <target state="new">[Train Model][train-model]</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>[Score Model][score-model]</source>
          <target state="new">[Score Model][score-model]</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>[Evaluate Model][evaluate-model]</source>
          <target state="new">[Evaluate Model][evaluate-model]</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to <bpt id="p1">*</bpt>income<ept id="p1">*</ept>.</source>
          <target state="new">Connect the ports as shown below in Figure 5 and set the Label column of the [Train Model][train-model] module to <bpt id="p1">*</bpt>income<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Evaluating a Binary Classification Model</source>
          <target state="new">Evaluating a Binary Classification Model</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Figure 5.</source>
          <target state="new">Figure 5.</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>Evaluating a Binary Classification Model.</source>
          <target state="new">Evaluating a Binary Classification Model.</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>Inspecting the Evaluation Results</source>
          <target state="new">Inspecting the Evaluation Results</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select <bpt id="p1">*</bpt>Visualize<ept id="p1">*</ept> to see the evaluation results (Figure 7).</source>
          <target state="new">After running the experiment, you can click on the output port of the [Evaluate Model][evaluate-model] module and select <bpt id="p1">*</bpt>Visualize<ept id="p1">*</ept> to see the evaluation results (Figure 7).</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The evaluation metrics available for binary classification models are: <bpt id="p1">*</bpt>Accuracy<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Precision<ept id="p2">*</ept>, <bpt id="p3">*</bpt>Recall<ept id="p3">*</ept>, <bpt id="p4">*</bpt>F1 Score<ept id="p4">*</ept>, and <bpt id="p5">*</bpt>AUC<ept id="p5">*</ept>.</source>
          <target state="new">The evaluation metrics available for binary classification models are: <bpt id="p1">*</bpt>Accuracy<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Precision<ept id="p2">*</ept>, <bpt id="p3">*</bpt>Recall<ept id="p3">*</ept>, <bpt id="p4">*</bpt>F1 Score<ept id="p4">*</ept>, and <bpt id="p5">*</bpt>AUC<ept id="p5">*</ept>.</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as <bpt id="p1">*</bpt>ROC<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Precision/Recall<ept id="p2">*</ept>, and <bpt id="p3">*</bpt>Lift<ept id="p3">*</ept> curves.</source>
          <target state="new">In addition, the module outputs a confusion matrix showing the number of true positives, false negatives, false positives, and true negatives, as well as <bpt id="p1">*</bpt>ROC<ept id="p1">*</ept>, <bpt id="p2">*</bpt>Precision/Recall<ept id="p2">*</ept>, and <bpt id="p3">*</bpt>Lift<ept id="p3">*</ept> curves.</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Accuracy is simply the proportion of correctly classified instances.</source>
          <target state="new">Accuracy is simply the proportion of correctly classified instances.</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>It is usually the first metric you look at when evaluating a classifier.</source>
          <target state="new">It is usually the first metric you look at when evaluating a classifier.</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</source>
          <target state="new">However, when the test data is unbalanced (where most of the instances belong to one of the classes), or you are more interested in the performance on either one of the classes, accuracy doesn’t really capture the effectiveness of a classifier.</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</source>
          <target state="new">In the income level classification scenario, assume you are testing on some data where 99% of the instances represent people who earn less than or equal to 50K per year.</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>It is possible to achieve a 0.99 accuracy by predicting the class “&lt;=50K” for all instances.</source>
          <target state="new">It is possible to achieve a 0.99 accuracy by predicting the class “&lt;=50K” for all instances.</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source>The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</source>
          <target state="new">The classifier in this case appears to be doing a good job overall, but in reality, it fails to classify any of the high-income individuals (the 1%) correctly.</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</source>
          <target state="new">For that reason, it is helpful to compute additional metrics that capture more specific aspects of the evaluation.</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</source>
          <target state="new">Before going into the details of such metrics, it is important to understand the confusion matrix of a binary classification evaluation.</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</source>
          <target state="new">The class labels in the training set can take on only 2 possible values, which we usually refer to as positive or negative.</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</source>
          <target state="new">The positive and negative instances that a classifier predicts correctly are called true positives (TP) and true negatives (TN), respectively.</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</source>
          <target state="new">Similarly, the incorrectly classified instances are called false positives (FP) and false negatives (FN).</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</source>
          <target state="new">The confusion matrix is simply a table showing the number of instances that fall under each of these 4 categories.</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</source>
          <target state="new">Azure Machine Learning automatically decides which of the two classes in the dataset is the positive class.</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</source>
          <target state="new">If the class labels are Boolean or integers, then the ‘true’ or ‘1’ labeled instances are assigned the positive class.</target>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</source>
          <target state="new">If the labels are strings, as in the case of the income dataset, the labels are sorted alphabetically and the first level is chosen to be the negative class while the second level is the positive class.</target>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>Binary Classification Confusion Matrix</source>
          <target state="new">Binary Classification Confusion Matrix</target>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Figure 6.</source>
          <target state="new">Figure 6.</target>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve">
          <source>Binary Classification Confusion Matrix.</source>
          <target state="new">Binary Classification Confusion Matrix.</target>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve">
          <source>Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</source>
          <target state="new">Going back to the income classification problem, we would want to ask several evaluation questions that help us understand the performance of the classifier used.</target>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve">
          <source>A very natural question is: ‘Out of the individuals whom the model predicted to be earning &gt;50K (TP+FP), how many were classified correctly (TP)?’</source>
          <target state="new">A very natural question is: ‘Out of the individuals whom the model predicted to be earning &gt;50K (TP+FP), how many were classified correctly (TP)?’</target>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve">
          <source>This question can be answered by looking at the <bpt id="p1">**</bpt>Precision<ept id="p1">**</ept> of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</source>
          <target state="new">This question can be answered by looking at the <bpt id="p1">**</bpt>Precision<ept id="p1">**</ept> of the model, which is the proportion of positives that are classified correctly: TP/(TP+FP).</target>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve">
          <source>Another common question is “Out of all the high earning employees with income &gt;50k (TP+FN), how many did the classifier classify correctly (TP)”.</source>
          <target state="new">Another common question is “Out of all the high earning employees with income &gt;50k (TP+FN), how many did the classifier classify correctly (TP)”.</target>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve">
          <source>This is actually the <bpt id="p1">**</bpt>Recall<ept id="p1">**</ept>, or the true positive rate: TP/(TP+FN) of the classifier.</source>
          <target state="new">This is actually the <bpt id="p1">**</bpt>Recall<ept id="p1">**</ept>, or the true positive rate: TP/(TP+FN) of the classifier.</target>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve">
          <source>You might notice that there is an obvious trade-off between precision and recall.</source>
          <target state="new">You might notice that there is an obvious trade-off between precision and recall.</target>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve">
          <source>For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</source>
          <target state="new">For example, given a relatively balanced dataset, a classifier that predicts mostly positive instances, would have a high recall, but a rather low precision as many of the negative instances would be misclassified resulting in a large number of false positives.</target>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</source>
          <target state="new">To see a plot of how these two metrics vary, you can click on the ‘PRECISION/RECALL’ curve in the evaluation result output page (top left part of Figure 7).</target>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve">
          <source>Binary Classification Evaluation Results</source>
          <target state="new">Binary Classification Evaluation Results</target>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve">
          <source>Figure 7.</source>
          <target state="new">Figure 7.</target>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve">
          <source>Binary Classification Evaluation Results.</source>
          <target state="new">Binary Classification Evaluation Results.</target>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve">
          <source>Another related metric that is often used is the <bpt id="p1">**</bpt>F1 Score<ept id="p1">**</ept>, which takes both precision and recall into consideration.</source>
          <target state="new">Another related metric that is often used is the <bpt id="p1">**</bpt>F1 Score<ept id="p1">**</ept>, which takes both precision and recall into consideration.</target>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source>It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</source>
          <target state="new">It is the harmonic mean of these 2 metrics and is computed as such: F1 = 2 (precision x recall) / (precision + recall).</target>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</source>
          <target state="new">The F1 score is a good way to summarize the evaluation in a single number, but it’s always a good practice to look at both precision and recall together to better understand how a classifier behaves.</target>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve">
          <source>In addition, one can inspect the true positive rate vs. the false positive rate in the <bpt id="p1">**</bpt>Receiver Operating Characteristic (ROC)<ept id="p1">**</ept> curve and the corresponding <bpt id="p2">**</bpt>Area Under the Curve (AUC)<ept id="p2">**</ept> value.</source>
          <target state="new">In addition, one can inspect the true positive rate vs. the false positive rate in the <bpt id="p1">**</bpt>Receiver Operating Characteristic (ROC)<ept id="p1">**</ept> curve and the corresponding <bpt id="p2">**</bpt>Area Under the Curve (AUC)<ept id="p2">**</ept> value.</target>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</source>
          <target state="new">The closer this curve is to the upper left corner, the better the classifier’s performance is (that is maximizing the true positive rate while minimizing the false positive rate).</target>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</source>
          <target state="new">Curves that are close to the diagonal of the plot, result from classifiers that tend to make predictions that are close to random guessing.</target>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve">
          <source>Using Cross Validation</source>
          <target state="new">Using Cross Validation</target>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve">
          <source>As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</source>
          <target state="new">As in the regression example, we can perform cross validation to repeatedly train, score and evaluate different subsets of the data automatically.</target>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve">
          <source>Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</source>
          <target state="new">Similarly, we can use the [Cross-Validate Model][cross-validate-model] module, an untrained logistic regression model, and a dataset.</target>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>The label column must be set to <bpt id="p1">*</bpt>income<ept id="p1">*</ept> in the [Cross-Validate Model][cross-validate-model] module’s properties.</source>
          <target state="new">The label column must be set to <bpt id="p1">*</bpt>income<ept id="p1">*</ept> in the [Cross-Validate Model][cross-validate-model] module’s properties.</target>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</source>
          <target state="new">After running the experiment and clicking on the right output port of the [Cross-Validate Model][cross-validate-model] module, we can see the binary classification metric values for each fold, in addition to the mean and standard deviation of each.</target>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Binary Classification Model</source>
          <target state="new">Cross-Validating a Binary Classification Model</target>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve">
          <source>Figure 8.</source>
          <target state="new">Figure 8.</target>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Binary Classification Model.</source>
          <target state="new">Cross-Validating a Binary Classification Model.</target>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Binary Classifier</source>
          <target state="new">Cross-Validation Results of a Binary Classifier</target>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>Figure 9.</source>
          <target state="new">Figure 9.</target>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Binary Classifier.</source>
          <target state="new">Cross-Validation Results of a Binary Classifier.</target>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve">
          <source>Evaluating a Multiclass Classification Model</source>
          <target state="new">Evaluating a Multiclass Classification Model</target>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve">
          <source>In this experiment we will use the popular <bpt id="p1">[</bpt>Iris<ept id="p1">](http://archive.ics.uci.edu/ml/datasets/Iris "Iris")</ept> dataset which contains instances of 3 different types (classes) of the iris plant.</source>
          <target state="new">In this experiment we will use the popular <bpt id="p1">[</bpt>Iris<ept id="p1">](http://archive.ics.uci.edu/ml/datasets/Iris "Iris")</ept> dataset which contains instances of 3 different types (classes) of the iris plant.</target>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve">
          <source>There are 4 feature values (sepal length/width and petal length/width) for each instance.</source>
          <target state="new">There are 4 feature values (sepal length/width and petal length/width) for each instance.</target>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve">
          <source>In the previous experiments we trained and tested the models using the same datasets.</source>
          <target state="new">In the previous experiments we trained and tested the models using the same datasets.</target>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve">
          <source>Here, we will use the [Split][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</source>
          <target state="new">Here, we will use the [Split][split] module to create 2 subsets of the data, train on the first, and score and evaluate on the second.</target>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve">
          <source>The Iris dataset is publicly available on the <bpt id="p1">[</bpt>UCI Machine Learning Repository<ept id="p1">](http://archive.ics.uci.edu/ml/index.html)</ept>, and can be downloaded using a [Reader][reader] module.</source>
          <target state="new">The Iris dataset is publicly available on the <bpt id="p1">[</bpt>UCI Machine Learning Repository<ept id="p1">](http://archive.ics.uci.edu/ml/index.html)</ept>, and can be downloaded using a [Reader][reader] module.</target>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve">
          <source>Creating the Experiment</source>
          <target state="new">Creating the Experiment</target>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve">
          <source>Add the following modules to your workspace in Azure Machine Learning Studio:</source>
          <target state="new">Add the following modules to your workspace in Azure Machine Learning Studio:</target>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>[Reader][reader]</source>
          <target state="new">[Reader][reader]</target>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve">
          <source>[Multiclass Decision Forest][multiclass-decision-forest]</source>
          <target state="new">[Multiclass Decision Forest][multiclass-decision-forest]</target>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve">
          <source>[Split][split]</source>
          <target state="new">[Split][split]</target>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>[Train Model][train-model]</source>
          <target state="new">[Train Model][train-model]</target>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>[Score Model][score-model]</source>
          <target state="new">[Score Model][score-model]</target>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve">
          <source>[Evaluate Model][evaluate-model]</source>
          <target state="new">[Evaluate Model][evaluate-model]</target>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve">
          <source>Connect the ports as shown below in Figure 10.</source>
          <target state="new">Connect the ports as shown below in Figure 10.</target>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve">
          <source>Set the Label column index of the [Train Model][train-model] module to 5.</source>
          <target state="new">Set the Label column index of the [Train Model][train-model] module to 5.</target>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve">
          <source>The dataset has no header row but we know that the class labels are in the fifth column.</source>
          <target state="new">The dataset has no header row but we know that the class labels are in the fifth column.</target>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve">
          <source>Click on the [Reader][reader] module and set the <bpt id="p1">*</bpt>Data source<ept id="p1">*</ept> property to <bpt id="p2">*</bpt>Web URL via HTTP<ept id="p2">*</ept>, and the <bpt id="p3">*</bpt>URL<ept id="p3">*</ept> to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</source>
          <target state="new">Click on the [Reader][reader] module and set the <bpt id="p1">*</bpt>Data source<ept id="p1">*</ept> property to <bpt id="p2">*</bpt>Web URL via HTTP<ept id="p2">*</ept>, and the <bpt id="p3">*</bpt>URL<ept id="p3">*</ept> to http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.</target>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve">
          <source>Set the fraction of instances to be used for training in the [Split][split] module (0.7 for example).</source>
          <target state="new">Set the fraction of instances to be used for training in the [Split][split] module (0.7 for example).</target>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source>Evaluating a Multiclass Classifier</source>
          <target state="new">Evaluating a Multiclass Classifier</target>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Figure 10.</source>
          <target state="new">Figure 10.</target>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve">
          <source>Evaluating a Multiclass Classifier</source>
          <target state="new">Evaluating a Multiclass Classifier</target>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve">
          <source>Inspecting the Evaluation Results</source>
          <target state="new">Inspecting the Evaluation Results</target>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve">
          <source>Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</source>
          <target state="new">Run the experiment and click on the output port of [Evaluate Model][evaluate-model].</target>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve">
          <source>The evaluation results are presented in the form of a confusion matrix, in this case.</source>
          <target state="new">The evaluation results are presented in the form of a confusion matrix, in this case.</target>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>The matrix shows the actual vs. predicted instances for all 3 classes.</source>
          <target state="new">The matrix shows the actual vs. predicted instances for all 3 classes.</target>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Multiclass Classification Evaluation Results</source>
          <target state="new">Multiclass Classification Evaluation Results</target>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve">
          <source>Figure 11.</source>
          <target state="new">Figure 11.</target>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Multiclass Classification Evaluation Results.</source>
          <target state="new">Multiclass Classification Evaluation Results.</target>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Using Cross Validation</source>
          <target state="new">Using Cross Validation</target>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve">
          <source>As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</source>
          <target state="new">As mentioned earlier, you can perform repeated training, scoring and evaluations automatically using the [Cross-Validate Model][cross-validate-model] module.</target>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve">
          <source>You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</source>
          <target state="new">You would need a dataset, an untrained model, and a [Cross-Validate Model][cross-validate-model] module (see figure below).</target>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve">
          <source>Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</source>
          <target state="new">Again you need to set the label column of the [Cross-Validate Model][cross-validate-model] module (column index 5 in this case).</target>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve">
          <source>After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</source>
          <target state="new">After running the experiment and clicking the right output port of the [Cross-Validate Model][cross-validate-model], you can inspect the metric values for each fold as well as the mean and standard deviation.</target>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve">
          <source>The metrics displayed here are the similar to the ones discussed in the binary classification case.</source>
          <target state="new">The metrics displayed here are the similar to the ones discussed in the binary classification case.</target>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve">
          <source>However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</source>
          <target state="new">However, note that in multiclass classification, computing the true positives/negatives and false positives/negatives is done by counting on a per-class basis, as there is no overall positive or negative class.</target>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve">
          <source>For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</source>
          <target state="new">For example, when computing the precision or recall of the ‘Iris-setosa’ class, it is assumed that this is the positive class and all others as negative.</target>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Multiclass Classification Model</source>
          <target state="new">Cross-Validating a Multiclass Classification Model</target>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve">
          <source>Figure 12.</source>
          <target state="new">Figure 12.</target>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve">
          <source>Cross-Validating a Multiclass Classification Model.</source>
          <target state="new">Cross-Validating a Multiclass Classification Model.</target>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Multiclass Classification Model</source>
          <target state="new">Cross-Validation Results of a Multiclass Classification Model</target>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>Figure 13.</source>
          <target state="new">Figure 13.</target>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Cross-Validation Results of a Multiclass Classification Model.</source>
          <target state="new">Cross-Validation Results of a Multiclass Classification Model.</target>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9f98cfe438ab35fef302b22a12b0d64058534811</xliffext:olfilehash>
  </header>
</xliff>