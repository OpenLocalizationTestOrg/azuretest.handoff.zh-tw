<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Optimize your Hive queries for faster execution in HDInsight | Microsoft Azure</source>
          <target state="new">Optimize your Hive queries for faster execution in HDInsight | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to optimize your Hive queries for Hadoop in HDInsight.</source>
          <target state="new">Learn how to optimize your Hive queries for Hadoop in HDInsight.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Optimize Hive queries for Hadoop in HDInsight</source>
          <target state="new">Optimize Hive queries for Hadoop in HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>By default, Hadoop clusters are not optimized for performance.</source>
          <target state="new">By default, Hadoop clusters are not optimized for performance.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>This article covers a few of the most common Hive performance optimization methods that you can apply to our queries.</source>
          <target state="new">This article covers a few of the most common Hive performance optimization methods that you can apply to our queries.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Optimize Hive queries for Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-optimize-hive-query-v1.md)</ept>.</source>
          <target state="new"><bpt id="p1">[</bpt>Optimize Hive queries for Hadoop in HDInsight<ept id="p1">](hdinsight-hadoop-optimize-hive-query-v1.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Scale out worker nodes</source>
          <target state="new">Scale out worker nodes</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Increasing the number of worker nodes in a cluster can leverage more mappers and reducers to be run in parallel.</source>
          <target state="new">Increasing the number of worker nodes in a cluster can leverage more mappers and reducers to be run in parallel.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>There are two ways you can increase scale out in HDInsight:</source>
          <target state="new">There are two ways you can increase scale out in HDInsight:</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>At the provision time, you can specify the number of worker nodes using the Azure preview portal, Azure PowerShell or Cross-platform command line interface.</source>
          <target state="new">At the provision time, you can specify the number of worker nodes using the Azure preview portal, Azure PowerShell or Cross-platform command line interface.</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">](hdinsight-provision-clusters.md)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Provision HDInsight clusters<ept id="p1">](hdinsight-provision-clusters.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The following screen show the worker node configuration on the Azure preview portal:</source>
          <target state="new">The following screen show the worker node configuration on the Azure preview portal:</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>scaleout_1</source>
          <target state="new">scaleout_1</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>At the run time, you can also scale out a cluster without recreating one.</source>
          <target state="new">At the run time, you can also scale out a cluster without recreating one.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>This is shown below.</source>
          <target state="new">This is shown below.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>scaleout_1</source>
          <target state="new">scaleout_1</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>For more details on the different virtual machines supported by HDInsight, see <bpt id="p1">[</bpt>HDInsight pricing<ept id="p1">](http://azure.microsoft.com/pricing/details/hdinsight/)</ept>.</source>
          <target state="new">For more details on the different virtual machines supported by HDInsight, see <bpt id="p1">[</bpt>HDInsight pricing<ept id="p1">](http://azure.microsoft.com/pricing/details/hdinsight/)</ept>.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Enable Tez</source>
          <target state="new">Enable Tez</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Apache Tez<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept> is an alternative execution engine to the MapReduce engine:</source>
          <target state="new"><bpt id="p1">[</bpt>Apache Tez<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept> is an alternative execution engine to the MapReduce engine:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>tez_1</source>
          <target state="new">tez_1</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Tez is faster because:</source>
          <target state="new">Tez is faster because:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Execute Directed Acyclic Graph (DAG) as a single job in the MapReduce engine, the DAG that is expressed requires each set of mappers to be followed by one set of reducers.</source>
          <target state="new">Execute Directed Acyclic Graph (DAG) as a single job in the MapReduce engine, the DAG that is expressed requires each set of mappers to be followed by one set of reducers.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>This causes multiple MapReduce jobs to be spun off for each Hive query.</source>
          <target state="new">This causes multiple MapReduce jobs to be spun off for each Hive query.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Tez does not have such constraint and can process complex DAG as one job thus minimizing job startup overhead.</source>
          <target state="new">Tez does not have such constraint and can process complex DAG as one job thus minimizing job startup overhead.</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Avoids unnecessary writes<ept id="p1">**</ept> Due to multiple jobs being spun for the same Hive query in the MapReduce engine, the output of each job is written to HDFS for intermediate data.</source>
          <target state="new"><bpt id="p1">**</bpt>Avoids unnecessary writes<ept id="p1">**</ept> Due to multiple jobs being spun for the same Hive query in the MapReduce engine, the output of each job is written to HDFS for intermediate data.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Since Tez minimizes number of jobs for each Hive query it is able to avoid unnecessary write.</source>
          <target state="new">Since Tez minimizes number of jobs for each Hive query it is able to avoid unnecessary write.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Minimizes start-up delays<ept id="p1">**</ept> Tez is better able to minimize start-up delay by reducing the number of mappers it needs to start and also improving optimization throughout.</source>
          <target state="new"><bpt id="p1">**</bpt>Minimizes start-up delays<ept id="p1">**</ept> Tez is better able to minimize start-up delay by reducing the number of mappers it needs to start and also improving optimization throughout.</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Reuses containers<ept id="p1">**</ept> Whenever possible Tez is able to reuse containers to ensure that latency due to starting up containers is reduced.</source>
          <target state="new"><bpt id="p1">**</bpt>Reuses containers<ept id="p1">**</ept> Whenever possible Tez is able to reuse containers to ensure that latency due to starting up containers is reduced.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Continuous optimization techniques<ept id="p1">**</ept> Traditionally optimization was done during compilation phase.</source>
          <target state="new"><bpt id="p1">**</bpt>Continuous optimization techniques<ept id="p1">**</ept> Traditionally optimization was done during compilation phase.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>However more information about the inputs is available that allow for better optimization during runtime.</source>
          <target state="new">However more information about the inputs is available that allow for better optimization during runtime.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Tez uses continous optimization techniques that allows it to optimize the plan further into the runtime phase.</source>
          <target state="new">Tez uses continous optimization techniques that allows it to optimize the plan further into the runtime phase.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>For more details on these concepts, click <bpt id="p1">[</bpt>here<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept></source>
          <target state="new">For more details on these concepts, click <bpt id="p1">[</bpt>here<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept></target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>You can make any Hive query Tez enabled by prefixing the query with the setting below:</source>
          <target state="new">You can make any Hive query Tez enabled by prefixing the query with the setting below:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Tez must be enabled at the provision time.</source>
          <target state="new">Tez must be enabled at the provision time.</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>The following is a sample Azure PowerShell script for provisioning a Hadoop cluster with Tez enabled:</source>
          <target state="new">The following is a sample Azure PowerShell script for provisioning a Hadoop cluster with Tez enabled:</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Hive partitioning</source>
          <target state="new">Hive partitioning</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>I/O operation is the major performance bottleneck for running Hive queries.</source>
          <target state="new">I/O operation is the major performance bottleneck for running Hive queries.</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>The performance can be improved if the amount of data that needs to be read can be reduced.</source>
          <target state="new">The performance can be improved if the amount of data that needs to be read can be reduced.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>By default, Hive queries scan entire Hive tables.</source>
          <target state="new">By default, Hive queries scan entire Hive tables.</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>This is great for queries like table scans, however for queries that only need to scan a small amount of data (e.g. queries with filtering), this creates unnecessary overhead.</source>
          <target state="new">This is great for queries like table scans, however for queries that only need to scan a small amount of data (e.g. queries with filtering), this creates unnecessary overhead.</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Hive partitioning allows Hive queries to access only the necessary amount of data in Hive tables.</source>
          <target state="new">Hive partitioning allows Hive queries to access only the necessary amount of data in Hive tables.</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Hive partitioning is implemented by reorganizing the raw data into new directories with each partition having its own directory - where the partition is defined by the user.</source>
          <target state="new">Hive partitioning is implemented by reorganizing the raw data into new directories with each partition having its own directory - where the partition is defined by the user.</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>The following diagram illustrates partitioning a Hive table by the column <bpt id="p1">*</bpt>Year<ept id="p1">*</ept>.</source>
          <target state="new">The following diagram illustrates partitioning a Hive table by the column <bpt id="p1">*</bpt>Year<ept id="p1">*</ept>.</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>A new directory is created for each year.</source>
          <target state="new">A new directory is created for each year.</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>partitioning</source>
          <target state="new">partitioning</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Some partitioning considerations:</source>
          <target state="new">Some partitioning considerations:</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Do not under-partition<ept id="p1">**</ept> - Partitioning on columns with only a few values can cause very few partitions.</source>
          <target state="new"><bpt id="p1">**</bpt>Do not under-partition<ept id="p1">**</ept> - Partitioning on columns with only a few values can cause very few partitions.</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>For example, partitioning on gender will only create two partitions to be created (male and female), thus only reduce the latency by a maximum of half.</source>
          <target state="new">For example, partitioning on gender will only create two partitions to be created (male and female), thus only reduce the latency by a maximum of half.</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Do not over-partition<ept id="p1">**</ept> - On the other extreme, creating a partition on a column with a unique value (e.g. userid) will cause multiple partitions causing a lot of stress on the cluster namenode as it will have to handle the large amount of directories.</source>
          <target state="new"><bpt id="p1">**</bpt>Do not over-partition<ept id="p1">**</ept> - On the other extreme, creating a partition on a column with a unique value (e.g. userid) will cause multiple partitions causing a lot of stress on the cluster namenode as it will have to handle the large amount of directories.</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Avoid data skew<ept id="p1">**</ept> - Choose your partitioning key wisely so that all partitions are even size.</source>
          <target state="new"><bpt id="p1">**</bpt>Avoid data skew<ept id="p1">**</ept> - Choose your partitioning key wisely so that all partitions are even size.</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>An example is partitioning on <bpt id="p1">*</bpt>State<ept id="p1">*</ept> may cause the number of records under California to be almost 30x that of Vermont due to the difference in population.</source>
          <target state="new">An example is partitioning on <bpt id="p1">*</bpt>State<ept id="p1">*</ept> may cause the number of records under California to be almost 30x that of Vermont due to the difference in population.</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>To create a partition table, use the <bpt id="p1">*</bpt>Partitioned By<ept id="p1">*</ept> clause:</source>
          <target state="new">To create a partition table, use the <bpt id="p1">*</bpt>Partitioned By<ept id="p1">*</ept> clause:</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>Once the partitioned table is created, you can either create static partitioning or dynamic partitioning.</source>
          <target state="new">Once the partitioned table is created, you can either create static partitioning or dynamic partitioning.</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Static partitioning<ept id="p1">**</ept> means that you have already sharded data in the appropriate directories and you can ask Hive partitions manually based on the directory location.</source>
          <target state="new"><bpt id="p1">**</bpt>Static partitioning<ept id="p1">**</ept> means that you have already sharded data in the appropriate directories and you can ask Hive partitions manually based on the directory location.</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>This is shown in the code snippet below.</source>
          <target state="new">This is shown in the code snippet below.</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Dynamic partitioning<ept id="p1">**</ept> means that you want Hive to create partitions automatically for you.</source>
          <target state="new"><bpt id="p1">**</bpt>Dynamic partitioning<ept id="p1">**</ept> means that you want Hive to create partitions automatically for you.</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Since we have already created the partitioning table from the staging table, all we need to do is insert data to the partitioned table as shown below:</source>
          <target state="new">Since we have already created the partitioning table from the staging table, all we need to do is insert data to the partitioned table as shown below:</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>For more details, see <bpt id="p1">[</bpt>Partitioned Tables<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)</ept>.</source>
          <target state="new">For more details, see <bpt id="p1">[</bpt>Partitioned Tables<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)</ept>.</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Use the ORCFile format</source>
          <target state="new">Use the ORCFile format</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Hive supports different file formats.</source>
          <target state="new">Hive supports different file formats.</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new">For example:</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Text<ept id="p1">**</ept>: this is the default file format and works with most scenarios</source>
          <target state="new"><bpt id="p1">**</bpt>Text<ept id="p1">**</ept>: this is the default file format and works with most scenarios</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Avro<ept id="p1">**</ept>: works well for interoperability scenarios</source>
          <target state="new"><bpt id="p1">**</bpt>Avro<ept id="p1">**</ept>: works well for interoperability scenarios</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ORC/Parquet<ept id="p1">**</ept>: best suited for performance</source>
          <target state="new"><bpt id="p1">**</bpt>ORC/Parquet<ept id="p1">**</ept>: best suited for performance</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>ORC (Optimized Row Columnar) format is a highly efficient way to store Hive data.</source>
          <target state="new">ORC (Optimized Row Columnar) format is a highly efficient way to store Hive data.</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Compared to other formats, ORC has the following advantages:</source>
          <target state="new">Compared to other formats, ORC has the following advantages:</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>support for complex types including DateTime and complex and semi-structured types</source>
          <target state="new">support for complex types including DateTime and complex and semi-structured types</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>up to 70% compression</source>
          <target state="new">up to 70% compression</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>indexes every 10,000 rows which allow skipping rows</source>
          <target state="new">indexes every 10,000 rows which allow skipping rows</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>a significant drop in run-time execution</source>
          <target state="new">a significant drop in run-time execution</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>To enable ORC format, you first create a table with the clause <bpt id="p1">*</bpt>Stored as ORC<ept id="p1">*</ept>:</source>
          <target state="new">To enable ORC format, you first create a table with the clause <bpt id="p1">*</bpt>Stored as ORC<ept id="p1">*</ept>:</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>Next, you insert data to the ORC table from the staging table.</source>
          <target state="new">Next, you insert data to the ORC table from the staging table.</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>For example:</source>
          <target state="new">For example:</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>You can read more on the ORC format <bpt id="p1">[</bpt>here<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)</ept>.</source>
          <target state="new">You can read more on the ORC format <bpt id="p1">[</bpt>here<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)</ept>.</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Vectorization</source>
          <target state="new">Vectorization</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Vectorization allows Hive to process a batch of 1024 rows together instead of processing one row at a time.</source>
          <target state="new">Vectorization allows Hive to process a batch of 1024 rows together instead of processing one row at a time.</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>This means that simple operations are done faster because less internal code needs to run.</source>
          <target state="new">This means that simple operations are done faster because less internal code needs to run.</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>To enable vectorization prefix your Hive query with the following setting:</source>
          <target state="new">To enable vectorization prefix your Hive query with the following setting:</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Vectorized query execution<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Vectorized query execution<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)</ept>.</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Other optimization methods</source>
          <target state="new">Other optimization methods</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>There are more optimization methods that you can consider, for example:</source>
          <target state="new">There are more optimization methods that you can consider, for example:</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Hive bucketing:<ept id="p1">**</ept> a technique that allows to cluster or segment large sets of data to optimize query performance.</source>
          <target state="new"><bpt id="p1">**</bpt>Hive bucketing:<ept id="p1">**</ept> a technique that allows to cluster or segment large sets of data to optimize query performance.</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Join optimization:<ept id="p1">**</ept> optimization of Hive's query execution planning to improve the efficiency of joins and reduce the need for user hints.</source>
          <target state="new"><bpt id="p1">**</bpt>Join optimization:<ept id="p1">**</ept> optimization of Hive's query execution planning to improve the efficiency of joins and reduce the need for user hints.</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Join optimization<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Join optimization<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)</ept>.</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>increase Reducers</source>
          <target state="new">increase Reducers</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Next steps</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> Next steps</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>In this article, you have learned several common Hive query optimization methods.</source>
          <target state="new">In this article, you have learned several common Hive query optimization methods.</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>To learn more, see the following articles:</source>
          <target state="new">To learn more, see the following articles:</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Use Apache Hive in HDInsight</source>
          <target state="new">Use Apache Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Analyze flight delay data by using Hive in HDInsight</source>
          <target state="new">Analyze flight delay data by using Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Analyze Twitter data using Hive in HDInsight</source>
          <target state="new">Analyze Twitter data using Hive in HDInsight</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>Analyze sensor data using the Hive Query Console on Hadoop in HDInsight</source>
          <target state="new">Analyze sensor data using the Hive Query Console on Hadoop in HDInsight</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>Use Hive with HDInsight to analyze logs from websites</source>
          <target state="new">Use Hive with HDInsight to analyze logs from websites</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">90c4422438b92478f5f4ea828df168af12895bab</xliffext:olfilehash>
  </header>
</xliff>