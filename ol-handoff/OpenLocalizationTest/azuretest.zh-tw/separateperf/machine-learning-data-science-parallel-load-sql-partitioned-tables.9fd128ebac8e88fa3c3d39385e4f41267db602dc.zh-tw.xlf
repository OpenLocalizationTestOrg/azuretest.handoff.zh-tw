<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Parallel Bulk Data Import Using SQL Partition Tables | Microsoft Azure</source>
          <target state="new">Parallel Bulk Data Import Using SQL Partition Tables | Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Parallel Bulk Data Import Using SQL Partition Tables</source>
          <target state="new">Parallel Bulk Data Import Using SQL Partition Tables</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Parallel Bulk Data Import Using SQL Partition Tables</source>
          <target state="new">Parallel Bulk Data Import Using SQL Partition Tables</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>For big data loading/transfer to an SQL database, importing data to the SQL DB and subsequent queries can be improved by using <bpt id="p1">_</bpt>Partitioned Tables and Views<ept id="p1">_</ept>.</source>
          <target state="new">For big data loading/transfer to an SQL database, importing data to the SQL DB and subsequent queries can be improved by using <bpt id="p1">_</bpt>Partitioned Tables and Views<ept id="p1">_</ept>.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>This document describes how to build partitioned table(s) for fast parallel bluk importing of data to a SQL Server database.</source>
          <target state="new">This document describes how to build partitioned table(s) for fast parallel bluk importing of data to a SQL Server database.</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Create a new database and a set of filegroups</source>
          <target state="new">Create a new database and a set of filegroups</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Create a new database<ept id="p1">](https://technet.microsoft.com/library/ms176061.aspx)</ept> (if not exists)</source>
          <target state="new"><bpt id="p1">[</bpt>Create a new database<ept id="p1">](https://technet.microsoft.com/library/ms176061.aspx)</ept> (if not exists)</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Add database filegroups to the database which will hold the partitioned physical files</source>
          <target state="new">Add database filegroups to the database which will hold the partitioned physical files</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Note: This can be done with <bpt id="p1">[</bpt>CREATE DATABASE<ept id="p1">](https://technet.microsoft.com/library/ms176061.aspx)</ept> if new or <bpt id="p2">[</bpt>ALTER DATABASE<ept id="p2">](https://msdn.microsoft.com/library/bb522682.aspx)</ept> if database exists already</source>
          <target state="new">Note: This can be done with <bpt id="p1">[</bpt>CREATE DATABASE<ept id="p1">](https://technet.microsoft.com/library/ms176061.aspx)</ept> if new or <bpt id="p2">[</bpt>ALTER DATABASE<ept id="p2">](https://msdn.microsoft.com/library/bb522682.aspx)</ept> if database exists already</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Add one or more files (as needed) to each database filegroup</source>
          <target state="new">Add one or more files (as needed) to each database filegroup</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> Specify the target filegroup which will hold data for this partition and the physical database file name(s) where the filegroup data will be stored.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> Specify the target filegroup which will hold data for this partition and the physical database file name(s) where the filegroup data will be stored.</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>The following example creates a new database with three filegroups other than the primary and log groups, containing one physical file in each.</source>
          <target state="new">The following example creates a new database with three filegroups other than the primary and log groups, containing one physical file in each.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The database files are created in the default SQL Server Data folder, as configured in the SQL Server instance.</source>
          <target state="new">The database files are created in the default SQL Server Data folder, as configured in the SQL Server instance.</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>For more information about the default file locations, see <bpt id="p1">[</bpt>File Locations for Default and Named Instances of SQL Server<ept id="p1">](https://msdn.microsoft.com/library/ms143547.aspx)</ept>.</source>
          <target state="new">For more information about the default file locations, see <bpt id="p1">[</bpt>File Locations for Default and Named Instances of SQL Server<ept id="p1">](https://msdn.microsoft.com/library/ms143547.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Create a partitioned table</source>
          <target state="new">Create a partitioned table</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Create partitioned table(s) according to the data schema, mapped to the database filegroups created in the previous step.</source>
          <target state="new">Create partitioned table(s) according to the data schema, mapped to the database filegroups created in the previous step.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>When data is bulk imported to the partitioned table(s), records will be distributed among the filegroups according to a partition scheme, as described below.</source>
          <target state="new">When data is bulk imported to the partitioned table(s), records will be distributed among the filegroups according to a partition scheme, as described below.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>To create a partition table, you need to:</source>
          <target state="new">To create a partition table, you need to:</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Create a partition function<ept id="p1">](https://msdn.microsoft.com/library/ms187802.aspx)</ept> which defines the range of values/boundaries to be included in each individual partition table, e.g., to limit partitions by month(some\_datetime\_field) in the year 2013:</source>
          <target state="new"><bpt id="p1">[</bpt>Create a partition function<ept id="p1">](https://msdn.microsoft.com/library/ms187802.aspx)</ept> which defines the range of values/boundaries to be included in each individual partition table, e.g., to limit partitions by month(some\_datetime\_field) in the year 2013:</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Create a partition scheme<ept id="p1">](https://msdn.microsoft.com/library/ms179854.aspx)</ept> which maps each partition range in the partition function to a physical filegroup, e.g.:</source>
          <target state="new"><bpt id="p1">[</bpt>Create a partition scheme<ept id="p1">](https://msdn.microsoft.com/library/ms179854.aspx)</ept> which maps each partition range in the partition function to a physical filegroup, e.g.:</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Tip: To verify the ranges in effect in each partition according to the function/scheme, run the following query:</source>
          <target state="new">Tip: To verify the ranges in effect in each partition according to the function/scheme, run the following query:</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Create partitioned table<ept id="p1">](https://msdn.microsoft.com/library/ms174979.aspx)</ept>(s) according to your data schema, and specify the partition scheme and constraint field used to partition the table, e.g.:</source>
          <target state="new"><bpt id="p1">[</bpt>Create partitioned table<ept id="p1">](https://msdn.microsoft.com/library/ms174979.aspx)</ept>(s) according to your data schema, and specify the partition scheme and constraint field used to partition the table, e.g.:</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>For more information, see <bpt id="p1">[</bpt>Create Partitioned Tables and Indexes<ept id="p1">](https://msdn.microsoft.com/library/ms188730.aspx)</ept>.</source>
          <target state="new">For more information, see <bpt id="p1">[</bpt>Create Partitioned Tables and Indexes<ept id="p1">](https://msdn.microsoft.com/library/ms188730.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Bulk import the data for each individual partition table</source>
          <target state="new">Bulk import the data for each individual partition table</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>You may use BCP, BULK INSERT, or other methods such as <bpt id="p1">[</bpt>SQL Server Migration Wizard<ept id="p1">](http://sqlazuremw.codeplex.com/)</ept>.</source>
          <target state="new">You may use BCP, BULK INSERT, or other methods such as <bpt id="p1">[</bpt>SQL Server Migration Wizard<ept id="p1">](http://sqlazuremw.codeplex.com/)</ept>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The example provided uses the BCP method.</source>
          <target state="new">The example provided uses the BCP method.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Alter the database<ept id="p1">](https://msdn.microsoft.com/library/bb522682.aspx)</ept> to change transaction logging scheme to BULK_LOGGED to minimize overhead of logging, e.g.:</source>
          <target state="new"><bpt id="p1">[</bpt>Alter the database<ept id="p1">](https://msdn.microsoft.com/library/bb522682.aspx)</ept> to change transaction logging scheme to BULK_LOGGED to minimize overhead of logging, e.g.:</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>To expedite data loading, launch the bulk import operations in parallel.</source>
          <target state="new">To expedite data loading, launch the bulk import operations in parallel.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>For tips on expediting bulk importing of big data into SQL Server databases, see <bpt id="p1">[</bpt>Load 1TB in less than 1 hour<ept id="p1">](http://blogs.msdn.com/b/sqlcat/archive/2006/05/19/602142.aspx)</ept>.</source>
          <target state="new">For tips on expediting bulk importing of big data into SQL Server databases, see <bpt id="p1">[</bpt>Load 1TB in less than 1 hour<ept id="p1">](http://blogs.msdn.com/b/sqlcat/archive/2006/05/19/602142.aspx)</ept>.</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>The following PowerShell script is an example of parallel data loading using BCP.</source>
          <target state="new">The following PowerShell script is an example of parallel data loading using BCP.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Create indexes to optimize joins and query performance</source>
          <target state="new">Create indexes to optimize joins and query performance</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>If you will extract data for modeling from multiple tables, create indexes on the join keys to improve the join performance.</source>
          <target state="new">If you will extract data for modeling from multiple tables, create indexes on the join keys to improve the join performance.</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Create indexes<ept id="p1">](https://technet.microsoft.com/library/ms188783.aspx)</ept> (clustered or non-clustered) targeting the same filegroup for each partition, for e.g.:</source>
          <target state="new"><bpt id="p1">[</bpt>Create indexes<ept id="p1">](https://technet.microsoft.com/library/ms188783.aspx)</ept> (clustered or non-clustered) targeting the same filegroup for each partition, for e.g.:</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>or,</source>
          <target state="new">or,</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph> You may choose to create the indexes before bulk importing the data.</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph> You may choose to create the indexes before bulk importing the data.</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Index creation before bulk importing will slow down the data loading.</source>
          <target state="new">Index creation before bulk importing will slow down the data loading.</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Advanced Analytics Process and Technology in Action Example</source>
          <target state="new">Advanced Analytics Process and Technology in Action Example</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>For an end-to-end walkthrough example using the Advanced Analytics Process and Technology (ADAPT) with a public dataset, see <bpt id="p1">[</bpt>Advanced Analytics Process and Technology in Action: using SQL Server<ept id="p1">](machine-learning-data-science-process-sql-walkthrough.md)</ept>.</source>
          <target state="new">For an end-to-end walkthrough example using the Advanced Analytics Process and Technology (ADAPT) with a public dataset, see <bpt id="p1">[</bpt>Advanced Analytics Process and Technology in Action: using SQL Server<ept id="p1">](machine-learning-data-science-process-sql-walkthrough.md)</ept>.</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">46dfa5dce4f456e23700d547f6428a252a6ec734</xliffext:olfilehash>
  </header>
</xliff>