<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="zh-tw">
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure</source>
          <target state="new">Use Resource Manager to allocate resources to the Apache Spark cluster in HDInsight| Microsoft Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance.</source>
          <target state="new">Learn how to use the Resource Manager for Spark clusters on HDInsight for better performance.</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Manage resources for the Apache Spark cluster in Azure HDInsight</source>
          <target state="new">Manage resources for the Apache Spark cluster in Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Resource manager is a component of the Spark cluster dashboard that enables you to manage resources such as cores and RAM used by each application running on the cluster.</source>
          <target state="new">Resource manager is a component of the Spark cluster dashboard that enables you to manage resources such as cores and RAM used by each application running on the cluster.</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="launchrm"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I launch the Resource Manager?</source>
          <target state="new"><ph id="ph1">&lt;a name="launchrm"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I launch the Resource Manager?</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</source>
          <target state="new">From the <bpt id="p1">[</bpt>Azure Preview Portal<ept id="p1">](https://ms.portal.azure.com/)</ept>, from the startboard, click the tile for your Spark cluster (if you pinned it to the startboard).</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>You can also navigate to your cluster under <bpt id="p1">**</bpt>Browse All<ept id="p1">**</ept> &gt; <bpt id="p2">**</bpt>HDInsight Clusters<ept id="p2">**</ept>.</source>
          <target state="new">You can also navigate to your cluster under <bpt id="p1">**</bpt>Browse All<ept id="p1">**</ept> &gt; <bpt id="p2">**</bpt>HDInsight Clusters<ept id="p2">**</ept>.</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>From the Spark cluster blade, click <bpt id="p1">**</bpt>Dashboard<ept id="p1">**</ept>.</source>
          <target state="new">From the Spark cluster blade, click <bpt id="p1">**</bpt>Dashboard<ept id="p1">**</ept>.</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>When prompted, enter the admin credentials for the Spark cluster.</source>
          <target state="new">When prompted, enter the admin credentials for the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Launch Resource Manager</source>
          <target state="new">Launch Resource Manager</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="scenariosrm"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I fix these issues using the Resource Manager?</source>
          <target state="new"><ph id="ph1">&lt;a name="scenariosrm"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>How do I fix these issues using the Resource Manager?</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Here are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Resource Manager.</source>
          <target state="new">Here are some common scenarios that you might run into with your Spark cluster, and the instructions on how to address those using the Resource Manager.</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>My Spark cluster on HDInsight is slow</source>
          <target state="new">My Spark cluster on HDInsight is slow</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Apache Spark cluster in HDInsight is designed for multi-tenancy, so resources are split across multiple components (notebooks, job server, etc).</source>
          <target state="new">Apache Spark cluster in HDInsight is designed for multi-tenancy, so resources are split across multiple components (notebooks, job server, etc).</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>This allows you to use all Spark components concurrently without worrying about any component not able to get resources to run, but each component will be slower since resources are fragmented.</source>
          <target state="new">This allows you to use all Spark components concurrently without worrying about any component not able to get resources to run, but each component will be slower since resources are fragmented.</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>This can be adjusted based on your needs.</source>
          <target state="new">This can be adjusted based on your needs.</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>I only use the Jupyter notebook with the Spark cluster.</source>
          <target state="new">I only use the Jupyter notebook with the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>How can I allocate all resources to it?</source>
          <target state="new">How can I allocate all resources to it?</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>From the <bpt id="p1">**</bpt>Spark Dashboard<ept id="p1">**</ept>, click the <bpt id="p2">**</bpt>Spark UI<ept id="p2">**</ept> tab to find out the maximum number of cores and the maximum RAM that you can allocate to the applications.</source>
          <target state="new">From the <bpt id="p1">**</bpt>Spark Dashboard<ept id="p1">**</ept>, click the <bpt id="p2">**</bpt>Spark UI<ept id="p2">**</ept> tab to find out the maximum number of cores and the maximum RAM that you can allocate to the applications.</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Resource allocation</source>
          <target state="new">Resource allocation</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Going by the screen capture above, the maximum cores that you can allocate is 7 (total 8 cores of which 1 is in use), and the maximum RAM that you can allocate is 9GB (total 12GB RAM, of which 2GB must be set aside for system use and 1GB that is in use by other applications).</source>
          <target state="new">Going by the screen capture above, the maximum cores that you can allocate is 7 (total 8 cores of which 1 is in use), and the maximum RAM that you can allocate is 9GB (total 12GB RAM, of which 2GB must be set aside for system use and 1GB that is in use by other applications).</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>You should also factor any applications that are running.</source>
          <target state="new">You should also factor any applications that are running.</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>You can look at the running applications from the <bpt id="p1">**</bpt>Spark UI<ept id="p1">**</ept> tab.</source>
          <target state="new">You can look at the running applications from the <bpt id="p1">**</bpt>Spark UI<ept id="p1">**</ept> tab.</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Running applications</source>
          <target state="new">Running applications</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>From the HDInsight Spark Dashboard, click the <bpt id="p1">**</bpt>Resource Manager<ept id="p1">**</ept> tab and specify the values for <bpt id="p2">**</bpt>Default application core count<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Default executor memory per worker node<ept id="p3">**</ept>.</source>
          <target state="new">From the HDInsight Spark Dashboard, click the <bpt id="p1">**</bpt>Resource Manager<ept id="p1">**</ept> tab and specify the values for <bpt id="p2">**</bpt>Default application core count<ept id="p2">**</ept> and <bpt id="p3">**</bpt>Default executor memory per worker node<ept id="p3">**</ept>.</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Set other properties to 0.</source>
          <target state="new">Set other properties to 0.</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Resource allocation</source>
          <target state="new">Resource allocation</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>I do not use BI tools with the Spark cluster.</source>
          <target state="new">I do not use BI tools with the Spark cluster.</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>How can I take resources back?</source>
          <target state="new">How can I take resources back?</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Specify thrift server core Count and thrift Server executor memory as 0.</source>
          <target state="new">Specify thrift server core Count and thrift Server executor memory as 0.</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>With no core or memory allocated, the thrift server will go into a <bpt id="p1">**</bpt>WAITING<ept id="p1">**</ept> state.</source>
          <target state="new">With no core or memory allocated, the thrift server will go into a <bpt id="p1">**</bpt>WAITING<ept id="p1">**</ept> state.</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Resource allocation</source>
          <target state="new">Resource allocation</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="seealso"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>See also</source>
          <target state="new"><ph id="ph1">&lt;a name="seealso"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>See also</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Overview: Apache Spark on Azure HDInsight</source>
          <target state="new">Overview: Apache Spark on Azure HDInsight</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Provision a Spark on HDInsight cluster</source>
          <target state="new">Provision a Spark on HDInsight cluster</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Perform interactive data analysis using Spark in HDInsight with BI tools</source>
          <target state="new">Perform interactive data analysis using Spark in HDInsight with BI tools</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Use Spark in HDInsight for building machine learning applications</source>
          <target state="new">Use Spark in HDInsight for building machine learning applications</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Use Spark in HDInsight for building real-time streaming applications</source>
          <target state="new">Use Spark in HDInsight for building real-time streaming applications</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>test</source>
          <target state="new">test</target>
        </trans-unit>
      </group>
    </body>
  </file>
  <header xmlns="">
    <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">
    </xliffext:oltranslationpriority>
    <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1f952a3e957dc613de1b55594e1e32f44bd4651c</xliffext:olfilehash>
  </header>
</xliff>